{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from preprocessing import preprocess\n",
    "from windowfy import windowfy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%\n",
      "Oversampling train users\n",
      "\n",
      "Finished windowfying\n"
     ]
    }
   ],
   "source": [
    "windowfy(10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# methods\n",
    "\n",
    "def windowfy_sliding_training(users, window_size, pos_param_range_max=-1, neg_param_range_max=-1):\n",
    "    users_windows = []\n",
    "    for user, user_writings in users.items():     \n",
    "        if user_writings[0][\"g_truth\"] == 1:\n",
    "            param_range_max = pos_param_range_max\n",
    "        else:\n",
    "            param_range_max = neg_param_range_max\n",
    "        count = 0\n",
    "        if param_range_max < 0 or param_range_max > len(user_writings):\n",
    "            range_max = len(user_writings)\n",
    "            writings = user_writings.copy()\n",
    "        else:\n",
    "            range_max = param_range_max\n",
    "            writings = user_writings.copy()[:range_max]\n",
    "        for i in range(0, range_max):  # TODO parametrizar esto\n",
    "            #if i < window_size and len(writings) > (i + 1):\n",
    "            #    window = writings[:i + 1]  # rellenamos mientras \"no nos llegan los demas mensajes\"\n",
    "            if len(writings) < (i + window_size):\n",
    "                window = writings[i:range_max]  # TODO comprobar este range_max\n",
    "                continue\n",
    "            else:\n",
    "                window = writings[i:i + window_size]\n",
    "\n",
    "            if len(window) == 0:\n",
    "                pass\n",
    "                #print(\"Window: {}, i: {}, len(writings): {}\".format(window, i, len(writings)))\n",
    "\n",
    "            joined_window = join_window_elements(window)\n",
    "            users_windows.append(joined_window)\n",
    "            count += 1\n",
    "\n",
    "    logger(\"Length of train data after windowfying: {}\".format(len(users_windows)))\n",
    "    return users_windows\n",
    "\n",
    "\n",
    "def windowfy_sliding_testing(users, window_size, param_range_max=-1):\n",
    "    users_windows = []\n",
    "    for user, writings in users.items():\n",
    "        count = 0\n",
    "        if param_range_max < 0 or param_range_max > len(writings):\n",
    "            range_max = len(writings)\n",
    "        else:\n",
    "            range_max = param_range_max\n",
    "        for i in range(0, range_max):  # TODO parametrizar esto\n",
    "            if i < window_size and len(writings) > (i+1):\n",
    "                window = writings[:i+1] # rellenamos mientras \"no nos llegan los demas mensajes\" # todo cambiar esto\n",
    "            elif len(writings) < (i + window_size):\n",
    "                #window = writings[i:range_max]  # TODO comprobar este range_max\n",
    "                window = []\n",
    "            else:\n",
    "                window = writings[i:i + window_size]\n",
    "\n",
    "            if len(window) == 0:\n",
    "                pass\n",
    "                #print(\"Window: {}, i: {}, len(writings): {}\".format(window, i, len(writings)))\n",
    "            else:\n",
    "                joined_window = join_window_elements(window)\n",
    "                users_windows.append(joined_window)\n",
    "                count += 1\n",
    "\n",
    "    return users_windows\n",
    "\n",
    "\n",
    "def join_all_elements(users):\n",
    "    joined_writings = []\n",
    "    for user, writings in users.items():\n",
    "        joined_writings.append(join_window_elements(writings))\n",
    "\n",
    "    return joined_writings\n",
    "\n",
    "\n",
    "def join_window_elements(window: list) -> dict:\n",
    "    joint_window = {}\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "    for key in window[0].keys():\n",
    "        key_list = [message[key] for message in window]\n",
    "        if type(key_list[0]) is list:\n",
    "            joint_window[key] = flatten(key_list)\n",
    "        elif key == 'user':\n",
    "            joint_window[key] = key_list[0]\n",
    "        elif key == 'g_truth':\n",
    "            joint_window[key] = key_list[0]\n",
    "        elif key == 'date':\n",
    "            joint_window[key] = key_list\n",
    "        elif key == 'sequence':\n",
    "            joint_window[key] = key_list[-1]\n",
    "        else:\n",
    "            joint_window[key] = ' .'.join(key_list)\n",
    "\n",
    "    return joint_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data after windowfying: 167374\n"
     ]
    }
   ],
   "source": [
    "train_window = windowfy_sliding_training(train_users, 10)\n",
    "test_window = windowfy_sliding_testing(test_users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_window_frame = pd.DataFrame(train_window)\n",
    "test_window_frame = pd.DataFrame(test_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.keys of                                                      text         user  \\\n",
       "0       I'm a little late for this, but I agree. I tho...     subject0   \n",
       "1       Regular Monster was ruined for me. I was drink...     subject0   \n",
       "2       Can you elaborate on the prostitution? .Most f...     subject0   \n",
       "3       Most free porn sites (Pornhub, Redtube) are ow...     subject0   \n",
       "4       Why? You can not use the site if you feel \"exp...     subject0   \n",
       "...                                                   ...          ...   \n",
       "167369  u/sayswut .I wasn't even subscribed, but got b...  subject9961   \n",
       "167370  I wasn't even subscribed, but got banned.. I j...  subject9961   \n",
       "167371  You ain't fooling anyone you muppet .banana sl...  subject9961   \n",
       "167372  banana slugs  lt; Other UC Mascots .Nice .Can ...  subject9961   \n",
       "167373  Nice .Can confirm. At Merced .Alexa play Despa...  subject9961   \n",
       "\n",
       "        g_truth                                         clean_text  \\\n",
       "0             0  i am a little late for this but i agree i thou...   \n",
       "1             0  regular monster was ruined for me i was drinki...   \n",
       "2             0  can you elaborate on the prostitution  .most f...   \n",
       "3             0  most free porn sites pornhub redtube are owned...   \n",
       "4             0  why you can not use the site if you feel explo...   \n",
       "...         ...                                                ...   \n",
       "167369        0  u sayswut .i was not even subscribed but got b...   \n",
       "167370        0  i was not even subscribed but got banned i jus...   \n",
       "167371        0  you ai not fooling anyone you muppet .banana s...   \n",
       "167372        0  banana slugs lt other uc mascots .nice .can co...   \n",
       "167373        0  nice .can confirm at merced .alexa play despac...   \n",
       "\n",
       "                                                   tokens  \\\n",
       "0       [little, late, agree, thought, saying, bad, ov...   \n",
       "1       [regular, monster, ruined, drinking, friend, m...   \n",
       "2       [elaborate, prostitution, free, porn, sites, p...   \n",
       "3       [free, porn, sites, pornhub, redtube, owned, c...   \n",
       "4       [use, site, feel, exploited, ask, donate, keep...   \n",
       "...                                                   ...   \n",
       "167369  [u, sayswut, even, subscribed, got, banned, po...   \n",
       "167370  [even, subscribed, got, banned, posted, meta, ...   \n",
       "167371  [ai, fooling, anyone, muppet, banana, slugs, l...   \n",
       "167372  [banana, slugs, lt, uc, mascots, nice, confirm...   \n",
       "167373  [nice, confirm, merced, alexa, play, despacito...   \n",
       "\n",
       "                                                 pos_tags  \\\n",
       "0       [(little, JJ), (late, JJ), (agree, NN), (thoug...   \n",
       "1       [(regular, JJ), (monster, NN), (ruined, VBD), ...   \n",
       "2       [(elaborate, JJ), (prostitution, NN), (free, J...   \n",
       "3       [(free, JJ), (porn, NN), (sites, NNS), (pornhu...   \n",
       "4       [(use, NN), (site, NN), (feel, NN), (exploited...   \n",
       "...                                                   ...   \n",
       "167369  [(u, JJ), (sayswut, NN), (even, RB), (subscrib...   \n",
       "167370  [(even, RB), (subscribed, VBD), (got, VBD), (b...   \n",
       "167371  [(ai, NN), (fooling, VBG), (anyone, NN), (mupp...   \n",
       "167372  [(banana, NN), (slugs, NNS), (lt, VBP), (uc, J...   \n",
       "167373  [(nice, JJ), (confirm, NN), (merced, VBD), (al...   \n",
       "\n",
       "                                                    stems  \n",
       "0       [littl, late, agre, thought, say, bad, overal,...  \n",
       "1       [regular, monster, ruin, drink, friend, mine, ...  \n",
       "2       [elabor, prostitut, free, porn, site, pornhub,...  \n",
       "3       [free, porn, site, pornhub, redtub, own, compa...  \n",
       "4       [use, site, feel, exploit, ask, donat, keep, f...  \n",
       "...                                                   ...  \n",
       "167369  [u, sayswut, even, subscrib, got, ban, post, m...  \n",
       "167370  [even, subscrib, got, ban, post, meta, shitpos...  \n",
       "167371  [ai, fool, anyon, muppet, banana, slug, lt, uc...  \n",
       "167372  [banana, slug, lt, uc, mascot, nice, confirm, ...  \n",
       "167373  [nice, confirm, merc, alexa, play, despacito, ...  \n",
       "\n",
       "[167374 rows x 7 columns]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_frame.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_window_frame[\"clean_text\"] \n",
    "X_test = test_window_frame[\"clean_text\"]\n",
    "y_train = np.array(train_window_frame[\"g_truth\"])\n",
    "y_test = np.array(test_window_frame[\"g_truth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(\"pickles\", \"X_train.pkl\", X_train)\n",
    "save_pickle(\"pickles\", \"X_test.pkl\", X_test)\n",
    "save_pickle(\"pickles\", \"y_train.pkl\", y_train)\n",
    "save_pickle(\"pickles\", \"y_test.pkl\", y_test)\n",
    "save_pickle(\"pickles\", \"train_window.pkl\", train_window_frame)\n",
    "save_pickle(\"pickles\", \"test_window.pkl\", test_window_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
