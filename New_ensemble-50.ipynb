{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from preprocessing import preprocess\n",
    "from windowfy import windowfy\n",
    "from featurizing import featurize\n",
    "from tfidf_featurizer import combine_features, tfidf_featurize\n",
    "from training import train, do_ensemble, do_train\n",
    "from training_traditional import train_and_evaluate\n",
    "from eval_erisk import evaluate, ensemble_vote\n",
    "from IPython.display import display, Markdown\n",
    "from itertools import product\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized numpy random and tensorflow random seed at 42\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "tensorflow.random.set_seed(42) \n",
    "logger(\"Initialized numpy random and tensorflow random seed at 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With max_size = 10 and new data, sample_weights=10, oversample False, include_new_data=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%Data size: 5424\n",
      "\n",
      "Finished windowfying\n",
      "Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=10, include_feats=['first_prons', 'sentiment', 'nssi']\n",
      "Initialized numpy random and tensorflow random seed at 42\n",
      "Data size: 5424, 5424\n",
      "Data size: 4650, 4650\n",
      "Calculating first prons\n",
      "Calculating sentiment\n",
      "Calculating NSSI words\n",
      "Calculating first prons\n",
      "Calculating sentiment\n",
      "Calculating NSSI words\n",
      "Is the combined different from tfidf: False\n"
     ]
    }
   ],
   "source": [
    "train_users, y_train, test_users, y_test, train_samples, X_train, X_test = windowfy(window_size=10, max_size=50, sample_weights_size=20, is_oversample=False, include_new_data=True)\n",
    "feats_train, feats_test = featurize(calculate_feats=True, include_feats=[\"first_prons\",\"sentiment\",\"nssi\"], \n",
    "                       train_users=train_users, test_users=test_users, discretize=False)\n",
    "tfidf_train, tfidf_test = tfidf_featurize(train_users, test_users, max_features=50000)\n",
    "\n",
    "feats_train_comb, feats_test_comb = combine_features([tfidf_train, feats_train], [tfidf_test, feats_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traditional classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82      3602\n",
      "           1       0.43      0.61      0.51      1048\n",
      "\n",
      "    accuracy                           0.73      4650\n",
      "   macro avg       0.65      0.69      0.66      4650\n",
      "weighted avg       0.77      0.73      0.75      4650\n",
      "\n",
      "[[2771  831]\n",
      " [ 411  637]]\n"
     ]
    }
   ],
   "source": [
    "y_pred, classifier = train_and_evaluate(feats_train_comb, y_train, feats_test_comb, y_test, train_samples, \n",
    "                                        classifier_name=\"svm\", strategy=\"weights\")\n",
    "eval_resul = evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_preds[\"svm\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'tocsc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a3b9ab700c38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m y_pred, classifier = train_and_evaluate(feats_train_comb_minmax, y_train, feats_test_comb_minmax, y_test, train_samples, \n\u001b[0;32m---> 10\u001b[0;31m                                         classifier_name=\"bayes\", strategy=\"weights\")\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0meval_resul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bayes\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training_traditional.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(X_train, y_train, X_test, y_test, train_weights, classifier_name, strategy)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"svm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training_traditional.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(x_train, y_train, train_weights, classifier_name, strategy)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#if feats != 'text':\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocsc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# if train_feats.isnull().values.any():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'tocsc'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "feats_train_comb_minimax = feats_train_comb.tocsc().toarray()\n",
    "feats_test_comb_minimax = feats_test_comb.tocsc().toarray()\n",
    "scaler.fit(feats_train_comb_minimax)\n",
    "feats_train_comb_minmax = scaler.transform(feats_train_comb_minimax)\n",
    "feats_test_comb_minmax = scaler.transform(feats_test_comb_minimax)\n",
    "\n",
    "y_pred, classifier = train_and_evaluate(feats_train_comb_minmax, y_train, feats_test_comb_minmax, y_test, train_samples, \n",
    "                                        classifier_name=\"bayes\", strategy=\"weights\")\n",
    "eval_resul = evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_preds[\"bayes\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning classifiers\n",
    "batch_size=32\n",
    "model_name = \"cnn_model\"\n",
    "iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.9795 - tp: 687.0000 - fp: 1008.0000 - tn: 2594.0000 - fn: 361.0000 - accuracy: 0.7056 - precision: 0.4053 - recall: 0.6555 - f1_metric: 0.3586\n",
      "Test Score: 0.97948157787323\n",
      "Test Accuracy: 687.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79      3602\n",
      "           1       0.41      0.66      0.50      1048\n",
      "\n",
      "    accuracy                           0.71      4650\n",
      "   macro avg       0.64      0.69      0.65      4650\n",
      "weighted avg       0.77      0.71      0.73      4650\n",
      "\n",
      "[[2594 1008]\n",
      " [ 361  687]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.38425925925925924, 'recall': 0.7980769230769231, 'F1': 0.5187499999999999, 'ERDE_5': 0.32275047412298585, 'ERDE_50': 0.12694979572903334, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4985290010070824}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.6325 - tp: 476.0000 - fp: 375.0000 - tn: 3227.0000 - fn: 572.0000 - accuracy: 0.7963 - precision: 0.5593 - recall: 0.4542 - f1_metric: 0.2879\n",
      "Test Score: 0.6324586272239685\n",
      "Test Accuracy: 476.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87      3602\n",
      "           1       0.56      0.45      0.50      1048\n",
      "\n",
      "    accuracy                           0.80      4650\n",
      "   macro avg       0.70      0.68      0.69      4650\n",
      "weighted avg       0.78      0.80      0.79      4650\n",
      "\n",
      "[[3227  375]\n",
      " [ 572  476]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.5583333333333333, 'recall': 0.6442307692307693, 'F1': 0.5982142857142857, 'ERDE_5': 0.27635016774959276, 'ERDE_50': 0.11827596420927076, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5748957498704738}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.8425 - tp: 655.0000 - fp: 813.0000 - tn: 2789.0000 - fn: 393.0000 - accuracy: 0.7406 - precision: 0.4462 - recall: 0.6250 - f1_metric: 0.3526\n",
      "Test Score: 0.8425118923187256\n",
      "Test Accuracy: 655.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.77      0.82      3602\n",
      "           1       0.45      0.62      0.52      1048\n",
      "\n",
      "    accuracy                           0.74      4650\n",
      "   macro avg       0.66      0.70      0.67      4650\n",
      "weighted avg       0.78      0.74      0.75      4650\n",
      "\n",
      "[[2789  813]\n",
      " [ 393  655]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.39603960396039606, 'recall': 0.7692307692307693, 'F1': 0.5228758169934641, 'ERDE_5': 0.31636096229367977, 'ERDE_50': 0.12764839685014862, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5024939926679782}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 92.0393 - tp: 1048.0000 - fp: 3602.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2254 - precision: 0.2254 - recall: 1.0000 - f1_metric: 0.3146\n",
      "Test Score: 92.03934478759766\n",
      "Test Accuracy: 1048.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3602\n",
      "           1       0.23      1.00      0.37      1048\n",
      "\n",
      "    accuracy                           0.23      4650\n",
      "   macro avg       0.11      0.50      0.18      4650\n",
      "weighted avg       0.05      0.23      0.08      4650\n",
      "\n",
      "[[   0 3602]\n",
      " [   0 1048]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.6319 - tp: 534.0000 - fp: 463.0000 - tn: 3139.0000 - fn: 514.0000 - accuracy: 0.7899 - precision: 0.5356 - recall: 0.5095 - f1_metric: 0.3210\n",
      "Test Score: 0.6318933963775635\n",
      "Test Accuracy: 534.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      3602\n",
      "           1       0.54      0.51      0.52      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.70      0.69      0.69      4650\n",
      "weighted avg       0.79      0.79      0.79      4650\n",
      "\n",
      "[[3139  463]\n",
      " [ 514  534]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.5285714285714286, 'recall': 0.7115384615384616, 'F1': 0.6065573770491803, 'ERDE_5': 0.2838774569434117, 'ERDE_50': 0.10928357057827473, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5829136255109477}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.6895 - tp: 603.0000 - fp: 736.0000 - tn: 2866.0000 - fn: 445.0000 - accuracy: 0.7460 - precision: 0.4503 - recall: 0.5754 - f1_metric: 0.3432\n",
      "Test Score: 0.6894919276237488\n",
      "Test Accuracy: 603.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83      3602\n",
      "           1       0.45      0.58      0.51      1048\n",
      "\n",
      "    accuracy                           0.75      4650\n",
      "   macro avg       0.66      0.69      0.67      4650\n",
      "weighted avg       0.77      0.75      0.76      4650\n",
      "\n",
      "[[2866  736]\n",
      " [ 445  603]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.39069767441860465, 'recall': 0.8076923076923077, 'F1': 0.5266457680250783, 'ERDE_5': 0.3216192468484715, 'ERDE_50': 0.1234232572696458, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5061169901072772}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.6131 - tp: 458.0000 - fp: 438.0000 - tn: 3164.0000 - fn: 590.0000 - accuracy: 0.7789 - precision: 0.5112 - recall: 0.4370 - f1_metric: 0.2839\n",
      "Test Score: 0.6131290197372437\n",
      "Test Accuracy: 458.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      3602\n",
      "           1       0.51      0.44      0.47      1048\n",
      "\n",
      "    accuracy                           0.78      4650\n",
      "   macro avg       0.68      0.66      0.67      4650\n",
      "weighted avg       0.77      0.78      0.77      4650\n",
      "\n",
      "[[3164  438]\n",
      " [ 590  458]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.5153846153846153, 'recall': 0.6442307692307693, 'F1': 0.5726495726495727, 'ERDE_5': 0.282161478801977, 'ERDE_50': 0.12408832553694715, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5503275554315648}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 2.8845 - tp: 888.0000 - fp: 3207.0000 - tn: 395.0000 - fn: 160.0000 - accuracy: 0.2759 - precision: 0.2168 - recall: 0.8473 - f1_metric: 0.2934\n",
      "Test Score: 2.8845198154449463\n",
      "Test Accuracy: 888.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.11      0.19      3602\n",
      "           1       0.22      0.85      0.35      1048\n",
      "\n",
      "    accuracy                           0.28      4650\n",
      "   macro avg       0.46      0.48      0.27      4650\n",
      "weighted avg       0.60      0.28      0.23      4650\n",
      "\n",
      "[[ 395 3207]\n",
      " [ 160  888]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.24378109452736318, 'recall': 0.9423076923076923, 'F1': 0.38735177865612647, 'ERDE_5': 0.42205857262059376, 'ERDE_50': 0.19088018152451774, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.3722527137383234}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.8511 - tp: 693.0000 - fp: 1005.0000 - tn: 2597.0000 - fn: 355.0000 - accuracy: 0.7075 - precision: 0.4081 - recall: 0.6613 - f1_metric: 0.3611\n",
      "Test Score: 0.85109943151474\n",
      "Test Accuracy: 693.0\n",
      "146/146 [==============================] - 1s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.72      0.79      3602\n",
      "           1       0.41      0.66      0.50      1048\n",
      "\n",
      "    accuracy                           0.71      4650\n",
      "   macro avg       0.64      0.69      0.65      4650\n",
      "weighted avg       0.77      0.71      0.73      4650\n",
      "\n",
      "[[2597 1005]\n",
      " [ 355  693]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.38565022421524664, 'recall': 0.8269230769230769, 'F1': 0.5259938837920489, 'ERDE_5': 0.3250633317647085, 'ERDE_50': 0.12218254167854598, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5054905164774662}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.6975 - tp: 592.0000 - fp: 763.0000 - tn: 2839.0000 - fn: 456.0000 - accuracy: 0.7378 - precision: 0.4369 - recall: 0.5649 - f1_metric: 0.3271\n",
      "Test Score: 0.6975284814834595\n",
      "Test Accuracy: 592.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      3602\n",
      "           1       0.44      0.56      0.49      1048\n",
      "\n",
      "    accuracy                           0.74      4650\n",
      "   macro avg       0.65      0.68      0.66      4650\n",
      "weighted avg       0.77      0.74      0.75      4650\n",
      "\n",
      "[[2839  763]\n",
      " [ 456  592]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.40625, 'recall': 0.75, 'F1': 0.527027027027027, 'ERDE_5': 0.3117438240419436, 'ERDE_50': 0.12772664017571508, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5064833875422003}\n"
     ]
    }
   ],
   "source": [
    "model_resuls = {}\n",
    "for i in range(0, iterations):\n",
    "    y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "                 shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "                 X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "    eval_resul = evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "    model_resuls[eval_resul['latency_weighted_f1']] = y_pred\n",
    "\n",
    "y_preds[model_name] = model_resuls[max(model_resuls.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning classifiers\n",
    "batch_size=32\n",
    "model_name = \"lstm_model_32\"\n",
    "iterations = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 5424\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 24s 151ms/step - loss: 2.5221 - tp: 935.0000 - fp: 2103.0000 - tn: 1499.0000 - fn: 113.0000 - accuracy: 0.5234 - precision: 0.3078 - recall: 0.8922 - f1_metric: 0.3645\n",
      "Test Score: 2.5221431255340576\n",
      "Test Accuracy: 935.0\n",
      "146/146 [==============================] - 22s 148ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.42      0.57      3602\n",
      "           1       0.31      0.89      0.46      1048\n",
      "\n",
      "    accuracy                           0.52      4650\n",
      "   macro avg       0.62      0.65      0.52      4650\n",
      "weighted avg       0.79      0.52      0.55      4650\n",
      "\n",
      "[[1499 2103]\n",
      " [ 113  935]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2836676217765043, 'recall': 0.9519230769230769, 'F1': 0.4370860927152318, 'ERDE_5': 0.3906358952825279, 'ERDE_50': 0.15712936416120366, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.42004837234778514}\n"
     ]
    }
   ],
   "source": [
    "model_resuls = {}\n",
    "for i in range(0, iterations):\n",
    "    y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "                 shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "                 X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "    eval_resul = evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "    model_resuls[eval_resul['latency_weighted_f1']] = y_pred\n",
    "\n",
    "y_preds[model_name] = model_resuls[max(model_resuls.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_preds[\"cnn_model\"].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5285714285714286, 'recall': 0.7115384615384616, 'F1': 0.6065573770491803, 'ERDE_5': 0.2838774569434117, 'ERDE_50': 0.10928357057827473, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5829136255109477}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5285714285714286,\n",
       " 'recall': 0.7115384615384616,\n",
       " 'F1': 0.6065573770491803,\n",
       " 'ERDE_5': 0.2838774569434117,\n",
       " 'ERDE_50': 0.10928357057827473,\n",
       " 'median_latency_tps': 11.0,\n",
       " 'median_penalty_tps': 0.03898023902249159,\n",
       " 'speed': 0.9610197609775084,\n",
       " 'latency_weighted_f1': 0.5829136255109477}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ensemble_vote(np.array([y_preds[\"svm\"].flatten(), y_preds[\"cnn_model\"].flatten(), y_preds[\"cnn_model\"].flatten()]))\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
