{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from preprocessing import preprocess\n",
    "from windowfy import windowfy\n",
    "from featurizing import featurize\n",
    "from training import train, do_ensemble, do_train\n",
    "from eval_erisk import evaluate\n",
    "from IPython.display import display, Markdown\n",
    "from itertools import product\n",
    "from numpy.random import seed\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized numpy random and tensorflow random seed at 42\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "tensorflow.random.set_seed(42) \n",
    "logger(\"Initialized numpy random and tensorflow random seed at 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With max_size = 10 and new data, sample_weights=10, oversample False, include_new_data=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%Data size: 967\n",
      "\n",
      "Finished windowfying\n",
      "Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=10, include_feats=['first_prons', 'sentiment', 'nssi']\n",
      "Initialized numpy random and tensorflow random seed at 42\n",
      "Data size: 967, 967\n",
      "Data size: 841, 841\n",
      "Calculating first prons\n",
      "Calculating sentiment\n",
      "Calculating NSSI words\n",
      "Calculating first prons\n",
      "Calculating sentiment\n",
      "Calculating NSSI words\n"
     ]
    }
   ],
   "source": [
    "train_users, y_train, test_users, y_test, train_samples, X_train, X_test = windowfy(window_size=10, max_size=10, sample_weights_size=10, is_oversample=False, include_new_data=True)\n",
    "\n",
    "\n",
    "feats_train, feats_test = featurize(calculate_feats=True, include_feats=[\"first_prons\",\"sentiment\",\"nssi\"], \n",
    "                       train_users=train_users, test_users=test_users)\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.8798 - tp: 123.0000 - fp: 130.0000 - tn: 506.0000 - fn: 82.0000 - accuracy: 0.7479 - precision: 0.4862 - recall: 0.6000 - f1_metric: 0.4707\n",
      "Test Score: 0.8797976970672607\n",
      "Test Accuracy: 123.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       636\n",
      "           1       0.49      0.60      0.54       205\n",
      "\n",
      "    accuracy                           0.75       841\n",
      "   macro avg       0.67      0.70      0.68       841\n",
      "weighted avg       0.77      0.75      0.76       841\n",
      "\n",
      "[[506 130]\n",
      " [ 82 123]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.48201438848920863, 'recall': 0.6442307692307693, 'F1': 0.551440329218107, 'ERDE_5': 0.28732393257693184, 'ERDE_50': 0.12931945073185455, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5299450533785438}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 1.5937 - tp: 171.0000 - fp: 285.0000 - tn: 351.0000 - fn: 34.0000 - accuracy: 0.6207 - precision: 0.3750 - recall: 0.8341 - f1_metric: 0.4822\n",
      "Test Score: 1.5936907529830933\n",
      "Test Accuracy: 171.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.55      0.69       636\n",
      "           1       0.38      0.83      0.52       205\n",
      "\n",
      "    accuracy                           0.62       841\n",
      "   macro avg       0.64      0.69      0.60       841\n",
      "weighted avg       0.78      0.62      0.65       841\n",
      "\n",
      "[[351 285]\n",
      " [ 34 171]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.3651452282157676, 'recall': 0.8461538461538461, 'F1': 0.5101449275362319, 'ERDE_5': 0.33427761333052464, 'ERDE_50': 0.12675418741511996, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.49025935632475787}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.8090 - tp: 135.0000 - fp: 152.0000 - tn: 484.0000 - fn: 70.0000 - accuracy: 0.7360 - precision: 0.4704 - recall: 0.6585 - f1_metric: 0.4996\n",
      "Test Score: 0.8089733719825745\n",
      "Test Accuracy: 135.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81       636\n",
      "           1       0.47      0.66      0.55       205\n",
      "\n",
      "    accuracy                           0.74       841\n",
      "   macro avg       0.67      0.71      0.68       841\n",
      "weighted avg       0.78      0.74      0.75       841\n",
      "\n",
      "[[484 152]\n",
      " [ 70 135]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.45161290322580644, 'recall': 0.6730769230769231, 'F1': 0.5405405405405406, 'ERDE_5': 0.2948587743089831, 'ERDE_50': 0.12978332187627492, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5194701410689235}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 10ms/step - loss: 86.0732 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 86.0732421875\n",
      "Test Accuracy: 205.0\n",
      "27/27 [==============================] - 0s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.6317 - tp: 103.0000 - fp: 74.0000 - tn: 562.0000 - fn: 102.0000 - accuracy: 0.7907 - precision: 0.5819 - recall: 0.5024 - f1_metric: 0.4681\n",
      "Test Score: 0.6316781044006348\n",
      "Test Accuracy: 103.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       636\n",
      "           1       0.58      0.50      0.54       205\n",
      "\n",
      "    accuracy                           0.79       841\n",
      "   macro avg       0.71      0.69      0.70       841\n",
      "weighted avg       0.78      0.79      0.79       841\n",
      "\n",
      "[[562  74]\n",
      " [102 103]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.5729166666666666, 'recall': 0.5288461538461539, 'F1': 0.5499999999999999, 'ERDE_5': 0.2693720661394234, 'ERDE_50': 0.13966992494229552, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5285608685376295}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 0.8370 - tp: 134.0000 - fp: 167.0000 - tn: 469.0000 - fn: 71.0000 - accuracy: 0.7170 - precision: 0.4452 - recall: 0.6537 - f1_metric: 0.4879\n",
      "Test Score: 0.8370367884635925\n",
      "Test Accuracy: 134.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       636\n",
      "           1       0.45      0.65      0.53       205\n",
      "\n",
      "    accuracy                           0.72       841\n",
      "   macro avg       0.66      0.70      0.66       841\n",
      "weighted avg       0.77      0.72      0.73       841\n",
      "\n",
      "[[469 167]\n",
      " [ 71 134]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.4397590361445783, 'recall': 0.7019230769230769, 'F1': 0.5407407407407407, 'ERDE_5': 0.29950958533410676, 'ERDE_50': 0.12734101235685663, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5196625374174675}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 8ms/step - loss: 1.1522 - tp: 148.0000 - fp: 265.0000 - tn: 371.0000 - fn: 57.0000 - accuracy: 0.6171 - precision: 0.3584 - recall: 0.7220 - f1_metric: 0.4467\n",
      "Test Score: 1.1522184610366821\n",
      "Test Accuracy: 148.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70       636\n",
      "           1       0.36      0.72      0.48       205\n",
      "\n",
      "    accuracy                           0.62       841\n",
      "   macro avg       0.61      0.65      0.59       841\n",
      "weighted avg       0.74      0.62      0.64       841\n",
      "\n",
      "[[371 265]\n",
      " [ 57 148]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.3532110091743119, 'recall': 0.7403846153846154, 'F1': 0.4782608695652174, 'ERDE_5': 0.3273744629492441, 'ERDE_50': 0.1457840819542947, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.45961814655446054}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 0.9621 - tp: 143.0000 - fp: 185.0000 - tn: 451.0000 - fn: 62.0000 - accuracy: 0.7063 - precision: 0.4360 - recall: 0.6976 - f1_metric: 0.5012\n",
      "Test Score: 0.9621374011039734\n",
      "Test Accuracy: 143.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79       636\n",
      "           1       0.44      0.70      0.54       205\n",
      "\n",
      "    accuracy                           0.71       841\n",
      "   macro avg       0.66      0.70      0.66       841\n",
      "weighted avg       0.77      0.71      0.72       841\n",
      "\n",
      "[[451 185]\n",
      " [ 62 143]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.4367816091954023, 'recall': 0.7307692307692307, 'F1': 0.5467625899280576, 'ERDE_5': 0.3023871546850458, 'ERDE_50': 0.12315499443913507, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5254496534841053}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 1.1482 - tp: 162.0000 - fp: 245.0000 - tn: 391.0000 - fn: 43.0000 - accuracy: 0.6576 - precision: 0.3980 - recall: 0.7902 - f1_metric: 0.5008\n",
      "Test Score: 1.1481859683990479\n",
      "Test Accuracy: 162.0\n",
      "27/27 [==============================] - 0s 7ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73       636\n",
      "           1       0.40      0.79      0.53       205\n",
      "\n",
      "    accuracy                           0.66       841\n",
      "   macro avg       0.65      0.70      0.63       841\n",
      "weighted avg       0.78      0.66      0.68       841\n",
      "\n",
      "[[391 245]\n",
      " [ 43 162]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.39906103286384975, 'recall': 0.8173076923076923, 'F1': 0.5362776025236593, 'ERDE_5': 0.3197679380052603, 'ERDE_50': 0.1193154826774866, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5153733733948783}\n",
      "Starting training with cnn_model=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 1s 9ms/step - loss: 0.5693 - tp: 79.0000 - fp: 39.0000 - tn: 597.0000 - fn: 126.0000 - accuracy: 0.8038 - precision: 0.6695 - recall: 0.3854 - f1_metric: 0.4077\n",
      "Test Score: 0.5692701935768127\n",
      "Test Accuracy: 79.0\n",
      "27/27 [==============================] - 0s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       636\n",
      "           1       0.67      0.39      0.49       205\n",
      "\n",
      "    accuracy                           0.80       841\n",
      "   macro avg       0.75      0.66      0.68       841\n",
      "weighted avg       0.79      0.80      0.78       841\n",
      "\n",
      "[[597  39]\n",
      " [126  79]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.6615384615384615, 'recall': 0.41346153846153844, 'F1': 0.5088757396449703, 'ERDE_5': 0.25839872495461313, 'ERDE_50': 0.1569952327459495, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4890396416808622}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6615384615384615,\n",
       " 'recall': 0.41346153846153844,\n",
       " 'F1': 0.5088757396449703,\n",
       " 'ERDE_5': 0.25839872495461313,\n",
       " 'ERDE_50': 0.1569952327459495,\n",
       " 'median_latency_tps': 11.0,\n",
       " 'median_penalty_tps': 0.03898023902249159,\n",
       " 'speed': 0.9610197609775084,\n",
       " 'latency_weighted_f1': 0.4890396416808622}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"cnn_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=30, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 170ms/step - loss: 1.7052 - tp: 137.0000 - fp: 517.0000 - tn: 119.0000 - fn: 68.0000 - accuracy: 0.3044 - precision: 0.2095 - recall: 0.6683 - f1_metric: 0.3102\n",
      "Test Score: 1.7051887512207031\n",
      "Test Accuracy: 137.0\n",
      "27/27 [==============================] - 6s 179ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.19      0.29       636\n",
      "           1       0.21      0.67      0.32       205\n",
      "\n",
      "    accuracy                           0.30       841\n",
      "   macro avg       0.42      0.43      0.30       841\n",
      "weighted avg       0.53      0.30      0.30       841\n",
      "\n",
      "[[119 517]\n",
      " [ 68 137]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2182890855457227, 'recall': 0.7115384615384616, 'F1': 0.3340857787810384, 'ERDE_5': 0.39948742970379997, 'ERDE_50': 0.2249495609990555, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.3210630352701383}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 6s 167ms/step - loss: 0.6985 - tp: 115.0000 - fp: 153.0000 - tn: 483.0000 - fn: 90.0000 - accuracy: 0.7111 - precision: 0.4291 - recall: 0.5610 - f1_metric: 0.4276\n",
      "Test Score: 0.698518693447113\n",
      "Test Accuracy: 115.0\n",
      "27/27 [==============================] - 5s 158ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       636\n",
      "           1       0.43      0.56      0.49       205\n",
      "\n",
      "    accuracy                           0.71       841\n",
      "   macro avg       0.64      0.66      0.64       841\n",
      "weighted avg       0.74      0.71      0.72       841\n",
      "\n",
      "[[483 153]\n",
      " [ 90 115]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.41025641025641024, 'recall': 0.6153846153846154, 'F1': 0.4923076923076924, 'ERDE_5': 0.298966191566731, 'ERDE_50': 0.14803637196876973, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4731174207889273}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 184ms/step - loss: 3.5087 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 3.5087332725524902\n",
      "Test Accuracy: 205.0\n",
      "27/27 [==============================] - 6s 187ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 180ms/step - loss: 4.6295 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 4.629457950592041\n",
      "Test Accuracy: 205.0\n",
      "27/27 [==============================] - 6s 182ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 6s 164ms/step - loss: 1.3995 - tp: 203.0000 - fp: 634.0000 - tn: 2.0000 - fn: 2.0000 - accuracy: 0.2438 - precision: 0.2425 - recall: 0.9902 - f1_metric: 0.3732\n",
      "Test Score: 1.3994919061660767\n",
      "Test Accuracy: 203.0\n",
      "27/27 [==============================] - 5s 164ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.00      0.01       636\n",
      "           1       0.24      0.99      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.37      0.50      0.20       841\n",
      "weighted avg       0.44      0.24      0.10       841\n",
      "\n",
      "[[  2 634]\n",
      " [  2 203]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.24644549763033174, 'recall': 1.0, 'F1': 0.3954372623574145, 'ERDE_5': 0.4300954314391372, 'ERDE_50': 0.1848330902201432, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.38002302335232274}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 6s 166ms/step - loss: 0.8599 - tp: 152.0000 - fp: 219.0000 - tn: 417.0000 - fn: 53.0000 - accuracy: 0.6766 - precision: 0.4097 - recall: 0.7415 - f1_metric: 0.4970\n",
      "Test Score: 0.8598752617835999\n",
      "Test Accuracy: 152.0\n",
      "27/27 [==============================] - 5s 163ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.66      0.75       636\n",
      "           1       0.41      0.74      0.53       205\n",
      "\n",
      "    accuracy                           0.68       841\n",
      "   macro avg       0.65      0.70      0.64       841\n",
      "weighted avg       0.77      0.68      0.70       841\n",
      "\n",
      "[[417 219]\n",
      " [ 53 152]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.375, 'recall': 0.7788461538461539, 'F1': 0.5062500000000001, 'ERDE_5': 0.3238636643733787, 'ERDE_50': 0.13284040038227451, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4865162539948637}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 9s 225ms/step - loss: 0.9244 - tp: 145.0000 - fp: 262.0000 - tn: 374.0000 - fn: 60.0000 - accuracy: 0.6171 - precision: 0.3563 - recall: 0.7073 - f1_metric: 0.4535\n",
      "Test Score: 0.9243505597114563\n",
      "Test Accuracy: 145.0\n",
      "27/27 [==============================] - 7s 219ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.59      0.70       636\n",
      "           1       0.36      0.71      0.47       205\n",
      "\n",
      "    accuracy                           0.62       841\n",
      "   macro avg       0.61      0.65      0.59       841\n",
      "weighted avg       0.74      0.62      0.64       841\n",
      "\n",
      "[[374 262]\n",
      " [ 60 145]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.340080971659919, 'recall': 0.8076923076923077, 'F1': 0.47863247863247865, 'ERDE_5': 0.34014658137282766, 'ERDE_50': 0.14202281351821114, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.459975270211457}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 194ms/step - loss: 9.6032 - tp: 194.0000 - fp: 506.0000 - tn: 130.0000 - fn: 11.0000 - accuracy: 0.3853 - precision: 0.2771 - recall: 0.9463 - f1_metric: 0.4079\n",
      "Test Score: 9.603209495544434\n",
      "Test Accuracy: 194.0\n",
      "27/27 [==============================] - 7s 199ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.20      0.33       636\n",
      "           1       0.28      0.95      0.43       205\n",
      "\n",
      "    accuracy                           0.39       841\n",
      "   macro avg       0.60      0.58      0.38       841\n",
      "weighted avg       0.76      0.39      0.36       841\n",
      "\n",
      "[[130 506]\n",
      " [ 11 194]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.27548209366391185, 'recall': 0.9615384615384616, 'F1': 0.4282655246252677, 'ERDE_5': 0.3981434425971998, 'ERDE_50': 0.1623213676933309, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.41157163211028197}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 189ms/step - loss: 0.6118 - tp: 142.0000 - fp: 193.0000 - tn: 443.0000 - fn: 63.0000 - accuracy: 0.6956 - precision: 0.4239 - recall: 0.6927 - f1_metric: 0.4917\n",
      "Test Score: 0.6117864847183228\n",
      "Test Accuracy: 142.0\n",
      "27/27 [==============================] - 6s 187ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78       636\n",
      "           1       0.42      0.69      0.53       205\n",
      "\n",
      "    accuracy                           0.70       841\n",
      "   macro avg       0.65      0.69      0.65       841\n",
      "weighted avg       0.77      0.70      0.71       841\n",
      "\n",
      "[[443 193]\n",
      " [ 63 142]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.3979591836734694, 'recall': 0.75, 'F1': 0.5199999999999999, 'ERDE_5': 0.3140001864507712, 'ERDE_50': 0.13005158470678316, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4997302757083043}\n",
      "Starting training with cnn_model=lstm_model_32 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 7s 187ms/step - loss: 7.7982 - tp: 169.0000 - fp: 369.0000 - tn: 267.0000 - fn: 36.0000 - accuracy: 0.5184 - precision: 0.3141 - recall: 0.8244 - f1_metric: 0.4289\n",
      "Test Score: 7.798171520233154\n",
      "Test Accuracy: 169.0\n",
      "27/27 [==============================] - 6s 203ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.42      0.57       636\n",
      "           1       0.31      0.82      0.45       205\n",
      "\n",
      "    accuracy                           0.52       841\n",
      "   macro avg       0.60      0.62      0.51       841\n",
      "weighted avg       0.74      0.52      0.54       841\n",
      "\n",
      "[[267 369]\n",
      " [ 36 169]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.3096085409252669, 'recall': 0.8365384615384616, 'F1': 0.45194805194805204, 'ERDE_5': 0.35811414021881693, 'ERDE_50': 0.15294893505245097, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.43433100885736753}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.3096085409252669,\n",
       " 'recall': 0.8365384615384616,\n",
       " 'F1': 0.45194805194805204,\n",
       " 'ERDE_5': 0.35811414021881693,\n",
       " 'ERDE_50': 0.15294893505245097,\n",
       " 'median_latency_tps': 11.0,\n",
       " 'median_penalty_tps': 0.03898023902249159,\n",
       " 'speed': 0.9610197609775084,\n",
       " 'latency_weighted_f1': 0.43433100885736753}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=\"lstm_model_32\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot assign to variable embedding_1/embeddings:0 due to variable shape (14941, 100) and value shape (20883, 100) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c593ad39de92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred = do_train(model_name=\"ensemble_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n\u001b[1;32m      2\u001b[0m          \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cnn_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstm_model_32\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeats_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeats_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training.py\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(model_name, maxlen, epochs, early_epochs, batch_size, shuffle, patience, model_names, early_stopping, validation_split, feats_train, feats_test, X_train, X_test, y_train, y_test, train_sample_weights, save)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m\"ensemble_model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         y_pred = do_ensemble(maxlen, batch_size, shuffle, model_names, feats_train, feats_test, X_train, X_test,\n\u001b[0;32m---> 42\u001b[0;31m                              y_train, y_test, save)\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         y_pred = train(model_name, maxlen, epochs, early_epochs, batch_size, shuffle, patience, early_stopping, \n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training.py\u001b[0m in \u001b[0;36mdo_ensemble\u001b[0;34m(maxlen, batch_size, shuffle, model_names, feats_train, feats_test, X_train, X_test, y_train, y_test, save)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# reload trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/{}{}{}{}.hdf5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# reload trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2324\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2325\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    711\u001b[0m                        str(len(weight_values)) + ' elements.')\n\u001b[1;32m    712\u001b[0m     \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m   \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3802\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    899\u001b[0m             (\"Cannot assign to variable%s due to variable shape %s and value \"\n\u001b[1;32m    900\u001b[0m              \"shape %s are incompatible\") %\n\u001b[0;32m--> 901\u001b[0;31m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[0m\u001b[1;32m    902\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m    903\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot assign to variable embedding_1/embeddings:0 due to variable shape (14941, 100) and value shape (20883, 100) are incompatible"
     ]
    }
   ],
   "source": [
    "y_pred = do_train(model_name=\"ensemble_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=10, model_names=[\"cnn_model\", \"lstm_model_32\"], feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with different batch_size and all that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"lstm_model_16\"\n",
    "patience=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 4s 98ms/step - loss: 0.7755 - tp: 178.0000 - fp: 385.0000 - tn: 251.0000 - fn: 27.0000 - accuracy: 0.5101 - precision: 0.3162 - recall: 0.8683 - f1_metric: 0.4387\n",
      "Test Score: 0.775481641292572\n",
      "Test Accuracy: 178.0\n",
      "27/27 [==============================] - 4s 100ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.39      0.55       636\n",
      "           1       0.32      0.87      0.46       205\n",
      "\n",
      "    accuracy                           0.51       841\n",
      "   macro avg       0.61      0.63      0.51       841\n",
      "weighted avg       0.76      0.51      0.53       841\n",
      "\n",
      "[[251 385]\n",
      " [ 27 178]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.31208053691275167, 'recall': 0.8942307692307693, 'F1': 0.4626865671641791, 'ERDE_5': 0.36448373998882916, 'ERDE_50': 0.1451581353497756, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4446509341836233}\n",
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 5s 103ms/step - loss: 1.8861 - tp: 185.0000 - fp: 579.0000 - tn: 57.0000 - fn: 20.0000 - accuracy: 0.2878 - precision: 0.2421 - recall: 0.9024 - f1_metric: 0.3632\n",
      "Test Score: 1.8861323595046997\n",
      "Test Accuracy: 185.0\n",
      "27/27 [==============================] - 4s 103ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.09      0.16       636\n",
      "           1       0.24      0.90      0.38       205\n",
      "\n",
      "    accuracy                           0.29       841\n",
      "   macro avg       0.49      0.50      0.27       841\n",
      "weighted avg       0.62      0.29      0.21       841\n",
      "\n",
      "[[ 57 579]\n",
      " [ 20 185]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2467866323907455, 'recall': 0.9230769230769231, 'F1': 0.3894523326572008, 'ERDE_5': 0.4156149833379467, 'ERDE_50': 0.18921471645177695, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37427138764235623}\n",
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 4s 101ms/step - loss: 3.3354 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 3.3354387283325195\n",
      "Test Accuracy: 205.0\n",
      "27/27 [==============================] - 3s 97ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.2458628841607565,\n",
       " 'recall': 1.0,\n",
       " 'F1': 0.3946869070208729,\n",
       " 'ERDE_5': 0.43066928425293466,\n",
       " 'ERDE_50': 0.18541432635291089,\n",
       " 'median_latency_tps': 11.0,\n",
       " 'median_penalty_tps': 0.03898023902249159,\n",
       " 'speed': 0.9610197609775084,\n",
       " 'latency_weighted_f1': 0.37930191704615135}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = do_train(model_name=\"ensemble_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, model_names=[\"cnn_model\", model_name], feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = do_train(model_name=\"ensemble_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, model_names=[\"cnn_model\", \"lstm_model_16\", \"lstm_model_32\"], feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time with batch-size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=16\n",
      "Generating embeddings\n",
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 4s 110ms/step - loss: 78.8537 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 78.8536605834961\n",
      "Test Accuracy: 205.0\n",
      "53/53 [==============================] - 5s 75ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=16\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 4s 104ms/step - loss: 35.9097 - tp: 205.0000 - fp: 636.0000 - tn: 0.0000e+00 - fn: 0.0000e+00 - accuracy: 0.2438 - precision: 0.2438 - recall: 1.0000 - f1_metric: 0.3753\n",
      "Test Score: 35.90967559814453\n",
      "Test Accuracy: 205.0\n",
      "53/53 [==============================] - 5s 83ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       636\n",
      "           1       0.24      1.00      0.39       205\n",
      "\n",
      "    accuracy                           0.24       841\n",
      "   macro avg       0.12      0.50      0.20       841\n",
      "weighted avg       0.06      0.24      0.10       841\n",
      "\n",
      "[[  0 636]\n",
      " [  0 205]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.2458628841607565, 'recall': 1.0, 'F1': 0.3946869070208729, 'ERDE_5': 0.43066928425293466, 'ERDE_50': 0.18541432635291089, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.37930191704615135}\n",
      "Starting training with cnn_model=lstm_model_16 and maxlen=1000 and batch size=16\n",
      "Generating embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 967\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Evaluating\n",
      "27/27 [==============================] - 4s 103ms/step - loss: 3.4110 - tp: 171.0000 - fp: 561.0000 - tn: 75.0000 - fn: 34.0000 - accuracy: 0.2925 - precision: 0.2336 - recall: 0.8341 - f1_metric: 0.3497\n",
      "Test Score: 3.410984516143799\n",
      "Test Accuracy: 171.0\n",
      "53/53 [==============================] - 5s 83ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.12      0.20       636\n",
      "           1       0.23      0.83      0.36       205\n",
      "\n",
      "    accuracy                           0.29       841\n",
      "   macro avg       0.46      0.48      0.28       841\n",
      "weighted avg       0.58      0.29      0.24       841\n",
      "\n",
      "[[ 75 561]\n",
      " [ 34 171]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.23529411764705882, 'recall': 0.8461538461538461, 'F1': 0.3682008368200837, 'ERDE_5': 0.4115894023076051, 'ERDE_50': 0.20405859307323015, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.35384828019255543}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.23529411764705882,\n",
       " 'recall': 0.8461538461538461,\n",
       " 'F1': 0.3682008368200837,\n",
       " 'ERDE_5': 0.4115894023076051,\n",
       " 'ERDE_50': 0.20405859307323015,\n",
       " 'median_latency_tps': 11.0,\n",
       " 'median_penalty_tps': 0.03898023902249159,\n",
       " 'speed': 0.9610197609775084,\n",
       " 'latency_weighted_f1': 0.35384828019255543}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)\n",
    "y_pred = do_train(model_name=model_name, maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, train_sample_weights=train_samples)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = do_train(model_name=\"ensemble_model\", maxlen=1000, epochs=100, batch_size=batch_size,\n",
    "         shuffle=True, patience=patience, model_names=[\"cnn_model\", model_name], feats_train=feats_train, feats_test=feats_test, \n",
    "         X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "evaluate(1, 10, {\"test\":\"test\"}, y_pred=y_pred, test_users=test_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
