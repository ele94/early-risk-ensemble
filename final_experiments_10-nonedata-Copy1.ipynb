{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from experiment_utils import *\n",
    "from preprocessing import preprocess\n",
    "from windowfy import windowfy\n",
    "from featurizing import featurize\n",
    "from tfidf_featurizer import combine_features, tfidf_featurize\n",
    "from training import train, do_ensemble, do_train\n",
    "from training_traditional import train_and_evaluate\n",
    "from eval_erisk import evaluate, ensemble_vote\n",
    "from IPython.display import display, Markdown\n",
    "from itertools import product\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized numpy random and tensorflow random seed at 42\n"
     ]
    }
   ],
   "source": [
    "seed(42)\n",
    "tensorflow.random.set_seed(42) \n",
    "logger(\"Initialized numpy random and tensorflow random seed at 42\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "\n",
    "first_part = {\n",
    "    \"include_feats\": [[\"first_prons\", \"nssi\"],[\"first_prons\",\"sentiment\",\"nssi\"]],\n",
    "    \"feat_window_size\": [10], #10\n",
    "    \"max_size\": [20],\n",
    "    \"sample_weights_size\": [20],\n",
    "    \"oversample\": [False],\n",
    "    \"include_new_data\": [False],\n",
    "    \"tfidf_max_features\": [5000, 50000],\n",
    "    \"scale\": [False, True],\n",
    "    \"normalize\": [True, False],\n",
    "    \"discretize\": [True, False],\n",
    "    \"discretize_size\": [50, 75],\n",
    "    \"dis_strategy\": [\"quantile\"]\n",
    "}\n",
    "\n",
    "second_part = {\n",
    "    \"eval_window_size\": [1],\n",
    "    \"maxlen\": [1000],\n",
    "    \"batch_size\": [32],\n",
    "    \"epochs\": [100],\n",
    "    \"patience\": [10],\n",
    "    \"iterations\": [1],\n",
    "    \"shuffle\": [True, False],\n",
    "}\n",
    "\n",
    "models = [\"svm\", \"bayes\", \"cnn_model\"]\n",
    "ensemble_combinations = [[\"svm\", \"bayes\", \"cnn_model\"]]\n",
    "weights = [[1, 1, 1], [2, 1, 1], [1, 2, 1], [2, 2, 1], [1, 1, 2], [3, 3, 1], [5, 5, 1], [1, 5, 1]]\n",
    "eval_filename = \"experiments_10-nonedata-test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** CALCULATING FEATURES FOR {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATA FOR PARAMS {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}\n",
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%Data size: 3926\n",
      "\n",
      "Finished windowfying\n",
      "Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=['first_prons', 'nssi']\n",
      "Initialized numpy random and tensorflow random seed at 42\n",
      "Data size: 3926, 3926\n",
      "Data size: 4650, 4650\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Normalizing features\n",
      "Discretizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.\n",
      "  \"replaced with 0.\" % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the combined the same from tfidf: False\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.90      0.20      0.32      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.85      0.59      0.61      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3579   23]\n",
      " [ 843  205]]\n",
      "Evaluating after getting time 248.481100507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.90      0.20      0.32      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.85      0.59      0.61      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3579   23]\n",
      " [ 843  205]]\n",
      "Evaluated with elapsed time 36.46596258599999\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.7833333333333333, 'recall': 0.4519230769230769, 'F1': 0.573170731707317, 'ERDE_5': 0.25325679837577814, 'ERDE_50': 0.14230784277562714, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5508283995846694}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8974358974358975, 'recall': 0.33653846153846156, 'F1': 0.48951048951048953, 'ERDE_5': 0.248151200039192, 'ERDE_50': 0.16544551190696088, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.46471355081321036}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.9615384615384616, 'recall': 0.2403846153846154, 'F1': 0.38461538461538464, 'ERDE_5': 0.24643475938467724, 'ERDE_50': 0.18734246544719046, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.36363622788089367}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.85      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.82      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3589   13]\n",
      " [ 976   72]]\n",
      "Evaluating after getting time 288.778330626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.85      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.82      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3589   13]\n",
      " [ 976   72]]\n",
      "Evaluated with elapsed time 2.6180982879999988\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n",
      "{'precision': 0.8387096774193549, 'recall': 0.25, 'F1': 0.38518518518518513, 'ERDE_5': 0.2487081545412454, 'ERDE_50': 0.18730334378440736, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.3671716679073117}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8333333333333334, 'recall': 0.09615384615384616, 'F1': 0.1724137931034483, 'ERDE_5': 0.24701858132180415, 'ERDE_50': 0.22338469448775838, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.16267420992583512}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.08653846153846154, 'F1': 0.1592920353982301, 'ERDE_5': 0.24586193646336427, 'ERDE_50': 0.22458628841607742, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.14936509342257137}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.5444 - tp: 1.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1047.0000 - accuracy: 0.7742 - precision: 0.2500 - recall: 9.5420e-04 - f1_metric: 0.0011\n",
      "Test Score: 0.5444046258926392\n",
      "Test Accuracy: 1.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.25      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.51      0.50      0.44      4650\n",
      "weighted avg       0.66      0.77      0.68      4650\n",
      "\n",
      "[[3599    3]\n",
      " [1047    1]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.5, 'recall': 0.009615384615384616, 'F1': 0.01886792452830189, 'ERDE_5': 0.24644382858057864, 'ERDE_50': 0.24408005409967082, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.017912139559646656}\n",
      "Evaluating for elapsed time\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.5444 - tp: 1.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1047.0000 - accuracy: 0.7742 - precision: 0.2500 - recall: 9.5420e-04 - f1_metric: 0.0011\n",
      "Test Score: 0.5444046258926392\n",
      "Test Accuracy: 1.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.25      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.51      0.50      0.44      4650\n",
      "weighted avg       0.66      0.77      0.68      4650\n",
      "\n",
      "[[3599    3]\n",
      " [1047    1]]\n",
      "Evaluated with elapsed time 66.36291878500003\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model\n",
      "{'precision': 0.5, 'recall': 0.009615384615384616, 'F1': 0.01886792452830189, 'ERDE_5': 0.24644382858057864, 'ERDE_50': 0.24408005409967082, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.017912139559646656}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.24644412029352425, 'ERDE_50': 0.24644412029352425, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.24644412029352425, 'ERDE_50': 0.24644412029352425, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 2]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.24644412029352425, 'ERDE_50': 0.24644412029352425, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.24644412029352425, 'ERDE_50': 0.24644412029352425, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [3, 3, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [5, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8387096774193549, 'recall': 0.25, 'F1': 0.38518518518518513, 'ERDE_5': 0.2487081545412454, 'ERDE_50': 0.18730334378440736, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.3671716679073117}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8333333333333334, 'recall': 0.09615384615384616, 'F1': 0.1724137931034483, 'ERDE_5': 0.24701858132180415, 'ERDE_50': 0.22338469448775838, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.16267420992583512}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.08653846153846154, 'F1': 0.1592920353982301, 'ERDE_5': 0.24586193646336427, 'ERDE_50': 0.22458628841607742, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.14936509342257137}\n",
      "Writing results to CSV file\n",
      "************ FINISHED EXPERIMENT {'eval_window_size': 3, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile', 'weights': [1, 5, 1], 'model': ['svm', 'bayes', 'cnn_model'], 'eval_time': 66.36291878500003} ************* \n",
      "\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.90      0.20      0.32      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.85      0.59      0.61      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3579   23]\n",
      " [ 843  205]]\n",
      "Evaluating after getting time 930.182297032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.90      0.20      0.32      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.85      0.59      0.61      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3579   23]\n",
      " [ 843  205]]\n",
      "Evaluated with elapsed time 37.88156583\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.7833333333333333, 'recall': 0.4519230769230769, 'F1': 0.573170731707317, 'ERDE_5': 0.25325679837577814, 'ERDE_50': 0.14230784277562714, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.5508283995846694}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8974358974358975, 'recall': 0.33653846153846156, 'F1': 0.48951048951048953, 'ERDE_5': 0.248151200039192, 'ERDE_50': 0.16544551190696088, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.46471355081321036}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.9615384615384616, 'recall': 0.2403846153846154, 'F1': 0.38461538461538464, 'ERDE_5': 0.24643475938467724, 'ERDE_50': 0.18734246544719046, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.36363622788089367}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.85      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.82      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3589   13]\n",
      " [ 976   72]]\n",
      "Evaluating after getting time 971.925360401\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.85      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.82      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3589   13]\n",
      " [ 976   72]]\n",
      "Evaluated with elapsed time 2.689304991999961\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n",
      "{'precision': 0.8387096774193549, 'recall': 0.25, 'F1': 0.38518518518518513, 'ERDE_5': 0.2487081545412454, 'ERDE_50': 0.18730334378440736, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.3671716679073117}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8333333333333334, 'recall': 0.09615384615384616, 'F1': 0.1724137931034483, 'ERDE_5': 0.24701858132180415, 'ERDE_50': 0.22338469448775838, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.16267420992583512}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.08653846153846154, 'F1': 0.1592920353982301, 'ERDE_5': 0.24586193646336427, 'ERDE_50': 0.22458628841607742, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.14936509342257137}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 1.0830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 1.0830055475234985\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Evaluating for elapsed time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 2s 9ms/step - loss: 1.0830 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 1.0830055475234985\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluated with elapsed time 64.31685532000006\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 2]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [3, 3, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [5, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8461538461538461, 'recall': 0.21153846153846154, 'F1': 0.3384615384615385, 'ERDE_5': 0.24812800344341096, 'ERDE_50': 0.19617837242705216, 'median_latency_tps': 12.5, 'median_penalty_tps': 0.044819781830275796, 'speed': 0.9551802181697242, 'latency_weighted_f1': 0.3232917661497528}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.24701859584703958, 'ERDE_50': 0.2257487606816118, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.07692307692307693, 'F1': 0.14285714285714288, 'ERDE_5': 0.2458619418069205, 'ERDE_50': 0.22695035460993082, 'median_latency_tps': 16.5, 'median_penalty_tps': 0.06037624654335805, 'speed': 0.939623753456642, 'latency_weighted_f1': 0.1342319647795203}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8387096774193549, 'recall': 0.25, 'F1': 0.38518518518518513, 'ERDE_5': 0.2487081545412454, 'ERDE_50': 0.18730334378440736, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.3671716679073117}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8333333333333334, 'recall': 0.09615384615384616, 'F1': 0.1724137931034483, 'ERDE_5': 0.24701858132180415, 'ERDE_50': 0.22338469448775838, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.16267420992583512}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.08653846153846154, 'F1': 0.1592920353982301, 'ERDE_5': 0.24586193646336427, 'ERDE_50': 0.22458628841607742, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.14936509342257137}\n",
      "Writing results to CSV file\n",
      "************ FINISHED EXPERIMENT {'eval_window_size': 3, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile', 'weights': [1, 5, 1], 'model': ['svm', 'bayes', 'cnn_model'], 'eval_time': 64.31685532000006} ************* \n",
      "\n",
      "********** CALCULATING FEATURES FOR {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'} ***********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATA FOR PARAMS {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}\n",
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%Data size: 3926\n",
      "\n",
      "Finished windowfying\n",
      "Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=['first_prons', 'nssi']\n",
      "Initialized numpy random and tensorflow random seed at 42\n",
      "Data size: 3926, 3926\n",
      "Data size: 4650, 4650\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Normalizing features\n",
      "Discretizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.\n",
      "  \"replaced with 0.\" % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.\n",
      "  'decreasing the number of bins.' % jj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the combined the same from tfidf: False\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.91      0.18      0.30      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.86      0.59      0.60      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3582   20]\n",
      " [ 857  191]]\n",
      "Evaluating after getting time 1472.229396681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.91      0.18      0.30      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.86      0.59      0.60      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3582   20]\n",
      " [ 857  191]]\n",
      "Evaluated with elapsed time 47.77661557500005\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.8135593220338984, 'recall': 0.46153846153846156, 'F1': 0.588957055214724, 'ERDE_5': 0.25211384884922955, 'ERDE_50': 0.13878130431623883, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.563706286234989}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8823529411764706, 'recall': 0.28846153846153844, 'F1': 0.4347826086956522, 'ERDE_5': 0.24815099696411347, 'ERDE_50': 0.17726584287622718, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.41614186891441673}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.9545454545454546, 'recall': 0.20192307692307693, 'F1': 0.33333333333333337, 'ERDE_5': 0.2464354058352571, 'ERDE_50': 0.19679873022260408, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3164477988870909}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.87      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.83      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3591   11]\n",
      " [ 977   71]]\n",
      "Evaluating after getting time 1523.624963892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.87      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.83      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3591   11]\n",
      " [ 977   71]]\n",
      "Evaluated with elapsed time 2.7938710809999066\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n",
      "{'precision': 0.8928571428571429, 'recall': 0.2403846153846154, 'F1': 0.37878787878787884, 'ERDE_5': 0.24755775058878443, 'ERDE_50': 0.18850493771272692, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3595997714626033}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.2470186116233917, 'ERDE_50': 0.22574876068161176, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 2s 9ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 0.5897975564002991\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Evaluating for elapsed time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 2s 9ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 0.5897975564002991\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 1s 8ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluated with elapsed time 65.08561477300009\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 2]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [3, 3, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [5, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8928571428571429, 'recall': 0.2403846153846154, 'F1': 0.37878787878787884, 'ERDE_5': 0.24755775058878443, 'ERDE_50': 0.18850493771272692, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3595997714626033}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.2470186116233917, 'ERDE_50': 0.22574876068161176, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "************ FINISHED EXPERIMENT {'eval_window_size': 3, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile', 'weights': [1, 5, 1], 'model': ['svm', 'bayes', 'cnn_model'], 'eval_time': 65.08561477300009} ************* \n",
      "\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.91      0.18      0.30      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.86      0.59      0.60      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3582   20]\n",
      " [ 857  191]]\n",
      "Evaluating after getting time 2042.135082085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3602\n",
      "           1       0.91      0.18      0.30      1048\n",
      "\n",
      "    accuracy                           0.81      4650\n",
      "   macro avg       0.86      0.59      0.60      4650\n",
      "weighted avg       0.83      0.81      0.76      4650\n",
      "\n",
      "[[3582   20]\n",
      " [ 857  191]]\n",
      "Evaluated with elapsed time 108.74872146199982\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.8135593220338984, 'recall': 0.46153846153846156, 'F1': 0.588957055214724, 'ERDE_5': 0.25211384884922955, 'ERDE_50': 0.13878130431623883, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.563706286234989}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8823529411764706, 'recall': 0.28846153846153844, 'F1': 0.4347826086956522, 'ERDE_5': 0.24815099696411347, 'ERDE_50': 0.17726584287622718, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.41614186891441673}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.9545454545454546, 'recall': 0.20192307692307693, 'F1': 0.33333333333333337, 'ERDE_5': 0.2464354058352571, 'ERDE_50': 0.19679873022260408, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3164477988870909}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.87      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.83      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3591   11]\n",
      " [ 977   71]]\n",
      "Evaluating after getting time 2155.912903925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3602\n",
      "           1       0.87      0.07      0.13      1048\n",
      "\n",
      "    accuracy                           0.79      4650\n",
      "   macro avg       0.83      0.53      0.50      4650\n",
      "weighted avg       0.80      0.79      0.71      4650\n",
      "\n",
      "[[3591   11]\n",
      " [ 977   71]]\n",
      "Evaluated with elapsed time 3.838957566999852\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n",
      "{'precision': 0.8928571428571429, 'recall': 0.2403846153846154, 'F1': 0.37878787878787884, 'ERDE_5': 0.24755775058878443, 'ERDE_50': 0.18850493771272692, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3595997714626033}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.2470186116233917, 'ERDE_50': 0.22574876068161176, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 4s 15ms/step - loss: 0.8961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 0.8961288332939148\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 2s 13ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Evaluating for elapsed time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 5s 18ms/step - loss: 0.8961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00\n",
      "Test Score: 0.8961288332939148\n",
      "Test Accuracy: 0.0\n",
      "146/146 [==============================] - 2s 14ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluated with elapsed time 69.05809290199977\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 2]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [3, 3, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [5, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.9130434782608695, 'recall': 0.20192307692307693, 'F1': 0.3307086614173228, 'ERDE_5': 0.24698910545911937, 'ERDE_50': 0.19737996635537286, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.31395608393522395}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.8, 'recall': 0.07692307692307693, 'F1': 0.14035087719298248, 'ERDE_5': 0.24702076540872125, 'ERDE_50': 0.2281128268754652, 'median_latency_tps': 15.5, 'median_penalty_tps': 0.05648958243015645, 'speed': 0.9435104175698436, 'latency_weighted_f1': 0.13242251474664474}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.8928571428571429, 'recall': 0.2403846153846154, 'F1': 0.37878787878787884, 'ERDE_5': 0.24755775058878443, 'ERDE_50': 0.18850493771272692, 'median_latency_tps': 14.0, 'median_penalty_tps': 0.05065660333872746, 'speed': 0.9493433966612725, 'latency_weighted_f1': 0.3595997714626033}\n",
      "Writing results to CSV file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.8181818181818182, 'recall': 0.08653846153846154, 'F1': 0.15652173913043477, 'ERDE_5': 0.2470186116233917, 'ERDE_50': 0.22574876068161176, 'median_latency_tps': 15.0, 'median_penalty_tps': 0.054545807509676525, 'speed': 0.9454541924903235, 'latency_weighted_f1': 0.14798413447674627}\n",
      "Writing results to CSV file\n",
      "{'precision': 1.0, 'recall': 0.0673076923076923, 'F1': 0.12612612612612611, 'ERDE_5': 0.2458612388649735, 'ERDE_50': 0.22931442080378478, 'median_latency_tps': 17.0, 'median_penalty_tps': 0.06231913573607972, 'speed': 0.9376808642639203, 'latency_weighted_f1': 0.11826605495220616}\n",
      "Writing results to CSV file\n",
      "************ FINISHED EXPERIMENT {'eval_window_size': 3, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile', 'weights': [1, 5, 1], 'model': ['svm', 'bayes', 'cnn_model'], 'eval_time': 69.05809290199977} ************* \n",
      "\n",
      "********** CALCULATING FEATURES FOR {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***********\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATA FOR PARAMS {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}\n",
      "Windowfying training users\n",
      "[====================] 100%\n",
      "Windowfying test users\n",
      "[====================] 100%Data size: 3926\n",
      "\n",
      "Finished windowfying\n",
      "Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=['first_prons', 'nssi']\n",
      "Initialized numpy random and tensorflow random seed at 42\n",
      "Data size: 3926, 3926\n",
      "Data size: 4650, 4650\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Calculating first prons\n",
      "Calculating NSSI words\n",
      "Normalizing features\n",
      "Is the combined the same from tfidf: False\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3602\n",
      "           1       0.48      0.02      0.04      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.63      0.51      0.46      4650\n",
      "weighted avg       0.71      0.77      0.68      4650\n",
      "\n",
      "[[3578   24]\n",
      " [1026   22]]\n",
      "Evaluating after getting time 2873.120623878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3602\n",
      "           1       0.48      0.02      0.04      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.63      0.51      0.46      4650\n",
      "weighted avg       0.71      0.77      0.68      4650\n",
      "\n",
      "[[3578   24]\n",
      " [1026   22]]\n",
      "Evaluated with elapsed time 110.43294261999972\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluating after getting time 2989.150851314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluated with elapsed time 4.447577830999762\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Evaluating\n",
      "146/146 [==============================] - 4s 17ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533\n",
      "Test Score: 0.6330819725990295\n",
      "Test Accuracy: 719.0\n",
      "146/146 [==============================] - 2s 15ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76      3602\n",
      "           1       0.37      0.69      0.48      1048\n",
      "\n",
      "    accuracy                           0.67      4650\n",
      "   macro avg       0.63      0.68      0.62      4650\n",
      "weighted avg       0.77      0.67      0.70      4650\n",
      "\n",
      "[[2400 1202]\n",
      " [ 329  719]]\n",
      "Finished training and evaluation\n",
      "{'precision': 0.32167832167832167, 'recall': 0.8846153846153846, 'F1': 0.4717948717948718, 'ERDE_5': 0.3581736549592459, 'ERDE_50': 0.1411286040831851, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4534041949227219}\n",
      "Evaluating for elapsed time\n",
      "146/146 [==============================] - 8s 23ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533\n",
      "Test Score: 0.6330819725990295\n",
      "Test Accuracy: 719.0\n",
      "146/146 [==============================] - 3s 21ms/step\n",
      "Entered here\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76      3602\n",
      "           1       0.37      0.69      0.48      1048\n",
      "\n",
      "    accuracy                           0.67      4650\n",
      "   macro avg       0.63      0.68      0.62      4650\n",
      "weighted avg       0.77      0.67      0.70      4650\n",
      "\n",
      "[[2400 1202]\n",
      " [ 329  719]]\n",
      "Evaluated with elapsed time 74.85082967900007\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model\n",
      "{'precision': 0.32167832167832167, 'recall': 0.8846153846153846, 'F1': 0.4717948717948718, 'ERDE_5': 0.3581736549592459, 'ERDE_50': 0.1411286040831851, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.4534041949227219}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3534136546184739, 'recall': 0.8461538461538461, 'F1': 0.4985835694050992, 'ERDE_5': 0.3392827344943997, 'ERDE_50': 0.1314040764772667, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.47720744627919515}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3644859813084112, 'recall': 0.75, 'F1': 0.4905660377358491, 'ERDE_5': 0.3248588551659341, 'ERDE_50': 0.14051383509660673, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.46762429403289707}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 1, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [2, 2, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 1, 2]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [3, 3, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [5, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] with weights [1, 5, 1]\n",
      "EVALUATING ENSEMBLE ['svm', 'bayes', 'cnn_model'] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "************ FINISHED EXPERIMENT {'eval_window_size': 3, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile', 'weights': [1, 5, 1], 'model': ['svm', 'bayes', 'cnn_model'], 'eval_time': 74.85082967900007} ************* \n",
      "\n",
      "************ STARTING EXPERIMENT {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'} ***************\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 1, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND EVALUATING TRADITIONAL MODEL svm\n",
      "Starting training traditional\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3602\n",
      "           1       0.48      0.02      0.04      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.63      0.51      0.46      4650\n",
      "weighted avg       0.71      0.77      0.68      4650\n",
      "\n",
      "[[3578   24]\n",
      " [1026   22]]\n",
      "Evaluating after getting time 3877.139746118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.87      3602\n",
      "           1       0.48      0.02      0.04      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.63      0.51      0.46      4650\n",
      "weighted avg       0.71      0.77      0.68      4650\n",
      "\n",
      "[[3578   24]\n",
      " [1026   22]]\n",
      "Evaluated with elapsed time 110.82039464699983\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24933276462291873, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 11.0, 'median_penalty_tps': 0.03898023902249159, 'speed': 0.9610197609775084, 'latency_weighted_f1': 0.0510275979280093}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.3333333333333333, 'recall': 0.028846153846153848, 'F1': 0.05309734513274337, 'ERDE_5': 0.24934383960137432, 'ERDE_50': 0.2422581023758027, 'median_latency_tps': 12.0, 'median_penalty_tps': 0.042873701496841665, 'speed': 0.9571262985031583, 'latency_weighted_f1': 0.050820865407247354}\n",
      "Writing results to CSV file\n",
      "{'precision': 0.42857142857142855, 'recall': 0.028846153846153848, 'F1': 0.05405405405405405, 'ERDE_5': 0.24818545032210787, 'ERDE_50': 0.24109563011026722, 'median_latency_tps': 13.0, 'median_penalty_tps': 0.046765862163709926, 'speed': 0.9532341378362901, 'latency_weighted_f1': 0.051526169612772434}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING TRADITIONAL MODEL bayes\n",
      "Starting training traditional\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluating after getting time 3994.326170992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      3602\n",
      "           1       0.00      0.00      0.00      1048\n",
      "\n",
      "    accuracy                           0.77      4650\n",
      "   macro avg       0.39      0.50      0.44      4650\n",
      "weighted avg       0.60      0.77      0.68      4650\n",
      "\n",
      "[[3602    0]\n",
      " [1048    0]]\n",
      "Evaluated with elapsed time 3.0195249960002\n",
      "EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "{'precision': 0, 'recall': 0, 'F1': 0, 'ERDE_5': 0.2458628841607565, 'ERDE_50': 0.2458628841607565, 'median_latency_tps': nan, 'median_penalty_tps': nan, 'speed': nan, 'latency_weighted_f1': nan}\n",
      "Writing results to CSV file\n",
      "TRAINING AND EVALUATING DL MODEL cnn_model\n",
      "STARTING ITERATION FOR DL MODEL cnn_model FOR 1 ITERATIONS\n",
      "Starting training deep model cnn_model\n",
      "Starting training with model_name=cnn_model and maxlen=1000 and batch size=32\n",
      "Generating embeddings\n",
      "Data size: 3926\n",
      "Training with callback\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d9ad7fd1abb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#### Experiment {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"************ FINISHED EXPERIMENT {} ************* \\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/experiment_utils.py\u001b[0m in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(self, params, weights_combinations)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRAINING AND EVALUATING DL MODEL {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_dl_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating for elapsed time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 elapsed_time = evaluate_dl_time(model_name=params[\"model\"], maxlen=params[\"maxlen\"], epochs=params[\"epochs\"],\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/experiment_utils.py\u001b[0m in \u001b[0;36miterate_dl_model\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    120\u001b[0m                               \u001b[0mfeats_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeats_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeats_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                               \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                               train_sample_weights=self.train_samples, name=self.name)\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0meval_resul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_users\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mmodel_resuls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_resul\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latency_weighted_f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training.py\u001b[0m in \u001b[0;36mdo_train\u001b[0;34m(model_name, maxlen, epochs, early_epochs, batch_size, shuffle, patience, model_names, early_stopping, validation_split, feats_train, feats_test, X_train, X_test, y_train, y_test, train_sample_weights, save, name)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         y_pred = train(model_name, maxlen, epochs, early_epochs, batch_size, shuffle, patience, early_stopping, \n\u001b[0;32m---> 47\u001b[0;31m               validation_split, feats_train, feats_test, X_train, X_test, y_train, y_test, train_sample_weights, save, name)\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datos/ecampillo/jupyter/dl-notebooks/newensemble/early-risk-ensemble/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_name, maxlen, epochs, early_epochs, batch_size, shuffle, patience, early_stopping, validation_split, feats_train, feats_test, X_train, X_test, y_train, y_test, train_sample_weights, save, name)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training with callback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_feats_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training with no callback\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment = Experiment(models, ensemble_combinations, eval_filename)\n",
    "\n",
    "firstpart_generator = traverse(first_part)\n",
    "\n",
    "for i in firstpart_generator:\n",
    "    try:\n",
    "        logger(\"********** CALCULATING FEATURES FOR {} ***********\".format(i))\n",
    "        display(Markdown(\"#### Calculating features for {}\".format(i)))\n",
    "        \n",
    "        experiment.prepare_data(i)\n",
    "\n",
    "        secondpart_generator = traverse(second_part)\n",
    "\n",
    "        for j in secondpart_generator:\n",
    "            params = j.copy()\n",
    "            params.update(i)\n",
    "            logger(\"************ STARTING EXPERIMENT {} ***************\".format(params))\n",
    "            display(Markdown(\"#### Experiment {}\".format(params)))\n",
    "            try:\n",
    "                experiment.train_and_evaluate_model(params, weights)\n",
    "                logger(\"************ FINISHED EXPERIMENT {} ************* \\n\".format(params))\n",
    "            except Exception as e:\n",
    "                logger(\"*************************************\")\n",
    "                logger(\"Error during experiment {}: {}\".format(params, e))\n",
    "                logger(\"*************************************\")\n",
    "        del secondpart_generator\n",
    "    except Exception as e:\n",
    "        logger(\"*************************************\")\n",
    "        logger(\"General error during experiment {}: {}\".format(i, e))\n",
    "        logger(\"*************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
