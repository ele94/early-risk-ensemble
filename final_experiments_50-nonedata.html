<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>final_experiments_50-nonedata</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    .highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight  { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">experiment_utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">preprocessing</span> <span class="kn">import</span> <span class="n">preprocess</span>
<span class="kn">from</span> <span class="nn">windowfy</span> <span class="kn">import</span> <span class="n">windowfy</span>
<span class="kn">from</span> <span class="nn">featurizing</span> <span class="kn">import</span> <span class="n">featurize</span>
<span class="kn">from</span> <span class="nn">tfidf_featurizer</span> <span class="kn">import</span> <span class="n">combine_features</span><span class="p">,</span> <span class="n">tfidf_featurize</span>
<span class="kn">from</span> <span class="nn">training</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">do_ensemble</span><span class="p">,</span> <span class="n">do_train</span>
<span class="kn">from</span> <span class="nn">training_traditional</span> <span class="kn">import</span> <span class="n">train_and_evaluate</span>
<span class="kn">from</span> <span class="nn">eval_erisk</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">ensemble_vote</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Markdown</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">seed</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.
  warnings.warn(&#34;The twython library has not been installed. &#34;
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">logger</span><span class="p">(</span><span class="s2">&quot;Initialized numpy random and tensorflow random seed at 42&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Initialized numpy random and tensorflow random seed at 42
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># params</span>

<span class="n">first_part</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;include_feats&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="s2">&quot;first_prons&quot;</span><span class="p">,</span> <span class="s2">&quot;nssi&quot;</span><span class="p">],[</span><span class="s2">&quot;first_prons&quot;</span><span class="p">,</span><span class="s2">&quot;sentiment&quot;</span><span class="p">,</span><span class="s2">&quot;nssi&quot;</span><span class="p">]],</span>
    <span class="s2">&quot;feat_window_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="c1">#10</span>
    <span class="s2">&quot;max_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">],</span>
    <span class="s2">&quot;sample_weights_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">],</span>
    <span class="s2">&quot;oversample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;include_new_data&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;tfidf_max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">],</span>
    <span class="s2">&quot;scale&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
    <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;discretize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;discretize_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">],</span>
    <span class="s2">&quot;dis_strategy&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;quantile&quot;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">second_part</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;eval_window_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;maxlen&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">],</span>
    <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;patience&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span>
    <span class="s2">&quot;iterations&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span>
    <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="s2">&quot;bayes&quot;</span><span class="p">,</span> <span class="s2">&quot;cnn_model&quot;</span><span class="p">]</span>
<span class="n">ensemble_combinations</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="s2">&quot;bayes&quot;</span><span class="p">,</span> <span class="s2">&quot;cnn_model&quot;</span><span class="p">]]</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">eval_filename</span> <span class="o">=</span> <span class="s2">&quot;experiments_50-nonedata.csv&quot;</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Experiments">Experiments<a class="anchor-link" href="#Experiments">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">ensemble_combinations</span><span class="p">,</span> <span class="n">eval_filename</span><span class="p">)</span>

<span class="n">firstpart_generator</span> <span class="o">=</span> <span class="n">traverse</span><span class="p">(</span><span class="n">first_part</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">firstpart_generator</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;********** CALCULATING FEATURES FOR </span><span class="si">{}</span><span class="s2"> ***********&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="s2">&quot;#### Calculating features for </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
        
        <span class="n">experiment</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="n">secondpart_generator</span> <span class="o">=</span> <span class="n">traverse</span><span class="p">(</span><span class="n">second_part</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">secondpart_generator</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">j</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;************ STARTING EXPERIMENT </span><span class="si">{}</span><span class="s2"> ***************&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="s2">&quot;#### Experiment </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">)))</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">experiment</span><span class="o">.</span><span class="n">train_and_evaluate_model</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;************ FINISHED EXPERIMENT </span><span class="si">{}</span><span class="s2"> ************* </span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;Error during experiment </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">secondpart_generator</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;General error during experiment </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2218   484]]
Evaluating after getting time 1993.922931989
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2218   484]]
Evaluated with elapsed time 1288.189431747
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6875, &#39;ERDE_5&#39;: 0.2584829133920413, &#39;ERDE_50&#39;: 0.1061266181320945, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6553484697624494}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25337287589879065, &#39;ERDE_50&#39;: 0.1429436442207058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5441358493058512}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.25049931011454174, &#39;ERDE_50&#39;: 0.16895250603922493, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.45021628213824927}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10986   261]
 [ 2060   642]]
Evaluating after getting time 3298.632484656
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10986   261]
 [ 2060   642]]
Evaluated with elapsed time 5.412037923999833
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26439729322098676, &#39;ERDE_50&#39;: 0.13272647312861346, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5583236741268424}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 9s 15ms/step - loss: 0.5063 - tp: 368.0000 - fp: 89.0000 - tn: 11158.0000 - fn: 2334.0000 - accuracy: 0.8263 - precision: 0.8053 - recall: 0.1362 - f1_metric: 0.0763
Test Score: 0.5063048005104065
Test Accuracy: 368.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.14      0.23      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.56      0.57     13949
weighted avg       0.82      0.83      0.77     13949

[[11158    89]
 [ 2334   368]]
Finished training and evaluation
{&#39;precision&#39;: 0.6179775280898876, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5699481865284974, &#39;ERDE_5&#39;: 0.26550974714091863, &#39;ERDE_50&#39;: 0.1373958860459534, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5432940681968493}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.4046 - tp: 474.0000 - fp: 156.0000 - tn: 11091.0000 - fn: 2228.0000 - accuracy: 0.8291 - precision: 0.7524 - recall: 0.1754 - f1_metric: 0.1020
Test Score: 0.40456733107566833
Test Accuracy: 474.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.18      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11091   156]
 [ 2228   474]]
Finished training and evaluation
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713055417417727, &#39;ERDE_50&#39;: 0.12226518380910399, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5794114627510113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.4059 - tp: 450.0000 - fp: 127.0000 - tn: 11120.0000 - fn: 2252.0000 - accuracy: 0.8295 - precision: 0.7799 - recall: 0.1665 - f1_metric: 0.0948
Test Score: 0.4059257507324219
Test Accuracy: 450.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11120   127]
 [ 2252   450]]
Finished training and evaluation
{&#39;precision&#39;: 0.6181818181818182, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6355140186915889, &#39;ERDE_5&#39;: 0.2701302333779222, &#39;ERDE_50&#39;: 0.11126749523965757, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.6008493933583364}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 17ms/step - loss: 0.6197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6196771860122681
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 13s 22ms/step - loss: 0.4153 - tp: 471.0000 - fp: 130.0000 - tn: 11117.0000 - fn: 2231.0000 - accuracy: 0.8307 - precision: 0.7837 - recall: 0.1743 - f1_metric: 0.0979
Test Score: 0.41526246070861816
Test Accuracy: 471.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11117   130]
 [ 2231   471]]
Finished training and evaluation
{&#39;precision&#39;: 0.5784313725490197, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5728155339805826, &#39;ERDE_5&#39;: 0.2707127102878138, &#39;ERDE_50&#39;: 0.1369617711161085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5437986446894669}
Evaluating for elapsed time
436/436 [==============================] - 17s 20ms/step - loss: 0.4153 - tp: 471.0000 - fp: 130.0000 - tn: 11117.0000 - fn: 2231.0000 - accuracy: 0.8307 - precision: 0.7837 - recall: 0.1743 - f1_metric: 0.0979
Test Score: 0.41526246070861816
Test Accuracy: 471.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11117   130]
 [ 2231   471]]
Evaluated with elapsed time 199.9967846439995
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6181818181818182, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6355140186915889, &#39;ERDE_5&#39;: 0.2701302333779222, &#39;ERDE_50&#39;: 0.11126749523965757, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.6008493933583364}
Writing results to CSV file
{&#39;precision&#39;: 0.6582278481012658, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5683060109289617, &#39;ERDE_5&#39;: 0.2615183803682155, &#39;ERDE_50&#39;: 0.1427193110257367, &#39;median_latency_tps&#39;: 20.5, &#39;median_penalty_tps&#39;: 0.07590343710772685, &#39;speed&#39;: 0.9240965628922732, &#39;latency_weighted_f1&#39;: 0.5251696313704721}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.2528285175011324, &#39;ERDE_50&#39;: 0.16837299288133215, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.4478863667246098}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7468354430379747, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6448087431693988, &#39;ERDE_5&#39;: 0.25731810275545314, &#39;ERDE_50&#39;: 0.12186875470526241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6171634055922004}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533696130667868, &#39;ERDE_50&#39;: 0.14059539575235808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5546089529229323}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25108093090863864, &#39;ERDE_50&#39;: 0.16480560988282927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4664240682952262}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7681159420289855, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.6127167630057804, &#39;ERDE_5&#39;: 0.2550238392585726, &#39;ERDE_50&#39;: 0.13163794551213476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5864473274065595}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.25105553970305566, &#39;ERDE_50&#39;: 0.15007496515901111, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4722222222222222, &#39;ERDE_5&#39;: 0.24933884572674536, &#39;ERDE_50&#39;: 0.17015411448020396, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4455465860746483}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7368421052631579, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6222222222222222, &#39;ERDE_5&#39;: 0.25732825042740354, &#39;ERDE_50&#39;: 0.12723278973405097, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5955452524019652}
Writing results to CSV file
{&#39;precision&#39;: 0.7796610169491526, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5644171779141105, &#39;ERDE_5&#39;: 0.2533704399964041, &#39;ERDE_50&#39;: 0.14532352741689183, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.538021721968949}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510809434680869, &#39;ERDE_50&#39;: 0.1683517072078222, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4490137686911424}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7468354430379747, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6448087431693988, &#39;ERDE_5&#39;: 0.25731810275545314, &#39;ERDE_50&#39;: 0.12186875470526241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6171634055922004}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533696130667868, &#39;ERDE_50&#39;: 0.14059539575235808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5546089529229323}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25108093090863864, &#39;ERDE_50&#39;: 0.16480560988282927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4664240682952262}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.2538845751592949, &#39;ERDE_50&#39;: 0.13729386771431806, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.57062915759771}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5263157894736842, &#39;ERDE_5&#39;: 0.2504847914309165, &#39;ERDE_50&#39;: 0.1566017446446522, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4935162443494317}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24876223393823613, &#39;ERDE_50&#39;: 0.18375730254665143, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.3824918210091388}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7468354430379747, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6448087431693988, &#39;ERDE_5&#39;: 0.25731810275545314, &#39;ERDE_50&#39;: 0.12186875470526241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6171634055922004}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533696130667868, &#39;ERDE_50&#39;: 0.14059539575235808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5546089529229323}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25108093090863864, &#39;ERDE_50&#39;: 0.16480560988282927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4664240682952262}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7468354430379747, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6448087431693988, &#39;ERDE_5&#39;: 0.25731810275545314, &#39;ERDE_50&#39;: 0.12186875470526241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6171634055922004}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533696130667868, &#39;ERDE_50&#39;: 0.14059539575235808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5546089529229323}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25108093090863864, &#39;ERDE_50&#39;: 0.16480560988282927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4664240682952262}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26439729322098676, &#39;ERDE_50&#39;: 0.13272647312861346, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5583236741268424}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 199.9967846439995} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2218   484]]
Evaluating after getting time 12334.668153376
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2218   484]]
Evaluated with elapsed time 1301.3317851459997
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6875, &#39;ERDE_5&#39;: 0.2584829133920413, &#39;ERDE_50&#39;: 0.1061266181320945, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6553484697624494}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25337287589879065, &#39;ERDE_50&#39;: 0.1429436442207058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5441358493058512}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.25049931011454174, &#39;ERDE_50&#39;: 0.16895250603922493, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.45021628213824927}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10986   261]
 [ 2060   642]]
Evaluating after getting time 13654.005270376
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10986   261]
 [ 2060   642]]
Evaluated with elapsed time 6.663200417000553
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26439729322098676, &#39;ERDE_50&#39;: 0.13272647312861346, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5583236741268424}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.511385977268219
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 18s 33ms/step - loss: 0.5072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5072153210639954
Test Accuracy: 0.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 22s 29ms/step - loss: 0.4972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4971542954444885
Test Accuracy: 0.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 15s 24ms/step - loss: 0.5161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5161031484603882
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.5108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5107994675636292
Test Accuracy: 0.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 18s 27ms/step - loss: 0.5108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5107994675636292
Test Accuracy: 0.0
436/436 [==============================] - 11s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 210.078560725
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2550339869305229, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25105636663267294, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24933889776946042, &#39;ERDE_50&#39;: 0.17606427799905025, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.41744177725531134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26439729322098676, &#39;ERDE_50&#39;: 0.13272647312861346, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5583236741268424}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 210.078560725} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11154    93]
 [ 2222   480]]
Evaluating after getting time 20333.892315092
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11154    93]
 [ 2222   480]]
Evaluated with elapsed time 1675.1118766649997
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7472527472527473, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6974358974358975, &#39;ERDE_5&#39;: 0.25907038881332745, &#39;ERDE_50&#39;: 0.10143427884666163, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6621061638252979}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533749780415599, &#39;ERDE_50&#39;: 0.14213817170040619, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5500824392670973}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25050158465719646, &#39;ERDE_50&#39;: 0.15923190008351842, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.70      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10971   276]
 [ 2073   629]]
Evaluating after getting time 22025.625939267
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.70      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10971   276]
 [ 2073   629]]
Evaluated with elapsed time 6.592595802001597
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700744007524027, &#39;ERDE_50&#39;: 0.11838748712739833, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6521739130434783, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5202312138728323, &#39;ERDE_5&#39;: 0.25979554128056215, &#39;ERDE_50&#39;: 0.15375423206527367, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.49387806762725156}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 13s 23ms/step - loss: 0.5789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5788834691047668
Test Accuracy: 0.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 10s 17ms/step - loss: 0.4103 - tp: 327.0000 - fp: 111.0000 - tn: 11136.0000 - fn: 2375.0000 - accuracy: 0.8218 - precision: 0.7466 - recall: 0.1210 - f1_metric: 0.0721
Test Score: 0.4103216230869293
Test Accuracy: 327.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.75      0.12      0.21      2702

    accuracy                           0.82     13949
   macro avg       0.79      0.56      0.55     13949
weighted avg       0.81      0.82      0.77     13949

[[11136   111]
 [ 2375   327]]
Finished training and evaluation
{&#39;precision&#39;: 0.5591397849462365, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5279187817258884, &#39;ERDE_5&#39;: 0.26961716947863096, &#39;ERDE_50&#39;: 0.14717209726949315, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4970707149011869}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5128 - tp: 496.0000 - fp: 149.0000 - tn: 11098.0000 - fn: 2206.0000 - accuracy: 0.8312 - precision: 0.7690 - recall: 0.1836 - f1_metric: 0.1010
Test Score: 0.5127888321876526
Test Accuracy: 496.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11098   149]
 [ 2206   496]]
Finished training and evaluation
{&#39;precision&#39;: 0.5631067961165048, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5603864734299517, &#39;ERDE_5&#39;: 0.27188376554935895, &#39;ERDE_50&#39;: 0.13700590175791935, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5319991981290223}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 13s 24ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102219223976135
Test Accuracy: 0.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 12s 24ms/step - loss: 0.5131 - tp: 516.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2186.0000 - accuracy: 0.8334 - precision: 0.7890 - recall: 0.1910 - f1_metric: 0.1071
Test Score: 0.5130549669265747
Test Accuracy: 516.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2186   516]]
Finished training and evaluation
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5607476635514018, &#39;ERDE_5&#39;: 0.274789076670109, &#39;ERDE_50&#39;: 0.1372878784316655, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5312516605097932}
Evaluating for elapsed time
436/436 [==============================] - 14s 22ms/step - loss: 0.5131 - tp: 516.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2186.0000 - accuracy: 0.8334 - precision: 0.7890 - recall: 0.1910 - f1_metric: 0.1071
Test Score: 0.5130549669265747
Test Accuracy: 516.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2186   516]]
Evaluated with elapsed time 206.71065155399992
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700744007524027, &#39;ERDE_50&#39;: 0.11838748712739833, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6521739130434783, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5202312138728323, &#39;ERDE_5&#39;: 0.25979554128056215, &#39;ERDE_50&#39;: 0.15375423206527367, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.49387806762725156}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 206.71065155399992} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11154    93]
 [ 2222   480]]
Evaluating after getting time 31071.008229538
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11154    93]
 [ 2222   480]]
Evaluated with elapsed time 1308.3195734519977
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7472527472527473, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6974358974358975, &#39;ERDE_5&#39;: 0.25907038881332745, &#39;ERDE_50&#39;: 0.10143427884666163, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6621061638252979}
Writing results to CSV file
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2533749780415599, &#39;ERDE_50&#39;: 0.14213817170040619, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5500824392670973}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25050158465719646, &#39;ERDE_50&#39;: 0.15923190008351842, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.70      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10971   276]
 [ 2073   629]]
Evaluating after getting time 32394.872465982
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.70      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10971   276]
 [ 2073   629]]
Evaluated with elapsed time 6.343960729998798
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700744007524027, &#39;ERDE_50&#39;: 0.11838748712739833, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6521739130434783, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5202312138728323, &#39;ERDE_5&#39;: 0.25979554128056215, &#39;ERDE_50&#39;: 0.15375423206527367, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.49387806762725156}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.503360390663147
Test Accuracy: 0.0
436/436 [==============================] - 8s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5160 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5160304307937622
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4911855161190033
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.494177907705307
Test Accuracy: 0.0
436/436 [==============================] - 8s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5029453635215759
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 11s 16ms/step - loss: 0.5029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5029453635215759
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 199.13552003000223
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445100977545704, &#39;ERDE_50&#39;: 0.12432514100116286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522194003167997, &#39;ERDE_50&#39;: 0.15307783543069414, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505030378934408, &#39;ERDE_50&#39;: 0.17105216372672816, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231819155277796, &#39;speed&#39;: 0.937681808447222, &#39;latency_weighted_f1&#39;: 0.4367285135233637}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700744007524027, &#39;ERDE_50&#39;: 0.11838748712739833, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6521739130434783, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5202312138728323, &#39;ERDE_5&#39;: 0.25979554128056215, &#39;ERDE_50&#39;: 0.15375423206527367, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.49387806762725156}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 199.13552003000223} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 38333.615552664
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 996.3557928299997
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluating after getting time 39343.432860852
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluated with elapsed time 5.586335070001951
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6638 - tp: 1873.0000 - fp: 2455.0000 - tn: 8792.0000 - fn: 829.0000 - accuracy: 0.7646 - precision: 0.4328 - recall: 0.6932 - f1_metric: 0.2518
Test Score: 0.6638481020927429
Test Accuracy: 1873.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.78      0.84     11247
           1       0.43      0.69      0.53      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.74      0.69     13949
weighted avg       0.82      0.76      0.78     13949

[[8792 2455]
 [ 829 1873]]
Finished training and evaluation
{&#39;precision&#39;: 0.3671875, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5222222222222223, &#39;ERDE_5&#39;: 0.33958970512621445, &#39;ERDE_50&#39;: 0.11780102500411042, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5018658751771433}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.7050 - tp: 1633.0000 - fp: 1975.0000 - tn: 9272.0000 - fn: 1069.0000 - accuracy: 0.7818 - precision: 0.4526 - recall: 0.6044 - f1_metric: 0.2300
Test Score: 0.7049650549888611
Test Accuracy: 1633.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.60      0.52      2702

    accuracy                           0.78     13949
   macro avg       0.67      0.71      0.69     13949
weighted avg       0.81      0.78      0.79     13949

[[9272 1975]
 [1069 1633]]
Finished training and evaluation
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.8397 - tp: 1788.0000 - fp: 2381.0000 - tn: 8866.0000 - fn: 914.0000 - accuracy: 0.7638 - precision: 0.4289 - recall: 0.6617 - f1_metric: 0.2469
Test Score: 0.8396896719932556
Test Accuracy: 1788.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.79      0.84     11247
           1       0.43      0.66      0.52      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.73      0.68     13949
weighted avg       0.81      0.76      0.78     13949

[[8866 2381]
 [ 914 1788]]
Finished training and evaluation
{&#39;precision&#39;: 0.34782608695652173, &#39;recall&#39;: 0.9230769230769231, &#39;F1&#39;: 0.5052631578947369, &#39;ERDE_5&#39;: 0.35004284865763213, &#39;ERDE_50&#39;: 0.12353798078484782, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48556787923074113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 21.6905 - tp: 2297.0000 - fp: 5588.0000 - tn: 5659.0000 - fn: 405.0000 - accuracy: 0.5704 - precision: 0.2913 - recall: 0.8501 - f1_metric: 0.2506
Test Score: 21.69049835205078
Test Accuracy: 2297.0
436/436 [==============================] - 8s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.50      0.65     11247
           1       0.29      0.85      0.43      2702

    accuracy                           0.57     13949
   macro avg       0.61      0.68      0.54     13949
weighted avg       0.81      0.57      0.61     13949

[[5659 5588]
 [ 405 2297]]
Finished training and evaluation
{&#39;precision&#39;: 0.28901734104046245, &#39;recall&#39;: 0.9615384615384616, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.3883392304169796, &#39;ERDE_50&#39;: 0.15244035415949747, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4271198937677815}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00034: early stopping
Evaluating
436/436 [==============================] - 13s 23ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Finished training and evaluation
{&#39;precision&#39;: 0.2849162011173184, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.44155844155844154, &#39;ERDE_5&#39;: 0.39416086256759053, &#39;ERDE_50&#39;: 0.15352459690148623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42434638796409463}
Evaluating for elapsed time
436/436 [==============================] - 12s 18ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Evaluated with elapsed time 196.40316967500257
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Writing results to CSV file
{&#39;precision&#39;: 0.4090909090909091, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.3212894776241683, &#39;ERDE_50&#39;: 0.11049814093392929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5317368325017546}
Writing results to CSV file
{&#39;precision&#39;: 0.41968911917098445, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.3109184332473117, &#39;ERDE_50&#39;: 0.12183848257490924, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 196.40316967500257} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 48569.903780916
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 775.556288163003
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluating after getting time 49364.517215799
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluated with elapsed time 5.094184652996773
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 2.4027 - tp: 2392.0000 - fp: 6611.0000 - tn: 4636.0000 - fn: 310.0000 - accuracy: 0.5038 - precision: 0.2657 - recall: 0.8853 - f1_metric: 0.2488
Test Score: 2.4026808738708496
Test Accuracy: 2392.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.41      0.57     11247
           1       0.27      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.54     13949

[[4636 6611]
 [ 310 2392]]
Finished training and evaluation
{&#39;precision&#39;: 0.2670157068062827, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.4197530864197531, &#39;ERDE_5&#39;: 0.4080746548120302, &#39;ERDE_50&#39;: 0.1674742495675605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.40339101078068257}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 13.3630 - tp: 2690.0000 - fp: 10687.0000 - tn: 560.0000 - fn: 12.0000 - accuracy: 0.2330 - precision: 0.2011 - recall: 0.9956 - f1_metric: 0.2346
Test Score: 13.36298656463623
Test Accuracy: 2690.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.98      0.05      0.09     11247
           1       0.20      1.00      0.33      2702

    accuracy                           0.23     13949
   macro avg       0.59      0.52      0.21     13949
weighted avg       0.83      0.23      0.14     13949

[[  560 10687]
 [   12  2690]]
Finished training and evaluation
{&#39;precision&#39;: 0.24644549763033174, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3954372623574145, &#39;ERDE_5&#39;: 0.4300880481201669, &#39;ERDE_50&#39;: 0.1848330902201432, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.38002302335232274}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 14s 23ms/step - loss: 2.0498 - tp: 2273.0000 - fp: 5233.0000 - tn: 6014.0000 - fn: 429.0000 - accuracy: 0.5941 - precision: 0.3028 - recall: 0.8412 - f1_metric: 0.2529
Test Score: 2.049755811691284
Test Accuracy: 2273.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.53      0.68     11247
           1       0.30      0.84      0.45      2702

    accuracy                           0.59     13949
   macro avg       0.62      0.69      0.56     13949
weighted avg       0.81      0.59      0.63     13949

[[6014 5233]
 [ 429 2273]]
Finished training and evaluation
{&#39;precision&#39;: 0.28994082840236685, &#39;recall&#39;: 0.9423076923076923, &#39;F1&#39;: 0.4434389140271493, &#39;ERDE_5&#39;: 0.38485709880709723, &#39;ERDE_50&#39;: 0.1536810690406908, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42615355916649694}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 21ms/step - loss: 1.4021 - tp: 2687.0000 - fp: 10984.0000 - tn: 263.0000 - fn: 15.0000 - accuracy: 0.2115 - precision: 0.1965 - recall: 0.9944 - f1_metric: 0.2314
Test Score: 1.4021421670913696
Test Accuracy: 2687.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.02      0.05     11247
           1       0.20      0.99      0.33      2702

    accuracy                           0.21     13949
   macro avg       0.57      0.51      0.19     13949
weighted avg       0.80      0.21      0.10     13949

[[  263 10984]
 [   15  2687]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Finished training and evaluation
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Evaluated with elapsed time 177.34767557400482
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Writing results to CSV file
{&#39;precision&#39;: 0.42780748663101603, &#39;recall&#39;: 0.7692307692307693, &#39;F1&#39;: 0.549828178694158, &#39;ERDE_5&#39;: 0.3079335104772061, &#39;ERDE_50&#39;: 0.11893217008086455, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5262550094862726}
Writing results to CSV file
{&#39;precision&#39;: 0.4277456647398844, &#39;recall&#39;: 0.7115384615384616, &#39;F1&#39;: 0.5342960288808665, &#39;ERDE_5&#39;: 0.3033662849152717, &#39;ERDE_50&#39;: 0.12875241328919224, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5093092144396063}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 177.34767557400482} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 57458.787773708
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 1499.7877544380026
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluating after getting time 58973.651984022
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluated with elapsed time 5.599555535998661
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 11s 19ms/step - loss: 0.6638 - tp: 1873.0000 - fp: 2455.0000 - tn: 8792.0000 - fn: 829.0000 - accuracy: 0.7646 - precision: 0.4328 - recall: 0.6932 - f1_metric: 0.2518
Test Score: 0.6638481020927429
Test Accuracy: 1873.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.78      0.84     11247
           1       0.43      0.69      0.53      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.74      0.69     13949
weighted avg       0.82      0.76      0.78     13949

[[8792 2455]
 [ 829 1873]]
Finished training and evaluation
{&#39;precision&#39;: 0.3671875, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5222222222222223, &#39;ERDE_5&#39;: 0.33958970512621445, &#39;ERDE_50&#39;: 0.11780102500411042, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5018658751771433}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.7050 - tp: 1633.0000 - fp: 1975.0000 - tn: 9272.0000 - fn: 1069.0000 - accuracy: 0.7818 - precision: 0.4526 - recall: 0.6044 - f1_metric: 0.2300
Test Score: 0.7049650549888611
Test Accuracy: 1633.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.60      0.52      2702

    accuracy                           0.78     13949
   macro avg       0.67      0.71      0.69     13949
weighted avg       0.81      0.78      0.79     13949

[[9272 1975]
 [1069 1633]]
Finished training and evaluation
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.8397 - tp: 1788.0000 - fp: 2381.0000 - tn: 8866.0000 - fn: 914.0000 - accuracy: 0.7638 - precision: 0.4289 - recall: 0.6617 - f1_metric: 0.2469
Test Score: 0.8396896719932556
Test Accuracy: 1788.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.79      0.84     11247
           1       0.43      0.66      0.52      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.73      0.68     13949
weighted avg       0.81      0.76      0.78     13949

[[8866 2381]
 [ 914 1788]]
Finished training and evaluation
{&#39;precision&#39;: 0.34782608695652173, &#39;recall&#39;: 0.9230769230769231, &#39;F1&#39;: 0.5052631578947369, &#39;ERDE_5&#39;: 0.35004284865763213, &#39;ERDE_50&#39;: 0.12353798078484782, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48556787923074113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 12s 21ms/step - loss: 21.6905 - tp: 2297.0000 - fp: 5588.0000 - tn: 5659.0000 - fn: 405.0000 - accuracy: 0.5704 - precision: 0.2913 - recall: 0.8501 - f1_metric: 0.2506
Test Score: 21.69049835205078
Test Accuracy: 2297.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.50      0.65     11247
           1       0.29      0.85      0.43      2702

    accuracy                           0.57     13949
   macro avg       0.61      0.68      0.54     13949
weighted avg       0.81      0.57      0.61     13949

[[5659 5588]
 [ 405 2297]]
Finished training and evaluation
{&#39;precision&#39;: 0.28901734104046245, &#39;recall&#39;: 0.9615384615384616, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.3883392304169796, &#39;ERDE_50&#39;: 0.15244035415949747, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4271198937677815}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00034: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Finished training and evaluation
{&#39;precision&#39;: 0.2849162011173184, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.44155844155844154, &#39;ERDE_5&#39;: 0.39416086256759053, &#39;ERDE_50&#39;: 0.15352459690148623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42434638796409463}
Evaluating for elapsed time
436/436 [==============================] - 16s 23ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Evaluated with elapsed time 196.978245418999
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Writing results to CSV file
{&#39;precision&#39;: 0.4090909090909091, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.3212894776241683, &#39;ERDE_50&#39;: 0.11049814093392929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5317368325017546}
Writing results to CSV file
{&#39;precision&#39;: 0.41968911917098445, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.3109184332473117, &#39;ERDE_50&#39;: 0.12183848257490924, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 196.978245418999} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 67269.761778443
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 768.3511660770018
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluating after getting time 68053.933882795
              precision    recall  f1-score   support

           0       0.81      0.99      0.89     11247
           1       0.49      0.04      0.08      2702

    accuracy                           0.81     13949
   macro avg       0.65      0.52      0.48     13949
weighted avg       0.75      0.81      0.73     13949

[[11129   118]
 [ 2589   113]]
Evaluated with elapsed time 6.506460732998676
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 2.4027 - tp: 2392.0000 - fp: 6611.0000 - tn: 4636.0000 - fn: 310.0000 - accuracy: 0.5038 - precision: 0.2657 - recall: 0.8853 - f1_metric: 0.2488
Test Score: 2.4026808738708496
Test Accuracy: 2392.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.41      0.57     11247
           1       0.27      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.54     13949

[[4636 6611]
 [ 310 2392]]
Finished training and evaluation
{&#39;precision&#39;: 0.2670157068062827, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.4197530864197531, &#39;ERDE_5&#39;: 0.4080746548120302, &#39;ERDE_50&#39;: 0.1674742495675605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.40339101078068257}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 22s 33ms/step - loss: 13.3630 - tp: 2690.0000 - fp: 10687.0000 - tn: 560.0000 - fn: 12.0000 - accuracy: 0.2330 - precision: 0.2011 - recall: 0.9956 - f1_metric: 0.2346
Test Score: 13.36298656463623
Test Accuracy: 2690.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.98      0.05      0.09     11247
           1       0.20      1.00      0.33      2702

    accuracy                           0.23     13949
   macro avg       0.59      0.52      0.21     13949
weighted avg       0.83      0.23      0.14     13949

[[  560 10687]
 [   12  2690]]
Finished training and evaluation
{&#39;precision&#39;: 0.24644549763033174, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3954372623574145, &#39;ERDE_5&#39;: 0.4300880481201669, &#39;ERDE_50&#39;: 0.1848330902201432, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.38002302335232274}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 2.0498 - tp: 2273.0000 - fp: 5233.0000 - tn: 6014.0000 - fn: 429.0000 - accuracy: 0.5941 - precision: 0.3028 - recall: 0.8412 - f1_metric: 0.2529
Test Score: 2.049755811691284
Test Accuracy: 2273.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.53      0.68     11247
           1       0.30      0.84      0.45      2702

    accuracy                           0.59     13949
   macro avg       0.62      0.69      0.56     13949
weighted avg       0.81      0.59      0.63     13949

[[6014 5233]
 [ 429 2273]]
Finished training and evaluation
{&#39;precision&#39;: 0.28994082840236685, &#39;recall&#39;: 0.9423076923076923, &#39;F1&#39;: 0.4434389140271493, &#39;ERDE_5&#39;: 0.38485709880709723, &#39;ERDE_50&#39;: 0.1536810690406908, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42615355916649694}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 13s 24ms/step - loss: 1.4021 - tp: 2687.0000 - fp: 10984.0000 - tn: 263.0000 - fn: 15.0000 - accuracy: 0.2115 - precision: 0.1965 - recall: 0.9944 - f1_metric: 0.2314
Test Score: 1.4021421670913696
Test Accuracy: 2687.0
436/436 [==============================] - 10s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.02      0.05     11247
           1       0.20      0.99      0.33      2702

    accuracy                           0.21     13949
   macro avg       0.57      0.51      0.19     13949
weighted avg       0.80      0.21      0.10     13949

[[  263 10984]
 [   15  2687]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 16s 24ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Finished training and evaluation
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Evaluating for elapsed time
436/436 [==============================] - 9s 17ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Evaluated with elapsed time 193.6192899000016
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Writing results to CSV file
{&#39;precision&#39;: 0.42780748663101603, &#39;recall&#39;: 0.7692307692307693, &#39;F1&#39;: 0.549828178694158, &#39;ERDE_5&#39;: 0.3079335104772061, &#39;ERDE_50&#39;: 0.11893217008086455, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5262550094862726}
Writing results to CSV file
{&#39;precision&#39;: 0.4277456647398844, &#39;recall&#39;: 0.7115384615384616, &#39;F1&#39;: 0.5342960288808665, &#39;ERDE_5&#39;: 0.3033662849152717, &#39;ERDE_50&#39;: 0.12875241328919224, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5093092144396063}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6451612903225806, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29629629629629634, &#39;ERDE_5&#39;: 0.2521852853822935, &#39;ERDE_50&#39;: 0.20497515774414984, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.2847465958451877}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.29411764705882354, &#39;ERDE_5&#39;: 0.25276652151506124, &#39;ERDE_50&#39;: 0.2055563938769176, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.28265287087573776}
Writing results to CSV file
{&#39;precision&#39;: 0.5769230769230769, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.23076923076923075, &#39;ERDE_5&#39;: 0.2522367510904967, &#39;ERDE_50&#39;: 0.21679548871344545, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.22087529965457497}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.21705426356589147, &#39;ERDE_5&#39;: 0.25225001183688517, &#39;ERDE_50&#39;: 0.21915955490737646, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.20690353379392343}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 193.6192899000016} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluating after getting time 76493.483693371
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluated with elapsed time 750.2980516370008
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7252747252747253, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6769230769230768, &#39;ERDE_5&#39;: 0.2602099204885222, &#39;ERDE_50&#39;: 0.10811040451523657, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6465835322995055}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6242774566473989, &#39;ERDE_5&#39;: 0.25452544543166006, &#39;ERDE_50&#39;: 0.12963995592723004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5950825831579152}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25049925192367656, &#39;ERDE_50&#39;: 0.1583142227856328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluating after getting time 77260.78164045
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluated with elapsed time 5.514645784001914
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.5205 - tp: 409.0000 - fp: 85.0000 - tn: 11162.0000 - fn: 2293.0000 - accuracy: 0.8295 - precision: 0.8279 - recall: 0.1514 - f1_metric: 0.0832
Test Score: 0.5204916000366211
Test Accuracy: 409.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.15      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.58     13949
weighted avg       0.83      0.83      0.78     13949

[[11162    85]
 [ 2293   409]]
Finished training and evaluation
{&#39;precision&#39;: 0.6794871794871795, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5824175824175823, &#39;ERDE_5&#39;: 0.2602910134248677, &#39;ERDE_50&#39;: 0.13693204464176645, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5529142859675543}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4000 - tp: 584.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2118.0000 - accuracy: 0.8344 - precision: 0.7526 - recall: 0.2161 - f1_metric: 0.1211
Test Score: 0.400028258562088
Test Accuracy: 584.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.6055045871559633, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.619718309859155, &#39;ERDE_5&#39;: 0.27069331202449276, &#39;ERDE_50&#39;: 0.11603158997275352, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5895310670274139}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.4022 - tp: 623.0000 - fp: 188.0000 - tn: 11059.0000 - fn: 2079.0000 - accuracy: 0.8375 - precision: 0.7682 - recall: 0.2306 - f1_metric: 0.1231
Test Score: 0.40219637751579285
Test Accuracy: 623.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.23      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.61      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11059   188]
 [ 2079   623]]
Finished training and evaluation
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.6176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.617611825466156
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.5596330275229358, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5727699530516431, &#39;ERDE_5&#39;: 0.2735923421691488, &#39;ERDE_50&#39;: 0.1298676685075436, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.548213185058147}
Evaluating for elapsed time
436/436 [==============================] - 12s 20ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Evaluated with elapsed time 211.31381711100403
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Writing results to CSV file
{&#39;precision&#39;: 0.6744186046511628, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6105263157894736, &#39;ERDE_5&#39;: 0.26208100053306677, &#39;ERDE_50&#39;: 0.12561273950461457, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5784118956357502}
Writing results to CSV file
{&#39;precision&#39;: 0.7205882352941176, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5697674418604651, &#39;ERDE_5&#39;: 0.2568923025147678, &#39;ERDE_50&#39;: 0.14330145840852437, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5342600273131639}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.2567235883154993, &#39;ERDE_50&#39;: 0.1215188045500775, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.25336365864084154, &#39;ERDE_50&#39;: 0.13112335341772507, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5866056232838709}
Writing results to CSV file
{&#39;precision&#39;: 0.8409090909090909, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2499182805879903, &#39;ERDE_50&#39;: 0.16246111894272472, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4707833213246818}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7176470588235294, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6455026455026455, &#39;ERDE_5&#39;: 0.2596196200909691, &#39;ERDE_50&#39;: 0.11575916728498295, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6203407980913017}
Writing results to CSV file
{&#39;precision&#39;: 0.7368421052631579, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6222222222222222, &#39;ERDE_5&#39;: 0.2574266597368462, &#39;ERDE_50&#39;: 0.12549382420788652, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5931234635425805}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.2539836532274734, &#39;ERDE_50&#39;: 0.15499122090567521, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.76, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6368715083798883, &#39;ERDE_5&#39;: 0.2561611714557076, &#39;ERDE_50&#39;: 0.12762081168746775, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6095664694377656}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5952380952380952, &#39;ERDE_5&#39;: 0.253949045532347, &#39;ERDE_50&#39;: 0.13623332542047709, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5639278539141654}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522439983591769, &#39;ERDE_50&#39;: 0.15469399516586682, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.5027286324226619}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 211.31381711100403} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluating after getting time 85720.318109774
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluated with elapsed time 809.3471150169935
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7252747252747253, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6769230769230768, &#39;ERDE_5&#39;: 0.2602099204885222, &#39;ERDE_50&#39;: 0.10811040451523657, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6465835322995055}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6242774566473989, &#39;ERDE_5&#39;: 0.25452544543166006, &#39;ERDE_50&#39;: 0.12963995592723004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5950825831579152}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25049925192367656, &#39;ERDE_50&#39;: 0.1583142227856328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluating after getting time 86545.139513691
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluated with elapsed time 5.4216889109957265
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5012255311012268
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 15ms/step - loss: 0.5095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5095410346984863
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00035: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4506 - tp: 982.0000 - fp: 621.0000 - tn: 10626.0000 - fn: 1720.0000 - accuracy: 0.8322 - precision: 0.6126 - recall: 0.3634 - f1_metric: 0.1773
Test Score: 0.45056480169296265
Test Accuracy: 982.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.94      0.90     11247
           1       0.61      0.36      0.46      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.65      0.68     13949
weighted avg       0.81      0.83      0.81     13949

[[10626   621]
 [ 1720   982]]
Finished training and evaluation
{&#39;precision&#39;: 0.4880952380952381, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.6029411764705882, &#39;ERDE_5&#39;: 0.29556808679097213, &#39;ERDE_50&#39;: 0.1043756921166237, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5794383852952624}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5211 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5210582613945007
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 15ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 8s 14ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 213.17965064800228
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 213.17965064800228} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluating after getting time 93564.128824718
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluated with elapsed time 964.0073927829944
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25849361896774087, &#39;ERDE_50&#39;: 0.11364270037434163, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6354894252241934}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.25394921117838753, &#39;ERDE_50&#39;: 0.1357968918591065, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5753247459130271}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5234899328859061, &#39;ERDE_5&#39;: 0.24933667957653524, &#39;ERDE_50&#39;: 0.15778755849526319, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.490866492701918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluating after getting time 94545.735644742
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluated with elapsed time 6.066768828997738
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5936288833618164
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 10s 17ms/step - loss: 0.3994 - tp: 512.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2190.0000 - accuracy: 0.8331 - precision: 0.7877 - recall: 0.1895 - f1_metric: 0.1028
Test Score: 0.3994370400905609
Test Accuracy: 512.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2190   512]]
Finished training and evaluation
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6494845360824743, &#39;ERDE_5&#39;: 0.26140644379269445, &#39;ERDE_50&#39;: 0.11262328232115389, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6165838555635069}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4017 - tp: 568.0000 - fp: 194.0000 - tn: 11053.0000 - fn: 2134.0000 - accuracy: 0.8331 - precision: 0.7454 - recall: 0.2102 - f1_metric: 0.1139
Test Score: 0.4016605317592621
Test Accuracy: 568.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.75      0.21      0.33      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.60      0.62     13949
weighted avg       0.82      0.83      0.79     13949

[[11053   194]
 [ 2134   568]]
Finished training and evaluation
{&#39;precision&#39;: 0.6017699115044248, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6267281105990784, &#39;ERDE_5&#39;: 0.27183954873518135, &#39;ERDE_50&#39;: 0.11328805467567826, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5986382934151268}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 23ms/step - loss: 0.6187 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6187241673469543
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Finished training and evaluation
{&#39;precision&#39;: 0.6444444444444445, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5979381443298969, &#39;ERDE_5&#39;: 0.2643079528067778, &#39;ERDE_50&#39;: 0.12768686242459712, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5688118402106115}
Evaluating for elapsed time
436/436 [==============================] - 8s 13ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Evaluated with elapsed time 195.0279512410052
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 195.0279512410052} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluating after getting time 101865.051234904
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluated with elapsed time 966.9810828200134
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25849361896774087, &#39;ERDE_50&#39;: 0.11364270037434163, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6354894252241934}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.25394921117838753, &#39;ERDE_50&#39;: 0.1357968918591065, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5753247459130271}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5234899328859061, &#39;ERDE_5&#39;: 0.24933667957653524, &#39;ERDE_50&#39;: 0.15778755849526319, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.490866492701918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluating after getting time 102850.899836801
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluated with elapsed time 5.723359155992512
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 19s 34ms/step - loss: 0.5063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062928795814514
Test Accuracy: 0.0
436/436 [==============================] - 11s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.4938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49377965927124023
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 22s 37ms/step - loss: 0.4958 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49575263261795044
Test Accuracy: 0.0
436/436 [==============================] - 15s 34ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 20s 37ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5005954504013062
Test Accuracy: 0.0
436/436 [==============================] - 13s 28ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 15s 28ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 11s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 20s 33ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 13s 30ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 223.4444551810011
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 223.4444551810011} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 109190.786932388
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 718.0965742029948
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluating after getting time 109921.994807598
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluated with elapsed time 6.590156991995173
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 1.8411 - tp: 2607.0000 - fp: 9393.0000 - tn: 1854.0000 - fn: 95.0000 - accuracy: 0.3198 - precision: 0.2173 - recall: 0.9648 - f1_metric: 0.2398
Test Score: 1.8410987854003906
Test Accuracy: 2607.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.16      0.28     11247
           1       0.22      0.96      0.35      2702

    accuracy                           0.32     13949
   macro avg       0.58      0.56      0.32     13949
weighted avg       0.81      0.32      0.30     13949

[[1854 9393]
 [  95 2607]]
Finished training and evaluation
{&#39;precision&#39;: 0.2549019607843137, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.40625, &#39;ERDE_5&#39;: 0.42199367926099673, &#39;ERDE_50&#39;: 0.17669578436142755, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3904142778971128}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 15s 25ms/step - loss: 1.0303 - tp: 1993.0000 - fp: 2992.0000 - tn: 8255.0000 - fn: 709.0000 - accuracy: 0.7347 - precision: 0.3998 - recall: 0.7376 - f1_metric: 0.2542
Test Score: 1.030272364616394
Test Accuracy: 1993.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.73      0.82     11247
           1       0.40      0.74      0.52      2702

    accuracy                           0.73     13949
   macro avg       0.66      0.74      0.67     13949
weighted avg       0.82      0.73      0.76     13949

[[8255 2992]
 [ 709 1993]]
Finished training and evaluation
{&#39;precision&#39;: 0.33916083916083917, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.49743589743589745, &#39;ERDE_5&#39;: 0.3552429735866426, &#39;ERDE_50&#39;: 0.12641791479377032, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47804572725547856}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 14s 23ms/step - loss: 0.6222 - tp: 1716.0000 - fp: 2059.0000 - tn: 9188.0000 - fn: 986.0000 - accuracy: 0.7817 - precision: 0.4546 - recall: 0.6351 - f1_metric: 0.2350
Test Score: 0.6222425103187561
Test Accuracy: 1716.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.64      0.53      2702

    accuracy                           0.78     13949
   macro avg       0.68      0.73      0.69     13949
weighted avg       0.82      0.78      0.79     13949

[[9188 2059]
 [ 986 1716]]
Finished training and evaluation
{&#39;precision&#39;: 0.3467153284671533, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.5026455026455027, &#39;ERDE_5&#39;: 0.3494565491730302, &#39;ERDE_50&#39;: 0.12531894827977272, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48305226080880054}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 13s 23ms/step - loss: 28.4680 - tp: 2395.0000 - fp: 6703.0000 - tn: 4544.0000 - fn: 307.0000 - accuracy: 0.4975 - precision: 0.2632 - recall: 0.8864 - f1_metric: 0.2481
Test Score: 28.467981338500977
Test Accuracy: 2395.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.40      0.56     11247
           1       0.26      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.53     13949

[[4544 6703]
 [ 307 2395]]
Finished training and evaluation
{&#39;precision&#39;: 0.2724867724867725, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.42738589211618255, &#39;ERDE_5&#39;: 0.4051767502640007, &#39;ERDE_50&#39;: 0.1622041100334401, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.41072628788665294}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Finished training and evaluation
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Evaluating for elapsed time
436/436 [==============================] - 15s 23ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Evaluated with elapsed time 195.05066297699523
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Writing results to CSV file
{&#39;precision&#39;: 0.37872340425531914, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5250737463126843, &#39;ERDE_5&#39;: 0.330569517623507, &#39;ERDE_50&#39;: 0.12204974523208358, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.502561891249446}
Writing results to CSV file
{&#39;precision&#39;: 0.37327188940092165, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5046728971962617, &#39;ERDE_5&#39;: 0.3248608206651402, &#39;ERDE_50&#39;: 0.136139710927823, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4810714340482212}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5390625, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5948275862068966, &#39;ERDE_5&#39;: 0.27990027247132604, &#39;ERDE_50&#39;: 0.11979331536549008, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.57164106471938}
Writing results to CSV file
{&#39;precision&#39;: 0.5675675675675675, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5860465116279069, &#39;ERDE_5&#39;: 0.27368311940996654, &#39;ERDE_50&#39;: 0.13129848952472944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5609205284251066}
Writing results to CSV file
{&#39;precision&#39;: 0.5494505494505495, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5128205128205129, &#39;ERDE_5&#39;: 0.26967093935147823, &#39;ERDE_50&#39;: 0.1563333911587042, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.48883801940322574}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 195.05066297699523} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 118112.124944016
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 464.3349926009978
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluating after getting time 118590.644995912
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluated with elapsed time 6.969228930000099
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 1.2387 - tp: 2107.0000 - fp: 4122.0000 - tn: 7125.0000 - fn: 595.0000 - accuracy: 0.6618 - precision: 0.3383 - recall: 0.7798 - f1_metric: 0.2513
Test Score: 1.2387062311172485
Test Accuracy: 2107.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75     11247
           1       0.34      0.78      0.47      2702

    accuracy                           0.66     13949
   macro avg       0.63      0.71      0.61     13949
weighted avg       0.81      0.66      0.70     13949

[[7125 4122]
 [ 595 2107]]
Finished training and evaluation
{&#39;precision&#39;: 0.3089171974522293, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.46411483253588515, &#39;ERDE_5&#39;: 0.3715099833486213, &#39;ERDE_50&#39;: 0.1426777887430125, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4460235254297527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 1.1399 - tp: 1889.0000 - fp: 2783.0000 - tn: 8464.0000 - fn: 813.0000 - accuracy: 0.7422 - precision: 0.4043 - recall: 0.6991 - f1_metric: 0.2450
Test Score: 1.139872431755066
Test Accuracy: 1889.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.75      0.82     11247
           1       0.40      0.70      0.51      2702

    accuracy                           0.74     13949
   macro avg       0.66      0.73      0.67     13949
weighted avg       0.81      0.74      0.76     13949

[[8464 2783]
 [ 813 1889]]
Finished training and evaluation
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 1.8779 - tp: 2518.0000 - fp: 7650.0000 - tn: 3597.0000 - fn: 184.0000 - accuracy: 0.4384 - precision: 0.2476 - recall: 0.9319 - f1_metric: 0.2559
Test Score: 1.8779231309890747
Test Accuracy: 2518.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.32      0.48     11247
           1       0.25      0.93      0.39      2702

    accuracy                           0.44     13949
   macro avg       0.60      0.63      0.44     13949
weighted avg       0.82      0.44      0.46     13949

[[3597 7650]
 [ 184 2518]]
Finished training and evaluation
{&#39;precision&#39;: 0.2594458438287154, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.4111776447105789, &#39;ERDE_5&#39;: 0.4161876896193017, &#39;ERDE_50&#39;: 0.17324748922757083, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3951498418390554}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 13s 23ms/step - loss: 2.6045 - tp: 2692.0000 - fp: 11232.0000 - tn: 15.0000 - fn: 10.0000 - accuracy: 0.1941 - precision: 0.1933 - recall: 0.9963 - f1_metric: 0.2296
Test Score: 2.6044859886169434
Test Accuracy: 2692.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.60      0.00      0.00     11247
           1       0.19      1.00      0.32      2702

    accuracy                           0.19     13949
   macro avg       0.40      0.50      0.16     13949
weighted avg       0.52      0.19      0.06     13949

[[   15 11232]
 [   10  2692]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 15s 28ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Finished training and evaluation
{&#39;precision&#39;: 0.24821002386634844, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.39770554493307836, &#39;ERDE_5&#39;: 0.4283501706414428, &#39;ERDE_50&#39;: 0.18308938182183992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3822028877310167}
Evaluating for elapsed time
436/436 [==============================] - 12s 20ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Evaluated with elapsed time 208.16373446000216
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Writing results to CSV file
{&#39;precision&#39;: 0.3723849372384937, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5189504373177842, &#39;ERDE_5&#39;: 0.33289417733800136, &#39;ERDE_50&#39;: 0.12474453796969241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4967011111765661}
Writing results to CSV file
{&#39;precision&#39;: 0.37272727272727274, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.326022395106226, &#39;ERDE_50&#39;: 0.13436075741070738, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4825012302628135}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5147058823529411, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.2839689251154769, &#39;ERDE_50&#39;: 0.12122194389844017, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5605948605702132}
Writing results to CSV file
{&#39;precision&#39;: 0.5416666666666666, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5803571428571429, &#39;ERDE_5&#39;: 0.27775177201454054, &#39;ERDE_50&#39;: 0.13011533795505117, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5554750839527258}
Writing results to CSV file
{&#39;precision&#39;: 0.5288461538461539, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5288461538461539, &#39;ERDE_5&#39;: 0.2743200355174701, &#39;ERDE_50&#39;: 0.14945061281977112, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5041142075095765}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 208.16373446000216} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 125299.982834653
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 428.5602351240086
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluating after getting time 125744.587895303
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluated with elapsed time 6.121612474002177
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 1.8411 - tp: 2607.0000 - fp: 9393.0000 - tn: 1854.0000 - fn: 95.0000 - accuracy: 0.3198 - precision: 0.2173 - recall: 0.9648 - f1_metric: 0.2398
Test Score: 1.8410987854003906
Test Accuracy: 2607.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.16      0.28     11247
           1       0.22      0.96      0.35      2702

    accuracy                           0.32     13949
   macro avg       0.58      0.56      0.32     13949
weighted avg       0.81      0.32      0.30     13949

[[1854 9393]
 [  95 2607]]
Finished training and evaluation
{&#39;precision&#39;: 0.2549019607843137, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.40625, &#39;ERDE_5&#39;: 0.42199367926099673, &#39;ERDE_50&#39;: 0.17669578436142755, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3904142778971128}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 1.0303 - tp: 1993.0000 - fp: 2992.0000 - tn: 8255.0000 - fn: 709.0000 - accuracy: 0.7347 - precision: 0.3998 - recall: 0.7376 - f1_metric: 0.2542
Test Score: 1.030272364616394
Test Accuracy: 1993.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.73      0.82     11247
           1       0.40      0.74      0.52      2702

    accuracy                           0.73     13949
   macro avg       0.66      0.74      0.67     13949
weighted avg       0.82      0.73      0.76     13949

[[8255 2992]
 [ 709 1993]]
Finished training and evaluation
{&#39;precision&#39;: 0.33916083916083917, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.49743589743589745, &#39;ERDE_5&#39;: 0.3552429735866426, &#39;ERDE_50&#39;: 0.12641791479377032, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47804572725547856}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.6222 - tp: 1716.0000 - fp: 2059.0000 - tn: 9188.0000 - fn: 986.0000 - accuracy: 0.7817 - precision: 0.4546 - recall: 0.6351 - f1_metric: 0.2350
Test Score: 0.6222425103187561
Test Accuracy: 1716.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.64      0.53      2702

    accuracy                           0.78     13949
   macro avg       0.68      0.73      0.69     13949
weighted avg       0.82      0.78      0.79     13949

[[9188 2059]
 [ 986 1716]]
Finished training and evaluation
{&#39;precision&#39;: 0.3467153284671533, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.5026455026455027, &#39;ERDE_5&#39;: 0.3494565491730302, &#39;ERDE_50&#39;: 0.12531894827977272, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48305226080880054}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 14s 27ms/step - loss: 28.4680 - tp: 2395.0000 - fp: 6703.0000 - tn: 4544.0000 - fn: 307.0000 - accuracy: 0.4975 - precision: 0.2632 - recall: 0.8864 - f1_metric: 0.2481
Test Score: 28.467981338500977
Test Accuracy: 2395.0
436/436 [==============================] - 11s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.40      0.56     11247
           1       0.26      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.53     13949

[[4544 6703]
 [ 307 2395]]
Finished training and evaluation
{&#39;precision&#39;: 0.2724867724867725, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.42738589211618255, &#39;ERDE_5&#39;: 0.4051767502640007, &#39;ERDE_50&#39;: 0.1622041100334401, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.41072628788665294}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Finished training and evaluation
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Evaluating for elapsed time
436/436 [==============================] - 8s 13ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Evaluated with elapsed time 179.0433009180124
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Writing results to CSV file
{&#39;precision&#39;: 0.37872340425531914, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5250737463126843, &#39;ERDE_5&#39;: 0.330569517623507, &#39;ERDE_50&#39;: 0.12204974523208358, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.502561891249446}
Writing results to CSV file
{&#39;precision&#39;: 0.37327188940092165, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5046728971962617, &#39;ERDE_5&#39;: 0.3248608206651402, &#39;ERDE_50&#39;: 0.136139710927823, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4810714340482212}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5390625, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5948275862068966, &#39;ERDE_5&#39;: 0.27990027247132604, &#39;ERDE_50&#39;: 0.11979331536549008, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.57164106471938}
Writing results to CSV file
{&#39;precision&#39;: 0.5675675675675675, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5860465116279069, &#39;ERDE_5&#39;: 0.27368311940996654, &#39;ERDE_50&#39;: 0.13129848952472944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5609205284251066}
Writing results to CSV file
{&#39;precision&#39;: 0.5494505494505495, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5128205128205129, &#39;ERDE_5&#39;: 0.26967093935147823, &#39;ERDE_50&#39;: 0.1563333911587042, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.48883801940322574}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5384615384615384, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5982905982905983, &#39;ERDE_5&#39;: 0.2804756631592791, &#39;ERDE_50&#39;: 0.1180104853044044, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5749690877643212}
Writing results to CSV file
{&#39;precision&#39;: 0.5663716814159292, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5898617511520737, &#39;ERDE_5&#39;: 0.2742622017574047, &#39;ERDE_50&#39;: 0.12951565946364377, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5645721945087754}
Writing results to CSV file
{&#39;precision&#39;: 0.5483870967741935, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5177664974619289, &#39;ERDE_5&#39;: 0.2702513826943394, &#39;ERDE_50&#39;: 0.1545505610976185, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4935527008086375}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 179.0433009180124} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 133041.927015294
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 448.51412162798806
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluating after getting time 133507.489123508
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.33      0.42      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.64      0.66     13949
weighted avg       0.80      0.82      0.80     13949

[[10613   634]
 [ 1811   891]]
Evaluated with elapsed time 6.787650763988495
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 1.2387 - tp: 2107.0000 - fp: 4122.0000 - tn: 7125.0000 - fn: 595.0000 - accuracy: 0.6618 - precision: 0.3383 - recall: 0.7798 - f1_metric: 0.2513
Test Score: 1.2387062311172485
Test Accuracy: 2107.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75     11247
           1       0.34      0.78      0.47      2702

    accuracy                           0.66     13949
   macro avg       0.63      0.71      0.61     13949
weighted avg       0.81      0.66      0.70     13949

[[7125 4122]
 [ 595 2107]]
Finished training and evaluation
{&#39;precision&#39;: 0.3089171974522293, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.46411483253588515, &#39;ERDE_5&#39;: 0.3715099833486213, &#39;ERDE_50&#39;: 0.1426777887430125, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4460235254297527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 1.1399 - tp: 1889.0000 - fp: 2783.0000 - tn: 8464.0000 - fn: 813.0000 - accuracy: 0.7422 - precision: 0.4043 - recall: 0.6991 - f1_metric: 0.2450
Test Score: 1.139872431755066
Test Accuracy: 1889.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.75      0.82     11247
           1       0.40      0.70      0.51      2702

    accuracy                           0.74     13949
   macro avg       0.66      0.73      0.67     13949
weighted avg       0.81      0.74      0.76     13949

[[8464 2783]
 [ 813 1889]]
Finished training and evaluation
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 14s 28ms/step - loss: 1.8779 - tp: 2518.0000 - fp: 7650.0000 - tn: 3597.0000 - fn: 184.0000 - accuracy: 0.4384 - precision: 0.2476 - recall: 0.9319 - f1_metric: 0.2559
Test Score: 1.8779231309890747
Test Accuracy: 2518.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.32      0.48     11247
           1       0.25      0.93      0.39      2702

    accuracy                           0.44     13949
   macro avg       0.60      0.63      0.44     13949
weighted avg       0.82      0.44      0.46     13949

[[3597 7650]
 [ 184 2518]]
Finished training and evaluation
{&#39;precision&#39;: 0.2594458438287154, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.4111776447105789, &#39;ERDE_5&#39;: 0.4161876896193017, &#39;ERDE_50&#39;: 0.17324748922757083, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3951498418390554}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 2.6045 - tp: 2692.0000 - fp: 11232.0000 - tn: 15.0000 - fn: 10.0000 - accuracy: 0.1941 - precision: 0.1933 - recall: 0.9963 - f1_metric: 0.2296
Test Score: 2.6044859886169434
Test Accuracy: 2692.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.60      0.00      0.00     11247
           1       0.19      1.00      0.32      2702

    accuracy                           0.19     13949
   macro avg       0.40      0.50      0.16     13949
weighted avg       0.52      0.19      0.06     13949

[[   15 11232]
 [   10  2692]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Finished training and evaluation
{&#39;precision&#39;: 0.24821002386634844, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.39770554493307836, &#39;ERDE_5&#39;: 0.4283501706414428, &#39;ERDE_50&#39;: 0.18308938182183992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3822028877310167}
Evaluating for elapsed time
436/436 [==============================] - 10s 16ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Evaluated with elapsed time 196.9667927279952
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Writing results to CSV file
{&#39;precision&#39;: 0.3723849372384937, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5189504373177842, &#39;ERDE_5&#39;: 0.33289417733800136, &#39;ERDE_50&#39;: 0.12474453796969241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4967011111765661}
Writing results to CSV file
{&#39;precision&#39;: 0.37272727272727274, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.326022395106226, &#39;ERDE_50&#39;: 0.13436075741070738, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4825012302628135}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5147058823529411, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.2839689251154769, &#39;ERDE_50&#39;: 0.12122194389844017, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5605948605702132}
Writing results to CSV file
{&#39;precision&#39;: 0.5416666666666666, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5803571428571429, &#39;ERDE_5&#39;: 0.27775177201454054, &#39;ERDE_50&#39;: 0.13011533795505117, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5554750839527258}
Writing results to CSV file
{&#39;precision&#39;: 0.5288461538461539, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5288461538461539, &#39;ERDE_5&#39;: 0.2743200355174701, &#39;ERDE_50&#39;: 0.14945061281977112, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5041142075095765}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5144927536231884, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5867768595041323, &#39;ERDE_5&#39;: 0.28454431580342987, &#39;ERDE_50&#39;: 0.11943911383735449, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5639041572677942}
Writing results to CSV file
{&#39;precision&#39;: 0.5409836065573771, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5840707964601771, &#39;ERDE_5&#39;: 0.27833085436197874, &#39;ERDE_50&#39;: 0.1283325078939655, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5590295194797209}
Writing results to CSV file
{&#39;precision&#39;: 0.5283018867924528, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2749004788603313, &#39;ERDE_50&#39;: 0.14766778275868545, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5083915401793547}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.45806451612903226, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5482625482625483, &#39;ERDE_5&#39;: 0.29442025773249053, &#39;ERDE_50&#39;: 0.12921798709357843, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5268911430841938}
Writing results to CSV file
{&#39;precision&#39;: 0.5076923076923077, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2829810278637154, &#39;ERDE_50&#39;: 0.13263099605862133, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5399173991556278}
Writing results to CSV file
{&#39;precision&#39;: 0.48695652173913045, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5114155251141552, &#39;ERDE_5&#39;: 0.28013170868984444, &#39;ERDE_50&#39;: 0.15209342687467356, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4874987371582853}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 196.9667927279952} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11154    93]
 [ 2216   486]]
Evaluating after getting time 141460.607595111
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11154    93]
 [ 2216   486]]
Evaluated with elapsed time 1154.5029770839901
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7386363636363636, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6770833333333333, &#39;ERDE_5&#39;: 0.25906784118438353, &#39;ERDE_50&#39;: 0.10907192045692309, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6454189474933213}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.2533742368942137, &#39;ERDE_50&#39;: 0.1429436442207058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5441358493058512}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510810473242704, &#39;ERDE_50&#39;: 0.16953374217199266, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44717428023190975}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10984   263]
 [ 2062   640]]
Evaluating after getting time 142632.170118236
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10984   263]
 [ 2062   640]]
Evaluated with elapsed time 5.227424539974891
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.632183908045977, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5759162303664922, &#39;ERDE_5&#39;: 0.26439944700631635, &#39;ERDE_50&#39;: 0.13509053932246687, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5512245698185729}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5864 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5864015221595764
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4044 - tp: 501.0000 - fp: 171.0000 - tn: 11076.0000 - fn: 2201.0000 - accuracy: 0.8300 - precision: 0.7455 - recall: 0.1854 - f1_metric: 0.1072
Test Score: 0.40444839000701904
Test Accuracy: 501.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.98      0.90     11247
           1       0.75      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.59      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11076   171]
 [ 2201   501]]
Finished training and evaluation
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5866666666666666, &#39;ERDE_5&#39;: 0.27769189615542506, &#39;ERDE_50&#39;: 0.12612502911273288, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.554666459594323}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4189 - tp: 368.0000 - fp: 113.0000 - tn: 11134.0000 - fn: 2334.0000 - accuracy: 0.8246 - precision: 0.7651 - recall: 0.1362 - f1_metric: 0.0769
Test Score: 0.41891103982925415
Test Accuracy: 368.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.14      0.23      2702

    accuracy                           0.82     13949
   macro avg       0.80      0.56      0.57     13949
weighted avg       0.81      0.82      0.77     13949

[[11134   113]
 [ 2334   368]]
Finished training and evaluation
{&#39;precision&#39;: 0.6276595744680851, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5959595959595959, &#39;ERDE_5&#39;: 0.26610279958858635, &#39;ERDE_50&#39;: 0.12853378919850525, &#39;median_latency_tps&#39;: 19.0, &#39;median_penalty_tps&#39;: 0.07008491072449874, &#39;speed&#39;: 0.9299150892755013, &#39;latency_weighted_f1&#39;: 0.5541918208813593}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.6198 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6198097467422485
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 14s 24ms/step - loss: 0.4676 - tp: 464.0000 - fp: 124.0000 - tn: 11123.0000 - fn: 2238.0000 - accuracy: 0.8307 - precision: 0.7891 - recall: 0.1717 - f1_metric: 0.0951
Test Score: 0.4675743877887726
Test Accuracy: 464.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.79      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11123   124]
 [ 2238   464]]
Finished training and evaluation
{&#39;precision&#39;: 0.5784313725490197, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5728155339805826, &#39;ERDE_5&#39;: 0.2707314546655556, &#39;ERDE_50&#39;: 0.13870586431451912, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5415708481255251}
Evaluating for elapsed time
436/436 [==============================] - 8s 14ms/step - loss: 0.4676 - tp: 464.0000 - fp: 124.0000 - tn: 11123.0000 - fn: 2238.0000 - accuracy: 0.8307 - precision: 0.7891 - recall: 0.1717 - f1_metric: 0.0951
Test Score: 0.4675743877887726
Test Accuracy: 464.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.79      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11123   124]
 [ 2238   464]]
Evaluated with elapsed time 205.86880073999055
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.632183908045977, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5759162303664922, &#39;ERDE_5&#39;: 0.26439944700631635, &#39;ERDE_50&#39;: 0.13509053932246687, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5512245698185729}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 205.86880073999055} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11154    93]
 [ 2216   486]]
Evaluating after getting time 150633.587504237
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11154    93]
 [ 2216   486]]
Evaluated with elapsed time 1162.956577998004
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7386363636363636, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6770833333333333, &#39;ERDE_5&#39;: 0.25906784118438353, &#39;ERDE_50&#39;: 0.10907192045692309, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6454189474933213}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.2533742368942137, &#39;ERDE_50&#39;: 0.1429436442207058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5441358493058512}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510810473242704, &#39;ERDE_50&#39;: 0.16953374217199266, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44717428023190975}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10984   263]
 [ 2062   640]]
Evaluating after getting time 151813.446921805
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.71      0.24      0.36      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.61      0.63     13949
weighted avg       0.82      0.83      0.80     13949

[[10984   263]
 [ 2062   640]]
Evaluated with elapsed time 6.4063743419828825
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.632183908045977, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5759162303664922, &#39;ERDE_5&#39;: 0.26439944700631635, &#39;ERDE_50&#39;: 0.13509053932246687, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5512245698185729}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114208459854126
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.5070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5069946050643921
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49764135479927063
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 13s 23ms/step - loss: 0.5178 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5177649259567261
Test Accuracy: 0.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.5115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114524364471436
Test Accuracy: 0.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 10s 18ms/step - loss: 0.5115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114524364471436
Test Accuracy: 0.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 210.9658673320082
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.25503767859000814, &#39;ERDE_50&#39;: 0.13700198054092333, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Writing results to CSV file
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.2510577276280959, &#39;ERDE_50&#39;: 0.15480309682354487, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.503423660936406}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24992063497918907, &#39;ERDE_50&#39;: 0.176645514131818, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2688927100010355, &#39;ERDE_50&#39;: 0.1175789544802252, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.632183908045977, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5759162303664922, &#39;ERDE_5&#39;: 0.26439944700631635, &#39;ERDE_50&#39;: 0.13509053932246687, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5512245698185729}
Writing results to CSV file
{&#39;precision&#39;: 0.6619718309859155, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5371428571428571, &#39;ERDE_5&#39;: 0.25979343910887526, &#39;ERDE_50&#39;: 0.14874429215379156, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5099330244923407}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 210.9658673320082} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11153    94]
 [ 2221   481]]
Evaluating after getting time 157698.942087038
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11153    94]
 [ 2221   481]]
Evaluated with elapsed time 1106.9235961499799
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7472527472527473, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6974358974358975, &#39;ERDE_5&#39;: 0.2590698877363665, &#39;ERDE_50&#39;: 0.10143427884666163, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6621061638252979}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539578918573327, &#39;ERDE_50&#39;: 0.14271940783317394, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.547893278790823}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505023096067703, &#39;ERDE_50&#39;: 0.1592319000883911, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4843649497522238}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10966   281]
 [ 2074   628]]
Evaluating after getting time 158822.291423797
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10966   281]
 [ 2074   628]]
Evaluated with elapsed time 5.637722172017675
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700765544398614, &#39;ERDE_50&#39;: 0.11838748712739997, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6470588235294118, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5116279069767442, &#39;ERDE_5&#39;: 0.25979554199049, &#39;ERDE_50&#39;: 0.1561182962933517, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4857105750359999}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5785 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5785091519355774
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 15s 22ms/step - loss: 0.4119 - tp: 377.0000 - fp: 160.0000 - tn: 11087.0000 - fn: 2325.0000 - accuracy: 0.8219 - precision: 0.7020 - recall: 0.1395 - f1_metric: 0.0835
Test Score: 0.4118872284889221
Test Accuracy: 377.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.70      0.14      0.23      2702

    accuracy                           0.82     13949
   macro avg       0.76      0.56      0.57     13949
weighted avg       0.80      0.82      0.77     13949

[[11087   160]
 [ 2325   377]]
Finished training and evaluation
{&#39;precision&#39;: 0.5566037735849056, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5619047619047619, &#39;ERDE_5&#39;: 0.2730883117056404, &#39;ERDE_50&#39;: 0.13501138688376482, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5290707801553567}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 16s 30ms/step - loss: 0.4113 - tp: 275.0000 - fp: 59.0000 - tn: 11188.0000 - fn: 2427.0000 - accuracy: 0.8218 - precision: 0.8234 - recall: 0.1018 - f1_metric: 0.0625
Test Score: 0.41131502389907837
Test Accuracy: 275.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.82      0.10      0.18      2702

    accuracy                           0.82     13949
   macro avg       0.82      0.55      0.54     13949
weighted avg       0.82      0.82      0.76     13949

[[11188    59]
 [ 2427   275]]
Finished training and evaluation
{&#39;precision&#39;: 0.6578947368421053, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.2608765182527739, &#39;ERDE_50&#39;: 0.14485613142687018, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5274129981451514}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102396845817566
Test Accuracy: 0.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 14s 22ms/step - loss: 0.4919 - tp: 544.0000 - fp: 175.0000 - tn: 11072.0000 - fn: 2158.0000 - accuracy: 0.8327 - precision: 0.7566 - recall: 0.2013 - f1_metric: 0.1083
Test Score: 0.4919048845767975
Test Accuracy: 544.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11072   175]
 [ 2158   544]]
Finished training and evaluation
{&#39;precision&#39;: 0.5508474576271186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5855855855855856, &#39;ERDE_5&#39;: 0.2765235900341768, &#39;ERDE_50&#39;: 0.12536827602059106, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.553644346953793}
Evaluating for elapsed time
436/436 [==============================] - 17s 28ms/step - loss: 0.4919 - tp: 544.0000 - fp: 175.0000 - tn: 11072.0000 - fn: 2158.0000 - accuracy: 0.8327 - precision: 0.7566 - recall: 0.2013 - f1_metric: 0.1083
Test Score: 0.4919048845767975
Test Accuracy: 544.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11072   175]
 [ 2158   544]]
Evaluated with elapsed time 217.8331776940031
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700765544398614, &#39;ERDE_50&#39;: 0.11838748712739997, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6470588235294118, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5116279069767442, &#39;ERDE_5&#39;: 0.25979554199049, &#39;ERDE_50&#39;: 0.1561182962933517, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4857105750359999}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 217.8331776940031} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11153    94]
 [ 2221   481]]
Evaluating after getting time 166542.339506093
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11153    94]
 [ 2221   481]]
Evaluated with elapsed time 812.5041881329962
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7472527472527473, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6974358974358975, &#39;ERDE_5&#39;: 0.2590698877363665, &#39;ERDE_50&#39;: 0.10143427884666163, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6621061638252979}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539578918573327, &#39;ERDE_50&#39;: 0.14271940783317394, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.547893278790823}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505023096067703, &#39;ERDE_50&#39;: 0.1592319000883911, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4843649497522238}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10966   281]
 [ 2074   628]]
Evaluating after getting time 167368.636086915
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.23      0.35      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.63     13949
weighted avg       0.81      0.83      0.80     13949

[[10966   281]
 [ 2074   628]]
Evaluated with elapsed time 5.344049479987007
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700765544398614, &#39;ERDE_50&#39;: 0.11838748712739997, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6470588235294118, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5116279069767442, &#39;ERDE_5&#39;: 0.25979554199049, &#39;ERDE_50&#39;: 0.1561182962933517, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4857105750359999}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 21ms/step - loss: 0.5034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5033852458000183
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5161073207855225
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4913 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4912576377391815
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49392426013946533
Test Accuracy: 0.0
436/436 [==============================] - 8s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5014899373054504
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 11s 16ms/step - loss: 0.5015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5014899373054504
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 233.42102465601056
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7887323943661971, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.64, &#39;ERDE_5&#39;: 0.25445071806430397, &#39;ERDE_50&#39;: 0.12432514100107359, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6075797738632145}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522212623891629, &#39;ERDE_50&#39;: 0.15307783542232145, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.50376814001622}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2505038313932302, &#39;ERDE_50&#39;: 0.1710521242615913, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.43491913868948956}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2700765544398614, &#39;ERDE_50&#39;: 0.11838748712739997, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5896986673242207}
Writing results to CSV file
{&#39;precision&#39;: 0.6263736263736264, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.5846153846153846, &#39;ERDE_5&#39;: 0.26556788334980885, &#39;ERDE_50&#39;: 0.13308429739888525, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5550007549712055}
Writing results to CSV file
{&#39;precision&#39;: 0.6470588235294118, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5116279069767442, &#39;ERDE_5&#39;: 0.25979554199049, &#39;ERDE_50&#39;: 0.1561182962933517, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4857105750359999}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 233.42102465601056} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluating after getting time 172939.361034786
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluated with elapsed time 470.4999443599954
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7671232876712328, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.632768361581921, &#39;ERDE_5&#39;: 0.25559501382710553, &#39;ERDE_50&#39;: 0.12458074722652146, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6007144656839691}
Writing results to CSV file
{&#39;precision&#39;: 0.7384615384615385, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5680473372781065, &#39;ERDE_5&#39;: 0.2556964061068788, &#39;ERDE_50&#39;: 0.14410911526054704, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5370627365625507}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522429581242549, &#39;ERDE_50&#39;: 0.1588758960199972, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4949260557515886}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 470.4999443599954}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluating after getting time 174355.131110741
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluated with elapsed time 440.4109628429869
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7671232876712328, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.632768361581921, &#39;ERDE_5&#39;: 0.25559501382710553, &#39;ERDE_50&#39;: 0.12458074722652146, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6007144656839691}
Writing results to CSV file
{&#39;precision&#39;: 0.7384615384615385, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5680473372781065, &#39;ERDE_5&#39;: 0.2556964061068788, &#39;ERDE_50&#39;: 0.14410911526054704, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5370627365625507}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522429581242549, &#39;ERDE_50&#39;: 0.1588758960199972, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4949260557515886}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 440.4109628429869}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluating after getting time 176020.412954675
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluated with elapsed time 728.9849739889905
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7671232876712328, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.632768361581921, &#39;ERDE_5&#39;: 0.25559501382710553, &#39;ERDE_50&#39;: 0.12458074722652146, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6007144656839691}
Writing results to CSV file
{&#39;precision&#39;: 0.7384615384615385, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5680473372781065, &#39;ERDE_5&#39;: 0.2556964061068788, &#39;ERDE_50&#39;: 0.14410911526054704, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5370627365625507}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522429581242549, &#39;ERDE_50&#39;: 0.1588758960199972, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4949260557515886}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 728.9849739889905}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluating after getting time 177494.035612492
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11095   152]
 [ 2262   440]]
Evaluated with elapsed time 358.76534308100236
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7671232876712328, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.632768361581921, &#39;ERDE_5&#39;: 0.25559501382710553, &#39;ERDE_50&#39;: 0.12458074722652146, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6007144656839691}
Writing results to CSV file
{&#39;precision&#39;: 0.7384615384615385, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5680473372781065, &#39;ERDE_5&#39;: 0.2556964061068788, &#39;ERDE_50&#39;: 0.14410911526054704, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5370627365625507}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522429581242549, &#39;ERDE_50&#39;: 0.1588758960199972, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4949260557515886}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 358.76534308100236}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluating after getting time 179055.969205361
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluated with elapsed time 587.7992368869891
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7252747252747253, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6769230769230768, &#39;ERDE_5&#39;: 0.2602099204885222, &#39;ERDE_50&#39;: 0.10811040451523657, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6465835322995055}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6242774566473989, &#39;ERDE_5&#39;: 0.25452544543166006, &#39;ERDE_50&#39;: 0.12963995592723004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5950825831579152}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25049925192367656, &#39;ERDE_50&#39;: 0.1583142227856328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluating after getting time 179661.166504797
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluated with elapsed time 6.304291504988214
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5205 - tp: 409.0000 - fp: 85.0000 - tn: 11162.0000 - fn: 2293.0000 - accuracy: 0.8295 - precision: 0.8279 - recall: 0.1514 - f1_metric: 0.0832
Test Score: 0.5204916000366211
Test Accuracy: 409.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.15      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.58     13949
weighted avg       0.83      0.83      0.78     13949

[[11162    85]
 [ 2293   409]]
Finished training and evaluation
{&#39;precision&#39;: 0.6794871794871795, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5824175824175823, &#39;ERDE_5&#39;: 0.2602910134248677, &#39;ERDE_50&#39;: 0.13693204464176645, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5529142859675543}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4000 - tp: 584.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2118.0000 - accuracy: 0.8344 - precision: 0.7526 - recall: 0.2161 - f1_metric: 0.1211
Test Score: 0.400028258562088
Test Accuracy: 584.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.6055045871559633, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.619718309859155, &#39;ERDE_5&#39;: 0.27069331202449276, &#39;ERDE_50&#39;: 0.11603158997275352, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5895310670274139}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4022 - tp: 623.0000 - fp: 188.0000 - tn: 11059.0000 - fn: 2079.0000 - accuracy: 0.8375 - precision: 0.7682 - recall: 0.2306 - f1_metric: 0.1231
Test Score: 0.40219637751579285
Test Accuracy: 623.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.23      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.61      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11059   188]
 [ 2079   623]]
Finished training and evaluation
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.617611825466156
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.5596330275229358, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5727699530516431, &#39;ERDE_5&#39;: 0.2735923421691488, &#39;ERDE_50&#39;: 0.1298676685075436, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.548213185058147}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Evaluated with elapsed time 200.22888564199093
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Writing results to CSV file
{&#39;precision&#39;: 0.6744186046511628, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6105263157894736, &#39;ERDE_5&#39;: 0.26208100053306677, &#39;ERDE_50&#39;: 0.12561273950461457, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5784118956357502}
Writing results to CSV file
{&#39;precision&#39;: 0.7205882352941176, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5697674418604651, &#39;ERDE_5&#39;: 0.2568923025147678, &#39;ERDE_50&#39;: 0.14330145840852437, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5342600273131639}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.2567235883154993, &#39;ERDE_50&#39;: 0.1215188045500775, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.25336365864084154, &#39;ERDE_50&#39;: 0.13112335341772507, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5866056232838709}
Writing results to CSV file
{&#39;precision&#39;: 0.8409090909090909, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2499182805879903, &#39;ERDE_50&#39;: 0.16246111894272472, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4707833213246818}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7176470588235294, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6455026455026455, &#39;ERDE_5&#39;: 0.2596196200909691, &#39;ERDE_50&#39;: 0.11575916728498295, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6203407980913017}
Writing results to CSV file
{&#39;precision&#39;: 0.7368421052631579, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6222222222222222, &#39;ERDE_5&#39;: 0.2574266597368462, &#39;ERDE_50&#39;: 0.12549382420788652, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5931234635425805}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.2539836532274734, &#39;ERDE_50&#39;: 0.15499122090567521, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.76, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6368715083798883, &#39;ERDE_5&#39;: 0.2561611714557076, &#39;ERDE_50&#39;: 0.12762081168746775, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6095664694377656}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5952380952380952, &#39;ERDE_5&#39;: 0.253949045532347, &#39;ERDE_50&#39;: 0.13623332542047709, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5639278539141654}
Writing results to CSV file
{&#39;precision&#39;: 0.7924528301886793, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5350318471337578, &#39;ERDE_5&#39;: 0.2522439983591769, &#39;ERDE_50&#39;: 0.15469399516586682, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.5027286324226619}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7191011235955056, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6632124352331606, &#39;ERDE_5&#39;: 0.2601950107789217, &#39;ERDE_50&#39;: 0.113058737846216, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.636069159620532}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742450594843636, &#39;ERDE_50&#39;: 0.12312975677136251, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.25398363745849056, &#39;ERDE_50&#39;: 0.15262715133389934, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5050252208333404}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 200.22888564199093} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluating after getting time 188494.224293699
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.82      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11132   115]
 [ 2191   511]]
Evaluated with elapsed time 671.4747500240046
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7252747252747253, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6769230769230768, &#39;ERDE_5&#39;: 0.2602099204885222, &#39;ERDE_50&#39;: 0.10811040451523657, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6465835322995055}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6242774566473989, &#39;ERDE_5&#39;: 0.25452544543166006, &#39;ERDE_50&#39;: 0.12963995592723004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5950825831579152}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.25049925192367656, &#39;ERDE_50&#39;: 0.1583142227856328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluating after getting time 189177.827919199
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10698   549]
 [ 1829   873]]
Evaluated with elapsed time 6.161256278021028
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5012255311012268
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5095410346984863
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00035: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4506 - tp: 982.0000 - fp: 621.0000 - tn: 10626.0000 - fn: 1720.0000 - accuracy: 0.8322 - precision: 0.6126 - recall: 0.3634 - f1_metric: 0.1773
Test Score: 0.45056480169296265
Test Accuracy: 982.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.94      0.90     11247
           1       0.61      0.36      0.46      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.65      0.68     13949
weighted avg       0.81      0.83      0.81     13949

[[10626   621]
 [ 1720   982]]
Finished training and evaluation
{&#39;precision&#39;: 0.4880952380952381, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.6029411764705882, &#39;ERDE_5&#39;: 0.29556808679097213, &#39;ERDE_50&#39;: 0.1043756921166237, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5794383852952624}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5211 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5210582613945007
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 9s 14ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 221.54022667501704
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561481976275467, &#39;ERDE_50&#39;: 0.12421923398884446, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.6034616816343671}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25336581580702033, &#39;ERDE_50&#39;: 0.13348742085424917, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5787492979720332}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24991828405032013, &#39;ERDE_50&#39;: 0.16482518851451203, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5882352941176471, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6278026905829597, &#39;ERDE_5&#39;: 0.27408594746021087, &#39;ERDE_50&#39;: 0.1090135005496287, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6033307916450725}
Writing results to CSV file
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713515844812237, &#39;ERDE_50&#39;: 0.11816711153008327, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5841615906357304}
Writing results to CSV file
{&#39;precision&#39;: 0.6021505376344086, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5685279187817259, &#39;ERDE_5&#39;: 0.2673434358997137, &#39;ERDE_50&#39;: 0.13589881566330933, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5419402204957589}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 221.54022667501704} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluating after getting time 196243.82942174
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluated with elapsed time 644.1036778170092
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25849361896774087, &#39;ERDE_50&#39;: 0.11364270037434163, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6354894252241934}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.25394921117838753, &#39;ERDE_50&#39;: 0.1357968918591065, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5753247459130271}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5234899328859061, &#39;ERDE_5&#39;: 0.24933667957653524, &#39;ERDE_50&#39;: 0.15778755849526319, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.490866492701918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluating after getting time 196903.100257986
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluated with elapsed time 6.19973694201326
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5936288833618164
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.3994 - tp: 512.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2190.0000 - accuracy: 0.8331 - precision: 0.7877 - recall: 0.1895 - f1_metric: 0.1028
Test Score: 0.3994370400905609
Test Accuracy: 512.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2190   512]]
Finished training and evaluation
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6494845360824743, &#39;ERDE_5&#39;: 0.26140644379269445, &#39;ERDE_50&#39;: 0.11262328232115389, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6165838555635069}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4017 - tp: 568.0000 - fp: 194.0000 - tn: 11053.0000 - fn: 2134.0000 - accuracy: 0.8331 - precision: 0.7454 - recall: 0.2102 - f1_metric: 0.1139
Test Score: 0.4016605317592621
Test Accuracy: 568.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.75      0.21      0.33      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.60      0.62     13949
weighted avg       0.82      0.83      0.79     13949

[[11053   194]
 [ 2134   568]]
Finished training and evaluation
{&#39;precision&#39;: 0.6017699115044248, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6267281105990784, &#39;ERDE_5&#39;: 0.27183954873518135, &#39;ERDE_50&#39;: 0.11328805467567826, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5986382934151268}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6187 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6187241673469543
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Finished training and evaluation
{&#39;precision&#39;: 0.6444444444444445, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5979381443298969, &#39;ERDE_5&#39;: 0.2643079528067778, &#39;ERDE_50&#39;: 0.12768686242459712, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5688118402106115}
Evaluating for elapsed time
436/436 [==============================] - 11s 16ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Evaluated with elapsed time 210.1215142669971
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 210.1215142669971} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluating after getting time 204462.665148752
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11156    91]
 [ 2211   491]]
Evaluated with elapsed time 625.7506865919859
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25849361896774087, &#39;ERDE_50&#39;: 0.11364270037434163, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6354894252241934}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.25394921117838753, &#39;ERDE_50&#39;: 0.1357968918591065, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5753247459130271}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5234899328859061, &#39;ERDE_5&#39;: 0.24933667957653524, &#39;ERDE_50&#39;: 0.15778755849526319, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.490866492701918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluating after getting time 205103.423624479
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.61      0.32      0.42      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.64      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10701   546]
 [ 1841   861]]
Evaluated with elapsed time 7.501823073980631
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062928795814514
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 23ms/step - loss: 0.4938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49377965927124023
Test Accuracy: 0.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 14ms/step - loss: 0.4958 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49575263261795044
Test Accuracy: 0.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5005954504013062
Test Accuracy: 0.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 15ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 7s 12ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 214.9328751390276
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.25617362379724895, &#39;ERDE_50&#39;: 0.11903990604781563, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6214454600258686}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522076565684968, &#39;ERDE_50&#39;: 0.13669905331474036, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5696155213899782}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.2487554579701377, &#39;ERDE_50&#39;: 0.16193445465248477, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.48117405036256283}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5867768595041323, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6311111111111112, &#39;ERDE_5&#39;: 0.2746716868632801, &#39;ERDE_50&#39;: 0.10711855848584213, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6065102491502499}
Writing results to CSV file
{&#39;precision&#39;: 0.6090909090909091, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6261682242990654, &#39;ERDE_5&#39;: 0.2707706469152623, &#39;ERDE_50&#39;: 0.11287358138542777, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5993220747636598}
Writing results to CSV file
{&#39;precision&#39;: 0.6105263157894737, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5829145728643217, &#39;ERDE_5&#39;: 0.26734198597926767, &#39;ERDE_50&#39;: 0.13261748558324254, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.555654070296531}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 214.9328751390276} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluating after getting time 210438.89497334
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluated with elapsed time 330.1581963659846
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25558316371811146, &#39;ERDE_50&#39;: 0.12063813998728103, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6189994709926704}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2533688595851934, &#39;ERDE_50&#39;: 0.13556965316154154, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5740257597262678}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505006757094122, &#39;ERDE_50&#39;: 0.1594962860861073, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 330.1581963659846}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluating after getting time 211328.801818974
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluated with elapsed time 348.6528203790076
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25558316371811146, &#39;ERDE_50&#39;: 0.12063813998728103, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6189994709926704}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2533688595851934, &#39;ERDE_50&#39;: 0.13556965316154154, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5740257597262678}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505006757094122, &#39;ERDE_50&#39;: 0.1594962860861073, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 348.6528203790076}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluating after getting time 212416.856135969
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluated with elapsed time 452.6990009380097
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25558316371811146, &#39;ERDE_50&#39;: 0.12063813998728103, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6189994709926704}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2533688595851934, &#39;ERDE_50&#39;: 0.13556965316154154, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5740257597262678}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505006757094122, &#39;ERDE_50&#39;: 0.1594962860861073, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 452.6990009380097}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluating after getting time 213512.192018055
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11151    96]
 [ 2236   466]]
Evaluated with elapsed time 366.5602407849801
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25558316371811146, &#39;ERDE_50&#39;: 0.12063813998728103, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6189994709926704}
Writing results to CSV file
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2533688595851934, &#39;ERDE_50&#39;: 0.13556965316154154, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5740257597262678}
Writing results to CSV file
{&#39;precision&#39;: 0.8297872340425532, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5165562913907286, &#39;ERDE_5&#39;: 0.2505006757094122, &#39;ERDE_50&#39;: 0.1594962860861073, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4863721730241747}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 366.5602407849801}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2218   484]]
Evaluating after getting time 216265.729130026
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2218   484]]
Evaluated with elapsed time 1239.0134099719871
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6808510638297872, &#39;ERDE_5&#39;: 0.25732521749015774, &#39;ERDE_50&#39;: 0.10796400809272798, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6476859691906596}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2533715945799426, &#39;ERDE_50&#39;: 0.14029778361037085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504996071710436, &#39;ERDE_50&#39;: 0.17368066338496302, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43034466692663004}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluating after getting time 217524.153679862
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluated with elapsed time 6.998677242983831
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340755154782524, &#39;ERDE_50&#39;: 0.17540506132106976, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4159998446957423}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5063 - tp: 368.0000 - fp: 89.0000 - tn: 11158.0000 - fn: 2334.0000 - accuracy: 0.8263 - precision: 0.8053 - recall: 0.1362 - f1_metric: 0.0763
Test Score: 0.5063048005104065
Test Accuracy: 368.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.14      0.23      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.56      0.57     13949
weighted avg       0.82      0.83      0.77     13949

[[11158    89]
 [ 2334   368]]
Finished training and evaluation
{&#39;precision&#39;: 0.6179775280898876, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5699481865284974, &#39;ERDE_5&#39;: 0.26550974714091863, &#39;ERDE_50&#39;: 0.1373958860459534, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5432940681968493}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4046 - tp: 474.0000 - fp: 156.0000 - tn: 11091.0000 - fn: 2228.0000 - accuracy: 0.8291 - precision: 0.7524 - recall: 0.1754 - f1_metric: 0.1020
Test Score: 0.40456733107566833
Test Accuracy: 474.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.18      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11091   156]
 [ 2228   474]]
Finished training and evaluation
{&#39;precision&#39;: 0.5963302752293578, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6103286384976525, &#39;ERDE_5&#39;: 0.2713055417417727, &#39;ERDE_50&#39;: 0.12226518380910399, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5794114627510113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.4059 - tp: 450.0000 - fp: 127.0000 - tn: 11120.0000 - fn: 2252.0000 - accuracy: 0.8295 - precision: 0.7799 - recall: 0.1665 - f1_metric: 0.0948
Test Score: 0.4059257507324219
Test Accuracy: 450.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11120   127]
 [ 2252   450]]
Finished training and evaluation
{&#39;precision&#39;: 0.6181818181818182, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6355140186915889, &#39;ERDE_5&#39;: 0.2701302333779222, &#39;ERDE_50&#39;: 0.11126749523965757, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.6008493933583364}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6197 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6196771860122681
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 11s 22ms/step - loss: 0.4153 - tp: 471.0000 - fp: 130.0000 - tn: 11117.0000 - fn: 2231.0000 - accuracy: 0.8307 - precision: 0.7837 - recall: 0.1743 - f1_metric: 0.0979
Test Score: 0.41526246070861816
Test Accuracy: 471.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11117   130]
 [ 2231   471]]
Finished training and evaluation
{&#39;precision&#39;: 0.5784313725490197, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5728155339805826, &#39;ERDE_5&#39;: 0.2707127102878138, &#39;ERDE_50&#39;: 0.1369617711161085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5437986446894669}
Evaluating for elapsed time
436/436 [==============================] - 13s 22ms/step - loss: 0.4153 - tp: 471.0000 - fp: 130.0000 - tn: 11117.0000 - fn: 2231.0000 - accuracy: 0.8307 - precision: 0.7837 - recall: 0.1743 - f1_metric: 0.0979
Test Score: 0.41526246070861816
Test Accuracy: 471.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.78      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11117   130]
 [ 2231   471]]
Evaluated with elapsed time 244.96534944500308
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6181818181818182, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6355140186915889, &#39;ERDE_5&#39;: 0.2701302333779222, &#39;ERDE_50&#39;: 0.11126749523965757, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.6008493933583364}
Writing results to CSV file
{&#39;precision&#39;: 0.6582278481012658, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5683060109289617, &#39;ERDE_5&#39;: 0.2615183803682155, &#39;ERDE_50&#39;: 0.1427193110257367, &#39;median_latency_tps&#39;: 20.5, &#39;median_penalty_tps&#39;: 0.07590343710772685, &#39;speed&#39;: 0.9240965628922732, &#39;latency_weighted_f1&#39;: 0.5251696313704721}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.2528285175011324, &#39;ERDE_50&#39;: 0.16837299288133215, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.4478863667246098}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5930232558139534, &#39;ERDE_5&#39;: 0.2555997205565127, &#39;ERDE_50&#39;: 0.13695315946515849, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5675981537635009}
Writing results to CSV file
{&#39;precision&#39;: 0.8103448275862069, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5802469135802469, &#39;ERDE_5&#39;: 0.25221156994979926, &#39;ERDE_50&#39;: 0.143863469417058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5508535758404915}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24992158311502344, &#39;ERDE_50&#39;: 0.1730994023927846, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.43155137788095826}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532965126061328, &#39;ERDE_50&#39;: 0.14171456807481525, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5546089529229323}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5419354838709677, &#39;ERDE_5&#39;: 0.2510586362492299, &#39;ERDE_50&#39;: 0.1545213033830603, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.511321774683012}
Writing results to CSV file
{&#39;precision&#39;: 0.8285714285714286, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4172661870503597, &#39;ERDE_5&#39;: 0.24934075529833172, &#39;ERDE_50&#39;: 0.18197447040757944, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3928839228321086}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5714285714285714, &#39;ERDE_5&#39;: 0.2550368527513607, &#39;ERDE_50&#39;: 0.14197513404689452, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5469293134303762}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.25221886348084804, &#39;ERDE_50&#39;: 0.15596556377870735, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.49901383670656635}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.24992318390715126, &#39;ERDE_50&#39;: 0.18137363210728108, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3900776090975935}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5930232558139534, &#39;ERDE_5&#39;: 0.2555997205565127, &#39;ERDE_50&#39;: 0.13695315946515849, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5675981537635009}
Writing results to CSV file
{&#39;precision&#39;: 0.8103448275862069, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5802469135802469, &#39;ERDE_5&#39;: 0.25221156994979926, &#39;ERDE_50&#39;: 0.143863469417058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5508535758404915}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24992158311502344, &#39;ERDE_50&#39;: 0.1730994023927846, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.43155137788095826}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8103448275862069, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5802469135802469, &#39;ERDE_5&#39;: 0.2521489338320065, &#39;ERDE_50&#39;: 0.1429220081690891, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5485968771240148}
Writing results to CSV file
{&#39;precision&#39;: 0.8888888888888888, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5369127516778524, &#39;ERDE_5&#39;: 0.248741122698134, &#39;ERDE_50&#39;: 0.1569245297854282, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620202323028923, &#39;speed&#39;: 0.9337979767697108, &#39;latency_weighted_f1&#39;: 0.5013680412186367}
Writing results to CSV file
{&#39;precision&#39;: 0.896551724137931, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.39097744360902253, &#39;ERDE_5&#39;: 0.24760055449373927, &#39;ERDE_50&#39;: 0.18732296070306387, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.3658528105355941}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5930232558139534, &#39;ERDE_5&#39;: 0.2555997205565127, &#39;ERDE_50&#39;: 0.13695315946515849, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5675981537635009}
Writing results to CSV file
{&#39;precision&#39;: 0.8103448275862069, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5802469135802469, &#39;ERDE_5&#39;: 0.25221156994979926, &#39;ERDE_50&#39;: 0.143863469417058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5508535758404915}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24992158311502344, &#39;ERDE_50&#39;: 0.1730994023927846, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.43155137788095826}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5930232558139534, &#39;ERDE_5&#39;: 0.2555997205565127, &#39;ERDE_50&#39;: 0.13695315946515849, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5675981537635009}
Writing results to CSV file
{&#39;precision&#39;: 0.8103448275862069, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5802469135802469, &#39;ERDE_5&#39;: 0.25221156994979926, &#39;ERDE_50&#39;: 0.143863469417058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5508535758404915}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24992158311502344, &#39;ERDE_50&#39;: 0.1730994023927846, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.43155137788095826}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340755154782524, &#39;ERDE_50&#39;: 0.17540506132106976, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4159998446957423}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 244.96534944500308} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2218   484]]
Evaluating after getting time 227460.971012455
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2218   484]]
Evaluated with elapsed time 2741.063713624986
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6808510638297872, &#39;ERDE_5&#39;: 0.25732521749015774, &#39;ERDE_50&#39;: 0.10796400809272798, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6476859691906596}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2533715945799426, &#39;ERDE_50&#39;: 0.14029778361037085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504996071710436, &#39;ERDE_50&#39;: 0.17368066338496302, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43034466692663004}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluating after getting time 230222.59390355
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluated with elapsed time 6.877538770000683
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340755154782524, &#39;ERDE_50&#39;: 0.17540506132106976, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4159998446957423}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 21ms/step - loss: 0.5114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.511385977268219
Test Accuracy: 0.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.5072 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5072153210639954
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 14s 28ms/step - loss: 0.4972 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4971542954444885
Test Accuracy: 0.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5161031484603882
Test Accuracy: 0.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5107994675636292
Test Accuracy: 0.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 12s 20ms/step - loss: 0.5108 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5107994675636292
Test Accuracy: 0.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 201.02609386498807
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340755154782524, &#39;ERDE_50&#39;: 0.17540506132106976, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4159998446957423}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 201.02609386498807} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2226   476]]
Evaluating after getting time 237678.356578078
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2226   476]]
Evaluated with elapsed time 2158.69079444799
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7558139534883721, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6842105263157895, &#39;ERDE_5&#39;: 0.2579114329811147, &#39;ERDE_50&#39;: 0.1061819700753635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6522128311511458}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25337587015058316, &#39;ERDE_50&#39;: 0.13977410550168015, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8444444444444444, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5100671140939597, &#39;ERDE_5&#39;: 0.24992003379798547, &#39;ERDE_50&#39;: 0.1610147301362314, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4802621801432995}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11098   149]
 [ 2250   452]]
Evaluating after getting time 239865.230052616
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11098   149]
 [ 2250   452]]
Evaluated with elapsed time 5.454033900983632
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6705882352941176, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6031746031746031, &#39;ERDE_5&#39;: 0.26198104609133216, &#39;ERDE_50&#39;: 0.1297559804705575, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5773142752876192}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618712542508, &#39;ERDE_50&#39;: 0.1464470255784464, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7254901960784313, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.47741935483870973, &#39;ERDE_5&#39;: 0.25398802197350023, &#39;ERDE_50&#39;: 0.16657266254734118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4495221390713091}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.5789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5788834691047668
Test Accuracy: 0.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 15s 28ms/step - loss: 0.4103 - tp: 327.0000 - fp: 111.0000 - tn: 11136.0000 - fn: 2375.0000 - accuracy: 0.8218 - precision: 0.7466 - recall: 0.1210 - f1_metric: 0.0721
Test Score: 0.4103216230869293
Test Accuracy: 327.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.75      0.12      0.21      2702

    accuracy                           0.82     13949
   macro avg       0.79      0.56      0.55     13949
weighted avg       0.81      0.82      0.77     13949

[[11136   111]
 [ 2375   327]]
Finished training and evaluation
{&#39;precision&#39;: 0.5591397849462365, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5279187817258884, &#39;ERDE_5&#39;: 0.26961716947863096, &#39;ERDE_50&#39;: 0.14717209726949315, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4970707149011869}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 12s 21ms/step - loss: 0.5128 - tp: 496.0000 - fp: 149.0000 - tn: 11098.0000 - fn: 2206.0000 - accuracy: 0.8312 - precision: 0.7690 - recall: 0.1836 - f1_metric: 0.1010
Test Score: 0.5127888321876526
Test Accuracy: 496.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11098   149]
 [ 2206   496]]
Finished training and evaluation
{&#39;precision&#39;: 0.5631067961165048, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5603864734299517, &#39;ERDE_5&#39;: 0.27188376554935895, &#39;ERDE_50&#39;: 0.13700590175791935, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5319991981290223}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 18s 32ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102219223976135
Test Accuracy: 0.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 15s 26ms/step - loss: 0.5131 - tp: 516.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2186.0000 - accuracy: 0.8334 - precision: 0.7890 - recall: 0.1910 - f1_metric: 0.1071
Test Score: 0.5130549669265747
Test Accuracy: 516.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2186   516]]
Finished training and evaluation
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5607476635514018, &#39;ERDE_5&#39;: 0.274789076670109, &#39;ERDE_50&#39;: 0.1372878784316655, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5312516605097932}
Evaluating for elapsed time
436/436 [==============================] - 16s 25ms/step - loss: 0.5131 - tp: 516.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2186.0000 - accuracy: 0.8334 - precision: 0.7890 - recall: 0.1910 - f1_metric: 0.1071
Test Score: 0.5130549669265747
Test Accuracy: 516.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2186   516]]
Evaluated with elapsed time 209.86964922901825
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6705882352941176, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6031746031746031, &#39;ERDE_5&#39;: 0.26198104609133216, &#39;ERDE_50&#39;: 0.1297559804705575, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5773142752876192}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618712542508, &#39;ERDE_50&#39;: 0.1464470255784464, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7254901960784313, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.47741935483870973, &#39;ERDE_5&#39;: 0.25398802197350023, &#39;ERDE_50&#39;: 0.16657266254734118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4495221390713091}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 209.86964922901825} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2226   476]]
Evaluating after getting time 250867.331371272
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2226   476]]
Evaluated with elapsed time 1998.4645671839826
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7558139534883721, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6842105263157895, &#39;ERDE_5&#39;: 0.2579114329811147, &#39;ERDE_50&#39;: 0.1061819700753635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6522128311511458}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25337587015058316, &#39;ERDE_50&#39;: 0.13977410550168015, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8444444444444444, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5100671140939597, &#39;ERDE_5&#39;: 0.24992003379798547, &#39;ERDE_50&#39;: 0.1610147301362314, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4802621801432995}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11098   149]
 [ 2250   452]]
Evaluating after getting time 252885.602893634
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11098   149]
 [ 2250   452]]
Evaluated with elapsed time 8.05584551001084
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6705882352941176, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6031746031746031, &#39;ERDE_5&#39;: 0.26198104609133216, &#39;ERDE_50&#39;: 0.1297559804705575, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5773142752876192}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618712542508, &#39;ERDE_50&#39;: 0.1464470255784464, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7254901960784313, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.47741935483870973, &#39;ERDE_5&#39;: 0.25398802197350023, &#39;ERDE_50&#39;: 0.16657266254734118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4495221390713091}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 14s 27ms/step - loss: 0.5034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.503360390663147
Test Accuracy: 0.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 22s 41ms/step - loss: 0.5160 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5160304307937622
Test Accuracy: 0.0
436/436 [==============================] - 16s 37ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 17s 33ms/step - loss: 0.4912 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4911855161190033
Test Accuracy: 0.0
436/436 [==============================] - 13s 30ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 19s 34ms/step - loss: 0.4942 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.494177907705307
Test Accuracy: 0.0
436/436 [==============================] - 13s 30ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 16s 30ms/step - loss: 0.5029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5029453635215759
Test Accuracy: 0.0
436/436 [==============================] - 10s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 11s 19ms/step - loss: 0.5029 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5029453635215759
Test Accuracy: 0.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 195.36693347798428
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.25388000018903334, &#39;ERDE_50&#39;: 0.14081266204545215, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5523933791824911}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6705882352941176, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6031746031746031, &#39;ERDE_5&#39;: 0.26198104609133216, &#39;ERDE_50&#39;: 0.1297559804705575, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5773142752876192}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618712542508, &#39;ERDE_50&#39;: 0.1464470255784464, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7254901960784313, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.47741935483870973, &#39;ERDE_5&#39;: 0.25398802197350023, &#39;ERDE_50&#39;: 0.16657266254734118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4495221390713091}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 195.36693347798428} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 259364.396669777
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 1005.0833119240124
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluating after getting time 260391.390807738
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluated with elapsed time 8.20718567998847
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6638 - tp: 1873.0000 - fp: 2455.0000 - tn: 8792.0000 - fn: 829.0000 - accuracy: 0.7646 - precision: 0.4328 - recall: 0.6932 - f1_metric: 0.2518
Test Score: 0.6638481020927429
Test Accuracy: 1873.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.78      0.84     11247
           1       0.43      0.69      0.53      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.74      0.69     13949
weighted avg       0.82      0.76      0.78     13949

[[8792 2455]
 [ 829 1873]]
Finished training and evaluation
{&#39;precision&#39;: 0.3671875, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5222222222222223, &#39;ERDE_5&#39;: 0.33958970512621445, &#39;ERDE_50&#39;: 0.11780102500411042, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5018658751771433}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.7050 - tp: 1633.0000 - fp: 1975.0000 - tn: 9272.0000 - fn: 1069.0000 - accuracy: 0.7818 - precision: 0.4526 - recall: 0.6044 - f1_metric: 0.2300
Test Score: 0.7049650549888611
Test Accuracy: 1633.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.60      0.52      2702

    accuracy                           0.78     13949
   macro avg       0.67      0.71      0.69     13949
weighted avg       0.81      0.78      0.79     13949

[[9272 1975]
 [1069 1633]]
Finished training and evaluation
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.8397 - tp: 1788.0000 - fp: 2381.0000 - tn: 8866.0000 - fn: 914.0000 - accuracy: 0.7638 - precision: 0.4289 - recall: 0.6617 - f1_metric: 0.2469
Test Score: 0.8396896719932556
Test Accuracy: 1788.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.79      0.84     11247
           1       0.43      0.66      0.52      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.73      0.68     13949
weighted avg       0.81      0.76      0.78     13949

[[8866 2381]
 [ 914 1788]]
Finished training and evaluation
{&#39;precision&#39;: 0.34782608695652173, &#39;recall&#39;: 0.9230769230769231, &#39;F1&#39;: 0.5052631578947369, &#39;ERDE_5&#39;: 0.35004284865763213, &#39;ERDE_50&#39;: 0.12353798078484782, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48556787923074113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 21.6905 - tp: 2297.0000 - fp: 5588.0000 - tn: 5659.0000 - fn: 405.0000 - accuracy: 0.5704 - precision: 0.2913 - recall: 0.8501 - f1_metric: 0.2506
Test Score: 21.69049835205078
Test Accuracy: 2297.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.50      0.65     11247
           1       0.29      0.85      0.43      2702

    accuracy                           0.57     13949
   macro avg       0.61      0.68      0.54     13949
weighted avg       0.81      0.57      0.61     13949

[[5659 5588]
 [ 405 2297]]
Finished training and evaluation
{&#39;precision&#39;: 0.28901734104046245, &#39;recall&#39;: 0.9615384615384616, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.3883392304169796, &#39;ERDE_50&#39;: 0.15244035415949747, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4271198937677815}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00034: early stopping
Evaluating
436/436 [==============================] - 7s 15ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Finished training and evaluation
{&#39;precision&#39;: 0.2849162011173184, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.44155844155844154, &#39;ERDE_5&#39;: 0.39416086256759053, &#39;ERDE_50&#39;: 0.15352459690148623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42434638796409463}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Evaluated with elapsed time 217.271814711974
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Writing results to CSV file
{&#39;precision&#39;: 0.4090909090909091, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.3212894776241683, &#39;ERDE_50&#39;: 0.11049814093392929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5317368325017546}
Writing results to CSV file
{&#39;precision&#39;: 0.41968911917098445, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.3109184332473117, &#39;ERDE_50&#39;: 0.12183848257490924, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 217.271814711974} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 269974.739342712
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 1179.701742053032
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluating after getting time 271176.390550127
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluated with elapsed time 7.671948425006121
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 10s 21ms/step - loss: 2.4027 - tp: 2392.0000 - fp: 6611.0000 - tn: 4636.0000 - fn: 310.0000 - accuracy: 0.5038 - precision: 0.2657 - recall: 0.8853 - f1_metric: 0.2488
Test Score: 2.4026808738708496
Test Accuracy: 2392.0
436/436 [==============================] - 10s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.41      0.57     11247
           1       0.27      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.54     13949

[[4636 6611]
 [ 310 2392]]
Finished training and evaluation
{&#39;precision&#39;: 0.2670157068062827, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.4197530864197531, &#39;ERDE_5&#39;: 0.4080746548120302, &#39;ERDE_50&#39;: 0.1674742495675605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.40339101078068257}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 13.3630 - tp: 2690.0000 - fp: 10687.0000 - tn: 560.0000 - fn: 12.0000 - accuracy: 0.2330 - precision: 0.2011 - recall: 0.9956 - f1_metric: 0.2346
Test Score: 13.36298656463623
Test Accuracy: 2690.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.98      0.05      0.09     11247
           1       0.20      1.00      0.33      2702

    accuracy                           0.23     13949
   macro avg       0.59      0.52      0.21     13949
weighted avg       0.83      0.23      0.14     13949

[[  560 10687]
 [   12  2690]]
Finished training and evaluation
{&#39;precision&#39;: 0.24644549763033174, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3954372623574145, &#39;ERDE_5&#39;: 0.4300880481201669, &#39;ERDE_50&#39;: 0.1848330902201432, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.38002302335232274}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 2.0498 - tp: 2273.0000 - fp: 5233.0000 - tn: 6014.0000 - fn: 429.0000 - accuracy: 0.5941 - precision: 0.3028 - recall: 0.8412 - f1_metric: 0.2529
Test Score: 2.049755811691284
Test Accuracy: 2273.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.53      0.68     11247
           1       0.30      0.84      0.45      2702

    accuracy                           0.59     13949
   macro avg       0.62      0.69      0.56     13949
weighted avg       0.81      0.59      0.63     13949

[[6014 5233]
 [ 429 2273]]
Finished training and evaluation
{&#39;precision&#39;: 0.28994082840236685, &#39;recall&#39;: 0.9423076923076923, &#39;F1&#39;: 0.4434389140271493, &#39;ERDE_5&#39;: 0.38485709880709723, &#39;ERDE_50&#39;: 0.1536810690406908, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42615355916649694}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 13s 20ms/step - loss: 1.4021 - tp: 2687.0000 - fp: 10984.0000 - tn: 263.0000 - fn: 15.0000 - accuracy: 0.2115 - precision: 0.1965 - recall: 0.9944 - f1_metric: 0.2314
Test Score: 1.4021421670913696
Test Accuracy: 2687.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.02      0.05     11247
           1       0.20      0.99      0.33      2702

    accuracy                           0.21     13949
   macro avg       0.57      0.51      0.19     13949
weighted avg       0.80      0.21      0.10     13949

[[  263 10984]
 [   15  2687]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 15s 27ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Finished training and evaluation
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Evaluating for elapsed time
436/436 [==============================] - 13s 19ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Evaluated with elapsed time 198.13499270397006
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Writing results to CSV file
{&#39;precision&#39;: 0.42780748663101603, &#39;recall&#39;: 0.7692307692307693, &#39;F1&#39;: 0.549828178694158, &#39;ERDE_5&#39;: 0.3079335104772061, &#39;ERDE_50&#39;: 0.11893217008086455, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5262550094862726}
Writing results to CSV file
{&#39;precision&#39;: 0.4277456647398844, &#39;recall&#39;: 0.7115384615384616, &#39;F1&#39;: 0.5342960288808665, &#39;ERDE_5&#39;: 0.3033662849152717, &#39;ERDE_50&#39;: 0.12875241328919224, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5093092144396063}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 198.13499270397006} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 280066.33038139
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 1071.6752439949778
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluating after getting time 281158.491260442
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluated with elapsed time 6.612982234975789
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6638 - tp: 1873.0000 - fp: 2455.0000 - tn: 8792.0000 - fn: 829.0000 - accuracy: 0.7646 - precision: 0.4328 - recall: 0.6932 - f1_metric: 0.2518
Test Score: 0.6638481020927429
Test Accuracy: 1873.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.78      0.84     11247
           1       0.43      0.69      0.53      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.74      0.69     13949
weighted avg       0.82      0.76      0.78     13949

[[8792 2455]
 [ 829 1873]]
Finished training and evaluation
{&#39;precision&#39;: 0.3671875, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5222222222222223, &#39;ERDE_5&#39;: 0.33958970512621445, &#39;ERDE_50&#39;: 0.11780102500411042, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5018658751771433}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.7050 - tp: 1633.0000 - fp: 1975.0000 - tn: 9272.0000 - fn: 1069.0000 - accuracy: 0.7818 - precision: 0.4526 - recall: 0.6044 - f1_metric: 0.2300
Test Score: 0.7049650549888611
Test Accuracy: 1633.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.60      0.52      2702

    accuracy                           0.78     13949
   macro avg       0.67      0.71      0.69     13949
weighted avg       0.81      0.78      0.79     13949

[[9272 1975]
 [1069 1633]]
Finished training and evaluation
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 12s 21ms/step - loss: 0.8397 - tp: 1788.0000 - fp: 2381.0000 - tn: 8866.0000 - fn: 914.0000 - accuracy: 0.7638 - precision: 0.4289 - recall: 0.6617 - f1_metric: 0.2469
Test Score: 0.8396896719932556
Test Accuracy: 1788.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.79      0.84     11247
           1       0.43      0.66      0.52      2702

    accuracy                           0.76     13949
   macro avg       0.67      0.73      0.68     13949
weighted avg       0.81      0.76      0.78     13949

[[8866 2381]
 [ 914 1788]]
Finished training and evaluation
{&#39;precision&#39;: 0.34782608695652173, &#39;recall&#39;: 0.9230769230769231, &#39;F1&#39;: 0.5052631578947369, &#39;ERDE_5&#39;: 0.35004284865763213, &#39;ERDE_50&#39;: 0.12353798078484782, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48556787923074113}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 21.6905 - tp: 2297.0000 - fp: 5588.0000 - tn: 5659.0000 - fn: 405.0000 - accuracy: 0.5704 - precision: 0.2913 - recall: 0.8501 - f1_metric: 0.2506
Test Score: 21.69049835205078
Test Accuracy: 2297.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.50      0.65     11247
           1       0.29      0.85      0.43      2702

    accuracy                           0.57     13949
   macro avg       0.61      0.68      0.54     13949
weighted avg       0.81      0.57      0.61     13949

[[5659 5588]
 [ 405 2297]]
Finished training and evaluation
{&#39;precision&#39;: 0.28901734104046245, &#39;recall&#39;: 0.9615384615384616, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.3883392304169796, &#39;ERDE_50&#39;: 0.15244035415949747, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4271198937677815}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00034: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Finished training and evaluation
{&#39;precision&#39;: 0.2849162011173184, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.44155844155844154, &#39;ERDE_5&#39;: 0.39416086256759053, &#39;ERDE_50&#39;: 0.15352459690148623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42434638796409463}
Evaluating for elapsed time
436/436 [==============================] - 15s 26ms/step - loss: 0.9258 - tp: 2132.0000 - fp: 4081.0000 - tn: 7166.0000 - fn: 570.0000 - accuracy: 0.6666 - precision: 0.3432 - recall: 0.7890 - f1_metric: 0.2530
Test Score: 0.9257922172546387
Test Accuracy: 2132.0
436/436 [==============================] - 12s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.64      0.75     11247
           1       0.34      0.79      0.48      2702

    accuracy                           0.67     13949
   macro avg       0.63      0.71      0.62     13949
weighted avg       0.81      0.67      0.70     13949

[[7166 4081]
 [ 570 2132]]
Evaluated with elapsed time 227.7763641870115
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4051724137931034, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5595238095238095, &#39;ERDE_5&#39;: 0.3256643854181763, &#39;ERDE_50&#39;: 0.10507584910618228, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5377134376897964}
Writing results to CSV file
{&#39;precision&#39;: 0.4090909090909091, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.3212894776241683, &#39;ERDE_50&#39;: 0.11049814093392929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5317368325017546}
Writing results to CSV file
{&#39;precision&#39;: 0.41968911917098445, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.3109184332473117, &#39;ERDE_50&#39;: 0.12183848257490924, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 227.7763641870115} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 290445.527533286
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 1050.9938065449824
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluating after getting time 291514.208967147
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.70      0.01      0.02      2702

    accuracy                           0.81     13949
   macro avg       0.76      0.51      0.46     13949
weighted avg       0.79      0.81      0.72     13949

[[11234    13]
 [ 2671    31]]
Evaluated with elapsed time 7.606070270994678
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 2.4027 - tp: 2392.0000 - fp: 6611.0000 - tn: 4636.0000 - fn: 310.0000 - accuracy: 0.5038 - precision: 0.2657 - recall: 0.8853 - f1_metric: 0.2488
Test Score: 2.4026808738708496
Test Accuracy: 2392.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.41      0.57     11247
           1       0.27      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.54     13949

[[4636 6611]
 [ 310 2392]]
Finished training and evaluation
{&#39;precision&#39;: 0.2670157068062827, &#39;recall&#39;: 0.9807692307692307, &#39;F1&#39;: 0.4197530864197531, &#39;ERDE_5&#39;: 0.4080746548120302, &#39;ERDE_50&#39;: 0.1674742495675605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.40339101078068257}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 11s 18ms/step - loss: 13.3630 - tp: 2690.0000 - fp: 10687.0000 - tn: 560.0000 - fn: 12.0000 - accuracy: 0.2330 - precision: 0.2011 - recall: 0.9956 - f1_metric: 0.2346
Test Score: 13.36298656463623
Test Accuracy: 2690.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.98      0.05      0.09     11247
           1       0.20      1.00      0.33      2702

    accuracy                           0.23     13949
   macro avg       0.59      0.52      0.21     13949
weighted avg       0.83      0.23      0.14     13949

[[  560 10687]
 [   12  2690]]
Finished training and evaluation
{&#39;precision&#39;: 0.24644549763033174, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3954372623574145, &#39;ERDE_5&#39;: 0.4300880481201669, &#39;ERDE_50&#39;: 0.1848330902201432, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.38002302335232274}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 2.0498 - tp: 2273.0000 - fp: 5233.0000 - tn: 6014.0000 - fn: 429.0000 - accuracy: 0.5941 - precision: 0.3028 - recall: 0.8412 - f1_metric: 0.2529
Test Score: 2.049755811691284
Test Accuracy: 2273.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.93      0.53      0.68     11247
           1       0.30      0.84      0.45      2702

    accuracy                           0.59     13949
   macro avg       0.62      0.69      0.56     13949
weighted avg       0.81      0.59      0.63     13949

[[6014 5233]
 [ 429 2273]]
Finished training and evaluation
{&#39;precision&#39;: 0.28994082840236685, &#39;recall&#39;: 0.9423076923076923, &#39;F1&#39;: 0.4434389140271493, &#39;ERDE_5&#39;: 0.38485709880709723, &#39;ERDE_50&#39;: 0.1536810690406908, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.42615355916649694}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 1.4021 - tp: 2687.0000 - fp: 10984.0000 - tn: 263.0000 - fn: 15.0000 - accuracy: 0.2115 - precision: 0.1965 - recall: 0.9944 - f1_metric: 0.2314
Test Score: 1.4021421670913696
Test Accuracy: 2687.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.02      0.05     11247
           1       0.20      0.99      0.33      2702

    accuracy                           0.21     13949
   macro avg       0.57      0.51      0.19     13949
weighted avg       0.80      0.21      0.10     13949

[[  263 10984]
 [   15  2687]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 8s 14ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Finished training and evaluation
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Evaluating for elapsed time
436/436 [==============================] - 10s 18ms/step - loss: 0.6321 - tp: 1405.0000 - fp: 1871.0000 - tn: 9376.0000 - fn: 1297.0000 - accuracy: 0.7729 - precision: 0.4289 - recall: 0.5200 - f1_metric: 0.2034
Test Score: 0.6320963501930237
Test Accuracy: 1405.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.83      0.86     11247
           1       0.43      0.52      0.47      2702

    accuracy                           0.77     13949
   macro avg       0.65      0.68      0.66     13949
weighted avg       0.79      0.77      0.78     13949

[[9376 1871]
 [1297 1405]]
Evaluated with elapsed time 193.2826354620047
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4166666666666667, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.551948051948052, &#39;ERDE_5&#39;: 0.31465784789378143, &#39;ERDE_50&#39;: 0.11526720324563171, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5304329849551183}
Writing results to CSV file
{&#39;precision&#39;: 0.42780748663101603, &#39;recall&#39;: 0.7692307692307693, &#39;F1&#39;: 0.549828178694158, &#39;ERDE_5&#39;: 0.3079335104772061, &#39;ERDE_50&#39;: 0.11893217008086455, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5262550094862726}
Writing results to CSV file
{&#39;precision&#39;: 0.4277456647398844, &#39;recall&#39;: 0.7115384615384616, &#39;F1&#39;: 0.5342960288808665, &#39;ERDE_5&#39;: 0.3033662849152717, &#39;ERDE_50&#39;: 0.12875241328919224, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5093092144396063}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.13559322033898308, &#39;ERDE_5&#39;: 0.2493149365737364, &#39;ERDE_50&#39;: 0.2304377714066248, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.13030776420034015}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10619469026548674, &#39;ERDE_5&#39;: 0.24759366984708245, &#39;ERDE_50&#39;: 0.23342219539593917, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10164173081449471}
Writing results to CSV file
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.04807692307692308, &#39;F1&#39;: 0.08928571428571429, &#39;ERDE_5&#39;: 0.2476034068741981, &#39;ERDE_50&#39;: 0.2357862615897926, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.08511019087824019}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12280701754385964, &#39;ERDE_5&#39;: 0.24757678190909485, &#39;ERDE_50&#39;: 0.23105812920208577, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.11801997064636068}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701448017607758, &#39;ERDE_50&#39;: 0.23284095926317144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.10254924626819553}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470229635313369, &#39;ERDE_50&#39;: 0.23756909165087828, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.06932611911536656}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 193.2826354620047} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluating after getting time 300622.810041294
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluated with elapsed time 1086.5614446149557
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7303370786516854, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6735751295336788, &#39;ERDE_5&#39;: 0.2596316193308309, &#39;ERDE_50&#39;: 0.10988875012693046, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6446964704943554}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6511627906976744, &#39;ERDE_5&#39;: 0.2527820221517472, &#39;ERDE_50&#39;: 0.12317396059925918, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6194438484410668}
Writing results to CSV file
{&#39;precision&#39;: 0.8541666666666666, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5394736842105263, &#39;ERDE_5&#39;: 0.24991804340045143, &#39;ERDE_50&#39;: 0.15300485430110675, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5079504256397883}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluating after getting time 301728.621822629
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluated with elapsed time 8.18353883898817
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5205 - tp: 409.0000 - fp: 85.0000 - tn: 11162.0000 - fn: 2293.0000 - accuracy: 0.8295 - precision: 0.8279 - recall: 0.1514 - f1_metric: 0.0832
Test Score: 0.5204916000366211
Test Accuracy: 409.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.15      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.58     13949
weighted avg       0.83      0.83      0.78     13949

[[11162    85]
 [ 2293   409]]
Finished training and evaluation
{&#39;precision&#39;: 0.6794871794871795, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5824175824175823, &#39;ERDE_5&#39;: 0.2602910134248677, &#39;ERDE_50&#39;: 0.13693204464176645, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5529142859675543}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 15s 23ms/step - loss: 0.4000 - tp: 584.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2118.0000 - accuracy: 0.8344 - precision: 0.7526 - recall: 0.2161 - f1_metric: 0.1211
Test Score: 0.400028258562088
Test Accuracy: 584.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.6055045871559633, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.619718309859155, &#39;ERDE_5&#39;: 0.27069331202449276, &#39;ERDE_50&#39;: 0.11603158997275352, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5895310670274139}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.4022 - tp: 623.0000 - fp: 188.0000 - tn: 11059.0000 - fn: 2079.0000 - accuracy: 0.8375 - precision: 0.7682 - recall: 0.2306 - f1_metric: 0.1231
Test Score: 0.40219637751579285
Test Accuracy: 623.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.23      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.61      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11059   188]
 [ 2079   623]]
Finished training and evaluation
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 14s 26ms/step - loss: 0.6176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.617611825466156
Test Accuracy: 0.0
436/436 [==============================] - 10s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 18s 34ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.5596330275229358, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5727699530516431, &#39;ERDE_5&#39;: 0.2735923421691488, &#39;ERDE_50&#39;: 0.1298676685075436, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.548213185058147}
Evaluating for elapsed time
436/436 [==============================] - 14s 23ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 12s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Evaluated with elapsed time 196.8892295899568
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Writing results to CSV file
{&#39;precision&#39;: 0.6744186046511628, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6105263157894736, &#39;ERDE_5&#39;: 0.26208100053306677, &#39;ERDE_50&#39;: 0.12561273950461457, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5784118956357502}
Writing results to CSV file
{&#39;precision&#39;: 0.7205882352941176, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5697674418604651, &#39;ERDE_5&#39;: 0.2568923025147678, &#39;ERDE_50&#39;: 0.14330145840852437, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5342600273131639}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.2561511333125505, &#39;ERDE_50&#39;: 0.12330163461117499, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6168147257020353}
Writing results to CSV file
{&#39;precision&#39;: 0.828125, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.6309523809523809, &#39;ERDE_5&#39;: 0.2522014714936964, &#39;ERDE_50&#39;: 0.12759681497156067, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6014453488728972}
Writing results to CSV file
{&#39;precision&#39;: 0.8478260869565217, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.52, &#39;ERDE_5&#39;: 0.24991830819753286, &#39;ERDE_50&#39;: 0.1577329865909664, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4896146541776691}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7283950617283951, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6378378378378379, &#39;ERDE_5&#39;: 0.25846377815921434, &#39;ERDE_50&#39;: 0.11956411165724333, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6129747664613298}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25626666852331265, &#39;ERDE_50&#39;: 0.1295831653920135, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5849391300359054}
Writing results to CSV file
{&#39;precision&#39;: 0.7358490566037735, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4968152866242037, &#39;ERDE_5&#39;: 0.2539837609956759, &#39;ERDE_50&#39;: 0.16180162506873094, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47358129140911215}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.76, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6368715083798883, &#39;ERDE_5&#39;: 0.2561611714562794, &#39;ERDE_50&#39;: 0.12821410084784307, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6095664694377656}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539490796723001, &#39;ERDE_50&#39;: 0.14317088550695795, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.543054599737038}
Writing results to CSV file
{&#39;precision&#39;: 0.78, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5064935064935064, &#39;ERDE_5&#39;: 0.25224401093130044, &#39;ERDE_50&#39;: 0.16005792215122625, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4768973904327945}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 196.8892295899568} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluating after getting time 311357.525954508
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluated with elapsed time 1645.38735593803
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7303370786516854, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6735751295336788, &#39;ERDE_5&#39;: 0.2596316193308309, &#39;ERDE_50&#39;: 0.10988875012693046, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6446964704943554}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6511627906976744, &#39;ERDE_5&#39;: 0.2527820221517472, &#39;ERDE_50&#39;: 0.12317396059925918, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6194438484410668}
Writing results to CSV file
{&#39;precision&#39;: 0.8541666666666666, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5394736842105263, &#39;ERDE_5&#39;: 0.24991804340045143, &#39;ERDE_50&#39;: 0.15300485430110675, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5079504256397883}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluating after getting time 313024.881296007
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluated with elapsed time 8.711176547978539
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 12ms/step - loss: 0.5012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5012255311012268
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5095410346984863
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00035: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4506 - tp: 982.0000 - fp: 621.0000 - tn: 10626.0000 - fn: 1720.0000 - accuracy: 0.8322 - precision: 0.6126 - recall: 0.3634 - f1_metric: 0.1773
Test Score: 0.45056480169296265
Test Accuracy: 982.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.94      0.90     11247
           1       0.61      0.36      0.46      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.65      0.68     13949
weighted avg       0.81      0.83      0.81     13949

[[10626   621]
 [ 1720   982]]
Finished training and evaluation
{&#39;precision&#39;: 0.4880952380952381, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.6029411764705882, &#39;ERDE_5&#39;: 0.29556808679097213, &#39;ERDE_50&#39;: 0.1043756921166237, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5794383852952624}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5211 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5210582613945007
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 7s 11ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 209.53094475000398
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 209.53094475000398} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluating after getting time 320172.937434078
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluated with elapsed time 1268.2192522599944
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7325581395348837, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.663157894736842, &#39;ERDE_5&#39;: 0.2590692743603174, &#39;ERDE_50&#39;: 0.11612189306656744, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6321447440388027}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2527867251107897, &#39;ERDE_50&#39;: 0.13498841131779749, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5822148626305483}
Writing results to CSV file
{&#39;precision&#39;: 0.8888888888888888, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5369127516778524, &#39;ERDE_5&#39;: 0.2487554431777269, &#39;ERDE_50&#39;: 0.15538849394318163, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5034528130276082}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluating after getting time 321462.106959231
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluated with elapsed time 8.56650734494906
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5936288833618164
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.3994 - tp: 512.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2190.0000 - accuracy: 0.8331 - precision: 0.7877 - recall: 0.1895 - f1_metric: 0.1028
Test Score: 0.3994370400905609
Test Accuracy: 512.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2190   512]]
Finished training and evaluation
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6494845360824743, &#39;ERDE_5&#39;: 0.26140644379269445, &#39;ERDE_50&#39;: 0.11262328232115389, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6165838555635069}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4017 - tp: 568.0000 - fp: 194.0000 - tn: 11053.0000 - fn: 2134.0000 - accuracy: 0.8331 - precision: 0.7454 - recall: 0.2102 - f1_metric: 0.1139
Test Score: 0.4016605317592621
Test Accuracy: 568.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.75      0.21      0.33      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.60      0.62     13949
weighted avg       0.82      0.83      0.79     13949

[[11053   194]
 [ 2134   568]]
Finished training and evaluation
{&#39;precision&#39;: 0.6017699115044248, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6267281105990784, &#39;ERDE_5&#39;: 0.27183954873518135, &#39;ERDE_50&#39;: 0.11328805467567826, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5986382934151268}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.6187 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6187241673469543
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Finished training and evaluation
{&#39;precision&#39;: 0.6444444444444445, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5979381443298969, &#39;ERDE_5&#39;: 0.2643079528067778, &#39;ERDE_50&#39;: 0.12768686242459712, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5688118402106115}
Evaluating for elapsed time
436/436 [==============================] - 7s 14ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Evaluated with elapsed time 235.31945848005125
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 235.31945848005125} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluating after getting time 329772.183575383
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluated with elapsed time 1019.9988489240059
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7325581395348837, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.663157894736842, &#39;ERDE_5&#39;: 0.2590692743603174, &#39;ERDE_50&#39;: 0.11612189306656744, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6321447440388027}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2527867251107897, &#39;ERDE_50&#39;: 0.13498841131779749, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5822148626305483}
Writing results to CSV file
{&#39;precision&#39;: 0.8888888888888888, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5369127516778524, &#39;ERDE_5&#39;: 0.2487554431777269, &#39;ERDE_50&#39;: 0.15538849394318163, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5034528130276082}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluating after getting time 330811.784957852
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluated with elapsed time 7.819588766025845
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 15ms/step - loss: 0.5063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062928795814514
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49377965927124023
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4958 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49575263261795044
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 14ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5005954504013062
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 14ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 7s 13ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 178.45176671398804
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 178.45176671398804} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 336379.925891478
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 1326.7594523309963
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluating after getting time 337727.136128414
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluated with elapsed time 6.596565957006533
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 1.8411 - tp: 2607.0000 - fp: 9393.0000 - tn: 1854.0000 - fn: 95.0000 - accuracy: 0.3198 - precision: 0.2173 - recall: 0.9648 - f1_metric: 0.2398
Test Score: 1.8410987854003906
Test Accuracy: 2607.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.16      0.28     11247
           1       0.22      0.96      0.35      2702

    accuracy                           0.32     13949
   macro avg       0.58      0.56      0.32     13949
weighted avg       0.81      0.32      0.30     13949

[[1854 9393]
 [  95 2607]]
Finished training and evaluation
{&#39;precision&#39;: 0.2549019607843137, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.40625, &#39;ERDE_5&#39;: 0.42199367926099673, &#39;ERDE_50&#39;: 0.17669578436142755, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3904142778971128}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 1.0303 - tp: 1993.0000 - fp: 2992.0000 - tn: 8255.0000 - fn: 709.0000 - accuracy: 0.7347 - precision: 0.3998 - recall: 0.7376 - f1_metric: 0.2542
Test Score: 1.030272364616394
Test Accuracy: 1993.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.73      0.82     11247
           1       0.40      0.74      0.52      2702

    accuracy                           0.73     13949
   macro avg       0.66      0.74      0.67     13949
weighted avg       0.82      0.73      0.76     13949

[[8255 2992]
 [ 709 1993]]
Finished training and evaluation
{&#39;precision&#39;: 0.33916083916083917, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.49743589743589745, &#39;ERDE_5&#39;: 0.3552429735866426, &#39;ERDE_50&#39;: 0.12641791479377032, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47804572725547856}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.6222 - tp: 1716.0000 - fp: 2059.0000 - tn: 9188.0000 - fn: 986.0000 - accuracy: 0.7817 - precision: 0.4546 - recall: 0.6351 - f1_metric: 0.2350
Test Score: 0.6222425103187561
Test Accuracy: 1716.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.64      0.53      2702

    accuracy                           0.78     13949
   macro avg       0.68      0.73      0.69     13949
weighted avg       0.82      0.78      0.79     13949

[[9188 2059]
 [ 986 1716]]
Finished training and evaluation
{&#39;precision&#39;: 0.3467153284671533, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.5026455026455027, &#39;ERDE_5&#39;: 0.3494565491730302, &#39;ERDE_50&#39;: 0.12531894827977272, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48305226080880054}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 28.4680 - tp: 2395.0000 - fp: 6703.0000 - tn: 4544.0000 - fn: 307.0000 - accuracy: 0.4975 - precision: 0.2632 - recall: 0.8864 - f1_metric: 0.2481
Test Score: 28.467981338500977
Test Accuracy: 2395.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.40      0.56     11247
           1       0.26      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.53     13949

[[4544 6703]
 [ 307 2395]]
Finished training and evaluation
{&#39;precision&#39;: 0.2724867724867725, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.42738589211618255, &#39;ERDE_5&#39;: 0.4051767502640007, &#39;ERDE_50&#39;: 0.1622041100334401, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.41072628788665294}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 14ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Finished training and evaluation
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Evaluating for elapsed time
436/436 [==============================] - 7s 12ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Evaluated with elapsed time 200.93058261997066
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Writing results to CSV file
{&#39;precision&#39;: 0.37872340425531914, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5250737463126843, &#39;ERDE_5&#39;: 0.330569517623507, &#39;ERDE_50&#39;: 0.12204974523208358, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.502561891249446}
Writing results to CSV file
{&#39;precision&#39;: 0.37327188940092165, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5046728971962617, &#39;ERDE_5&#39;: 0.3248608206651402, &#39;ERDE_50&#39;: 0.136139710927823, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4810714340482212}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5619834710743802, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6044444444444445, &#39;ERDE_5&#39;: 0.2764308589464142, &#39;ERDE_50&#39;: 0.12259257665012142, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5808830555241828}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701999423433874, &#39;ERDE_50&#39;: 0.12837457260333038, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5925925925925926, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.518918918918919, &#39;ERDE_5&#39;: 0.2650210701580968, &#39;ERDE_50&#39;: 0.15641163439127084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49465122828261543}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 200.93058261997066} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 345022.823082765
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 1059.3911199240247
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluating after getting time 346105.068638469
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluated with elapsed time 8.353714430995751
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 15s 27ms/step - loss: 1.2387 - tp: 2107.0000 - fp: 4122.0000 - tn: 7125.0000 - fn: 595.0000 - accuracy: 0.6618 - precision: 0.3383 - recall: 0.7798 - f1_metric: 0.2513
Test Score: 1.2387062311172485
Test Accuracy: 2107.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75     11247
           1       0.34      0.78      0.47      2702

    accuracy                           0.66     13949
   macro avg       0.63      0.71      0.61     13949
weighted avg       0.81      0.66      0.70     13949

[[7125 4122]
 [ 595 2107]]
Finished training and evaluation
{&#39;precision&#39;: 0.3089171974522293, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.46411483253588515, &#39;ERDE_5&#39;: 0.3715099833486213, &#39;ERDE_50&#39;: 0.1426777887430125, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4460235254297527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 1.1399 - tp: 1889.0000 - fp: 2783.0000 - tn: 8464.0000 - fn: 813.0000 - accuracy: 0.7422 - precision: 0.4043 - recall: 0.6991 - f1_metric: 0.2450
Test Score: 1.139872431755066
Test Accuracy: 1889.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.75      0.82     11247
           1       0.40      0.70      0.51      2702

    accuracy                           0.74     13949
   macro avg       0.66      0.73      0.67     13949
weighted avg       0.81      0.74      0.76     13949

[[8464 2783]
 [ 813 1889]]
Finished training and evaluation
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 1.8779 - tp: 2518.0000 - fp: 7650.0000 - tn: 3597.0000 - fn: 184.0000 - accuracy: 0.4384 - precision: 0.2476 - recall: 0.9319 - f1_metric: 0.2559
Test Score: 1.8779231309890747
Test Accuracy: 2518.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.32      0.48     11247
           1       0.25      0.93      0.39      2702

    accuracy                           0.44     13949
   macro avg       0.60      0.63      0.44     13949
weighted avg       0.82      0.44      0.46     13949

[[3597 7650]
 [ 184 2518]]
Finished training and evaluation
{&#39;precision&#39;: 0.2594458438287154, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.4111776447105789, &#39;ERDE_5&#39;: 0.4161876896193017, &#39;ERDE_50&#39;: 0.17324748922757083, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3951498418390554}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 16s 25ms/step - loss: 2.6045 - tp: 2692.0000 - fp: 11232.0000 - tn: 15.0000 - fn: 10.0000 - accuracy: 0.1941 - precision: 0.1933 - recall: 0.9963 - f1_metric: 0.2296
Test Score: 2.6044859886169434
Test Accuracy: 2692.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.60      0.00      0.00     11247
           1       0.19      1.00      0.32      2702

    accuracy                           0.19     13949
   macro avg       0.40      0.50      0.16     13949
weighted avg       0.52      0.19      0.06     13949

[[   15 11232]
 [   10  2692]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Finished training and evaluation
{&#39;precision&#39;: 0.24821002386634844, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.39770554493307836, &#39;ERDE_5&#39;: 0.4283501706414428, &#39;ERDE_50&#39;: 0.18308938182183992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3822028877310167}
Evaluating for elapsed time
436/436 [==============================] - 11s 17ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Evaluated with elapsed time 192.97452491294825
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Writing results to CSV file
{&#39;precision&#39;: 0.3723849372384937, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5189504373177842, &#39;ERDE_5&#39;: 0.33289417733800136, &#39;ERDE_50&#39;: 0.12474453796969241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4967011111765661}
Writing results to CSV file
{&#39;precision&#39;: 0.37272727272727274, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.326022395106226, &#39;ERDE_50&#39;: 0.13436075741070738, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4825012302628135}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5303030303030303, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5932203389830509, &#39;ERDE_5&#39;: 0.281661983854306, &#39;ERDE_50&#39;: 0.11900323512970122, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5700964683764881}
Writing results to CSV file
{&#39;precision&#39;: 0.5803571428571429, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6018518518518519, &#39;ERDE_5&#39;: 0.27310612268176654, &#39;ERDE_50&#39;: 0.12366488257450577, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5760482352102342}
Writing results to CSV file
{&#39;precision&#39;: 0.5652173913043478, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5306122448979592, &#39;ERDE_5&#39;: 0.26908893019132096, &#39;ERDE_50&#39;: 0.15130584066860875, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5057977057906846}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 192.97452491294825} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 354233.915422354
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 908.8881159189623
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluating after getting time 355160.006000001
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluated with elapsed time 8.071183525025845
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 1.8411 - tp: 2607.0000 - fp: 9393.0000 - tn: 1854.0000 - fn: 95.0000 - accuracy: 0.3198 - precision: 0.2173 - recall: 0.9648 - f1_metric: 0.2398
Test Score: 1.8410987854003906
Test Accuracy: 2607.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.16      0.28     11247
           1       0.22      0.96      0.35      2702

    accuracy                           0.32     13949
   macro avg       0.58      0.56      0.32     13949
weighted avg       0.81      0.32      0.30     13949

[[1854 9393]
 [  95 2607]]
Finished training and evaluation
{&#39;precision&#39;: 0.2549019607843137, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.40625, &#39;ERDE_5&#39;: 0.42199367926099673, &#39;ERDE_50&#39;: 0.17669578436142755, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3904142778971128}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00030: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 1.0303 - tp: 1993.0000 - fp: 2992.0000 - tn: 8255.0000 - fn: 709.0000 - accuracy: 0.7347 - precision: 0.3998 - recall: 0.7376 - f1_metric: 0.2542
Test Score: 1.030272364616394
Test Accuracy: 1993.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.73      0.82     11247
           1       0.40      0.74      0.52      2702

    accuracy                           0.73     13949
   macro avg       0.66      0.74      0.67     13949
weighted avg       0.82      0.73      0.76     13949

[[8255 2992]
 [ 709 1993]]
Finished training and evaluation
{&#39;precision&#39;: 0.33916083916083917, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.49743589743589745, &#39;ERDE_5&#39;: 0.3552429735866426, &#39;ERDE_50&#39;: 0.12641791479377032, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47804572725547856}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 9s 19ms/step - loss: 0.6222 - tp: 1716.0000 - fp: 2059.0000 - tn: 9188.0000 - fn: 986.0000 - accuracy: 0.7817 - precision: 0.4546 - recall: 0.6351 - f1_metric: 0.2350
Test Score: 0.6222425103187561
Test Accuracy: 1716.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.82      0.86     11247
           1       0.45      0.64      0.53      2702

    accuracy                           0.78     13949
   macro avg       0.68      0.73      0.69     13949
weighted avg       0.82      0.78      0.79     13949

[[9188 2059]
 [ 986 1716]]
Finished training and evaluation
{&#39;precision&#39;: 0.3467153284671533, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.5026455026455027, &#39;ERDE_5&#39;: 0.3494565491730302, &#39;ERDE_50&#39;: 0.12531894827977272, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48305226080880054}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 28.4680 - tp: 2395.0000 - fp: 6703.0000 - tn: 4544.0000 - fn: 307.0000 - accuracy: 0.4975 - precision: 0.2632 - recall: 0.8864 - f1_metric: 0.2481
Test Score: 28.467981338500977
Test Accuracy: 2395.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.94      0.40      0.56     11247
           1       0.26      0.89      0.41      2702

    accuracy                           0.50     13949
   macro avg       0.60      0.65      0.49     13949
weighted avg       0.81      0.50      0.53     13949

[[4544 6703]
 [ 307 2395]]
Finished training and evaluation
{&#39;precision&#39;: 0.2724867724867725, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.42738589211618255, &#39;ERDE_5&#39;: 0.4051767502640007, &#39;ERDE_50&#39;: 0.1622041100334401, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.41072628788665294}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Finished training and evaluation
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Evaluating for elapsed time
436/436 [==============================] - 9s 16ms/step - loss: 0.8663 - tp: 1793.0000 - fp: 2670.0000 - tn: 8577.0000 - fn: 909.0000 - accuracy: 0.7434 - precision: 0.4017 - recall: 0.6636 - f1_metric: 0.2330
Test Score: 0.8663389086723328
Test Accuracy: 1793.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.76      0.83     11247
           1       0.40      0.66      0.50      2702

    accuracy                           0.74     13949
   macro avg       0.65      0.71      0.66     13949
weighted avg       0.81      0.74      0.76     13949

[[8577 2670]
 [ 909 1793]]
Evaluated with elapsed time 180.78239296597894
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3684210526315789, &#39;recall&#39;: 0.875, &#39;F1&#39;: 0.5185185185185185, &#39;ERDE_5&#39;: 0.3360891328020567, &#39;ERDE_50&#39;: 0.12140569946441912, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4983065427290784}
Writing results to CSV file
{&#39;precision&#39;: 0.37872340425531914, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5250737463126843, &#39;ERDE_5&#39;: 0.330569517623507, &#39;ERDE_50&#39;: 0.12204974523208358, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.502561891249446}
Writing results to CSV file
{&#39;precision&#39;: 0.37327188940092165, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5046728971962617, &#39;ERDE_5&#39;: 0.3248608206651402, &#39;ERDE_50&#39;: 0.136139710927823, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4810714340482212}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5619834710743802, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6044444444444445, &#39;ERDE_5&#39;: 0.2764308589464142, &#39;ERDE_50&#39;: 0.12259257665012142, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5808830555241828}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701999423433874, &#39;ERDE_50&#39;: 0.12837457260333038, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5925925925925926, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.518918918918919, &#39;ERDE_5&#39;: 0.2650210701580968, &#39;ERDE_50&#39;: 0.15641163439127084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49465122828261543}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5609756097560976, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6079295154185023, &#39;ERDE_5&#39;: 0.27700044367281923, &#39;ERDE_50&#39;: 0.12080974658903573, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5842322775986616}
Writing results to CSV file
{&#39;precision&#39;: 0.5887850467289719, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5971563981042654, &#39;ERDE_5&#39;: 0.2713602608235933, &#39;ERDE_50&#39;: 0.12717297867501245, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5715540929450139}
Writing results to CSV file
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5212765957446809, &#39;ERDE_5&#39;: 0.26618274963372573, &#39;ERDE_50&#39;: 0.15521004046295292, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49689864631891717}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 180.78239296597894} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 363752.27755815
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 965.0850177899702
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluating after getting time 364734.370174658
              precision    recall  f1-score   support

           0       0.85      0.95      0.90     11247
           1       0.62      0.31      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10722   525]
 [ 1860   842]]
Evaluated with elapsed time 7.501896921952721
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 1.2387 - tp: 2107.0000 - fp: 4122.0000 - tn: 7125.0000 - fn: 595.0000 - accuracy: 0.6618 - precision: 0.3383 - recall: 0.7798 - f1_metric: 0.2513
Test Score: 1.2387062311172485
Test Accuracy: 2107.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75     11247
           1       0.34      0.78      0.47      2702

    accuracy                           0.66     13949
   macro avg       0.63      0.71      0.61     13949
weighted avg       0.81      0.66      0.70     13949

[[7125 4122]
 [ 595 2107]]
Finished training and evaluation
{&#39;precision&#39;: 0.3089171974522293, &#39;recall&#39;: 0.9326923076923077, &#39;F1&#39;: 0.46411483253588515, &#39;ERDE_5&#39;: 0.3715099833486213, &#39;ERDE_50&#39;: 0.1426777887430125, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4460235254297527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 1.1399 - tp: 1889.0000 - fp: 2783.0000 - tn: 8464.0000 - fn: 813.0000 - accuracy: 0.7422 - precision: 0.4043 - recall: 0.6991 - f1_metric: 0.2450
Test Score: 1.139872431755066
Test Accuracy: 1889.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.75      0.82     11247
           1       0.40      0.70      0.51      2702

    accuracy                           0.74     13949
   macro avg       0.66      0.73      0.67     13949
weighted avg       0.81      0.74      0.76     13949

[[8464 2783]
 [ 813 1889]]
Finished training and evaluation
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 1.8779 - tp: 2518.0000 - fp: 7650.0000 - tn: 3597.0000 - fn: 184.0000 - accuracy: 0.4384 - precision: 0.2476 - recall: 0.9319 - f1_metric: 0.2559
Test Score: 1.8779231309890747
Test Accuracy: 2518.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.95      0.32      0.48     11247
           1       0.25      0.93      0.39      2702

    accuracy                           0.44     13949
   macro avg       0.60      0.63      0.44     13949
weighted avg       0.82      0.44      0.46     13949

[[3597 7650]
 [ 184 2518]]
Finished training and evaluation
{&#39;precision&#39;: 0.2594458438287154, &#39;recall&#39;: 0.9903846153846154, &#39;F1&#39;: 0.4111776447105789, &#39;ERDE_5&#39;: 0.4161876896193017, &#39;ERDE_50&#39;: 0.17324748922757083, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3951498418390554}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 7s 15ms/step - loss: 2.6045 - tp: 2692.0000 - fp: 11232.0000 - tn: 15.0000 - fn: 10.0000 - accuracy: 0.1941 - precision: 0.1933 - recall: 0.9963 - f1_metric: 0.2296
Test Score: 2.6044859886169434
Test Accuracy: 2692.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.60      0.00      0.00     11247
           1       0.19      1.00      0.32      2702

    accuracy                           0.19     13949
   macro avg       0.40      0.50      0.16     13949
weighted avg       0.52      0.19      0.06     13949

[[   15 11232]
 [   10  2692]]
Finished training and evaluation
{&#39;precision&#39;: 0.2458628841607565, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.3946869070208729, &#39;ERDE_5&#39;: 0.43066928425293466, &#39;ERDE_50&#39;: 0.18541432635291089, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.37930191704615135}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
436/436 [==============================] - 13s 25ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 10s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Finished training and evaluation
{&#39;precision&#39;: 0.24821002386634844, &#39;recall&#39;: 1.0, &#39;F1&#39;: 0.39770554493307836, &#39;ERDE_5&#39;: 0.4283501706414428, &#39;ERDE_50&#39;: 0.18308938182183992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.3822028877310167}
Evaluating for elapsed time
436/436 [==============================] - 12s 23ms/step - loss: 3.1618 - tp: 2610.0000 - fp: 10144.0000 - tn: 1103.0000 - fn: 92.0000 - accuracy: 0.2662 - precision: 0.2046 - recall: 0.9660 - f1_metric: 0.2342
Test Score: 3.1618428230285645
Test Accuracy: 2610.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.10      0.18     11247
           1       0.20      0.97      0.34      2702

    accuracy                           0.27     13949
   macro avg       0.56      0.53      0.26     13949
weighted avg       0.78      0.27      0.21     13949

[[ 1103 10144]
 [   92  2610]]
Evaluated with elapsed time 198.33662138902582
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.36363636363636365, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.5154061624649859, &#39;ERDE_5&#39;: 0.3389937909914647, &#39;ERDE_50&#39;: 0.12195365937901174, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49531550705843563}
Writing results to CSV file
{&#39;precision&#39;: 0.3723849372384937, &#39;recall&#39;: 0.8557692307692307, &#39;F1&#39;: 0.5189504373177842, &#39;ERDE_5&#39;: 0.33289417733800136, &#39;ERDE_50&#39;: 0.12474453796969241, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4967011111765661}
Writing results to CSV file
{&#39;precision&#39;: 0.37272727272727274, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.326022395106226, &#39;ERDE_50&#39;: 0.13436075741070738, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4825012302628135}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5303030303030303, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.5932203389830509, &#39;ERDE_5&#39;: 0.281661983854306, &#39;ERDE_50&#39;: 0.11900323512970122, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5700964683764881}
Writing results to CSV file
{&#39;precision&#39;: 0.5803571428571429, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6018518518518519, &#39;ERDE_5&#39;: 0.27310612268176654, &#39;ERDE_50&#39;: 0.12366488257450577, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5760482352102342}
Writing results to CSV file
{&#39;precision&#39;: 0.5652173913043478, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5306122448979592, &#39;ERDE_5&#39;: 0.26908893019132096, &#39;ERDE_50&#39;: 0.15130584066860875, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5057977057906846}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5298507462686567, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.5966386554621849, &#39;ERDE_5&#39;: 0.2822315685807111, &#39;ERDE_50&#39;: 0.11722040506861554, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5733815380622109}
Writing results to CSV file
{&#39;precision&#39;: 0.5739130434782609, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6027397260273972, &#39;ERDE_5&#39;: 0.2742664411619724, &#39;ERDE_50&#39;: 0.12246328864618784, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5768980429334105}
Writing results to CSV file
{&#39;precision&#39;: 0.5578947368421052, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5326633165829145, &#39;ERDE_5&#39;: 0.27025060966694986, &#39;ERDE_50&#39;: 0.15010424674029083, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5077528573399334}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4896551724137931, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.570281124497992, &#39;ERDE_5&#39;: 0.28862589967471486, &#39;ERDE_50&#39;: 0.1235177068751769, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.548051429955045}
Writing results to CSV file
{&#39;precision&#39;: 0.5537190082644629, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5955555555555556, &#39;ERDE_5&#39;: 0.2771726145506693, &#39;ERDE_50&#39;: 0.12265400212090542, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5700218844418811}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5320197044334977, &#39;ERDE_5&#39;: 0.27199431537628993, &#39;ERDE_50&#39;: 0.14867840786581907, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.507139344267583}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 198.33662138902582} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2216   486]]
Evaluating after getting time 373164.140670551
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2216   486]]
Evaluated with elapsed time 1522.0580626550363
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6808510638297872, &#39;ERDE_5&#39;: 0.2573198731223932, &#39;ERDE_50&#39;: 0.1079640080909354, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6476859691906596}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2533715945799426, &#39;ERDE_50&#39;: 0.14029778361037085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2504995926458081, &#39;ERDE_50&#39;: 0.17131659719110962, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4403485280091918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluating after getting time 374709.607077446
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluated with elapsed time 8.295366432983428
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.7333333333333333, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4429530201342282, &#39;ERDE_5&#39;: 0.2528263155129281, &#39;ERDE_50&#39;: 0.17482382591147347, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4187917899621567}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5864 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5864015221595764
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4044 - tp: 501.0000 - fp: 171.0000 - tn: 11076.0000 - fn: 2201.0000 - accuracy: 0.8300 - precision: 0.7455 - recall: 0.1854 - f1_metric: 0.1072
Test Score: 0.40444839000701904
Test Accuracy: 501.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.98      0.90     11247
           1       0.75      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.59      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11076   171]
 [ 2201   501]]
Finished training and evaluation
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5866666666666666, &#39;ERDE_5&#39;: 0.27769189615542506, &#39;ERDE_50&#39;: 0.12612502911273288, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.554666459594323}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4189 - tp: 368.0000 - fp: 113.0000 - tn: 11134.0000 - fn: 2334.0000 - accuracy: 0.8246 - precision: 0.7651 - recall: 0.1362 - f1_metric: 0.0769
Test Score: 0.41891103982925415
Test Accuracy: 368.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.14      0.23      2702

    accuracy                           0.82     13949
   macro avg       0.80      0.56      0.57     13949
weighted avg       0.81      0.82      0.77     13949

[[11134   113]
 [ 2334   368]]
Finished training and evaluation
{&#39;precision&#39;: 0.6276595744680851, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5959595959595959, &#39;ERDE_5&#39;: 0.26610279958858635, &#39;ERDE_50&#39;: 0.12853378919850525, &#39;median_latency_tps&#39;: 19.0, &#39;median_penalty_tps&#39;: 0.07008491072449874, &#39;speed&#39;: 0.9299150892755013, &#39;latency_weighted_f1&#39;: 0.5541918208813593}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.6198 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6198097467422485
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00027: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4676 - tp: 464.0000 - fp: 124.0000 - tn: 11123.0000 - fn: 2238.0000 - accuracy: 0.8307 - precision: 0.7891 - recall: 0.1717 - f1_metric: 0.0951
Test Score: 0.4675743877887726
Test Accuracy: 464.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.79      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11123   124]
 [ 2238   464]]
Finished training and evaluation
{&#39;precision&#39;: 0.5784313725490197, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5728155339805826, &#39;ERDE_5&#39;: 0.2707314546655556, &#39;ERDE_50&#39;: 0.13870586431451912, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5415708481255251}
Evaluating for elapsed time
436/436 [==============================] - 8s 14ms/step - loss: 0.4676 - tp: 464.0000 - fp: 124.0000 - tn: 11123.0000 - fn: 2238.0000 - accuracy: 0.8307 - precision: 0.7891 - recall: 0.1717 - f1_metric: 0.0951
Test Score: 0.4675743877887726
Test Accuracy: 464.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.79      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11123   124]
 [ 2238   464]]
Evaluated with elapsed time 183.09583136299625
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.7333333333333333, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4429530201342282, &#39;ERDE_5&#39;: 0.2528263155129281, &#39;ERDE_50&#39;: 0.17482382591147347, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4187917899621567}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 183.09583136299625} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2216   486]]
Evaluating after getting time 381449.495980868
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11159    88]
 [ 2216   486]]
Evaluated with elapsed time 644.1428067620145
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6808510638297872, &#39;ERDE_5&#39;: 0.2573198731223932, &#39;ERDE_50&#39;: 0.1079640080909354, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6476859691906596}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2533715945799426, &#39;ERDE_50&#39;: 0.14029778361037085, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4657534246575343, &#39;ERDE_5&#39;: 0.2504995926458081, &#39;ERDE_50&#39;: 0.17131659719110962, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4403485280091918}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluating after getting time 382113.653825409
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11113   134]
 [ 2254   448]]
Evaluated with elapsed time 9.193436043977272
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.7333333333333333, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4429530201342282, &#39;ERDE_5&#39;: 0.2528263155129281, &#39;ERDE_50&#39;: 0.17482382591147347, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4187917899621567}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5114 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114208459854126
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5069946050643921
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4976 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49764135479927063
Test Accuracy: 0.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5178 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5177649259567261
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114524364471436
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 8s 13ms/step - loss: 0.5115 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5114524364471436
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 228.54980708198855
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.2527336450311057, &#39;ERDE_50&#39;: 0.14673654337793568, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5306888552764878}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.2510659690953757, &#39;ERDE_50&#39;: 0.16662343722797543, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4549852232936523}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24934235602859336, &#39;ERDE_50&#39;: 0.19024870012207312, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.348728386166431}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6708860759493671, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5792349726775956, &#39;ERDE_5&#39;: 0.26082512302012006, &#39;ERDE_50&#39;: 0.1359673112043417, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5544010253624851}
Writing results to CSV file
{&#39;precision&#39;: 0.6984126984126984, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5269461077844312, &#39;ERDE_5&#39;: 0.25686185569558306, &#39;ERDE_50&#39;: 0.1535233615797802, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.502303018740081}
Writing results to CSV file
{&#39;precision&#39;: 0.7333333333333333, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4429530201342282, &#39;ERDE_5&#39;: 0.2528263155129281, &#39;ERDE_50&#39;: 0.17482382591147347, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4187917899621567}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 228.54980708198855} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11160    87]
 [ 2224   478]]
Evaluating after getting time 388800.414969336
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11160    87]
 [ 2224   478]]
Evaluated with elapsed time 1164.1269681620179
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6910994764397905, &#39;ERDE_5&#39;: 0.2579114334382352, &#39;ERDE_50&#39;: 0.10381790389475583, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6574351689886865}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25337587031875286, &#39;ERDE_50&#39;: 0.13977410550168118, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8444444444444444, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5100671140939597, &#39;ERDE_5&#39;: 0.24992003385985165, &#39;ERDE_50&#39;: 0.1610147301362342, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4802621801432995}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11097   150]
 [ 2251   451]]
Evaluating after getting time 389985.356697744
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11097   150]
 [ 2251   451]]
Evaluated with elapsed time 9.580767399980687
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6063829787234043, &#39;ERDE_5&#39;: 0.2613997850005331, &#39;ERDE_50&#39;: 0.12917474433778972, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5803850959008514}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618620725716, &#39;ERDE_50&#39;: 0.14644702557844638, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7115384615384616, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4743589743589744, &#39;ERDE_5&#39;: 0.25456925472849906, &#39;ERDE_50&#39;: 0.16715389868010888, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4466405868977751}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5785 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5785091519355774
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4119 - tp: 377.0000 - fp: 160.0000 - tn: 11087.0000 - fn: 2325.0000 - accuracy: 0.8219 - precision: 0.7020 - recall: 0.1395 - f1_metric: 0.0835
Test Score: 0.4118872284889221
Test Accuracy: 377.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.70      0.14      0.23      2702

    accuracy                           0.82     13949
   macro avg       0.76      0.56      0.57     13949
weighted avg       0.80      0.82      0.77     13949

[[11087   160]
 [ 2325   377]]
Finished training and evaluation
{&#39;precision&#39;: 0.5566037735849056, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5619047619047619, &#39;ERDE_5&#39;: 0.2730883117056404, &#39;ERDE_50&#39;: 0.13501138688376482, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5290707801553567}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4113 - tp: 275.0000 - fp: 59.0000 - tn: 11188.0000 - fn: 2427.0000 - accuracy: 0.8218 - precision: 0.8234 - recall: 0.1018 - f1_metric: 0.0625
Test Score: 0.41131502389907837
Test Accuracy: 275.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.82      0.10      0.18      2702

    accuracy                           0.82     13949
   macro avg       0.82      0.55      0.54     13949
weighted avg       0.82      0.82      0.76     13949

[[11188    59]
 [ 2427   275]]
Finished training and evaluation
{&#39;precision&#39;: 0.6578947368421053, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.2608765182527739, &#39;ERDE_50&#39;: 0.14485613142687018, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5274129981451514}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102396845817566
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4919 - tp: 544.0000 - fp: 175.0000 - tn: 11072.0000 - fn: 2158.0000 - accuracy: 0.8327 - precision: 0.7566 - recall: 0.2013 - f1_metric: 0.1083
Test Score: 0.4919048845767975
Test Accuracy: 544.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11072   175]
 [ 2158   544]]
Finished training and evaluation
{&#39;precision&#39;: 0.5508474576271186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5855855855855856, &#39;ERDE_5&#39;: 0.2765235900341768, &#39;ERDE_50&#39;: 0.12536827602059106, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.553644346953793}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.4919 - tp: 544.0000 - fp: 175.0000 - tn: 11072.0000 - fn: 2158.0000 - accuracy: 0.8327 - precision: 0.7566 - recall: 0.2013 - f1_metric: 0.1083
Test Score: 0.4919048845767975
Test Accuracy: 544.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11072   175]
 [ 2158   544]]
Evaluated with elapsed time 219.073853245005
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6063829787234043, &#39;ERDE_5&#39;: 0.2613997850005331, &#39;ERDE_50&#39;: 0.12917474433778972, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5803850959008514}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618620725716, &#39;ERDE_50&#39;: 0.14644702557844638, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7115384615384616, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4743589743589744, &#39;ERDE_5&#39;: 0.25456925472849906, &#39;ERDE_50&#39;: 0.16715389868010888, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4466405868977751}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 219.073853245005} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11160    87]
 [ 2224   478]]
Evaluating after getting time 399638.161283322
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11160    87]
 [ 2224   478]]
Evaluated with elapsed time 1658.1874948769691
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6910994764397905, &#39;ERDE_5&#39;: 0.2579114334382352, &#39;ERDE_50&#39;: 0.10381790389475583, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6574351689886865}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25337587031875286, &#39;ERDE_50&#39;: 0.13977410550168118, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5604557401976188}
Writing results to CSV file
{&#39;precision&#39;: 0.8444444444444444, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5100671140939597, &#39;ERDE_5&#39;: 0.24992003385985165, &#39;ERDE_50&#39;: 0.1610147301362342, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4802621801432995}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11097   150]
 [ 2251   451]]
Evaluating after getting time 401316.811753903
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.17      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11097   150]
 [ 2251   451]]
Evaluated with elapsed time 7.486670308979228
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6063829787234043, &#39;ERDE_5&#39;: 0.2613997850005331, &#39;ERDE_50&#39;: 0.12917474433778972, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5803850959008514}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618620725716, &#39;ERDE_50&#39;: 0.14644702557844638, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7115384615384616, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4743589743589744, &#39;ERDE_5&#39;: 0.25456925472849906, &#39;ERDE_50&#39;: 0.16715389868010888, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4466405868977751}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5034 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5033852458000183
Test Accuracy: 0.0
436/436 [==============================] - 10s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 19ms/step - loss: 0.5161 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5161073207855225
Test Accuracy: 0.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4913 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4912576377391815
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49392426013946533
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5014899373054504
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 8s 12ms/step - loss: 0.5015 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5014899373054504
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 224.12060156400548
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532987640562656, &#39;ERDE_50&#39;: 0.1402314259126844, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5557412178442032}
Writing results to CSV file
{&#39;precision&#39;: 0.851063829787234, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5298013245033113, &#39;ERDE_5&#39;: 0.2498998967695122, &#39;ERDE_50&#39;: 0.1560047009465007, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.49781390911610174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24876171257776386, &#39;ERDE_50&#39;: 0.178482877029257, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4030778306093872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6063829787234043, &#39;ERDE_5&#39;: 0.2613997850005331, &#39;ERDE_50&#39;: 0.12917474433778972, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5803850959008514}
Writing results to CSV file
{&#39;precision&#39;: 0.7121212121212122, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5529411764705883, &#39;ERDE_5&#39;: 0.2568618620725716, &#39;ERDE_50&#39;: 0.14644702557844638, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5249310546244684}
Writing results to CSV file
{&#39;precision&#39;: 0.7115384615384616, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4743589743589744, &#39;ERDE_5&#39;: 0.25456925472849906, &#39;ERDE_50&#39;: 0.16715389868010888, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4466405868977751}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 224.12060156400548} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluating after getting time 407088.488882724
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluated with elapsed time 1167.340857498988
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25619148563890176, &#39;ERDE_50&#39;: 0.12989012109883583, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5825516297694173}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395693671577374, &#39;ERDE_50&#39;: 0.14525316498698213, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.25166250408255725, &#39;ERDE_50&#39;: 0.16155898053788045, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.48912552864902015}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 1167.340857498988}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluating after getting time 409632.069926189
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluated with elapsed time 471.9118103419896
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25619148563890176, &#39;ERDE_50&#39;: 0.12989012109883583, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5825516297694173}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395693671577374, &#39;ERDE_50&#39;: 0.14525316498698213, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.25166250408255725, &#39;ERDE_50&#39;: 0.16155898053788045, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.48912552864902015}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 471.9118103419896}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluating after getting time 410820.286204877
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluated with elapsed time 474.8183575979783
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25619148563890176, &#39;ERDE_50&#39;: 0.12989012109883583, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5825516297694173}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395693671577374, &#39;ERDE_50&#39;: 0.14525316498698213, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.25166250408255725, &#39;ERDE_50&#39;: 0.16155898053788045, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.48912552864902015}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 474.8183575979783}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluating after getting time 412553.756197557
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2272   430]]
Evaluated with elapsed time 798.0726988620008
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25619148563890176, &#39;ERDE_50&#39;: 0.12989012109883583, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5825516297694173}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395693671577374, &#39;ERDE_50&#39;: 0.14525316498698213, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.25166250408255725, &#39;ERDE_50&#39;: 0.16155898053788045, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.48912552864902015}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 798.0726988620008}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluating after getting time 415451.456130052
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluated with elapsed time 911.607639127993
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7303370786516854, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6735751295336788, &#39;ERDE_5&#39;: 0.2596316193308309, &#39;ERDE_50&#39;: 0.10988875012693046, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6446964704943554}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6511627906976744, &#39;ERDE_5&#39;: 0.2527820221517472, &#39;ERDE_50&#39;: 0.12317396059925918, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6194438484410668}
Writing results to CSV file
{&#39;precision&#39;: 0.8541666666666666, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5394736842105263, &#39;ERDE_5&#39;: 0.24991804340045143, &#39;ERDE_50&#39;: 0.15300485430110675, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5079504256397883}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluating after getting time 416385.478253894
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluated with elapsed time 8.023232521954924
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5205 - tp: 409.0000 - fp: 85.0000 - tn: 11162.0000 - fn: 2293.0000 - accuracy: 0.8295 - precision: 0.8279 - recall: 0.1514 - f1_metric: 0.0832
Test Score: 0.5204916000366211
Test Accuracy: 409.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.15      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.58     13949
weighted avg       0.83      0.83      0.78     13949

[[11162    85]
 [ 2293   409]]
Finished training and evaluation
{&#39;precision&#39;: 0.6794871794871795, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5824175824175823, &#39;ERDE_5&#39;: 0.2602910134248677, &#39;ERDE_50&#39;: 0.13693204464176645, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5529142859675543}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4000 - tp: 584.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2118.0000 - accuracy: 0.8344 - precision: 0.7526 - recall: 0.2161 - f1_metric: 0.1211
Test Score: 0.400028258562088
Test Accuracy: 584.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.6055045871559633, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.619718309859155, &#39;ERDE_5&#39;: 0.27069331202449276, &#39;ERDE_50&#39;: 0.11603158997275352, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5895310670274139}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4022 - tp: 623.0000 - fp: 188.0000 - tn: 11059.0000 - fn: 2079.0000 - accuracy: 0.8375 - precision: 0.7682 - recall: 0.2306 - f1_metric: 0.1231
Test Score: 0.40219637751579285
Test Accuracy: 623.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.23      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.61      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11059   188]
 [ 2079   623]]
Finished training and evaluation
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.6176 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.617611825466156
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Finished training and evaluation
{&#39;precision&#39;: 0.5596330275229358, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5727699530516431, &#39;ERDE_5&#39;: 0.2735923421691488, &#39;ERDE_50&#39;: 0.1298676685075436, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.548213185058147}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.4485 - tp: 584.0000 - fp: 190.0000 - tn: 11057.0000 - fn: 2118.0000 - accuracy: 0.8345 - precision: 0.7545 - recall: 0.2161 - f1_metric: 0.1148
Test Score: 0.44846898317337036
Test Accuracy: 584.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11057   190]
 [ 2118   584]]
Evaluated with elapsed time 226.49525495700072
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6226415094339622, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.6285714285714284, &#39;ERDE_5&#39;: 0.26893197288027204, &#39;ERDE_50&#39;: 0.11537922007061593, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6016222447734136}
Writing results to CSV file
{&#39;precision&#39;: 0.6744186046511628, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6105263157894736, &#39;ERDE_5&#39;: 0.26208100053306677, &#39;ERDE_50&#39;: 0.12561273950461457, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5784118956357502}
Writing results to CSV file
{&#39;precision&#39;: 0.7205882352941176, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5697674418604651, &#39;ERDE_5&#39;: 0.2568923025147678, &#39;ERDE_50&#39;: 0.14330145840852437, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5342600273131639}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.2561511333125505, &#39;ERDE_50&#39;: 0.12330163461117499, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6168147257020353}
Writing results to CSV file
{&#39;precision&#39;: 0.828125, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.6309523809523809, &#39;ERDE_5&#39;: 0.2522014714936964, &#39;ERDE_50&#39;: 0.12759681497156067, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6014453488728972}
Writing results to CSV file
{&#39;precision&#39;: 0.8478260869565217, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.52, &#39;ERDE_5&#39;: 0.24991830819753286, &#39;ERDE_50&#39;: 0.1577329865909664, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4896146541776691}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7283950617283951, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6378378378378379, &#39;ERDE_5&#39;: 0.25846377815921434, &#39;ERDE_50&#39;: 0.11956411165724333, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6129747664613298}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25626666852331265, &#39;ERDE_50&#39;: 0.1295831653920135, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5849391300359054}
Writing results to CSV file
{&#39;precision&#39;: 0.7358490566037735, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4968152866242037, &#39;ERDE_5&#39;: 0.2539837609956759, &#39;ERDE_50&#39;: 0.16180162506873094, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47358129140911215}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.76, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6368715083798883, &#39;ERDE_5&#39;: 0.2561611714562794, &#39;ERDE_50&#39;: 0.12821410084784307, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6095664694377656}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539490796723001, &#39;ERDE_50&#39;: 0.14317088550695795, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.543054599737038}
Writing results to CSV file
{&#39;precision&#39;: 0.78, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5064935064935064, &#39;ERDE_5&#39;: 0.25224401093130044, &#39;ERDE_50&#39;: 0.16005792215122625, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4768973904327945}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7241379310344828, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6596858638743456, &#39;ERDE_5&#39;: 0.2596196174231275, &#39;ERDE_50&#39;: 0.1150808509145476, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6314026890649108}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6333333333333334, &#39;ERDE_5&#39;: 0.2568435890823963, &#39;ERDE_50&#39;: 0.12307219832287043, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6037149539629838}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5250000000000001, &#39;ERDE_5&#39;: 0.25398375465263423, &#39;ERDE_50&#39;: 0.15470941392779955, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.49738436715229406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 226.49525495700072} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluating after getting time 425900.505250826
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.83      0.19      0.31      2702

    accuracy                           0.84     13949
   macro avg       0.83      0.59      0.61     13949
weighted avg       0.83      0.84      0.79     13949

[[11143   104]
 [ 2189   513]]
Evaluated with elapsed time 1181.0691052419716
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7303370786516854, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6735751295336788, &#39;ERDE_5&#39;: 0.2596316193308309, &#39;ERDE_50&#39;: 0.10988875012693046, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6446964704943554}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6511627906976744, &#39;ERDE_5&#39;: 0.2527820221517472, &#39;ERDE_50&#39;: 0.12317396059925918, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6194438484410668}
Writing results to CSV file
{&#39;precision&#39;: 0.8541666666666666, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5394736842105263, &#39;ERDE_5&#39;: 0.24991804340045143, &#39;ERDE_50&#39;: 0.15300485430110675, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5079504256397883}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluating after getting time 427102.334866402
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.62      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.73      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10799   448]
 [ 1969   733]]
Evaluated with elapsed time 7.836177098040935
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 14s 27ms/step - loss: 0.5012 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5012255311012268
Test Accuracy: 0.0
436/436 [==============================] - 11s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.5095 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5095410346984863
Test Accuracy: 0.0
436/436 [==============================] - 12s 28ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00035: early stopping
Evaluating
436/436 [==============================] - 14s 27ms/step - loss: 0.4506 - tp: 982.0000 - fp: 621.0000 - tn: 10626.0000 - fn: 1720.0000 - accuracy: 0.8322 - precision: 0.6126 - recall: 0.3634 - f1_metric: 0.1773
Test Score: 0.45056480169296265
Test Accuracy: 982.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.94      0.90     11247
           1       0.61      0.36      0.46      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.65      0.68     13949
weighted avg       0.81      0.83      0.81     13949

[[10626   621]
 [ 1720   982]]
Finished training and evaluation
{&#39;precision&#39;: 0.4880952380952381, &#39;recall&#39;: 0.7884615384615384, &#39;F1&#39;: 0.6029411764705882, &#39;ERDE_5&#39;: 0.29556808679097213, &#39;ERDE_50&#39;: 0.1043756921166237, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5794383852952624}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5211 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5210582613945007
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Evaluating for elapsed time
436/436 [==============================] - 10s 17ms/step - loss: 0.5060 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5060158371925354
Test Accuracy: 0.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 206.29032427701168
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6206896551724139, &#39;ERDE_5&#39;: 0.25499529404863736, &#39;ERDE_50&#39;: 0.12778489535387072, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5940783921743743}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.6097560975609756, &#39;ERDE_5&#39;: 0.25162455162178127, &#39;ERDE_50&#39;: 0.134107782040708, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5800541263712081}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.249918314083442, &#39;ERDE_50&#39;: 0.16482519773189744, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4621275514627805}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6057692307692307, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6057692307692307, &#39;ERDE_5&#39;: 0.2694647995043324, &#39;ERDE_50&#39;: 0.12115135835812586, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5821562013613752}
Writing results to CSV file
{&#39;precision&#39;: 0.6185567010309279, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5970149253731344, &#39;ERDE_5&#39;: 0.26729172580936883, &#39;ERDE_50&#39;: 0.12788882834936985, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5714186856735274}
Writing results to CSV file
{&#39;precision&#39;: 0.6144578313253012, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5454545454545454, &#39;ERDE_5&#39;: 0.26443998004277586, &#39;ERDE_50&#39;: 0.14597774080774895, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5199458933652491}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 206.29032427701168} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluating after getting time 435531.663379636
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluated with elapsed time 2198.680188455968
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7325581395348837, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.663157894736842, &#39;ERDE_5&#39;: 0.2590692743603174, &#39;ERDE_50&#39;: 0.11612189306656744, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6321447440388027}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2527867251107897, &#39;ERDE_50&#39;: 0.13498841131779749, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5822148626305483}
Writing results to CSV file
{&#39;precision&#39;: 0.8888888888888888, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5369127516778524, &#39;ERDE_5&#39;: 0.2487554431777269, &#39;ERDE_50&#39;: 0.15538849394318163, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5034528130276082}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluating after getting time 437751.315968471
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluated with elapsed time 7.63393176702084
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5936 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5936288833618164
Test Accuracy: 0.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.3994 - tp: 512.0000 - fp: 138.0000 - tn: 11109.0000 - fn: 2190.0000 - accuracy: 0.8331 - precision: 0.7877 - recall: 0.1895 - f1_metric: 0.1028
Test Score: 0.3994370400905609
Test Accuracy: 512.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.79      0.19      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.81      0.59      0.61     13949
weighted avg       0.83      0.83      0.79     13949

[[11109   138]
 [ 2190   512]]
Finished training and evaluation
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6494845360824743, &#39;ERDE_5&#39;: 0.26140644379269445, &#39;ERDE_50&#39;: 0.11262328232115389, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6165838555635069}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 13s 20ms/step - loss: 0.4017 - tp: 568.0000 - fp: 194.0000 - tn: 11053.0000 - fn: 2134.0000 - accuracy: 0.8331 - precision: 0.7454 - recall: 0.2102 - f1_metric: 0.1139
Test Score: 0.4016605317592621
Test Accuracy: 568.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.75      0.21      0.33      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.60      0.62     13949
weighted avg       0.82      0.83      0.79     13949

[[11053   194]
 [ 2134   568]]
Finished training and evaluation
{&#39;precision&#39;: 0.6017699115044248, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6267281105990784, &#39;ERDE_5&#39;: 0.27183954873518135, &#39;ERDE_50&#39;: 0.11328805467567826, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5986382934151268}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.6187 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6187241673469543
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Finished training and evaluation
{&#39;precision&#39;: 0.6444444444444445, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.5979381443298969, &#39;ERDE_5&#39;: 0.2643079528067778, &#39;ERDE_50&#39;: 0.12768686242459712, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5688118402106115}
Evaluating for elapsed time
436/436 [==============================] - 10s 17ms/step - loss: 0.4689 - tp: 481.0000 - fp: 151.0000 - tn: 11096.0000 - fn: 2221.0000 - accuracy: 0.8300 - precision: 0.7611 - recall: 0.1780 - f1_metric: 0.1004
Test Score: 0.4689188599586487
Test Accuracy: 481.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.60     13949
weighted avg       0.82      0.83      0.78     13949

[[11096   151]
 [ 2221   481]]
Evaluated with elapsed time 196.7234299129923
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 196.7234299129923} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluating after getting time 446193.952061741
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.18      0.30      2702

    accuracy                           0.84     13949
   macro avg       0.84      0.59      0.60     13949
weighted avg       0.84      0.84      0.79     13949

[[11161    86]
 [ 2214   488]]
Evaluated with elapsed time 1372.4247084920062
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7325581395348837, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.663157894736842, &#39;ERDE_5&#39;: 0.2590692743603174, &#39;ERDE_50&#39;: 0.11612189306656744, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6321447440388027}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2527867251107897, &#39;ERDE_50&#39;: 0.13498841131779749, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5822148626305483}
Writing results to CSV file
{&#39;precision&#39;: 0.8888888888888888, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5369127516778524, &#39;ERDE_5&#39;: 0.2487554431777269, &#39;ERDE_50&#39;: 0.15538849394318163, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5034528130276082}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluating after getting time 447587.986889446
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.63      0.27      0.38      2702

    accuracy                           0.83     13949
   macro avg       0.74      0.62      0.64     13949
weighted avg       0.80      0.83      0.80     13949

[[10820   427]
 [ 1975   727]]
Evaluated with elapsed time 7.968928704038262
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5063 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062928795814514
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4938 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49377965927124023
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4958 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49575263261795044
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5005954504013062
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 8s 14ms/step - loss: 0.5026 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5025824904441833
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 186.73362034896854
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7534246575342466, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6214689265536723, &#39;ERDE_5&#39;: 0.2561758890228547, &#39;ERDE_50&#39;: 0.12866585646579706, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5948242533070475}
Writing results to CSV file
{&#39;precision&#39;: 0.8363636363636363, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5786163522012578, &#39;ERDE_5&#39;: 0.2510480834554249, &#39;ERDE_50&#39;: 0.1429827712571239, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5504312363955213}
Writing results to CSV file
{&#39;precision&#39;: 0.8809523809523809, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.5068493150684932, &#39;ERDE_5&#39;: 0.24875625261471526, &#39;ERDE_50&#39;: 0.1624806924270374, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4752629038050007}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6028708133971292, &#39;ERDE_5&#39;: 0.27005258035031704, &#39;ERDE_50&#39;: 0.1217327018144605, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5793707649912252}
Writing results to CSV file
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6030150753768844, &#39;ERDE_5&#39;: 0.26613136565964307, &#39;ERDE_50&#39;: 0.12672635608457108, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5771615870370803}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5531914893617021, &#39;ERDE_5&#39;: 0.2644407575604031, &#39;ERDE_50&#39;: 0.14479570771220104, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5273210124200753}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 186.73362034896854} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 452323.749031624
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 537.2579740260262
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7702702702702703, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6404494382022471, &#39;ERDE_5&#39;: 0.25558127662589564, &#39;ERDE_50&#39;: 0.12300220813717352, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.612991000164944}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6352941176470589, &#39;ERDE_5&#39;: 0.25278250925446444, &#39;ERDE_50&#39;: 0.12789622377728604, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6055840405077608}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5263157894736842, &#39;ERDE_5&#39;: 0.25049988291908876, &#39;ERDE_50&#39;: 0.15713221989183704, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4955613908680861}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 537.2579740260262}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 453690.786806903
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 487.00183134898543
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7702702702702703, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6404494382022471, &#39;ERDE_5&#39;: 0.25558127662589564, &#39;ERDE_50&#39;: 0.12300220813717352, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.612991000164944}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6352941176470589, &#39;ERDE_5&#39;: 0.25278250925446444, &#39;ERDE_50&#39;: 0.12789622377728604, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6055840405077608}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5263157894736842, &#39;ERDE_5&#39;: 0.25049988291908876, &#39;ERDE_50&#39;: 0.15713221989183704, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4955613908680861}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 487.00183134898543}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (12709, 7)
Test features shape: (13949, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 455257.322092168
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 627.4957165600499
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7702702702702703, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6404494382022471, &#39;ERDE_5&#39;: 0.25558127662589564, &#39;ERDE_50&#39;: 0.12300220813717352, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.612991000164944}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6352941176470589, &#39;ERDE_5&#39;: 0.25278250925446444, &#39;ERDE_50&#39;: 0.12789622377728604, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6055840405077608}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5263157894736842, &#39;ERDE_5&#39;: 0.25049988291908876, &#39;ERDE_50&#39;: 0.15713221989183704, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4955613908680861}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 627.4957165600499}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 456860.671899667
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 780.389521962963
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7702702702702703, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6404494382022471, &#39;ERDE_5&#39;: 0.25558127662589564, &#39;ERDE_50&#39;: 0.12300220813717352, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.612991000164944}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6352941176470589, &#39;ERDE_5&#39;: 0.25278250925446444, &#39;ERDE_50&#39;: 0.12789622377728604, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6055840405077608}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5263157894736842, &#39;ERDE_5&#39;: 0.25049988291908876, &#39;ERDE_50&#39;: 0.15713221989183704, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4955613908680861}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 780.389521962963}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 459616.166972805
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 680.6218179840362
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7349397590361446, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6524064171122996, &#39;ERDE_5&#39;: 0.2584818619187972, &#39;ERDE_50&#39;: 0.11794110362925261, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6244353391304029}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.2539503034784327, &#39;ERDE_50&#39;: 0.13615091261238715, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.57062915759771}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493369846420819, &#39;ERDE_50&#39;: 0.165426074895041, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4652928086645804}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.30      0.41      2702

    accuracy                           0.84     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.82      0.84      0.81     13949

[[10849   398]
 [ 1903   799]]
Evaluating after getting time 460312.628799228
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.30      0.41      2702

    accuracy                           0.84     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.82      0.84      0.81     13949

[[10849   398]
 [ 1903   799]]
Evaluated with elapsed time 5.952843168983236
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.2690359141100821, &#39;ERDE_50&#39;: 0.12203289130941043, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.26385791317464596, &#39;ERDE_50&#39;: 0.1341822191317234, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5849586129188538
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4024 - tp: 374.0000 - fp: 79.0000 - tn: 11168.0000 - fn: 2328.0000 - accuracy: 0.8274 - precision: 0.8256 - recall: 0.1384 - f1_metric: 0.0802
Test Score: 0.4023907482624054
Test Accuracy: 374.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.57     13949
weighted avg       0.83      0.83      0.77     13949

[[11168    79]
 [ 2328   374]]
Finished training and evaluation
{&#39;precision&#39;: 0.6588235294117647, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5925925925925926, &#39;ERDE_5&#39;: 0.26258244475618947, &#39;ERDE_50&#39;: 0.13414250894655058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5625738646881615}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 7s 15ms/step - loss: 0.4104 - tp: 435.0000 - fp: 158.0000 - tn: 11089.0000 - fn: 2267.0000 - accuracy: 0.8262 - precision: 0.7336 - recall: 0.1610 - f1_metric: 0.0917
Test Score: 0.41041767597198486
Test Accuracy: 435.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.73      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11089   158]
 [ 2267   435]]
Finished training and evaluation
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5943396226415095, &#39;ERDE_5&#39;: 0.2718887182070221, &#39;ERDE_50&#39;: 0.12546438231917012, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.561920887989532}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6101518273353577
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5472 - tp: 348.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2354.0000 - accuracy: 0.8263 - precision: 0.8345 - recall: 0.1288 - f1_metric: 0.0747
Test Score: 0.5472047328948975
Test Accuracy: 348.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.13      0.22      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11178    69]
 [ 2354   348]]
Finished training and evaluation
{&#39;precision&#39;: 0.6538461538461539, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5604395604395604, &#39;ERDE_5&#39;: 0.26147497148586657, &#39;ERDE_50&#39;: 0.14099700684422797, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5276911953309621}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.5472 - tp: 348.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2354.0000 - accuracy: 0.8263 - precision: 0.8345 - recall: 0.1288 - f1_metric: 0.0747
Test Score: 0.5472047328948975
Test Accuracy: 348.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.13      0.22      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11178    69]
 [ 2354   348]]
Evaluated with elapsed time 219.30651175102685
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.2690359141100821, &#39;ERDE_50&#39;: 0.12203289130941043, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.26385791317464596, &#39;ERDE_50&#39;: 0.1341822191317234, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 219.30651175102685} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluating after getting time 468698.67801149
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11157    90]
 [ 2233   469]]
Evaluated with elapsed time 1312.4644557190477
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7349397590361446, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6524064171122996, &#39;ERDE_5&#39;: 0.2584818619187972, &#39;ERDE_50&#39;: 0.11794110362925261, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6244353391304029}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.2539503034784327, &#39;ERDE_50&#39;: 0.13615091261238715, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.57062915759771}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493369846420819, &#39;ERDE_50&#39;: 0.165426074895041, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4652928086645804}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.30      0.41      2702

    accuracy                           0.84     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.82      0.84      0.81     13949

[[10849   398]
 [ 1903   799]]
Evaluating after getting time 470028.398811842
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.30      0.41      2702

    accuracy                           0.84     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.82      0.84      0.81     13949

[[10849   398]
 [ 1903   799]]
Evaluated with elapsed time 5.809649309958331
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.2690359141100821, &#39;ERDE_50&#39;: 0.12203289130941043, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.26385791317464596, &#39;ERDE_50&#39;: 0.1341822191317234, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5023 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5023209452629089
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5028 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5027718544006348
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49846234917640686
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 17ms/step - loss: 0.5126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.512560248374939
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017368197441101
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 9s 15ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017368197441101
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 193.54651305399602
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7638888888888888, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6250000000000001, &#39;ERDE_5&#39;: 0.2555950749806128, &#39;ERDE_50&#39;: 0.12576277866024432, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5933396229132955}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2533765341724295, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817538340960363, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.2690359141100821, &#39;ERDE_50&#39;: 0.12203289130941043, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.26385791317464596, &#39;ERDE_50&#39;: 0.1341822191317234, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 193.54651305399602} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2238   464]]
Evaluating after getting time 475519.512211852
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2238   464]]
Evaluated with elapsed time 714.6476815509959
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25848596268838747, &#39;ERDE_50&#39;: 0.11148470766044276, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6328955977741817}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522149356122282, &#39;ERDE_50&#39;: 0.1386116331795913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5649665296588519}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47945205479452063, &#39;ERDE_5&#39;: 0.24992075367637773, &#39;ERDE_50&#39;: 0.16747106344884563, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4514360615442155}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10845   402]
 [ 1918   784]]
Evaluating after getting time 476251.146962771
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10845   402]
 [ 1918   784]]
Evaluated with elapsed time 6.146314623008948
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.2769995573805016, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2702075932841982, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650238385230976, &#39;ERDE_50&#39;: 0.13770886491311884, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5711 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5710906982421875
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4012 - tp: 367.0000 - fp: 81.0000 - tn: 11166.0000 - fn: 2335.0000 - accuracy: 0.8268 - precision: 0.8192 - recall: 0.1358 - f1_metric: 0.0811
Test Score: 0.40118831396102905
Test Accuracy: 367.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.82      0.14      0.23      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.56      0.57     13949
weighted avg       0.83      0.83      0.77     13949

[[11166    81]
 [ 2335   367]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5957446808510638, &#39;ERDE_5&#39;: 0.26202620138260535, &#39;ERDE_50&#39;: 0.13348909436737333, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.563249306164448}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4084 - tp: 496.0000 - fp: 161.0000 - tn: 11086.0000 - fn: 2206.0000 - accuracy: 0.8303 - precision: 0.7549 - recall: 0.1836 - f1_metric: 0.1011
Test Score: 0.4083895683288574
Test Accuracy: 496.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11086   161]
 [ 2206   496]]
Finished training and evaluation
{&#39;precision&#39;: 0.6106194690265486, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6359447004608295, &#39;ERDE_5&#39;: 0.27127571437121056, &#39;ERDE_50&#39;: 0.11158690768244317, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6062041982553366}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 19ms/step - loss: 0.6070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6070265173912048
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5436148047447205
Test Accuracy: 0.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 9s 15ms/step - loss: 0.5436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5436148047447205
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 191.8964141550241
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.2769995573805016, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2702075932841982, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650238385230976, &#39;ERDE_50&#39;: 0.13770886491311884, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 191.8964141550241} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2238   464]]
Evaluating after getting time 482073.019938148
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2238   464]]
Evaluated with elapsed time 653.5791674790089
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7411764705882353, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6666666666666666, &#39;ERDE_5&#39;: 0.25848596268838747, &#39;ERDE_50&#39;: 0.11148470766044276, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6328955977741817}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522149356122282, &#39;ERDE_50&#39;: 0.1386116331795913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5649665296588519}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47945205479452063, &#39;ERDE_5&#39;: 0.24992075367637773, &#39;ERDE_50&#39;: 0.16747106344884563, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4514360615442155}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10845   402]
 [ 1918   784]]
Evaluating after getting time 482742.948550193
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10845   402]
 [ 1918   784]]
Evaluated with elapsed time 5.825618011003826
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.2769995573805016, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2702075932841982, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650238385230976, &#39;ERDE_50&#39;: 0.13770886491311884, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5045 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.504548966884613
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5051 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5051088929176331
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 21ms/step - loss: 0.5040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5039865970611572
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5053 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5052889585494995
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5079 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5078795552253723
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 9s 17ms/step - loss: 0.5079 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5078795552253723
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 206.36956075002672
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6444444444444444, &#39;ERDE_5&#39;: 0.25617358229234216, &#39;ERDE_50&#39;: 0.11925215281889441, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6130527611158813}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.2522201767265595, &#39;ERDE_50&#39;: 0.14834970303126052, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.2499216379954707, &#39;ERDE_50&#39;: 0.17456326477462367, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4179231213404556}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.2769995573805016, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.2702075932841982, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650238385230976, &#39;ERDE_50&#39;: 0.13770886491311884, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 206.36956075002672} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 488661.703928293
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 686.5763613389572
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 686.5763613389572}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 490271.958540751
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 461.1806259849691
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 461.1806259849691}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 491681.543933408
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 456.457023578987
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 456.457023578987}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 492746.823142818
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 440.2306435270002
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 440.2306435270002}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluating after getting time 494763.953735451
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluated with elapsed time 753.3661359469988
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7126436781609196, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.649214659685864, &#39;ERDE_5&#39;: 0.2602187941625183, &#39;ERDE_50&#39;: 0.11756587652364936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6188535763963351}
Writing results to CSV file
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.25510906601184913, &#39;ERDE_50&#39;: 0.13759515477766088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5662750085347941}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.2522417509912007, &#39;ERDE_50&#39;: 0.1695141959528773, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4448425976569354}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluating after getting time 495535.176685599
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluated with elapsed time 6.255054512992501
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5862516164779663
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4010 - tp: 590.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2112.0000 - accuracy: 0.8348 - precision: 0.7545 - recall: 0.2184 - f1_metric: 0.1189
Test Score: 0.40101370215415955
Test Accuracy: 590.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2112   590]]
Finished training and evaluation
{&#39;precision&#39;: 0.6194690265486725, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6451612903225806, &#39;ERDE_5&#39;: 0.2706721291459233, &#39;ERDE_50&#39;: 0.10658529896984618, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6149897663459936}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 12s 22ms/step - loss: 0.4009 - tp: 631.0000 - fp: 216.0000 - tn: 11031.0000 - fn: 2071.0000 - accuracy: 0.8360 - precision: 0.7450 - recall: 0.2335 - f1_metric: 0.1154
Test Score: 0.40091532468795776
Test Accuracy: 631.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.74      0.23      0.36      2702

    accuracy                           0.84     13949
   macro avg       0.79      0.61      0.63     13949
weighted avg       0.82      0.84      0.80     13949

[[11031   216]
 [ 2071   631]]
Finished training and evaluation
{&#39;precision&#39;: 0.5819672131147541, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6283185840707964, &#39;ERDE_5&#39;: 0.2753425904424409, &#39;ERDE_50&#39;: 0.1116284310234064, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5964900987871712}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6157369017601013
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.616822429906542, &#39;ERDE_5&#39;: 0.27126136940928736, &#39;ERDE_50&#39;: 0.11545159255399763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5903769691701723}
Evaluating for elapsed time
436/436 [==============================] - 14s 23ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 9s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Evaluated with elapsed time 204.69926512101665
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 204.69926512101665} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluating after getting time 502658.205062697
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluated with elapsed time 882.6840401180089
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7126436781609196, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.649214659685864, &#39;ERDE_5&#39;: 0.2602187941625183, &#39;ERDE_50&#39;: 0.11756587652364936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6188535763963351}
Writing results to CSV file
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.25510906601184913, &#39;ERDE_50&#39;: 0.13759515477766088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5662750085347941}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.2522417509912007, &#39;ERDE_50&#39;: 0.1695141959528773, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4448425976569354}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluating after getting time 503555.450899853
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluated with elapsed time 6.308316460985225
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5188224911689758
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5034902691841125
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.4848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.48482373356819153
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5081223845481873
Test Accuracy: 0.0
436/436 [==============================] - 6s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 6s 11ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 155.18124463001732
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 155.18124463001732} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluating after getting time 508778.300507689
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluated with elapsed time 544.4441679709707
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6382978723404256, &#39;ERDE_5&#39;: 0.25964605569532345, &#39;ERDE_50&#39;: 0.1199789479074211, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6096895009593984}
Writing results to CSV file
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2551156734485785, &#39;ERDE_50&#39;: 0.13995926517295995, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5505068217325723}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24991970119366202, &#39;ERDE_50&#39;: 0.1730994294675553, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43333317155806483}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluating after getting time 509340.091070394
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluated with elapsed time 7.239751170040108
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4144 - tp: 477.0000 - fp: 109.0000 - tn: 11138.0000 - fn: 2225.0000 - accuracy: 0.8327 - precision: 0.8140 - recall: 0.1765 - f1_metric: 0.0996
Test Score: 0.41441696882247925
Test Accuracy: 477.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11138   109]
 [ 2225   477]]
Finished training and evaluation
{&#39;precision&#39;: 0.6262626262626263, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.6108374384236452, &#39;ERDE_5&#39;: 0.267188306660477, &#39;ERDE_50&#39;: 0.12317886177861229, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5846485764255744}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4548 - tp: 545.0000 - fp: 170.0000 - tn: 11077.0000 - fn: 2157.0000 - accuracy: 0.8332 - precision: 0.7622 - recall: 0.2017 - f1_metric: 0.1092
Test Score: 0.45476004481315613
Test Accuracy: 545.0
436/436 [==============================] - 4s 9ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11077   170]
 [ 2157   545]]
Finished training and evaluation
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.26893537276146445, &#39;ERDE_50&#39;: 0.1173781600317242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5929207555919508}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4027 - tp: 529.0000 - fp: 163.0000 - tn: 11084.0000 - fn: 2173.0000 - accuracy: 0.8325 - precision: 0.7645 - recall: 0.1958 - f1_metric: 0.1050
Test Score: 0.4027296006679535
Test Accuracy: 529.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.90     11247
           1       0.76      0.20      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11084   163]
 [ 2173   529]]
Finished training and evaluation
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5452 - tp: 321.0000 - fp: 57.0000 - tn: 11190.0000 - fn: 2381.0000 - accuracy: 0.8252 - precision: 0.8492 - recall: 0.1188 - f1_metric: 0.0738
Test Score: 0.5451857447624207
Test Accuracy: 321.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.85      0.12      0.21      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11190    57]
 [ 2381   321]]
Finished training and evaluation
{&#39;precision&#39;: 0.7391304347826086, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5895953757225433, &#39;ERDE_5&#39;: 0.2562168785047715, &#39;ERDE_50&#39;: 0.137356286508025, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.5505623778786023}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 12ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Finished training and evaluation
{&#39;precision&#39;: 0.5779816513761468, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5915492957746479, &#39;ERDE_5&#39;: 0.2724499660885206, &#39;ERDE_50&#39;: 0.12697102250612122, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5592827617548393}
Evaluating for elapsed time
436/436 [==============================] - 7s 13ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Evaluated with elapsed time 220.07580913900165
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Writing results to CSV file
{&#39;precision&#39;: 0.7073170731707317, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6236559139784946, &#39;ERDE_5&#39;: 0.2597674656713013, &#39;ERDE_50&#39;: 0.12781435716813794, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5847902164226599}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.25457117883635827, &#39;ERDE_50&#39;: 0.15350515364565748, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.5060622073110747}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.25790373184127985, &#39;ERDE_50&#39;: 0.12123510103686998, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6067030088872479}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.2545344373217837, &#39;ERDE_50&#39;: 0.13937802904518543, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5537836480524089}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6923076923076923, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6461538461538462, &#39;ERDE_5&#39;: 0.2619341372937513, &#39;ERDE_50&#39;: 0.11348320858670101, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.620966614785467}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742406264960277, &#39;ERDE_50&#39;: 0.12337174282759242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7066666666666667, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5921787709497207, &#39;ERDE_5&#39;: 0.2585077652737567, &#39;ERDE_50&#39;: 0.13363645346341618, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5667898750912558}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395727360034664, &#39;ERDE_50&#39;: 0.14356752222642452, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2510837676656205, &#39;ERDE_50&#39;: 0.1743743222533362, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.42563971517026017}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 220.07580913900165} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluating after getting time 518005.166165887
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluated with elapsed time 657.2006038309773
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6382978723404256, &#39;ERDE_5&#39;: 0.25964605569532345, &#39;ERDE_50&#39;: 0.1199789479074211, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6096895009593984}
Writing results to CSV file
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2551156734485785, &#39;ERDE_50&#39;: 0.13995926517295995, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5505068217325723}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24991970119366202, &#39;ERDE_50&#39;: 0.1730994294675553, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43333317155806483}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluating after getting time 518679.352869541
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluated with elapsed time 6.955131351016462
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 13s 19ms/step - loss: 0.5106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5105624794960022
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062195658683777
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 19ms/step - loss: 0.4961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4961474537849426
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047220587730408
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 15ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 13s 17ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 207.97564409003826
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 207.97564409003826} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 523782.189754333
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 452.20373168599326
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 452.20373168599326}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 525032.270392147
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 628.4324000020279
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 628.4324000020279}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 526731.101781053
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 621.7422758189496
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 621.7422758189496}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 528148.169973404
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 396.689709304017
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 396.689709304017}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2234   468]]
Evaluating after getting time 529564.293561671
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2234   468]]
Evaluated with elapsed time 513.2080544419587
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7439024390243902, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6559139784946237, &#39;ERDE_5&#39;: 0.2579006257860294, &#39;ERDE_50&#39;: 0.11735986749648486, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6277925183730394}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.2539521655508167, &#39;ERDE_50&#39;: 0.13615091261238715, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.57062915759771}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.24933767010842178, &#39;ERDE_50&#39;: 0.165426074895041, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4652928086645804}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.29      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10849   398]
 [ 1907   795]]
Evaluating after getting time 530091.262489219
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.29      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10849   398]
 [ 1907   795]]
Evaluated with elapsed time 6.923302175011486
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.26903591607583655, &#39;ERDE_50&#39;: 0.12203289131428305, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.263857913897807, &#39;ERDE_50&#39;: 0.13418221914496856, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 22ms/step - loss: 0.5850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5849684476852417
Test Accuracy: 0.0
436/436 [==============================] - 8s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.4003 - tp: 459.0000 - fp: 112.0000 - tn: 11135.0000 - fn: 2243.0000 - accuracy: 0.8312 - precision: 0.8039 - recall: 0.1699 - f1_metric: 0.0947
Test Score: 0.4003196656703949
Test Accuracy: 459.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.59     13949
weighted avg       0.83      0.83      0.78     13949

[[11135   112]
 [ 2243   459]]
Finished training and evaluation
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.594059405940594, &#39;ERDE_5&#39;: 0.26779886393465063, &#39;ERDE_50&#39;: 0.1290163029388859, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5651220399497711}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 11s 22ms/step - loss: 0.4111 - tp: 424.0000 - fp: 143.0000 - tn: 11104.0000 - fn: 2278.0000 - accuracy: 0.8264 - precision: 0.7478 - recall: 0.1569 - f1_metric: 0.0912
Test Score: 0.41111093759536743
Test Accuracy: 424.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11104   143]
 [ 2278   424]]
Finished training and evaluation
{&#39;precision&#39;: 0.6037735849056604, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6095238095238096, &#39;ERDE_5&#39;: 0.27014593418534005, &#39;ERDE_50&#39;: 0.12402762962684931, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5762768411369591}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.6103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102716326713562
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 10s 20ms/step - loss: 0.4538 - tp: 504.0000 - fp: 122.0000 - tn: 11125.0000 - fn: 2198.0000 - accuracy: 0.8337 - precision: 0.8051 - recall: 0.1865 - f1_metric: 0.1021
Test Score: 0.45378759503364563
Test Accuracy: 504.0
436/436 [==============================] - 9s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.81      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11125   122]
 [ 2198   504]]
Finished training and evaluation
{&#39;precision&#39;: 0.6039603960396039, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5951219512195123, &#39;ERDE_5&#39;: 0.2689745247172591, &#39;ERDE_50&#39;: 0.12727636298815787, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5649750945984159}
Evaluating for elapsed time
436/436 [==============================] - 11s 19ms/step - loss: 0.4538 - tp: 504.0000 - fp: 122.0000 - tn: 11125.0000 - fn: 2198.0000 - accuracy: 0.8337 - precision: 0.8051 - recall: 0.1865 - f1_metric: 0.1021
Test Score: 0.45378759503364563
Test Accuracy: 504.0
436/436 [==============================] - 8s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.81      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11125   122]
 [ 2198   504]]
Evaluated with elapsed time 228.57775724609382
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.26903591607583655, &#39;ERDE_50&#39;: 0.12203289131428305, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.263857913897807, &#39;ERDE_50&#39;: 0.13418221914496856, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 228.57775724609382} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2234   468]]
Evaluating after getting time 537524.161374105
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2234   468]]
Evaluated with elapsed time 586.9129567770287
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7439024390243902, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6559139784946237, &#39;ERDE_5&#39;: 0.2579006257860294, &#39;ERDE_50&#39;: 0.11735986749648486, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6277925183730394}
Writing results to CSV file
{&#39;precision&#39;: 0.7846153846153846, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6035502958579881, &#39;ERDE_5&#39;: 0.2539521655508167, &#39;ERDE_50&#39;: 0.13615091261238715, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.57062915759771}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.24933767010842178, &#39;ERDE_50&#39;: 0.165426074895041, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.4652928086645804}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.29      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10849   398]
 [ 1907   795]]
Evaluating after getting time 538126.996173312
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.67      0.29      0.41      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.66     13949
weighted avg       0.81      0.83      0.81     13949

[[10849   398]
 [ 1907   795]]
Evaluated with elapsed time 6.5534870700212196
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.26903591607583655, &#39;ERDE_50&#39;: 0.12203289131428305, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.263857913897807, &#39;ERDE_50&#39;: 0.13418221914496856, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5023818016052246
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5025 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5024811029434204
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49872642755508423
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5120 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5120412707328796
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017363429069519
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 7s 12ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017363429069519
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 221.72752721002325
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7746478873239436, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.6285714285714286, &#39;ERDE_5&#39;: 0.25501383884784506, &#39;ERDE_50&#39;: 0.12518154252747657, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5967301350442284}
Writing results to CSV file
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.25337839624481345, &#39;ERDE_50&#39;: 0.15003613015440578, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5167699934108599}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24817606887594348, &#39;ERDE_50&#39;: 0.17135569388328611, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.44255302627206633}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5934959349593496, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.6431718061674009, &#39;ERDE_5&#39;: 0.2746683972424409, &#39;ERDE_50&#39;: 0.10250853495727127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.618100815430468}
Writing results to CSV file
{&#39;precision&#39;: 0.6116504854368932, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6086956521739131, &#39;ERDE_5&#39;: 0.26903591607583655, &#39;ERDE_50&#39;: 0.12203289131428305, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5825986164801834}
Writing results to CSV file
{&#39;precision&#39;: 0.6395348837209303, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5789473684210525, &#39;ERDE_5&#39;: 0.263857913897807, &#39;ERDE_50&#39;: 0.13418221914496856, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.551872395589431}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 221.72752721002325} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11164    83]
 [ 2239   463]]
Evaluating after getting time 544037.190912665
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11164    83]
 [ 2239   463]]
Evaluated with elapsed time 716.3400322640082
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6702127659574467, &#39;ERDE_5&#39;: 0.25790472655561975, &#39;ERDE_50&#39;: 0.110903471527675, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.636262063719789}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522150284105594, &#39;ERDE_50&#39;: 0.1386116331795913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5649665296588519}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47945205479452063, &#39;ERDE_5&#39;: 0.24992078782446092, &#39;ERDE_50&#39;: 0.1674710634488664, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4495730171128386}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10844   403]
 [ 1915   787]]
Evaluating after getting time 544771.007932075
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10844   403]
 [ 1915   787]]
Evaluated with elapsed time 7.176559915067628
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.27699586572101637, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.27020623228877516, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650233248878216, &#39;ERDE_50&#39;: 0.13770886491327214, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5710370540618896
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4034 - tp: 313.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2389.0000 - accuracy: 0.8238 - precision: 0.8194 - recall: 0.1158 - f1_metric: 0.0704
Test Score: 0.4034287929534912
Test Accuracy: 313.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.82      0.12      0.20      2702

    accuracy                           0.82     13949
   macro avg       0.82      0.55      0.55     13949
weighted avg       0.82      0.82      0.77     13949

[[11178    69]
 [ 2389   313]]
Finished training and evaluation
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25738789167491954, &#39;ERDE_50&#39;: 0.12467479805442179, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.6013582881214387}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4064 - tp: 445.0000 - fp: 133.0000 - tn: 11114.0000 - fn: 2257.0000 - accuracy: 0.8287 - precision: 0.7699 - recall: 0.1647 - f1_metric: 0.0895
Test Score: 0.40638354420661926
Test Accuracy: 445.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2257   445]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2689660442617192, &#39;ERDE_50&#39;: 0.12845901917262392, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.6071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6070516705513
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5442 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5442476868629456
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 7s 12ms/step - loss: 0.5442 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5442476868629456
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 219.29240898496937
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.27699586572101637, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.27020623228877516, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650233248878216, &#39;ERDE_50&#39;: 0.13770886491327214, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 219.29240898496937} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11164    83]
 [ 2239   463]]
Evaluating after getting time 550875.02584122
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11164    83]
 [ 2239   463]]
Evaluated with elapsed time 713.4846936669201
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6702127659574467, &#39;ERDE_5&#39;: 0.25790472655561975, &#39;ERDE_50&#39;: 0.110903471527675, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.636262063719789}
Writing results to CSV file
{&#39;precision&#39;: 0.8166666666666667, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5975609756097561, &#39;ERDE_5&#39;: 0.2522150284105594, &#39;ERDE_50&#39;: 0.1386116331795913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5649665296588519}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47945205479452063, &#39;ERDE_5&#39;: 0.24992078782446092, &#39;ERDE_50&#39;: 0.1674710634488664, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.4495730171128386}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10844   403]
 [ 1915   787]]
Evaluating after getting time 551602.30033147
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.66      0.29      0.40      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.63      0.65     13949
weighted avg       0.81      0.83      0.81     13949

[[10844   403]
 [ 1915   787]]
Evaluated with elapsed time 6.979266133974306
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.27699586572101637, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.27020623228877516, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650233248878216, &#39;ERDE_50&#39;: 0.13770886491327214, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047177076339722
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5046 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5045680999755859
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5040106773376465
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5051 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5051465630531311
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5080717206001282
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 9s 15ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5080717206001282
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 192.55894869100302
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7733333333333333, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6480446927374302, &#39;ERDE_5&#39;: 0.25559234615957444, &#39;ERDE_50&#39;: 0.11867091668612667, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.6164776368763052}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5534591194968553, &#39;ERDE_5&#39;: 0.252220142586849, &#39;ERDE_50&#39;: 0.1483497030312605, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5232702449003048}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.24992162544439522, &#39;ERDE_50&#39;: 0.17456326477464437, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06426108074549963, &#39;speed&#39;: 0.9357389192545004, &#39;latency_weighted_f1&#39;: 0.4187922435824337}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6260869565217392, &#39;ERDE_5&#39;: 0.27699586572101637, &#39;ERDE_50&#39;: 0.10719196709081465, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6016819373076575}
Writing results to CSV file
{&#39;precision&#39;: 0.6074766355140186, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6161137440758293, &#39;ERDE_5&#39;: 0.27020623228877516, &#39;ERDE_50&#39;: 0.11673968526060897, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5849035145306418}
Writing results to CSV file
{&#39;precision&#39;: 0.6206896551724138, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5654450261780105, &#39;ERDE_5&#39;: 0.2650233248878216, &#39;ERDE_50&#39;: 0.13770886491327214, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.5335032727620058}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 192.55894869100302} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluating after getting time 556248.270923927
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluated with elapsed time 258.66919475002214
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.2561704406205234, &#39;ERDE_50&#39;: 0.11979805761985461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6189089547294484}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453041781642666, &#39;ERDE_50&#39;: 0.1403007732024267, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5594403505859904}
Writing results to CSV file
{&#39;precision&#39;: 0.7735849056603774, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5222929936305732, &#39;ERDE_5&#39;: 0.25282369806579313, &#39;ERDE_50&#39;: 0.15827509906095313, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4917736604920243}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 258.66919475002214}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluating after getting time 556960.841692108
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluated with elapsed time 343.4357454290148
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.2561704406205234, &#39;ERDE_50&#39;: 0.11979805761985461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6189089547294484}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453041781642666, &#39;ERDE_50&#39;: 0.1403007732024267, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5594403505859904}
Writing results to CSV file
{&#39;precision&#39;: 0.7735849056603774, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5222929936305732, &#39;ERDE_5&#39;: 0.25282369806579313, &#39;ERDE_50&#39;: 0.15827509906095313, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4917736604920243}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 343.4357454290148}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluating after getting time 558350.030777856
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluated with elapsed time 481.70131763094105
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.2561704406205234, &#39;ERDE_50&#39;: 0.11979805761985461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6189089547294484}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453041781642666, &#39;ERDE_50&#39;: 0.1403007732024267, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5594403505859904}
Writing results to CSV file
{&#39;precision&#39;: 0.7735849056603774, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5222929936305732, &#39;ERDE_5&#39;: 0.25282369806579313, &#39;ERDE_50&#39;: 0.15827509906095313, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4917736604920243}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 481.70131763094105}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluating after getting time 559850.711719161
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.74      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.59     13949
weighted avg       0.81      0.83      0.78     13949

[[11093   154]
 [ 2258   444]]
Evaluated with elapsed time 592.9997699609958
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7662337662337663, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6519337016574586, &#39;ERDE_5&#39;: 0.2561704406205234, &#39;ERDE_50&#39;: 0.11979805761985461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6189089547294484}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453041781642666, &#39;ERDE_50&#39;: 0.1403007732024267, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5594403505859904}
Writing results to CSV file
{&#39;precision&#39;: 0.7735849056603774, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5222929936305732, &#39;ERDE_5&#39;: 0.25282369806579313, &#39;ERDE_50&#39;: 0.15827509906095313, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4917736604920243}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 592.9997699609958}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluating after getting time 561961.166929729
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluated with elapsed time 570.9036454099696
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7126436781609196, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.649214659685864, &#39;ERDE_5&#39;: 0.2602187941625183, &#39;ERDE_50&#39;: 0.11756587652364936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6188535763963351}
Writing results to CSV file
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.25510906601184913, &#39;ERDE_50&#39;: 0.13759515477766088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5662750085347941}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.2522417509912007, &#39;ERDE_50&#39;: 0.1695141959528773, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4448425976569354}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluating after getting time 562546.409800976
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluated with elapsed time 8.04186071397271
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5862516164779663
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4010 - tp: 590.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2112.0000 - accuracy: 0.8348 - precision: 0.7545 - recall: 0.2184 - f1_metric: 0.1189
Test Score: 0.40101370215415955
Test Accuracy: 590.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2112   590]]
Finished training and evaluation
{&#39;precision&#39;: 0.6194690265486725, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6451612903225806, &#39;ERDE_5&#39;: 0.2706721291459233, &#39;ERDE_50&#39;: 0.10658529896984618, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6149897663459936}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4009 - tp: 631.0000 - fp: 216.0000 - tn: 11031.0000 - fn: 2071.0000 - accuracy: 0.8360 - precision: 0.7450 - recall: 0.2335 - f1_metric: 0.1154
Test Score: 0.40091532468795776
Test Accuracy: 631.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.74      0.23      0.36      2702

    accuracy                           0.84     13949
   macro avg       0.79      0.61      0.63     13949
weighted avg       0.82      0.84      0.80     13949

[[11031   216]
 [ 2071   631]]
Finished training and evaluation
{&#39;precision&#39;: 0.5819672131147541, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6283185840707964, &#39;ERDE_5&#39;: 0.2753425904424409, &#39;ERDE_50&#39;: 0.1116284310234064, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5964900987871712}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 12ms/step - loss: 0.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6157369017601013
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.616822429906542, &#39;ERDE_5&#39;: 0.27126136940928736, &#39;ERDE_50&#39;: 0.11545159255399763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5903769691701723}
Evaluating for elapsed time
436/436 [==============================] - 9s 15ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Evaluated with elapsed time 194.32926595001481
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 194.32926595001481} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluating after getting time 569353.606798354
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11135   112]
 [ 2214   488]]
Evaluated with elapsed time 595.7208753360901
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7126436781609196, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.649214659685864, &#39;ERDE_5&#39;: 0.2602187941625183, &#39;ERDE_50&#39;: 0.11756587652364936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6188535763963351}
Writing results to CSV file
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.25510906601184913, &#39;ERDE_50&#39;: 0.13759515477766088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5662750085347941}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.2522417509912007, &#39;ERDE_50&#39;: 0.1695141959528773, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4448425976569354}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluating after getting time 569965.736418839
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10605   642]
 [ 1829   873]]
Evaluated with elapsed time 6.181733145029284
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5188224911689758
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5034902691841125
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.48482373356819153
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5081223845481873
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 8s 15ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 192.41354314098135
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7564102564102564, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.6483516483516483, &#39;ERDE_5&#39;: 0.25673166934488595, &#39;ERDE_50&#39;: 0.11782038903759481, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6205544133152344}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.2539468836328677, &#39;ERDE_50&#39;: 0.1438066893251938, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5452719518745266}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.25166052938366845, &#39;ERDE_50&#39;: 0.17129703857341114, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4379724417085657}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5538461538461539, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6153846153846154, &#39;ERDE_5&#39;: 0.27929509575561556, &#39;ERDE_50&#39;: 0.10964950807350525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.591396775986159}
Writing results to CSV file
{&#39;precision&#39;: 0.5641025641025641, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5972850678733032, &#39;ERDE_5&#39;: 0.2754183840576015, &#39;ERDE_50&#39;: 0.12041110668392815, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5716772461647823}
Writing results to CSV file
{&#39;precision&#39;: 0.56, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5490196078431373, &#39;ERDE_5&#39;: 0.2714098474300657, &#39;ERDE_50&#39;: 0.1408678488225798, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5233442325375711}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 192.41354314098135} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluating after getting time 575348.400948285
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluated with elapsed time 774.7036875729682
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6382978723404256, &#39;ERDE_5&#39;: 0.25964605569532345, &#39;ERDE_50&#39;: 0.1199789479074211, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6096895009593984}
Writing results to CSV file
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2551156734485785, &#39;ERDE_50&#39;: 0.13995926517295995, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5505068217325723}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24991970119366202, &#39;ERDE_50&#39;: 0.1730994294675553, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43333317155806483}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluating after getting time 576136.040649515
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluated with elapsed time 7.014812857960351
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4144 - tp: 477.0000 - fp: 109.0000 - tn: 11138.0000 - fn: 2225.0000 - accuracy: 0.8327 - precision: 0.8140 - recall: 0.1765 - f1_metric: 0.0996
Test Score: 0.41441696882247925
Test Accuracy: 477.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11138   109]
 [ 2225   477]]
Finished training and evaluation
{&#39;precision&#39;: 0.6262626262626263, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.6108374384236452, &#39;ERDE_5&#39;: 0.267188306660477, &#39;ERDE_50&#39;: 0.12317886177861229, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5846485764255744}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4548 - tp: 545.0000 - fp: 170.0000 - tn: 11077.0000 - fn: 2157.0000 - accuracy: 0.8332 - precision: 0.7622 - recall: 0.2017 - f1_metric: 0.1092
Test Score: 0.45476004481315613
Test Accuracy: 545.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11077   170]
 [ 2157   545]]
Finished training and evaluation
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.26893537276146445, &#39;ERDE_50&#39;: 0.1173781600317242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5929207555919508}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.4027 - tp: 529.0000 - fp: 163.0000 - tn: 11084.0000 - fn: 2173.0000 - accuracy: 0.8325 - precision: 0.7645 - recall: 0.1958 - f1_metric: 0.1050
Test Score: 0.4027296006679535
Test Accuracy: 529.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.90     11247
           1       0.76      0.20      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11084   163]
 [ 2173   529]]
Finished training and evaluation
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5452 - tp: 321.0000 - fp: 57.0000 - tn: 11190.0000 - fn: 2381.0000 - accuracy: 0.8252 - precision: 0.8492 - recall: 0.1188 - f1_metric: 0.0738
Test Score: 0.5451857447624207
Test Accuracy: 321.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.85      0.12      0.21      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11190    57]
 [ 2381   321]]
Finished training and evaluation
{&#39;precision&#39;: 0.7391304347826086, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5895953757225433, &#39;ERDE_5&#39;: 0.2562168785047715, &#39;ERDE_50&#39;: 0.137356286508025, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.5505623778786023}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Finished training and evaluation
{&#39;precision&#39;: 0.5779816513761468, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5915492957746479, &#39;ERDE_5&#39;: 0.2724499660885206, &#39;ERDE_50&#39;: 0.12697102250612122, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5592827617548393}
Evaluating for elapsed time
436/436 [==============================] - 7s 12ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Evaluated with elapsed time 181.17362343589775
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Writing results to CSV file
{&#39;precision&#39;: 0.7073170731707317, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6236559139784946, &#39;ERDE_5&#39;: 0.2597674656713013, &#39;ERDE_50&#39;: 0.12781435716813794, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5847902164226599}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.25457117883635827, &#39;ERDE_50&#39;: 0.15350515364565748, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.5060622073110747}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.25790373184127985, &#39;ERDE_50&#39;: 0.12123510103686998, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6067030088872479}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.2545344373217837, &#39;ERDE_50&#39;: 0.13937802904518543, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5537836480524089}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6923076923076923, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6461538461538462, &#39;ERDE_5&#39;: 0.2619341372937513, &#39;ERDE_50&#39;: 0.11348320858670101, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.620966614785467}
Writing results to CSV file
{&#39;precision&#39;: 0.7402597402597403, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6298342541436464, &#39;ERDE_5&#39;: 0.25742406264960277, &#39;ERDE_50&#39;: 0.12337174282759242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6003795122283816}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7066666666666667, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.5921787709497207, &#39;ERDE_5&#39;: 0.2585077652737567, &#39;ERDE_50&#39;: 0.13363645346341618, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5667898750912558}
Writing results to CSV file
{&#39;precision&#39;: 0.7704918032786885, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5696969696969697, &#39;ERDE_5&#39;: 0.25395727360034664, &#39;ERDE_50&#39;: 0.14356752222642452, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5386223884490328}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2510837676656205, &#39;ERDE_50&#39;: 0.1743743222533362, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.42563971517026017}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6847826086956522, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6428571428571429, &#39;ERDE_5&#39;: 0.262515373421647, &#39;ERDE_50&#39;: 0.11406444445346103, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6177984177712554}
Writing results to CSV file
{&#39;precision&#39;: 0.7341772151898734, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6338797814207651, &#39;ERDE_5&#39;: 0.2580052987817111, &#39;ERDE_50&#39;: 0.12158891276674932, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.604235846934479}
Writing results to CSV file
{&#39;precision&#39;: 0.7307692307692307, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4871794871794871, &#39;ERDE_5&#39;: 0.25398412296751455, &#39;ERDE_50&#39;: 0.16546014698858302, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.46344837378786774}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 181.17362343589775} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluating after getting time 584851.513280903
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.83      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11150    97]
 [ 2235   467]]
Evaluated with elapsed time 765.3815758790588
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6382978723404256, &#39;ERDE_5&#39;: 0.25964605569532345, &#39;ERDE_50&#39;: 0.1199789479074211, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.6096895009593984}
Writing results to CSV file
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2551156734485785, &#39;ERDE_50&#39;: 0.13995926517295995, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5505068217325723}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.24991970119366202, &#39;ERDE_50&#39;: 0.1730994294675553, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.43333317155806483}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluating after getting time 585633.49085854
              precision    recall  f1-score   support

           0       0.85      0.94      0.90     11247
           1       0.58      0.32      0.41      2702

    accuracy                           0.82     13949
   macro avg       0.71      0.63      0.65     13949
weighted avg       0.80      0.82      0.80     13949

[[10617   630]
 [ 1842   860]]
Evaluated with elapsed time 6.906777127995156
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5105624794960022
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062195658683777
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4961474537849426
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047220587730408
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 9s 16ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 205.8306570739951
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25732249571451726, &#39;ERDE_50&#39;: 0.12065386517026332, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6100365419031119}
Writing results to CSV file
{&#39;precision&#39;: 0.7741935483870968, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5783132530120482, &#39;ERDE_5&#39;: 0.2539532011896754, &#39;ERDE_50&#39;: 0.1411608591060285, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5501429015414638}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176720989, &#39;ERDE_50&#39;: 0.17782756185503154, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.549618320610687, &#39;recall&#39;: 0.6923076923076923, &#39;F1&#39;: 0.6127659574468085, &#39;ERDE_5&#39;: 0.2798829502405301, &#39;ERDE_50&#39;: 0.11023074419986242, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.588880193960686}
Writing results to CSV file
{&#39;precision&#39;: 0.5666666666666667, &#39;recall&#39;: 0.6538461538461539, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.2760015029989697, &#39;ERDE_50&#39;: 0.11598240683148164, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5811123955197747}
Writing results to CSV file
{&#39;precision&#39;: 0.5656565656565656, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.2708293044414413, &#39;ERDE_50&#39;: 0.1396507100816226, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.52592228294416}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 205.8306570739951} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluating after getting time 590848.484476592
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluated with elapsed time 422.9428518359782
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2555866192019714, &#39;ERDE_50&#39;: 0.13285497921689404, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5753822834932282}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.253369730431556, &#39;ERDE_50&#39;: 0.1376918365419494, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.2505006077383099, &#39;ERDE_50&#39;: 0.1656882106239543, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.45900506800695096}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 422.9428518359782}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluating after getting time 592205.852797488
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluated with elapsed time 527.3799063860206
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2555866192019714, &#39;ERDE_50&#39;: 0.13285497921689404, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5753822834932282}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.253369730431556, &#39;ERDE_50&#39;: 0.1376918365419494, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.2505006077383099, &#39;ERDE_50&#39;: 0.1656882106239543, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.45900506800695096}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 527.3799063860206}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluating after getting time 593886.844006562
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluated with elapsed time 503.3458909529727
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2555866192019714, &#39;ERDE_50&#39;: 0.13285497921689404, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5753822834932282}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.253369730431556, &#39;ERDE_50&#39;: 0.1376918365419494, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.2505006077383099, &#39;ERDE_50&#39;: 0.1656882106239543, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.45900506800695096}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 503.3458909529727}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluating after getting time 594987.322392518
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.81      0.15      0.25      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11151    96]
 [ 2305   397]]
Evaluated with elapsed time 337.56874736596365
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2555866192019714, &#39;ERDE_50&#39;: 0.13285497921689404, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5753822834932282}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.253369730431556, &#39;ERDE_50&#39;: 0.1376918365419494, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.2505006077383099, &#39;ERDE_50&#39;: 0.1656882106239543, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.45900506800695096}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 337.56874736596365}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluating after getting time 598500.155740023
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluated with elapsed time 1673.0202041110024
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7625, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6630434782608696, &#39;ERDE_5&#39;: 0.2567404145933969, &#39;ERDE_50&#39;: 0.11620324092856374, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6294559477862786}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.2545340098540806, &#39;ERDE_50&#39;: 0.1414602810968532, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5537836480524089}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.2499188383162641, &#39;ERDE_50&#39;: 0.16600731102779828, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46307960448505636}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10982   265]
 [ 2102   600]]
Evaluating after getting time 600194.941666335
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10982   265]
 [ 2102   600]]
Evaluated with elapsed time 8.649410817073658
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6237623762376238, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6146341463414634, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11930177992851507, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5906755604056881}
Writing results to CSV file
{&#39;precision&#39;: 0.6428571428571429, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.574468085106383, &#39;ERDE_5&#39;: 0.263238708701631, &#39;ERDE_50&#39;: 0.13629213325054967, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5487205508634586}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5849586129188538
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.4024 - tp: 374.0000 - fp: 79.0000 - tn: 11168.0000 - fn: 2328.0000 - accuracy: 0.8274 - precision: 0.8256 - recall: 0.1384 - f1_metric: 0.0802
Test Score: 0.4023907482624054
Test Accuracy: 374.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.57      0.57     13949
weighted avg       0.83      0.83      0.77     13949

[[11168    79]
 [ 2328   374]]
Finished training and evaluation
{&#39;precision&#39;: 0.6588235294117647, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5925925925925926, &#39;ERDE_5&#39;: 0.26258244475618947, &#39;ERDE_50&#39;: 0.13414250894655058, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5625738646881615}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4104 - tp: 435.0000 - fp: 158.0000 - tn: 11089.0000 - fn: 2267.0000 - accuracy: 0.8262 - precision: 0.7336 - recall: 0.1610 - f1_metric: 0.0917
Test Score: 0.41041767597198486
Test Accuracy: 435.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.73      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.78      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11089   158]
 [ 2267   435]]
Finished training and evaluation
{&#39;precision&#39;: 0.5833333333333334, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5943396226415095, &#39;ERDE_5&#39;: 0.2718887182070221, &#39;ERDE_50&#39;: 0.12546438231917012, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.561920887989532}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.6102 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6101518273353577
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5472 - tp: 348.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2354.0000 - accuracy: 0.8263 - precision: 0.8345 - recall: 0.1288 - f1_metric: 0.0747
Test Score: 0.5472047328948975
Test Accuracy: 348.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.13      0.22      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11178    69]
 [ 2354   348]]
Finished training and evaluation
{&#39;precision&#39;: 0.6538461538461539, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5604395604395604, &#39;ERDE_5&#39;: 0.26147497148586657, &#39;ERDE_50&#39;: 0.14099700684422797, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.5276911953309621}
Evaluating for elapsed time
436/436 [==============================] - 9s 16ms/step - loss: 0.5472 - tp: 348.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2354.0000 - accuracy: 0.8263 - precision: 0.8345 - recall: 0.1288 - f1_metric: 0.0747
Test Score: 0.5472047328948975
Test Accuracy: 348.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.83      0.13      0.22      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11178    69]
 [ 2354   348]]
Evaluated with elapsed time 185.9657086209627
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6237623762376238, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6146341463414634, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11930177992851507, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5906755604056881}
Writing results to CSV file
{&#39;precision&#39;: 0.6428571428571429, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.574468085106383, &#39;ERDE_5&#39;: 0.263238708701631, &#39;ERDE_50&#39;: 0.13629213325054967, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5487205508634586}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 185.9657086209627} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluating after getting time 608009.307326955
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluated with elapsed time 866.3268712579738
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7625, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6630434782608696, &#39;ERDE_5&#39;: 0.2567404145933969, &#39;ERDE_50&#39;: 0.11620324092856374, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6294559477862786}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.2545340098540806, &#39;ERDE_50&#39;: 0.1414602810968532, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5537836480524089}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.2499188383162641, &#39;ERDE_50&#39;: 0.16600731102779828, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46307960448505636}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10982   265]
 [ 2102   600]]
Evaluating after getting time 608894.967373422
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10982   265]
 [ 2102   600]]
Evaluated with elapsed time 9.498654001043178
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6237623762376238, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6146341463414634, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11930177992851507, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5906755604056881}
Writing results to CSV file
{&#39;precision&#39;: 0.6428571428571429, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.574468085106383, &#39;ERDE_5&#39;: 0.263238708701631, &#39;ERDE_50&#39;: 0.13629213325054967, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5487205508634586}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 5s 10ms/step - loss: 0.5023 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5023209452629089
Test Accuracy: 0.0
436/436 [==============================] - 4s 9ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 5s 11ms/step - loss: 0.5028 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5027718544006348
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 12ms/step - loss: 0.4985 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49846234917640686
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5126 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.512560248374939
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017368197441101
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 6s 12ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017368197441101
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 216.67742690991145
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125975805455, &#39;ERDE_50&#39;: 0.13313367441931237, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.2516424528130518, &#39;ERDE_50&#39;: 0.16011246097644796, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095635878454, &#39;ERDE_50&#39;: 0.18021116169465512, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6237623762376238, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6146341463414634, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11930177992851507, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5906755604056881}
Writing results to CSV file
{&#39;precision&#39;: 0.6428571428571429, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.574468085106383, &#39;ERDE_5&#39;: 0.263238708701631, &#39;ERDE_50&#39;: 0.13629213325054967, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5487205508634586}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 216.67742690991145} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11168    79]
 [ 2235   467]]
Evaluating after getting time 615430.835077551
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11168    79]
 [ 2235   467]]
Evaluated with elapsed time 1259.2705598730827
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6702127659574467, &#39;ERDE_5&#39;: 0.25790440980580687, &#39;ERDE_50&#39;: 0.11090931697257901, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.638869688124322}
Writing results to CSV file
{&#39;precision&#39;: 0.8305084745762712, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.6012269938650305, &#39;ERDE_5&#39;: 0.2516333307007026, &#39;ERDE_50&#39;: 0.13803039704682354, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5684325819880471}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493393818630101, &#39;ERDE_50&#39;: 0.16452576308801176, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.4633760975950563}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2101   601]]
Evaluating after getting time 616712.136587528
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2101   601]]
Evaluated with elapsed time 10.010517251910642
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2689036344271147, &#39;ERDE_50&#39;: 0.11573582808039443, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6436781609195402, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5863874345549739, &#39;ERDE_5&#39;: 0.2638206339927702, &#39;ERDE_50&#39;: 0.1321455287132776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5589645206160445}
Writing results to CSV file
{&#39;precision&#39;: 0.6231884057971014, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.4971098265895954, &#39;ERDE_5&#39;: 0.26095869046978704, &#39;ERDE_50&#39;: 0.1593630292077927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46999456967727066}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 20ms/step - loss: 0.5711 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5710906982421875
Test Accuracy: 0.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 11s 19ms/step - loss: 0.4012 - tp: 367.0000 - fp: 81.0000 - tn: 11166.0000 - fn: 2335.0000 - accuracy: 0.8268 - precision: 0.8192 - recall: 0.1358 - f1_metric: 0.0811
Test Score: 0.40118831396102905
Test Accuracy: 367.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.82      0.14      0.23      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.56      0.57     13949
weighted avg       0.83      0.83      0.77     13949

[[11166    81]
 [ 2335   367]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5957446808510638, &#39;ERDE_5&#39;: 0.26202620138260535, &#39;ERDE_50&#39;: 0.13348909436737333, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.563249306164448}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.4084 - tp: 496.0000 - fp: 161.0000 - tn: 11086.0000 - fn: 2206.0000 - accuracy: 0.8303 - precision: 0.7549 - recall: 0.1836 - f1_metric: 0.1011
Test Score: 0.4083895683288574
Test Accuracy: 496.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.18      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.58      0.60     13949
weighted avg       0.82      0.83      0.79     13949

[[11086   161]
 [ 2206   496]]
Finished training and evaluation
{&#39;precision&#39;: 0.6106194690265486, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6359447004608295, &#39;ERDE_5&#39;: 0.27127571437121056, &#39;ERDE_50&#39;: 0.11158690768244317, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6062041982553366}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.6070 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6070265173912048
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5436148047447205
Test Accuracy: 0.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 7s 12ms/step - loss: 0.5436 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5436148047447205
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 212.631058156956
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2689036344271147, &#39;ERDE_50&#39;: 0.11573582808039443, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6436781609195402, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5863874345549739, &#39;ERDE_5&#39;: 0.2638206339927702, &#39;ERDE_50&#39;: 0.1321455287132776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5589645206160445}
Writing results to CSV file
{&#39;precision&#39;: 0.6231884057971014, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.4971098265895954, &#39;ERDE_5&#39;: 0.26095869046978704, &#39;ERDE_50&#39;: 0.1593630292077927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46999456967727066}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 212.631058156956} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11168    79]
 [ 2235   467]]
Evaluating after getting time 623264.882479607
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11168    79]
 [ 2235   467]]
Evaluated with elapsed time 1452.5687893859576
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6702127659574467, &#39;ERDE_5&#39;: 0.25790440980580687, &#39;ERDE_50&#39;: 0.11090931697257901, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.638869688124322}
Writing results to CSV file
{&#39;precision&#39;: 0.8305084745762712, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.6012269938650305, &#39;ERDE_5&#39;: 0.2516333307007026, &#39;ERDE_50&#39;: 0.13803039704682354, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5684325819880471}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493393818630101, &#39;ERDE_50&#39;: 0.16452576308801176, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.4633760975950563}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2101   601]]
Evaluating after getting time 624737.030787629
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2101   601]]
Evaluated with elapsed time 8.95211160602048
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2689036344271147, &#39;ERDE_50&#39;: 0.11573582808039443, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6436781609195402, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5863874345549739, &#39;ERDE_5&#39;: 0.2638206339927702, &#39;ERDE_50&#39;: 0.1321455287132776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5589645206160445}
Writing results to CSV file
{&#39;precision&#39;: 0.6231884057971014, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.4971098265895954, &#39;ERDE_5&#39;: 0.26095869046978704, &#39;ERDE_50&#39;: 0.1593630292077927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46999456967727066}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5045 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.504548966884613
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5051 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5051088929176331
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5039865970611572
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5053 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5052889585494995
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5079 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5078795552253723
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 6s 12ms/step - loss: 0.5079 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5078795552253723
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 212.4562242779648
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7536231884057971, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6011560693641619, &#39;ERDE_5&#39;: 0.2556059774795592, &#39;ERDE_50&#39;: 0.13309430514336884, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5730424874853999}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.17606429310578453, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4106057617247872}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.2689036344271147, &#39;ERDE_50&#39;: 0.11573582808039443, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5977634876893593}
Writing results to CSV file
{&#39;precision&#39;: 0.6436781609195402, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5863874345549739, &#39;ERDE_5&#39;: 0.2638206339927702, &#39;ERDE_50&#39;: 0.1321455287132776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5589645206160445}
Writing results to CSV file
{&#39;precision&#39;: 0.6231884057971014, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.4971098265895954, &#39;ERDE_5&#39;: 0.26095869046978704, &#39;ERDE_50&#39;: 0.1593630292077927, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46999456967727066}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 212.4562242779648} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 630203.053562873
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 974.8672016729834
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 974.8672016729834}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 632296.543746609
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 697.1404917739565
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 697.1404917739565}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 634373.299198211
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 727.6336722580018
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 727.6336722580018}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluating after getting time 636323.573651629
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.34      0.00      0.01      2702

    accuracy                           0.81     13949
   macro avg       0.58      0.50      0.45     13949
weighted avg       0.72      0.81      0.72     13949

[[11226    21]
 [ 2691    11]]
Evaluated with elapsed time 815.9149125869153
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.24876321911194735, &#39;ERDE_50&#39;: 0.2416768662431248, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.04940131071370014}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760443867585932, &#39;ERDE_50&#39;: 0.24287846017135453, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.062295536863269274, &#39;speed&#39;: 0.9377044631367307, &#39;latency_weighted_f1&#39;: 0.034411172959146086}
Writing results to CSV file
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03669724770642202, &#39;ERDE_5&#39;: 0.24760579973314853, &#39;ERDE_50&#39;: 0.24287846017135734, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06617796869713954, &#39;speed&#39;: 0.9338220313028605, &#39;latency_weighted_f1&#39;: 0.034268698396435246}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 815.9149125869153}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluating after getting time 640132.081973185
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluated with elapsed time 1711.6902686310932
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7228915662650602, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6417112299465241, &#39;ERDE_5&#39;: 0.25905129429797685, &#39;ERDE_50&#39;: 0.11940326577435335, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6141986942266257}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5868263473053892, &#39;ERDE_5&#39;: 0.2539447443361169, &#39;ERDE_50&#39;: 0.1390785523401101, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.561666929660536}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510792787484245, &#39;ERDE_50&#39;: 0.1683517236873495, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4508539841117588}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluating after getting time 641864.379480192
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluated with elapsed time 6.457378735067323
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5862516164779663
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4010 - tp: 590.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2112.0000 - accuracy: 0.8348 - precision: 0.7545 - recall: 0.2184 - f1_metric: 0.1189
Test Score: 0.40101370215415955
Test Accuracy: 590.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2112   590]]
Finished training and evaluation
{&#39;precision&#39;: 0.6194690265486725, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6451612903225806, &#39;ERDE_5&#39;: 0.2706721291459233, &#39;ERDE_50&#39;: 0.10658529896984618, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6149897663459936}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.4009 - tp: 631.0000 - fp: 216.0000 - tn: 11031.0000 - fn: 2071.0000 - accuracy: 0.8360 - precision: 0.7450 - recall: 0.2335 - f1_metric: 0.1154
Test Score: 0.40091532468795776
Test Accuracy: 631.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.74      0.23      0.36      2702

    accuracy                           0.84     13949
   macro avg       0.79      0.61      0.63     13949
weighted avg       0.82      0.84      0.80     13949

[[11031   216]
 [ 2071   631]]
Finished training and evaluation
{&#39;precision&#39;: 0.5819672131147541, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6283185840707964, &#39;ERDE_5&#39;: 0.2753425904424409, &#39;ERDE_50&#39;: 0.1116284310234064, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5964900987871712}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6157369017601013
Test Accuracy: 0.0
436/436 [==============================] - 4s 9ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 4s 9ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.616822429906542, &#39;ERDE_5&#39;: 0.27126136940928736, &#39;ERDE_50&#39;: 0.11545159255399763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5903769691701723}
Evaluating for elapsed time
436/436 [==============================] - 8s 11ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Evaluated with elapsed time 127.12077305698767
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 127.12077305698767} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluating after getting time 648001.625448242
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluated with elapsed time 1310.344479343039
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7228915662650602, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6417112299465241, &#39;ERDE_5&#39;: 0.25905129429797685, &#39;ERDE_50&#39;: 0.11940326577435335, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6141986942266257}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5868263473053892, &#39;ERDE_5&#39;: 0.2539447443361169, &#39;ERDE_50&#39;: 0.1390785523401101, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.561666929660536}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510792787484245, &#39;ERDE_50&#39;: 0.1683517236873495, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4508539841117588}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluating after getting time 649329.382187488
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluated with elapsed time 6.380678266985342
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5188224911689758
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.5035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5034902691841125
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 14ms/step - loss: 0.4848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.48482373356819153
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5081223845481873
Test Accuracy: 0.0
436/436 [==============================] - 5s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 6s 11ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 185.6610882949317
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 185.6610882949317} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluating after getting time 654736.911636901
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluated with elapsed time 1191.9598035250092
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7125, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6195652173913043, &#39;ERDE_5&#39;: 0.25906482152833543, &#39;ERDE_50&#39;: 0.12476134774904293, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5930021632030438}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25336981199295583, &#39;ERDE_50&#39;: 0.13821555671763017, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8292682926829268, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.46896551724137925, &#39;ERDE_5&#39;: 0.24991970120624632, &#39;ERDE_50&#39;: 0.17073536337180328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.058432471622878124, &#39;speed&#39;: 0.9415675283771219, &#39;latency_weighted_f1&#39;: 0.441562702963064}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluating after getting time 655944.06532103
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluated with elapsed time 7.799409225001
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4144 - tp: 477.0000 - fp: 109.0000 - tn: 11138.0000 - fn: 2225.0000 - accuracy: 0.8327 - precision: 0.8140 - recall: 0.1765 - f1_metric: 0.0996
Test Score: 0.41441696882247925
Test Accuracy: 477.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11138   109]
 [ 2225   477]]
Finished training and evaluation
{&#39;precision&#39;: 0.6262626262626263, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.6108374384236452, &#39;ERDE_5&#39;: 0.267188306660477, &#39;ERDE_50&#39;: 0.12317886177861229, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5846485764255744}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4548 - tp: 545.0000 - fp: 170.0000 - tn: 11077.0000 - fn: 2157.0000 - accuracy: 0.8332 - precision: 0.7622 - recall: 0.2017 - f1_metric: 0.1092
Test Score: 0.45476004481315613
Test Accuracy: 545.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11077   170]
 [ 2157   545]]
Finished training and evaluation
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.26893537276146445, &#39;ERDE_50&#39;: 0.1173781600317242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5929207555919508}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.4027 - tp: 529.0000 - fp: 163.0000 - tn: 11084.0000 - fn: 2173.0000 - accuracy: 0.8325 - precision: 0.7645 - recall: 0.1958 - f1_metric: 0.1050
Test Score: 0.4027296006679535
Test Accuracy: 529.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.90     11247
           1       0.76      0.20      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11084   163]
 [ 2173   529]]
Finished training and evaluation
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5452 - tp: 321.0000 - fp: 57.0000 - tn: 11190.0000 - fn: 2381.0000 - accuracy: 0.8252 - precision: 0.8492 - recall: 0.1188 - f1_metric: 0.0738
Test Score: 0.5451857447624207
Test Accuracy: 321.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.85      0.12      0.21      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11190    57]
 [ 2381   321]]
Finished training and evaluation
{&#39;precision&#39;: 0.7391304347826086, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5895953757225433, &#39;ERDE_5&#39;: 0.2562168785047715, &#39;ERDE_50&#39;: 0.137356286508025, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.5505623778786023}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Finished training and evaluation
{&#39;precision&#39;: 0.5779816513761468, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5915492957746479, &#39;ERDE_5&#39;: 0.2724499660885206, &#39;ERDE_50&#39;: 0.12697102250612122, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5592827617548393}
Evaluating for elapsed time
436/436 [==============================] - 9s 14ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Evaluated with elapsed time 193.3210578269791
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Writing results to CSV file
{&#39;precision&#39;: 0.7073170731707317, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6236559139784946, &#39;ERDE_5&#39;: 0.2597674656713013, &#39;ERDE_50&#39;: 0.12781435716813794, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5847902164226599}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.25457117883635827, &#39;ERDE_50&#39;: 0.15350515364565748, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.5060622073110747}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7272727272727273, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6187845303867403, &#39;ERDE_5&#39;: 0.25790928763679505, &#39;ERDE_50&#39;: 0.1259629417248749, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5922549471400759}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.2533701037202872, &#39;ERDE_50&#39;: 0.14294369447489608, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5463659082720199}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.17782756185526205, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7093023255813954, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6421052631578947, &#39;ERDE_5&#39;: 0.2602007203928013, &#39;ERDE_50&#39;: 0.11646763428933689, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6170758465224001}
Writing results to CSV file
{&#39;precision&#39;: 0.7323943661971831, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5942857142857143, &#39;ERDE_5&#39;: 0.25684527212623093, &#39;ERDE_50&#39;: 0.1346108376280734, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5688064859675913}
Writing results to CSV file
{&#39;precision&#39;: 0.7446808510638298, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4635761589403974, &#39;ERDE_5&#39;: 0.2528216559476644, &#39;ERDE_50&#39;: 0.1700957077789542, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.44189662018900866}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7222222222222222, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.25734604730228205, &#39;ERDE_50&#39;: 0.13483804739182256, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5655746309336844}
Writing results to CSV file
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.25279480153055295, &#39;ERDE_50&#39;: 0.1470907012409325, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5285147659883797}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.249921295400085, &#39;ERDE_50&#39;: 0.17546379827816108, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.42140045545146343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 193.3210578269791} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluating after getting time 665925.564820548
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluated with elapsed time 1406.3905496419175
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7125, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6195652173913043, &#39;ERDE_5&#39;: 0.25906482152833543, &#39;ERDE_50&#39;: 0.12476134774904293, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5930021632030438}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25336981199295583, &#39;ERDE_50&#39;: 0.13821555671763017, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8292682926829268, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.46896551724137925, &#39;ERDE_5&#39;: 0.24991970120624632, &#39;ERDE_50&#39;: 0.17073536337180328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.058432471622878124, &#39;speed&#39;: 0.9415675283771219, &#39;latency_weighted_f1&#39;: 0.441562702963064}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluating after getting time 667349.961544801
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluated with elapsed time 7.596113141975366
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5105624794960022
Test Accuracy: 0.0
436/436 [==============================] - 7s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.5062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062195658683777
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 19ms/step - loss: 0.4961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4961474537849426
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 11s 19ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047220587730408
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 10s 18ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 11s 17ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 200.77116628200747
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 200.77116628200747} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 673539.958970755
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 697.2656523219775
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 697.2656523219775}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 675417.001966817
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 691.6747174860211
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 691.6747174860211}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 677408.501951844
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 732.041205338086
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 732.041205338086}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluating after getting time 680279.881766263
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.32      0.01      0.02      2702

    accuracy                           0.80     13949
   macro avg       0.56      0.50      0.45     13949
weighted avg       0.71      0.80      0.72     13949

[[11192    55]
 [ 2676    26]]
Evaluated with elapsed time 2077.921499261982
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10169491525423728, &#39;ERDE_5&#39;: 0.2504885986519404, &#39;ERDE_50&#39;: 0.23632837605986715, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.09773082315025508}
Writing results to CSV file
{&#39;precision&#39;: 0.3, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.052631578947368425, &#39;ERDE_5&#39;: 0.24992722951881216, &#39;ERDE_50&#39;: 0.24283933850881306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.0503750683422715}
Writing results to CSV file
{&#39;precision&#39;: 0.2222222222222222, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03539823008849558, &#39;ERDE_5&#39;: 0.24992995151031763, &#39;ERDE_50&#39;: 0.24520340470242385, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.03374280133933771}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 2077.921499261982}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluating after getting time 684572.851880375
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluated with elapsed time 861.521489815088
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7625, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6630434782608696, &#39;ERDE_5&#39;: 0.2567404145933854, &#39;ERDE_50&#39;: 0.11620324067576857, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6294559477862786}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453401008411203, &#39;ERDE_50&#39;: 0.1390962149390083, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5605910027075729}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.2499188384008896, &#39;ERDE_50&#39;: 0.16600731102780875, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46307960448505636}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10980   267]
 [ 2101   601]]
Evaluating after getting time 685455.222698894
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10980   267]
 [ 2101   601]]
Evaluated with elapsed time 8.526771328994073
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6274509803921569, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6213592233009709, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11866598460612737, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5959288728483625}
Writing results to CSV file
{&#39;precision&#39;: 0.6352941176470588, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2638199448343988, &#39;ERDE_50&#39;: 0.1368733693833174, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5458172675255568}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 13ms/step - loss: 0.5850 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5849684476852417
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4003 - tp: 459.0000 - fp: 112.0000 - tn: 11135.0000 - fn: 2243.0000 - accuracy: 0.8312 - precision: 0.8039 - recall: 0.1699 - f1_metric: 0.0947
Test Score: 0.4003196656703949
Test Accuracy: 459.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.17      0.28      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.59     13949
weighted avg       0.83      0.83      0.78     13949

[[11135   112]
 [ 2243   459]]
Finished training and evaluation
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.594059405940594, &#39;ERDE_5&#39;: 0.26779886393465063, &#39;ERDE_50&#39;: 0.1290163029388859, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5651220399497711}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4111 - tp: 424.0000 - fp: 143.0000 - tn: 11104.0000 - fn: 2278.0000 - accuracy: 0.8264 - precision: 0.7478 - recall: 0.1569 - f1_metric: 0.0912
Test Score: 0.41111093759536743
Test Accuracy: 424.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.75      0.16      0.26      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.81      0.83      0.78     13949

[[11104   143]
 [ 2278   424]]
Finished training and evaluation
{&#39;precision&#39;: 0.6037735849056604, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6095238095238096, &#39;ERDE_5&#39;: 0.27014593418534005, &#39;ERDE_50&#39;: 0.12402762962684931, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5762768411369591}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.6103 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6102716326713562
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.4538 - tp: 504.0000 - fp: 122.0000 - tn: 11125.0000 - fn: 2198.0000 - accuracy: 0.8337 - precision: 0.8051 - recall: 0.1865 - f1_metric: 0.1021
Test Score: 0.45378759503364563
Test Accuracy: 504.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.81      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11125   122]
 [ 2198   504]]
Finished training and evaluation
{&#39;precision&#39;: 0.6039603960396039, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5951219512195123, &#39;ERDE_5&#39;: 0.2689745247172591, &#39;ERDE_50&#39;: 0.12727636298815787, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5649750945984159}
Evaluating for elapsed time
436/436 [==============================] - 6s 11ms/step - loss: 0.4538 - tp: 504.0000 - fp: 122.0000 - tn: 11125.0000 - fn: 2198.0000 - accuracy: 0.8337 - precision: 0.8051 - recall: 0.1865 - f1_metric: 0.1021
Test Score: 0.45378759503364563
Test Accuracy: 504.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.91     11247
           1       0.81      0.19      0.30      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.59      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11125   122]
 [ 2198   504]]
Evaluated with elapsed time 210.98714608489536
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6274509803921569, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6213592233009709, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11866598460612737, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5959288728483625}
Writing results to CSV file
{&#39;precision&#39;: 0.6352941176470588, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2638199448343988, &#39;ERDE_50&#39;: 0.1368733693833174, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5458172675255568}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 210.98714608489536} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluating after getting time 693147.6845141
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.85      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11162    85]
 [ 2234   468]]
Evaluated with elapsed time 744.395800605067
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7625, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6630434782608696, &#39;ERDE_5&#39;: 0.2567404145933854, &#39;ERDE_50&#39;: 0.11620324067576857, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.6294559477862786}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5917159763313611, &#39;ERDE_5&#39;: 0.25453401008411203, &#39;ERDE_50&#39;: 0.1390962149390083, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.5605910027075729}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.2499188384008896, &#39;ERDE_50&#39;: 0.16600731102780875, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.46307960448505636}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10980   267]
 [ 2101   601]]
Evaluating after getting time 693912.748906981
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.77      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10980   267]
 [ 2101   601]]
Evaluated with elapsed time 8.396292136982083
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6274509803921569, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6213592233009709, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11866598460612737, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5959288728483625}
Writing results to CSV file
{&#39;precision&#39;: 0.6352941176470588, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2638199448343988, &#39;ERDE_50&#39;: 0.1368733693833174, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5458172675255568}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5024 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5023818016052246
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 10ms/step - loss: 0.5025 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5024811029434204
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 5s 11ms/step - loss: 0.4987 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.49872642755508423
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5120 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5120412707328796
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017363429069519
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 6s 11ms/step - loss: 0.5017 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5017363429069519
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 211.3485199379502
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.796875, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6071428571428571, &#39;ERDE_5&#39;: 0.25329125992621276, &#39;ERDE_50&#39;: 0.13313367416651822, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5763870622586297}
Writing results to CSV file
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.251642452874918, &#39;ERDE_50&#39;: 0.1601124609764508, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.4819962549950668}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24876095638154383, &#39;ERDE_50&#39;: 0.18021116169466272, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.3957309077801673}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6274509803921569, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.6213592233009709, &#39;ERDE_5&#39;: 0.2677492746560822, &#39;ERDE_50&#39;: 0.11866598460612737, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5959288728483625}
Writing results to CSV file
{&#39;precision&#39;: 0.6352941176470588, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2638199448343988, &#39;ERDE_50&#39;: 0.1368733693833174, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.5458172675255568}
Writing results to CSV file
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25979743372119324, &#39;ERDE_50&#39;: 0.15820055692927404, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4735364401628378}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 211.3485199379502} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11169    78]
 [ 2236   466]]
Evaluating after getting time 700466.233898382
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11169    78]
 [ 2236   466]]
Evaluated with elapsed time 1629.8951611489756
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7590361445783133, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6737967914438502, &#39;ERDE_5&#39;: 0.25732317367303914, &#39;ERDE_50&#39;: 0.11032808083981127, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6422861035688371}
Writing results to CSV file
{&#39;precision&#39;: 0.8305084745762712, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.6012269938650305, &#39;ERDE_5&#39;: 0.2516333307007026, &#39;ERDE_50&#39;: 0.13803039704682354, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5684325819880471}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493393818630101, &#39;ERDE_50&#39;: 0.16516151892713263, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.4633760975950563}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2098   604]]
Evaluating after getting time 702118.017650033
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2098   604]]
Evaluated with elapsed time 6.811181543045677
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.625, &#39;ERDE_5&#39;: 0.26832221390496797, &#39;ERDE_50&#39;: 0.1151545919476267, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6006373506109428}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26440176476775856, &#39;ERDE_50&#39;: 0.13272676484604523, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5560532470711692}
Writing results to CSV file
{&#39;precision&#39;: 0.6285714285714286, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5057471264367815, &#39;ERDE_5&#39;: 0.26095789767988053, &#39;ERDE_50&#39;: 0.15699896301393926, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.47914421794638057}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5710370540618896
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 10s 16ms/step - loss: 0.4034 - tp: 313.0000 - fp: 69.0000 - tn: 11178.0000 - fn: 2389.0000 - accuracy: 0.8238 - precision: 0.8194 - recall: 0.1158 - f1_metric: 0.0704
Test Score: 0.4034287929534912
Test Accuracy: 313.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.82      0.12      0.20      2702

    accuracy                           0.82     13949
   macro avg       0.82      0.55      0.55     13949
weighted avg       0.82      0.82      0.77     13949

[[11178    69]
 [ 2389   313]]
Finished training and evaluation
{&#39;precision&#39;: 0.7435897435897436, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6373626373626373, &#39;ERDE_5&#39;: 0.25738789167491954, &#39;ERDE_50&#39;: 0.12467479805442179, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.6013582881214387}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.4064 - tp: 445.0000 - fp: 133.0000 - tn: 11114.0000 - fn: 2257.0000 - accuracy: 0.8287 - precision: 0.7699 - recall: 0.1647 - f1_metric: 0.0895
Test Score: 0.40638354420661926
Test Accuracy: 445.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.77      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.58      0.59     13949
weighted avg       0.82      0.83      0.78     13949

[[11114   133]
 [ 2257   445]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.5882352941176471, &#39;ERDE_5&#39;: 0.2689660442617192, &#39;ERDE_50&#39;: 0.12845901917262392, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.5595816277934008}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.6071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6070516705513
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.5442 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5442476868629456
Test Accuracy: 0.0
436/436 [==============================] - 6s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 10s 17ms/step - loss: 0.5442 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5442476868629456
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 200.04584425198846
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.625, &#39;ERDE_5&#39;: 0.26832221390496797, &#39;ERDE_50&#39;: 0.1151545919476267, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6006373506109428}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26440176476775856, &#39;ERDE_50&#39;: 0.13272676484604523, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5560532470711692}
Writing results to CSV file
{&#39;precision&#39;: 0.6285714285714286, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5057471264367815, &#39;ERDE_5&#39;: 0.26095789767988053, &#39;ERDE_50&#39;: 0.15699896301393926, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.47914421794638057}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 200.04584425198846} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11169    78]
 [ 2236   466]]
Evaluating after getting time 709177.104683997
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.86      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.84      0.83      0.79     13949

[[11169    78]
 [ 2236   466]]
Evaluated with elapsed time 1255.1793399150483
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7590361445783133, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.6737967914438502, &#39;ERDE_5&#39;: 0.25732317367303914, &#39;ERDE_50&#39;: 0.11032808083981127, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6422861035688371}
Writing results to CSV file
{&#39;precision&#39;: 0.8305084745762712, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.6012269938650305, &#39;ERDE_5&#39;: 0.2516333307007026, &#39;ERDE_50&#39;: 0.13803039704682354, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5684325819880471}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4931506849315069, &#39;ERDE_5&#39;: 0.2493393818630101, &#39;ERDE_50&#39;: 0.16516151892713263, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.4633760975950563}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2098   604]]
Evaluating after getting time 710449.574630282
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.69      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.76      0.60      0.62     13949
weighted avg       0.81      0.83      0.79     13949

[[10973   274]
 [ 2098   604]]
Evaluated with elapsed time 6.976890638004988
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.625, &#39;ERDE_5&#39;: 0.26832221390496797, &#39;ERDE_50&#39;: 0.1151545919476267, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6006373506109428}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26440176476775856, &#39;ERDE_50&#39;: 0.13272676484604523, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5560532470711692}
Writing results to CSV file
{&#39;precision&#39;: 0.6285714285714286, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5057471264367815, &#39;ERDE_5&#39;: 0.26095789767988053, &#39;ERDE_50&#39;: 0.15699896301393926, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.47914421794638057}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 13s 24ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047177076339722
Test Accuracy: 0.0
436/436 [==============================] - 9s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5046 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5045680999755859
Test Accuracy: 0.0
436/436 [==============================] - 10s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5040 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5040106773376465
Test Accuracy: 0.0
436/436 [==============================] - 5s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5051 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5051465630531311
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 13ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5080717206001282
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 8s 13ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5080717206001282
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 176.10583764500916
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7647058823529411, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.6046511627906976, &#39;ERDE_5&#39;: 0.25502474134679143, &#39;ERDE_50&#39;: 0.13251306901060111, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.576374129854501}
Writing results to CSV file
{&#39;precision&#39;: 0.8269230769230769, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5512820512820512, &#39;ERDE_5&#39;: 0.2510596765362011, &#39;ERDE_50&#39;: 0.15007497463133365, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5212119266292808}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42857142857142855, &#39;ERDE_5&#39;: 0.24934119466340443, &#39;ERDE_50&#39;: 0.1784283198163712, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.4001987032478916}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.625, &#39;ERDE_5&#39;: 0.26832221390496797, &#39;ERDE_50&#39;: 0.1151545919476267, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6006373506109428}
Writing results to CSV file
{&#39;precision&#39;: 0.6363636363636364, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5833333333333334, &#39;ERDE_5&#39;: 0.26440176476775856, &#39;ERDE_50&#39;: 0.13272676484604523, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5560532470711692}
Writing results to CSV file
{&#39;precision&#39;: 0.6285714285714286, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5057471264367815, &#39;ERDE_5&#39;: 0.26095789767988053, &#39;ERDE_50&#39;: 0.15699896301393926, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.47914421794638057}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 176.10583764500916} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluating after getting time 715812.906124383
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluated with elapsed time 1065.1445884000277
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561895128651493, &#39;ERDE_50&#39;: 0.12516198533823267, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.597339665314958}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.25453608565934766, &#39;ERDE_50&#39;: 0.14121837745328653, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5515149456193553}
Writing results to CSV file
{&#39;precision&#39;: 0.7843137254901961, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5161290322580645, &#39;ERDE_5&#39;: 0.25224453406456393, &#39;ERDE_50&#39;: 0.1600579291220388, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4859698800770909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 1065.1445884000277}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluating after getting time 718512.398290245
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluated with elapsed time 1014.0114981910447
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561895128651493, &#39;ERDE_50&#39;: 0.12516198533823267, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.597339665314958}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.25453608565934766, &#39;ERDE_50&#39;: 0.14121837745328653, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5515149456193553}
Writing results to CSV file
{&#39;precision&#39;: 0.7843137254901961, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5161290322580645, &#39;ERDE_5&#39;: 0.25224453406456393, &#39;ERDE_50&#39;: 0.1600579291220388, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4859698800770909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 1014.0114981910447}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluating after getting time 721411.380232105
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluated with elapsed time 641.8568165859906
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561895128651493, &#39;ERDE_50&#39;: 0.12516198533823267, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.597339665314958}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.25453608565934766, &#39;ERDE_50&#39;: 0.14121837745328653, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5515149456193553}
Writing results to CSV file
{&#39;precision&#39;: 0.7843137254901961, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5161290322580645, &#39;ERDE_5&#39;: 0.25224453406456393, &#39;ERDE_50&#39;: 0.1600579291220388, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4859698800770909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 641.8568165859906}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluating after getting time 722866.170870254
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.76      0.16      0.27      2702

    accuracy                           0.83     13949
   macro avg       0.79      0.57      0.58     13949
weighted avg       0.82      0.83      0.78     13949

[[11108   139]
 [ 2268   434]]
Evaluated with elapsed time 491.10750137793366
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6292134831460674, &#39;ERDE_5&#39;: 0.2561895128651493, &#39;ERDE_50&#39;: 0.12516198533823267, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.597339665314958}
Writing results to CSV file
{&#39;precision&#39;: 0.765625, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5833333333333333, &#39;ERDE_5&#39;: 0.25453608565934766, &#39;ERDE_50&#39;: 0.14121837745328653, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5515149456193553}
Writing results to CSV file
{&#39;precision&#39;: 0.7843137254901961, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5161290322580645, &#39;ERDE_5&#39;: 0.25224453406456393, &#39;ERDE_50&#39;: 0.1600579291220388, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.4859698800770909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 491.10750137793366}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluating after getting time 724815.542782903
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluated with elapsed time 1140.892953360104
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7228915662650602, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6417112299465241, &#39;ERDE_5&#39;: 0.25905129429797685, &#39;ERDE_50&#39;: 0.11940326577435335, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6141986942266257}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5868263473053892, &#39;ERDE_5&#39;: 0.2539447443361169, &#39;ERDE_50&#39;: 0.1390785523401101, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.561666929660536}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510792787484245, &#39;ERDE_50&#39;: 0.1683517236873495, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4508539841117588}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluating after getting time 725975.972759332
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluated with elapsed time 8.280596177908592
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.5863 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5862516164779663
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4010 - tp: 590.0000 - fp: 192.0000 - tn: 11055.0000 - fn: 2112.0000 - accuracy: 0.8348 - precision: 0.7545 - recall: 0.2184 - f1_metric: 0.1189
Test Score: 0.40101370215415955
Test Accuracy: 590.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.75      0.22      0.34      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.60      0.62     13949
weighted avg       0.82      0.83      0.80     13949

[[11055   192]
 [ 2112   590]]
Finished training and evaluation
{&#39;precision&#39;: 0.6194690265486725, &#39;recall&#39;: 0.6730769230769231, &#39;F1&#39;: 0.6451612903225806, &#39;ERDE_5&#39;: 0.2706721291459233, &#39;ERDE_50&#39;: 0.10658529896984618, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6149897663459936}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.4009 - tp: 631.0000 - fp: 216.0000 - tn: 11031.0000 - fn: 2071.0000 - accuracy: 0.8360 - precision: 0.7450 - recall: 0.2335 - f1_metric: 0.1154
Test Score: 0.40091532468795776
Test Accuracy: 631.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.74      0.23      0.36      2702

    accuracy                           0.84     13949
   macro avg       0.79      0.61      0.63     13949
weighted avg       0.82      0.84      0.80     13949

[[11031   216]
 [ 2071   631]]
Finished training and evaluation
{&#39;precision&#39;: 0.5819672131147541, &#39;recall&#39;: 0.6826923076923077, &#39;F1&#39;: 0.6283185840707964, &#39;ERDE_5&#39;: 0.2753425904424409, &#39;ERDE_50&#39;: 0.1116284310234064, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.5964900987871712}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.6157 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6157369017601013
Test Accuracy: 0.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 7s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.616822429906542, &#39;ERDE_5&#39;: 0.27126136940928736, &#39;ERDE_50&#39;: 0.11545159255399763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5903769691701723}
Evaluating for elapsed time
436/436 [==============================] - 10s 17ms/step - loss: 0.4638 - tp: 602.0000 - fp: 183.0000 - tn: 11064.0000 - fn: 2100.0000 - accuracy: 0.8363 - precision: 0.7669 - recall: 0.2228 - f1_metric: 0.1164
Test Score: 0.46379026770591736
Test Accuracy: 602.0
436/436 [==============================] - 8s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.91     11247
           1       0.77      0.22      0.35      2702

    accuracy                           0.84     13949
   macro avg       0.80      0.60      0.63     13949
weighted avg       0.83      0.84      0.80     13949

[[11064   183]
 [ 2100   602]]
Evaluated with elapsed time 216.19684159907047
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 216.19684159907047} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluating after getting time 734554.005688285
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.82      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.83      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11143   104]
 [ 2218   484]]
Evaluated with elapsed time 1233.3056861120276
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7228915662650602, &#39;recall&#39;: 0.5769230769230769, &#39;F1&#39;: 0.6417112299465241, &#39;ERDE_5&#39;: 0.25905129429797685, &#39;ERDE_50&#39;: 0.11940326577435335, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.6141986942266257}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5868263473053892, &#39;ERDE_5&#39;: 0.2539447443361169, &#39;ERDE_50&#39;: 0.1390785523401101, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.561666929660536}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.2510792787484245, &#39;ERDE_50&#39;: 0.1683517236873495, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4508539841117588}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluating after getting time 735805.127491111
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10748   499]
 [ 1956   746]]
Evaluated with elapsed time 5.820661972975358
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5188 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5188224911689758
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.5035 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5034902691841125
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4848 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.48482373356819153
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.5081 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5081223845481873
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 16ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
436/436 [==============================] - 9s 15ms/step - loss: 0.5071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5070620179176331
Test Accuracy: 0.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 198.41201244003605
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6136363636363638, &#39;ERDE_5&#39;: 0.25615868934703784, &#39;ERDE_50&#39;: 0.12905948557406546, &#39;median_latency_tps&#39;: 11.5, &#39;median_penalty_tps&#39;: 0.04092697025966663, &#39;speed&#39;: 0.9590730297403334, &#39;latency_weighted_f1&#39;: 0.5885220864315683}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.55, &#39;ERDE_5&#39;: 0.25278511675947385, &#39;ERDE_50&#39;: 0.14973641559200412, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5264194641767371}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.25049831133456746, &#39;ERDE_50&#39;: 0.17249863240395502, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43388588342893203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5603448275862069, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.27526363399560994, &#39;ERDE_50&#39;: 0.12224143811229882, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5678753133048913}
Writing results to CSV file
{&#39;precision&#39;: 0.59, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.5784313725490196, &#39;ERDE_5&#39;: 0.2696130955506825, &#39;ERDE_50&#39;: 0.13113137181455337, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5536318785459444}
Writing results to CSV file
{&#39;precision&#39;: 0.5930232558139535, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.536842105263158, &#39;ERDE_5&#39;: 0.26618049303023456, &#39;ERDE_50&#39;: 0.1462748746091478, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5117362213647453}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 198.41201244003605} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluating after getting time 742042.238012177
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluated with elapsed time 1244.3508395348908
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7125, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6195652173913043, &#39;ERDE_5&#39;: 0.25906482152833543, &#39;ERDE_50&#39;: 0.12476134774904293, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5930021632030438}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25336981199295583, &#39;ERDE_50&#39;: 0.13821555671763017, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8292682926829268, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.46896551724137925, &#39;ERDE_5&#39;: 0.24991970120624632, &#39;ERDE_50&#39;: 0.17073536337180328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.058432471622878124, &#39;speed&#39;: 0.9415675283771219, &#39;latency_weighted_f1&#39;: 0.441562702963064}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluating after getting time 743305.511417702
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluated with elapsed time 7.618398891063407
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00024: early stopping
Evaluating
436/436 [==============================] - 8s 16ms/step - loss: 0.4144 - tp: 477.0000 - fp: 109.0000 - tn: 11138.0000 - fn: 2225.0000 - accuracy: 0.8327 - precision: 0.8140 - recall: 0.1765 - f1_metric: 0.0996
Test Score: 0.41441696882247925
Test Accuracy: 477.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.81      0.18      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11138   109]
 [ 2225   477]]
Finished training and evaluation
{&#39;precision&#39;: 0.6262626262626263, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.6108374384236452, &#39;ERDE_5&#39;: 0.267188306660477, &#39;ERDE_50&#39;: 0.12317886177861229, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5846485764255744}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4548 - tp: 545.0000 - fp: 170.0000 - tn: 11077.0000 - fn: 2157.0000 - accuracy: 0.8332 - precision: 0.7622 - recall: 0.2017 - f1_metric: 0.1092
Test Score: 0.45476004481315613
Test Accuracy: 545.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11077   170]
 [ 2157   545]]
Finished training and evaluation
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.6220095693779905, &#39;ERDE_5&#39;: 0.26893537276146445, &#39;ERDE_50&#39;: 0.1173781600317242, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5929207555919508}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.4027 - tp: 529.0000 - fp: 163.0000 - tn: 11084.0000 - fn: 2173.0000 - accuracy: 0.8325 - precision: 0.7645 - recall: 0.1958 - f1_metric: 0.1050
Test Score: 0.4027296006679535
Test Accuracy: 529.0
436/436 [==============================] - 6s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.99      0.90     11247
           1       0.76      0.20      0.31      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11084   163]
 [ 2173   529]]
Finished training and evaluation
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00036: early stopping
Evaluating
436/436 [==============================] - 8s 15ms/step - loss: 0.5452 - tp: 321.0000 - fp: 57.0000 - tn: 11190.0000 - fn: 2381.0000 - accuracy: 0.8252 - precision: 0.8492 - recall: 0.1188 - f1_metric: 0.0738
Test Score: 0.5451857447624207
Test Accuracy: 321.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.99      0.90     11247
           1       0.85      0.12      0.21      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.56      0.56     13949
weighted avg       0.83      0.83      0.77     13949

[[11190    57]
 [ 2381   321]]
Finished training and evaluation
{&#39;precision&#39;: 0.7391304347826086, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5895953757225433, &#39;ERDE_5&#39;: 0.2562168785047715, &#39;ERDE_50&#39;: 0.137356286508025, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.5505623778786023}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00028: early stopping
Evaluating
436/436 [==============================] - 9s 18ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Finished training and evaluation
{&#39;precision&#39;: 0.5779816513761468, &#39;recall&#39;: 0.6057692307692307, &#39;F1&#39;: 0.5915492957746479, &#39;ERDE_5&#39;: 0.2724499660885206, &#39;ERDE_50&#39;: 0.12697102250612122, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5592827617548393}
Evaluating for elapsed time
436/436 [==============================] - 8s 14ms/step - loss: 0.4605 - tp: 553.0000 - fp: 178.0000 - tn: 11069.0000 - fn: 2149.0000 - accuracy: 0.8332 - precision: 0.7565 - recall: 0.2047 - f1_metric: 0.1077
Test Score: 0.4605026841163635
Test Accuracy: 553.0
436/436 [==============================] - 6s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.98      0.90     11247
           1       0.76      0.20      0.32      2702

    accuracy                           0.83     13949
   macro avg       0.80      0.59      0.61     13949
weighted avg       0.82      0.83      0.79     13949

[[11069   178]
 [ 2149   553]]
Evaluated with elapsed time 185.49346246698406
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6509433962264151, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.6571428571428571, &#39;ERDE_5&#39;: 0.26719860292523284, &#39;ERDE_50&#39;: 0.10555821342523847, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.6264110048638477}
Writing results to CSV file
{&#39;precision&#39;: 0.7073170731707317, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6236559139784946, &#39;ERDE_5&#39;: 0.2597674656713013, &#39;ERDE_50&#39;: 0.12781435716813794, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.5847902164226599}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.25457117883635827, &#39;ERDE_50&#39;: 0.15350515364565748, &#39;median_latency_tps&#39;: 21.0, &#39;median_penalty_tps&#39;: 0.07784220001093067, &#39;speed&#39;: 0.9221577999890693, &#39;latency_weighted_f1&#39;: 0.5060622073110747}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7272727272727273, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6187845303867403, &#39;ERDE_5&#39;: 0.25790928763679505, &#39;ERDE_50&#39;: 0.1259629417248749, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5922549471400759}
Writing results to CSV file
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.2533701037202872, &#39;ERDE_50&#39;: 0.14294369447489608, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5463659082720199}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.17782756185526205, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4145020464295697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7093023255813954, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6421052631578947, &#39;ERDE_5&#39;: 0.2602007203928013, &#39;ERDE_50&#39;: 0.11646763428933689, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6170758465224001}
Writing results to CSV file
{&#39;precision&#39;: 0.7323943661971831, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5942857142857143, &#39;ERDE_5&#39;: 0.25684527212623093, &#39;ERDE_50&#39;: 0.1346108376280734, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5688064859675913}
Writing results to CSV file
{&#39;precision&#39;: 0.7446808510638298, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4635761589403974, &#39;ERDE_5&#39;: 0.2528216559476644, &#39;ERDE_50&#39;: 0.1700957077789542, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.44189662018900866}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7222222222222222, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5909090909090908, &#39;ERDE_5&#39;: 0.25734604730228205, &#39;ERDE_50&#39;: 0.13483804739182256, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5655746309336844}
Writing results to CSV file
{&#39;precision&#39;: 0.7894736842105263, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5590062111801243, &#39;ERDE_5&#39;: 0.25279480153055295, &#39;ERDE_50&#39;: 0.1470907012409325, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.5285147659883797}
Writing results to CSV file
{&#39;precision&#39;: 0.8205128205128205, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.44755244755244755, &#39;ERDE_5&#39;: 0.249921295400085, &#39;ERDE_50&#39;: 0.17546379827816108, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.42140045545146343}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6931818181818182, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.6354166666666667, &#39;ERDE_5&#39;: 0.26136319265233104, &#39;ERDE_50&#39;: 0.11763010458896456, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.6106479731211252}
Writing results to CSV file
{&#39;precision&#39;: 0.7397260273972602, &#39;recall&#39;: 0.5192307692307693, &#39;F1&#39;: 0.6101694915254238, &#39;ERDE_5&#39;: 0.2568452721255714, &#39;ERDE_50&#39;: 0.12988271058416542, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.582821828035764}
Writing results to CSV file
{&#39;precision&#39;: 0.7551020408163265, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.48366013071895425, &#39;ERDE_5&#39;: 0.25282165070197904, &#39;ERDE_50&#39;: 0.1665496230134079, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4610413477116697}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 185.49346246698406} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluating after getting time 752675.940837498
              precision    recall  f1-score   support

           0       0.83      0.99      0.91     11247
           1       0.84      0.17      0.29      2702

    accuracy                           0.83     13949
   macro avg       0.84      0.58      0.60     13949
weighted avg       0.83      0.83      0.79     13949

[[11158    89]
 [ 2236   466]]
Evaluated with elapsed time 1009.3260912440019
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7125, &#39;recall&#39;: 0.5480769230769231, &#39;F1&#39;: 0.6195652173913043, &#39;ERDE_5&#39;: 0.25906482152833543, &#39;ERDE_50&#39;: 0.12476134774904293, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5930021632030438}
Writing results to CSV file
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.25336981199295583, &#39;ERDE_50&#39;: 0.13821555671763017, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.56275268378287}
Writing results to CSV file
{&#39;precision&#39;: 0.8292682926829268, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.46896551724137925, &#39;ERDE_5&#39;: 0.24991970120624632, &#39;ERDE_50&#39;: 0.17073536337180328, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.058432471622878124, &#39;speed&#39;: 0.9415675283771219, &#39;latency_weighted_f1&#39;: 0.441562702963064}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluating after getting time 753703.528264698
              precision    recall  f1-score   support

           0       0.85      0.96      0.90     11247
           1       0.60      0.28      0.38      2702

    accuracy                           0.82     13949
   macro avg       0.72      0.62      0.64     13949
weighted avg       0.80      0.82      0.80     13949

[[10741   506]
 [ 1943   759]]
Evaluated with elapsed time 8.068523674970493
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 7s 12ms/step - loss: 0.5106 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5105624794960022
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 11ms/step - loss: 0.5062 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5062195658683777
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.4961 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.4961474537849426
Test Accuracy: 0.0
436/436 [==============================] - 5s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 6s 12ms/step - loss: 0.5047 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5047220587730408
Test Accuracy: 0.0
436/436 [==============================] - 4s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 12709
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
436/436 [==============================] - 9s 17ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>436/436 [==============================] - 10s 16ms/step - loss: 0.5006 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 11247.0000 - fn: 2702.0000 - accuracy: 0.8063 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5006016492843628
Test Accuracy: 0.0
436/436 [==============================] - 7s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      1.00      0.89     11247
           1       0.00      0.00      0.00      2702

    accuracy                           0.81     13949
   macro avg       0.40      0.50      0.45     13949
weighted avg       0.65      0.81      0.72     13949

[[11247     0]
 [ 2702     0]]
Evaluated with elapsed time 209.14416464802343
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7466666666666667, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.6256983240223464, &#39;ERDE_5&#39;: 0.2567468153772653, &#39;ERDE_50&#39;: 0.12480047142524722, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5988723208511382}
Writing results to CSV file
{&#39;precision&#39;: 0.7758620689655172, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5555555555555556, &#39;ERDE_5&#39;: 0.25337010902849827, &#39;ERDE_50&#39;: 0.14767182151880845, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5295745210201612}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2499197176846848, &#39;ERDE_50&#39;: 0.18137364662080677, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.39329940718824147}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5677966101694916, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.6036036036036035, &#39;ERDE_5&#39;: 0.2752505644375073, &#39;ERDE_50&#39;: 0.11739534240083983, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5800749908602978}
Writing results to CSV file
{&#39;precision&#39;: 0.5961538461538461, &#39;recall&#39;: 0.5961538461538461, &#39;F1&#39;: 0.5961538461538461, &#39;ERDE_5&#39;: 0.2701918449855876, &#39;ERDE_50&#39;: 0.12462042398399394, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5705945241076521}
Writing results to CSV file
{&#39;precision&#39;: 0.5842696629213483, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5388601036269429, &#39;ERDE_5&#39;: 0.26734288750679236, &#39;ERDE_50&#39;: 0.14651978746016084, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5136598462952029}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 209.14416464802343} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluating after getting time 759507.162268467
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluated with elapsed time 996.8538875050144
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.2550149214291205, &#39;ERDE_50&#39;: 0.13487709228586134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5709174412124102}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25279012250625804, &#39;ERDE_50&#39;: 0.13999834402193004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5579907148309992}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.2505004090897361, &#39;ERDE_50&#39;: 0.1677704732196461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.45206828412441546}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 996.8538875050144}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluating after getting time 762058.734405306
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluated with elapsed time 693.9935079449788
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.2550149214291205, &#39;ERDE_50&#39;: 0.13487709228586134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5709174412124102}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25279012250625804, &#39;ERDE_50&#39;: 0.13999834402193004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5579907148309992}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.2505004090897361, &#39;ERDE_50&#39;: 0.1677704732196461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.45206828412441546}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 693.9935079449788}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 12709

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 12709, 12709
Data size: 13949, 13949
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (12709, 8)
Test features shape: (13949, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluating after getting time 764148.34131517
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluated with elapsed time 696.1195261739194
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.2550149214291205, &#39;ERDE_50&#39;: 0.13487709228586134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5709174412124102}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25279012250625804, &#39;ERDE_50&#39;: 0.13999834402193004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5579907148309992}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.2505004090897361, &#39;ERDE_50&#39;: 0.1677704732196461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.45206828412441546}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 696.1195261739194}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 50, 'sample_weights_size': 50, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-50,-'sample_weights_size':-50,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluating after getting time 766056.446844206
              precision    recall  f1-score   support

           0       0.83      0.99      0.90     11247
           1       0.80      0.14      0.24      2702

    accuracy                           0.83     13949
   macro avg       0.82      0.57      0.57     13949
weighted avg       0.82      0.83      0.78     13949

[[11152    95]
 [ 2313   389]]
Evaluated with elapsed time 724.3656398210442
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7611940298507462, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.5964912280701754, &#39;ERDE_5&#39;: 0.2550149214291205, &#39;ERDE_50&#39;: 0.13487709228586134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5709174412124102}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25279012250625804, &#39;ERDE_50&#39;: 0.13999834402193004, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5579907148309992}
Writing results to CSV file
{&#39;precision&#39;: 0.813953488372093, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47619047619047616, &#39;ERDE_5&#39;: 0.2505004090897361, &#39;ERDE_50&#39;: 0.1677704732196461, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.45206828412441546}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 50, &#39;sample_weights_size&#39;: 50, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 724.3656398210442}: Negative values in data passed to MultinomialNB (input X)
*************************************
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>
