<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>final_experiments_20-nonedata</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>




<style type="text/css">
    .highlight .hll { background-color: var(--jp-cell-editor-active-background) }
.highlight  { background: var(--jp-cell-editor-background); color: var(--jp-mirror-editor-variable-color) }
.highlight .c { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment */
.highlight .err { color: var(--jp-mirror-editor-error-color) } /* Error */
.highlight .k { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword */
.highlight .o { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator */
.highlight .p { color: var(--jp-mirror-editor-punctuation-color) } /* Punctuation */
.highlight .ch { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Multiline */
.highlight .cp { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Preproc */
.highlight .cpf { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Single */
.highlight .cs { color: var(--jp-mirror-editor-comment-color); font-style: italic } /* Comment.Special */
.highlight .kc { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Pseudo */
.highlight .kr { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: var(--jp-mirror-editor-keyword-color); font-weight: bold } /* Keyword.Type */
.highlight .m { color: var(--jp-mirror-editor-number-color) } /* Literal.Number */
.highlight .s { color: var(--jp-mirror-editor-string-color) } /* Literal.String */
.highlight .ow { color: var(--jp-mirror-editor-operator-color); font-weight: bold } /* Operator.Word */
.highlight .w { color: var(--jp-mirror-editor-variable-color) } /* Text.Whitespace */
.highlight .mb { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Bin */
.highlight .mf { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Float */
.highlight .mh { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Hex */
.highlight .mi { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer */
.highlight .mo { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Oct */
.highlight .sa { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Affix */
.highlight .sb { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Backtick */
.highlight .sc { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Char */
.highlight .dl { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Delimiter */
.highlight .sd { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Doc */
.highlight .s2 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Double */
.highlight .se { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Escape */
.highlight .sh { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Heredoc */
.highlight .si { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Interpol */
.highlight .sx { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Other */
.highlight .sr { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Regex */
.highlight .s1 { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Single */
.highlight .ss { color: var(--jp-mirror-editor-string-color) } /* Literal.String.Symbol */
.highlight .il { color: var(--jp-mirror-editor-number-color) } /* Literal.Number.Integer.Long */
  </style>



<style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
 * Mozilla scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */
[data-jp-theme-scrollbars='true'] {
  scrollbar-color: rgb(var(--jp-scrollbar-thumb-color))
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar. These selectors
 * will match lower in the tree, and so will override the above */
[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar {
  scrollbar-color: rgba(var(--jp-scrollbar-thumb-color), 0.5) transparent;
}

/*
 * Webkit scrollbar styling
 */

/* use standard opaque scrollbars for most nodes */

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-corner {
  background: var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-thumb {
  background: rgb(var(--jp-scrollbar-thumb-color));
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-right: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

[data-jp-theme-scrollbars='true'] ::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
  border-bottom: var(--jp-scrollbar-endpad) solid
    var(--jp-scrollbar-background-color);
}

/* for code nodes, use a transparent style of scrollbar */

[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar::-webkit-scrollbar,
[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-corner,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-corner {
  background-color: transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-thumb,
[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-thumb {
  background: rgba(var(--jp-scrollbar-thumb-color), 0.5);
  border: var(--jp-scrollbar-thumb-margin) solid transparent;
  background-clip: content-box;
  border-radius: var(--jp-scrollbar-thumb-radius);
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-hscrollbar::-webkit-scrollbar-track:horizontal {
  border-left: var(--jp-scrollbar-endpad) solid transparent;
  border-right: var(--jp-scrollbar-endpad) solid transparent;
}

[data-jp-theme-scrollbars='true']
  .CodeMirror-vscrollbar::-webkit-scrollbar-track:vertical {
  border-top: var(--jp-scrollbar-endpad) solid transparent;
  border-bottom: var(--jp-scrollbar-endpad) solid transparent;
}

/*
 * Phosphor
 */

.lm-ScrollBar[data-orientation='horizontal'] {
  min-height: 16px;
  max-height: 16px;
  min-width: 45px;
  border-top: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] {
  min-width: 16px;
  max-width: 16px;
  min-height: 45px;
  border-left: 1px solid #a0a0a0;
}

.lm-ScrollBar-button {
  background-color: #f0f0f0;
  background-position: center center;
  min-height: 15px;
  max-height: 15px;
  min-width: 15px;
  max-width: 15px;
}

.lm-ScrollBar-button:hover {
  background-color: #dadada;
}

.lm-ScrollBar-button.lm-mod-active {
  background-color: #cdcdcd;
}

.lm-ScrollBar-track {
  background: #f0f0f0;
}

.lm-ScrollBar-thumb {
  background: #cdcdcd;
}

.lm-ScrollBar-thumb:hover {
  background: #bababa;
}

.lm-ScrollBar-thumb.lm-mod-active {
  background: #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb {
  height: 100%;
  min-width: 15px;
  border-left: 1px solid #a0a0a0;
  border-right: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb {
  width: 100%;
  min-height: 15px;
  border-top: 1px solid #a0a0a0;
  border-bottom: 1px solid #a0a0a0;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-left);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='horizontal']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-right);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='decrement'] {
  background-image: var(--jp-icon-caret-up);
  background-size: 17px;
}

.lm-ScrollBar[data-orientation='vertical']
  .lm-ScrollBar-button[data-action='increment'] {
  background-image: var(--jp-icon-caret-down);
  background-size: 17px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Widget, /* </DEPRECATED> */
.lm-Widget {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  cursor: default;
}


/* <DEPRECATED> */ .p-Widget.p-mod-hidden, /* </DEPRECATED> */
.lm-Widget.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-CommandPalette, /* </DEPRECATED> */
.lm-CommandPalette {
  display: flex;
  flex-direction: column;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-CommandPalette-search, /* </DEPRECATED> */
.lm-CommandPalette-search {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-content, /* </DEPRECATED> */
.lm-CommandPalette-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  min-height: 0;
  overflow: auto;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-CommandPalette-header, /* </DEPRECATED> */
.lm-CommandPalette-header {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}


/* <DEPRECATED> */ .p-CommandPalette-item, /* </DEPRECATED> */
.lm-CommandPalette-item {
  display: flex;
  flex-direction: row;
}


/* <DEPRECATED> */ .p-CommandPalette-itemIcon, /* </DEPRECATED> */
.lm-CommandPalette-itemIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemContent, /* </DEPRECATED> */
.lm-CommandPalette-itemContent {
  flex: 1 1 auto;
  overflow: hidden;
}


/* <DEPRECATED> */ .p-CommandPalette-itemShortcut, /* </DEPRECATED> */
.lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-CommandPalette-itemLabel, /* </DEPRECATED> */
.lm-CommandPalette-itemLabel {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-DockPanel, /* </DEPRECATED> */
.lm-DockPanel {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-widget, /* </DEPRECATED> */
.lm-DockPanel-widget {
  z-index: 0;
}


/* <DEPRECATED> */ .p-DockPanel-tabBar, /* </DEPRECATED> */
.lm-DockPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-DockPanel-handle, /* </DEPRECATED> */
.lm-DockPanel-handle {
  z-index: 2;
}


/* <DEPRECATED> */ .p-DockPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-DockPanel-handle:after, /* </DEPRECATED> */
.lm-DockPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal'] {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical'] {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='horizontal']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='horizontal']:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-DockPanel-handle[data-orientation='vertical']:after,
/* </DEPRECATED> */
.lm-DockPanel-handle[data-orientation='vertical']:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}


/* <DEPRECATED> */ .p-DockPanel-overlay, /* </DEPRECATED> */
.lm-DockPanel-overlay {
  z-index: 3;
  box-sizing: border-box;
  pointer-events: none;
}


/* <DEPRECATED> */ .p-DockPanel-overlay.p-mod-hidden, /* </DEPRECATED> */
.lm-DockPanel-overlay.lm-mod-hidden {
  display: none !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-Menu, /* </DEPRECATED> */
.lm-Menu {
  z-index: 10000;
  position: absolute;
  white-space: nowrap;
  overflow-x: hidden;
  overflow-y: auto;
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-Menu-content, /* </DEPRECATED> */
.lm-Menu-content {
  margin: 0;
  padding: 0;
  display: table;
  list-style-type: none;
}


/* <DEPRECATED> */ .p-Menu-item, /* </DEPRECATED> */
.lm-Menu-item {
  display: table-row;
}


/* <DEPRECATED> */
.p-Menu-item.p-mod-hidden,
.p-Menu-item.p-mod-collapsed,
/* </DEPRECATED> */
.lm-Menu-item.lm-mod-hidden,
.lm-Menu-item.lm-mod-collapsed {
  display: none !important;
}


/* <DEPRECATED> */
.p-Menu-itemIcon,
.p-Menu-itemSubmenuIcon,
/* </DEPRECATED> */
.lm-Menu-itemIcon,
.lm-Menu-itemSubmenuIcon {
  display: table-cell;
  text-align: center;
}


/* <DEPRECATED> */ .p-Menu-itemLabel, /* </DEPRECATED> */
.lm-Menu-itemLabel {
  display: table-cell;
  text-align: left;
}


/* <DEPRECATED> */ .p-Menu-itemShortcut, /* </DEPRECATED> */
.lm-Menu-itemShortcut {
  display: table-cell;
  text-align: right;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-MenuBar, /* </DEPRECATED> */
.lm-MenuBar {
  outline: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-MenuBar-content, /* </DEPRECATED> */
.lm-MenuBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex-direction: row;
  list-style-type: none;
}


/* <DEPRECATED> */ .p--MenuBar-item, /* </DEPRECATED> */
.lm-MenuBar-item {
  box-sizing: border-box;
}


/* <DEPRECATED> */
.p-MenuBar-itemIcon,
.p-MenuBar-itemLabel,
/* </DEPRECATED> */
.lm-MenuBar-itemIcon,
.lm-MenuBar-itemLabel {
  display: inline-block;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-ScrollBar, /* </DEPRECATED> */
.lm-ScrollBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='horizontal'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-ScrollBar[data-orientation='vertical'],
/* </DEPRECATED> */
.lm-ScrollBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-ScrollBar-button, /* </DEPRECATED> */
.lm-ScrollBar-button {
  box-sizing: border-box;
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-track, /* </DEPRECATED> */
.lm-ScrollBar-track {
  box-sizing: border-box;
  position: relative;
  overflow: hidden;
  flex: 1 1 auto;
}


/* <DEPRECATED> */ .p-ScrollBar-thumb, /* </DEPRECATED> */
.lm-ScrollBar-thumb {
  box-sizing: border-box;
  position: absolute;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-SplitPanel-child, /* </DEPRECATED> */
.lm-SplitPanel-child {
  z-index: 0;
}


/* <DEPRECATED> */ .p-SplitPanel-handle, /* </DEPRECATED> */
.lm-SplitPanel-handle {
  z-index: 1;
}


/* <DEPRECATED> */ .p-SplitPanel-handle.p-mod-hidden, /* </DEPRECATED> */
.lm-SplitPanel-handle.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-SplitPanel-handle:after, /* </DEPRECATED> */
.lm-SplitPanel-handle:after {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  content: '';
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle {
  cursor: ew-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle {
  cursor: ns-resize;
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='horizontal'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='horizontal'] > .lm-SplitPanel-handle:after {
  left: 50%;
  min-width: 8px;
  transform: translateX(-50%);
}


/* <DEPRECATED> */
.p-SplitPanel[data-orientation='vertical'] > .p-SplitPanel-handle:after,
/* </DEPRECATED> */
.lm-SplitPanel[data-orientation='vertical'] > .lm-SplitPanel-handle:after {
  top: 50%;
  min-height: 8px;
  transform: translateY(-50%);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabBar, /* </DEPRECATED> */
.lm-TabBar {
  display: flex;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='horizontal'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] {
  flex-direction: row;
}


/* <DEPRECATED> */ .p-TabBar[data-orientation='vertical'], /* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-content, /* </DEPRECATED> */
.lm-TabBar-content {
  margin: 0;
  padding: 0;
  display: flex;
  flex: 1 1 auto;
  list-style-type: none;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='horizontal'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='horizontal'] > .lm-TabBar-content {
  flex-direction: row;
}


/* <DEPRECATED> */
.p-TabBar[data-orientation='vertical'] > .p-TabBar-content,
/* </DEPRECATED> */
.lm-TabBar[data-orientation='vertical'] > .lm-TabBar-content {
  flex-direction: column;
}


/* <DEPRECATED> */ .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar-tab {
  display: flex;
  flex-direction: row;
  box-sizing: border-box;
  overflow: hidden;
}


/* <DEPRECATED> */
.p-TabBar-tabIcon,
.p-TabBar-tabCloseIcon,
/* </DEPRECATED> */
.lm-TabBar-tabIcon,
.lm-TabBar-tabCloseIcon {
  flex: 0 0 auto;
}


/* <DEPRECATED> */ .p-TabBar-tabLabel, /* </DEPRECATED> */
.lm-TabBar-tabLabel {
  flex: 1 1 auto;
  overflow: hidden;
  white-space: nowrap;
}


/* <DEPRECATED> */ .p-TabBar-tab.p-mod-hidden, /* </DEPRECATED> */
.lm-TabBar-tab.lm-mod-hidden {
  display: none !important;
}


/* <DEPRECATED> */ .p-TabBar.p-mod-dragging .p-TabBar-tab, /* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab {
  position: relative;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='horizontal'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab {
  left: 0;
  transition: left 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging[data-orientation='vertical'] .p-TabBar-tab,
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab {
  top: 0;
  transition: top 150ms ease;
}


/* <DEPRECATED> */
.p-TabBar.p-mod-dragging .p-TabBar-tab.p-mod-dragging
/* </DEPRECATED> */
.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging {
  transition: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ .p-TabPanel-tabBar, /* </DEPRECATED> */
.lm-TabPanel-tabBar {
  z-index: 1;
}


/* <DEPRECATED> */ .p-TabPanel-stackedPanel, /* </DEPRECATED> */
.lm-TabPanel-stackedPanel {
  z-index: 0;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/

@charset "UTF-8";
/*!

Copyright 2015-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
html{
  -webkit-box-sizing:border-box;
          box-sizing:border-box; }

*,
*::before,
*::after{
  -webkit-box-sizing:inherit;
          box-sizing:inherit; }

body{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400;
  color:#182026;
  font-family:-apple-system, "BlinkMacSystemFont", "Segoe UI", "Roboto", "Oxygen", "Ubuntu", "Cantarell", "Open Sans", "Helvetica Neue", "Icons16", sans-serif; }

p{
  margin-top:0;
  margin-bottom:10px; }

small{
  font-size:12px; }

strong{
  font-weight:600; }

::-moz-selection{
  background:rgba(125, 188, 255, 0.6); }

::selection{
  background:rgba(125, 188, 255, 0.6); }
.bp3-heading{
  color:#182026;
  font-weight:600;
  margin:0 0 10px;
  padding:0; }
  .bp3-dark .bp3-heading{
    color:#f5f8fa; }

h1.bp3-heading, .bp3-running-text h1{
  line-height:40px;
  font-size:36px; }

h2.bp3-heading, .bp3-running-text h2{
  line-height:32px;
  font-size:28px; }

h3.bp3-heading, .bp3-running-text h3{
  line-height:25px;
  font-size:22px; }

h4.bp3-heading, .bp3-running-text h4{
  line-height:21px;
  font-size:18px; }

h5.bp3-heading, .bp3-running-text h5{
  line-height:19px;
  font-size:16px; }

h6.bp3-heading, .bp3-running-text h6{
  line-height:16px;
  font-size:14px; }
.bp3-ui-text{
  text-transform:none;
  line-height:1.28581;
  letter-spacing:0;
  font-size:14px;
  font-weight:400; }

.bp3-monospace-text{
  text-transform:none;
  font-family:monospace; }

.bp3-text-muted{
  color:#5c7080; }
  .bp3-dark .bp3-text-muted{
    color:#a7b6c2; }

.bp3-text-disabled{
  color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-text-disabled{
    color:rgba(167, 182, 194, 0.6); }

.bp3-text-overflow-ellipsis{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal; }
.bp3-running-text{
  line-height:1.5;
  font-size:14px; }
  .bp3-running-text h1{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h1{
      color:#f5f8fa; }
  .bp3-running-text h2{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h2{
      color:#f5f8fa; }
  .bp3-running-text h3{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h3{
      color:#f5f8fa; }
  .bp3-running-text h4{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h4{
      color:#f5f8fa; }
  .bp3-running-text h5{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h5{
      color:#f5f8fa; }
  .bp3-running-text h6{
    color:#182026;
    font-weight:600;
    margin-top:40px;
    margin-bottom:20px; }
    .bp3-dark .bp3-running-text h6{
      color:#f5f8fa; }
  .bp3-running-text hr{
    margin:20px 0;
    border:none;
    border-bottom:1px solid rgba(16, 22, 26, 0.15); }
    .bp3-dark .bp3-running-text hr{
      border-color:rgba(255, 255, 255, 0.15); }
  .bp3-running-text p{
    margin:0 0 10px;
    padding:0; }

.bp3-text-large{
  font-size:16px; }

.bp3-text-small{
  font-size:12px; }
a{
  text-decoration:none;
  color:#106ba3; }
  a:hover{
    cursor:pointer;
    text-decoration:underline;
    color:#106ba3; }
  a .bp3-icon, a .bp3-icon-standard, a .bp3-icon-large{
    color:inherit; }
  a code,
  .bp3-dark a code{
    color:inherit; }
  .bp3-dark a,
  .bp3-dark a:hover{
    color:#48aff0; }
    .bp3-dark a .bp3-icon, .bp3-dark a .bp3-icon-standard, .bp3-dark a .bp3-icon-large,
    .bp3-dark a:hover .bp3-icon,
    .bp3-dark a:hover .bp3-icon-standard,
    .bp3-dark a:hover .bp3-icon-large{
      color:inherit; }
.bp3-running-text code, .bp3-code{
  text-transform:none;
  font-family:monospace;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2);
  background:rgba(255, 255, 255, 0.7);
  padding:2px 5px;
  color:#5c7080;
  font-size:smaller; }
  .bp3-dark .bp3-running-text code, .bp3-running-text .bp3-dark code, .bp3-dark .bp3-code{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#a7b6c2; }
  .bp3-running-text a > code, a > .bp3-code{
    color:#137cbd; }
    .bp3-dark .bp3-running-text a > code, .bp3-running-text .bp3-dark a > code, .bp3-dark a > .bp3-code{
      color:inherit; }

.bp3-running-text pre, .bp3-code-block{
  text-transform:none;
  font-family:monospace;
  display:block;
  margin:10px 0;
  border-radius:3px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
  background:rgba(255, 255, 255, 0.7);
  padding:13px 15px 12px;
  line-height:1.4;
  color:#182026;
  font-size:13px;
  word-break:break-all;
  word-wrap:break-word; }
  .bp3-dark .bp3-running-text pre, .bp3-running-text .bp3-dark pre, .bp3-dark .bp3-code-block{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
  .bp3-running-text pre > code, .bp3-code-block > code{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    padding:0;
    color:inherit;
    font-size:inherit; }

.bp3-running-text kbd, .bp3-key{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  min-width:24px;
  height:24px;
  padding:3px 6px;
  vertical-align:middle;
  line-height:24px;
  color:#5c7080;
  font-family:inherit;
  font-size:12px; }
  .bp3-running-text kbd .bp3-icon, .bp3-key .bp3-icon, .bp3-running-text kbd .bp3-icon-standard, .bp3-key .bp3-icon-standard, .bp3-running-text kbd .bp3-icon-large, .bp3-key .bp3-icon-large{
    margin-right:5px; }
  .bp3-dark .bp3-running-text kbd, .bp3-running-text .bp3-dark kbd, .bp3-dark .bp3-key{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
    background:#394b59;
    color:#a7b6c2; }
.bp3-running-text blockquote, .bp3-blockquote{
  margin:0 0 10px;
  border-left:solid 4px rgba(167, 182, 194, 0.5);
  padding:0 20px; }
  .bp3-dark .bp3-running-text blockquote, .bp3-running-text .bp3-dark blockquote, .bp3-dark .bp3-blockquote{
    border-color:rgba(115, 134, 148, 0.5); }
.bp3-running-text ul,
.bp3-running-text ol, .bp3-list{
  margin:10px 0;
  padding-left:30px; }
  .bp3-running-text ul li:not(:last-child), .bp3-running-text ol li:not(:last-child), .bp3-list li:not(:last-child){
    margin-bottom:5px; }
  .bp3-running-text ul ol, .bp3-running-text ol ol, .bp3-list ol,
  .bp3-running-text ul ul,
  .bp3-running-text ol ul,
  .bp3-list ul{
    margin-top:5px; }

.bp3-list-unstyled{
  margin:0;
  padding:0;
  list-style:none; }
  .bp3-list-unstyled li{
    padding:0; }
.bp3-rtl{
  text-align:right; }

.bp3-dark{
  color:#f5f8fa; }

:focus{
  outline:rgba(19, 124, 189, 0.6) auto 2px;
  outline-offset:2px;
  -moz-outline-radius:6px; }

.bp3-focus-disabled :focus{
  outline:none !important; }
  .bp3-focus-disabled :focus ~ .bp3-control-indicator{
    outline:none !important; }

.bp3-alert{
  max-width:400px;
  padding:20px; }

.bp3-alert-body{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-alert-body .bp3-icon{
    margin-top:0;
    margin-right:20px;
    font-size:40px; }

.bp3-alert-footer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:reverse;
      -ms-flex-direction:row-reverse;
          flex-direction:row-reverse;
  margin-top:10px; }
  .bp3-alert-footer .bp3-button{
    margin-left:10px; }
.bp3-breadcrumbs{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:wrap;
      flex-wrap:wrap;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  margin:0;
  cursor:default;
  height:30px;
  padding:0;
  list-style:none; }
  .bp3-breadcrumbs > li{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }
    .bp3-breadcrumbs > li::after{
      display:block;
      margin:0 5px;
      background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M10.71 7.29l-4-4a1.003 1.003 0 0 0-1.42 1.42L8.59 8 5.3 11.29c-.19.18-.3.43-.3.71a1.003 1.003 0 0 0 1.71.71l4-4c.18-.18.29-.43.29-.71 0-.28-.11-.53-.29-.71z' fill='%235C7080'/%3e%3c/svg%3e");
      width:16px;
      height:16px;
      content:""; }
    .bp3-breadcrumbs > li:last-of-type::after{
      display:none; }

.bp3-breadcrumb,
.bp3-breadcrumb-current,
.bp3-breadcrumbs-collapsed{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  font-size:16px; }

.bp3-breadcrumb,
.bp3-breadcrumbs-collapsed{
  color:#5c7080; }

.bp3-breadcrumb:hover{
  text-decoration:none; }

.bp3-breadcrumb.bp3-disabled{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-breadcrumb .bp3-icon{
  margin-right:5px; }

.bp3-breadcrumb-current{
  color:inherit;
  font-weight:600; }
  .bp3-breadcrumb-current .bp3-input{
    vertical-align:baseline;
    font-size:inherit;
    font-weight:inherit; }

.bp3-breadcrumbs-collapsed{
  margin-right:2px;
  border:none;
  border-radius:3px;
  background:#ced9e0;
  cursor:pointer;
  padding:1px 5px;
  vertical-align:text-bottom; }
  .bp3-breadcrumbs-collapsed::before{
    display:block;
    background:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cg fill='%235C7080'%3e%3ccircle cx='2' cy='8.03' r='2'/%3e%3ccircle cx='14' cy='8.03' r='2'/%3e%3ccircle cx='8' cy='8.03' r='2'/%3e%3c/g%3e%3c/svg%3e") center no-repeat;
    width:16px;
    height:16px;
    content:""; }
  .bp3-breadcrumbs-collapsed:hover{
    background:#bfccd6;
    text-decoration:none;
    color:#182026; }

.bp3-dark .bp3-breadcrumb,
.bp3-dark .bp3-breadcrumbs-collapsed{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumbs > li::after{
  color:#a7b6c2; }

.bp3-dark .bp3-breadcrumb.bp3-disabled{
  color:rgba(167, 182, 194, 0.6); }

.bp3-dark .bp3-breadcrumb-current{
  color:#f5f8fa; }

.bp3-dark .bp3-breadcrumbs-collapsed{
  background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-breadcrumbs-collapsed:hover{
    background:rgba(16, 22, 26, 0.6);
    color:#f5f8fa; }
.bp3-button{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  min-width:30px;
  min-height:30px; }
  .bp3-button > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-button > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-button::before,
  .bp3-button > *{
    margin-right:7px; }
  .bp3-button:empty::before,
  .bp3-button > :last-child{
    margin-right:0; }
  .bp3-button:empty{
    padding:0 !important; }
  .bp3-button:disabled, .bp3-button.bp3-disabled{
    cursor:not-allowed; }
  .bp3-button.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button.bp3-align-right,
  .bp3-align-right .bp3-button{
    text-align:right; }
  .bp3-button.bp3-align-left,
  .bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026; }
    .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-button:not([class*="bp3-intent-"]):active, .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active:hover, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active, .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-button.bp3-intent-primary{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover, .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-primary:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#106ba3; }
    .bp3-button.bp3-intent-primary:active, .bp3-button.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0e5a8a;
      background-image:none; }
    .bp3-button.bp3-intent-primary:disabled, .bp3-button.bp3-intent-primary.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(19, 124, 189, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-success{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#0f9960;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-success:hover, .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-success:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#0d8050; }
    .bp3-button.bp3-intent-success:active, .bp3-button.bp3-intent-success.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#0a6640;
      background-image:none; }
    .bp3-button.bp3-intent-success:disabled, .bp3-button.bp3-intent-success.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(15, 153, 96, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-warning{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#d9822b;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover, .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-warning:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#bf7326; }
    .bp3-button.bp3-intent-warning:active, .bp3-button.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a66321;
      background-image:none; }
    .bp3-button.bp3-intent-warning:disabled, .bp3-button.bp3-intent-warning.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(217, 130, 43, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button.bp3-intent-danger{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#db3737;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover, .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      color:#ffffff; }
    .bp3-button.bp3-intent-danger:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
      background-color:#c23030; }
    .bp3-button.bp3-intent-danger:active, .bp3-button.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#a82a2a;
      background-image:none; }
    .bp3-button.bp3-intent-danger:disabled, .bp3-button.bp3-intent-danger.bp3-disabled{
      border-color:transparent;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(219, 55, 55, 0.5);
      background-image:none;
      color:rgba(255, 255, 255, 0.6); }
  .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
    stroke:#ffffff; }
  .bp3-button.bp3-large,
  .bp3-large .bp3-button{
    min-width:40px;
    min-height:40px;
    padding:5px 15px;
    font-size:16px; }
    .bp3-button.bp3-large::before,
    .bp3-button.bp3-large > *,
    .bp3-large .bp3-button::before,
    .bp3-large .bp3-button > *{
      margin-right:10px; }
    .bp3-button.bp3-large:empty::before,
    .bp3-button.bp3-large > :last-child,
    .bp3-large .bp3-button:empty::before,
    .bp3-large .bp3-button > :last-child{
      margin-right:0; }
  .bp3-button.bp3-small,
  .bp3-small .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-button.bp3-loading{
    position:relative; }
    .bp3-button.bp3-loading[class*="bp3-icon-"]::before{
      visibility:hidden; }
    .bp3-button.bp3-loading .bp3-button-spinner{
      position:absolute;
      margin:0; }
    .bp3-button.bp3-loading > :not(.bp3-button-spinner){
      visibility:hidden; }
  .bp3-button[class*="bp3-icon-"]::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    color:#5c7080; }
  .bp3-button .bp3-icon, .bp3-button .bp3-icon-standard, .bp3-button .bp3-icon-large{
    color:#5c7080; }
    .bp3-button .bp3-icon.bp3-align-right, .bp3-button .bp3-icon-standard.bp3-align-right, .bp3-button .bp3-icon-large.bp3-align-right{
      margin-left:7px; }
  .bp3-button .bp3-icon:first-child:last-child,
  .bp3-button .bp3-spinner + .bp3-icon:last-child{
    margin:0 -7px; }
  .bp3-dark .bp3-button:not([class*="bp3-intent-"]){
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover, .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-button:not([class*="bp3-intent-"]):disabled.bp3-active, .bp3-dark .bp3-button:not([class*="bp3-intent-"]).bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"])[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
    .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-button:not([class*="bp3-intent-"]) .bp3-icon-large{
      color:#a7b6c2; }
  .bp3-dark .bp3-button[class*="bp3-intent-"]{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:active, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2); }
    .bp3-dark .bp3-button[class*="bp3-intent-"]:disabled, .bp3-dark .bp3-button[class*="bp3-intent-"].bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-image:none;
      color:rgba(255, 255, 255, 0.3); }
    .bp3-dark .bp3-button[class*="bp3-intent-"] .bp3-button-spinner .bp3-spinner-head{
      stroke:#8a9ba8; }
  .bp3-button:disabled::before,
  .bp3-button:disabled .bp3-icon, .bp3-button:disabled .bp3-icon-standard, .bp3-button:disabled .bp3-icon-large, .bp3-button.bp3-disabled::before,
  .bp3-button.bp3-disabled .bp3-icon, .bp3-button.bp3-disabled .bp3-icon-standard, .bp3-button.bp3-disabled .bp3-icon-large, .bp3-button[class*="bp3-intent-"]::before,
  .bp3-button[class*="bp3-intent-"] .bp3-icon, .bp3-button[class*="bp3-intent-"] .bp3-icon-standard, .bp3-button[class*="bp3-intent-"] .bp3-icon-large{
    color:inherit !important; }
  .bp3-button.bp3-minimal{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button.bp3-minimal:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button.bp3-minimal:active, .bp3-button.bp3-minimal.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button.bp3-minimal:disabled, .bp3-button.bp3-minimal:disabled:hover, .bp3-button.bp3-minimal.bp3-disabled, .bp3-button.bp3-minimal.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button.bp3-minimal{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button.bp3-minimal:hover, .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button.bp3-minimal:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button.bp3-minimal:active, .bp3-dark .bp3-button.bp3-minimal.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button.bp3-minimal:disabled, .bp3-dark .bp3-button.bp3-minimal:disabled:hover, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button.bp3-minimal:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal:disabled:hover.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover, .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-success{
      color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover, .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover, .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button.bp3-minimal.bp3-intent-danger{
      color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover, .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button.bp3-minimal.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button.bp3-minimal.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }

a.bp3-button{
  text-align:center;
  text-decoration:none;
  -webkit-transition:none;
  transition:none; }
  a.bp3-button, a.bp3-button:hover, a.bp3-button:active{
    color:#182026; }
  a.bp3-button.bp3-disabled{
    color:rgba(92, 112, 128, 0.6); }

.bp3-button-text{
  -webkit-box-flex:0;
      -ms-flex:0 1 auto;
          flex:0 1 auto; }

.bp3-button.bp3-align-left .bp3-button-text, .bp3-button.bp3-align-right .bp3-button-text,
.bp3-button-group.bp3-align-left .bp3-button-text,
.bp3-button-group.bp3-align-right .bp3-button-text{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto; }
.bp3-button-group{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex; }
  .bp3-button-group .bp3-button{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    position:relative;
    z-index:4; }
    .bp3-button-group .bp3-button:focus{
      z-index:5; }
    .bp3-button-group .bp3-button:hover{
      z-index:6; }
    .bp3-button-group .bp3-button:active, .bp3-button-group .bp3-button.bp3-active{
      z-index:7; }
    .bp3-button-group .bp3-button:disabled, .bp3-button-group .bp3-button.bp3-disabled{
      z-index:3; }
    .bp3-button-group .bp3-button[class*="bp3-intent-"]{
      z-index:9; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:focus{
        z-index:10; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:hover{
        z-index:11; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:active, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-active{
        z-index:12; }
      .bp3-button-group .bp3-button[class*="bp3-intent-"]:disabled, .bp3-button-group .bp3-button[class*="bp3-intent-"].bp3-disabled{
        z-index:8; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:first-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:first-child){
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
  .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:-1px;
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-button-group.bp3-minimal .bp3-button{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none; }
    .bp3-button-group.bp3-minimal .bp3-button:hover{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(167, 182, 194, 0.3);
      text-decoration:none;
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(115, 134, 148, 0.3);
      color:#182026; }
    .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
        background:rgba(115, 134, 148, 0.3); }
    .bp3-dark .bp3-button-group.bp3-minimal .bp3-button{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:inherit; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:hover{
        background:rgba(138, 155, 168, 0.15); }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-active{
        background:rgba(138, 155, 168, 0.3);
        color:#f5f8fa; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover{
        background:none;
        cursor:not-allowed;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button:disabled:hover.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-disabled:hover.bp3-active{
          background:rgba(138, 155, 168, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
      color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.15);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#106ba3; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(16, 107, 163, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
        stroke:#106ba3; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary{
        color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:hover{
          background:rgba(19, 124, 189, 0.2);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-active{
          background:rgba(19, 124, 189, 0.3);
          color:#48aff0; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled{
          background:none;
          color:rgba(72, 175, 240, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-primary.bp3-disabled.bp3-active{
            background:rgba(19, 124, 189, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
      color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.15);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#0d8050; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(13, 128, 80, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
        stroke:#0d8050; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success{
        color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:hover{
          background:rgba(15, 153, 96, 0.2);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-active{
          background:rgba(15, 153, 96, 0.3);
          color:#3dcc91; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled{
          background:none;
          color:rgba(61, 204, 145, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-success.bp3-disabled.bp3-active{
            background:rgba(15, 153, 96, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
      color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.15);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#bf7326; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(191, 115, 38, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
        stroke:#bf7326; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning{
        color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:hover{
          background:rgba(217, 130, 43, 0.2);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-active{
          background:rgba(217, 130, 43, 0.3);
          color:#ffb366; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled{
          background:none;
          color:rgba(255, 179, 102, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-warning.bp3-disabled.bp3-active{
            background:rgba(217, 130, 43, 0.3); }
    .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
      color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:none;
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.15);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#c23030; }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(194, 48, 48, 0.5); }
        .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }
      .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
        stroke:#c23030; }
      .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger{
        color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:hover{
          background:rgba(219, 55, 55, 0.2);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-active{
          background:rgba(219, 55, 55, 0.3);
          color:#ff7373; }
        .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled{
          background:none;
          color:rgba(255, 115, 115, 0.5); }
          .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-button-group.bp3-minimal .bp3-button.bp3-intent-danger.bp3-disabled.bp3-active{
            background:rgba(219, 55, 55, 0.3); }
  .bp3-button-group .bp3-popover-wrapper,
  .bp3-button-group .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-button-group .bp3-button.bp3-fill,
  .bp3-button-group.bp3-fill .bp3-button:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-button-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch;
    vertical-align:top; }
    .bp3-button-group.bp3-vertical.bp3-fill{
      width:unset;
      height:100%; }
    .bp3-button-group.bp3-vertical .bp3-button{
      margin-right:0 !important;
      width:100%; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:first-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:first-child{
      border-radius:3px 3px 0 0; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:last-child .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:last-child{
      border-radius:0 0 3px 3px; }
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
    .bp3-button-group.bp3-vertical:not(.bp3-minimal) > .bp3-button:not(:last-child){
      margin-bottom:-1px; }
  .bp3-button-group.bp3-align-left .bp3-button{
    text-align:left; }
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group:not(.bp3-minimal) > .bp3-button:not(:last-child){
    margin-right:1px; }
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-popover-wrapper:not(:last-child) .bp3-button,
  .bp3-dark .bp3-button-group.bp3-vertical > .bp3-button:not(:last-child){
    margin-bottom:1px; }
.bp3-callout{
  line-height:1.5;
  font-size:14px;
  position:relative;
  border-radius:3px;
  background-color:rgba(138, 155, 168, 0.15);
  width:100%;
  padding:10px 12px 9px; }
  .bp3-callout[class*="bp3-icon-"]{
    padding-left:40px; }
    .bp3-callout[class*="bp3-icon-"]::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout.bp3-callout-icon{
    padding-left:40px; }
    .bp3-callout.bp3-callout-icon > .bp3-icon:first-child{
      position:absolute;
      top:10px;
      left:10px;
      color:#5c7080; }
  .bp3-callout .bp3-heading{
    margin-top:0;
    margin-bottom:5px;
    line-height:20px; }
    .bp3-callout .bp3-heading:last-child{
      margin-bottom:0; }
  .bp3-dark .bp3-callout{
    background-color:rgba(138, 155, 168, 0.2); }
    .bp3-dark .bp3-callout[class*="bp3-icon-"]::before{
      color:#a7b6c2; }
  .bp3-callout.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15); }
    .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-primary .bp3-heading{
      color:#106ba3; }
    .bp3-dark .bp3-callout.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-primary[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-primary > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-primary .bp3-heading{
        color:#48aff0; }
  .bp3-callout.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15); }
    .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-success .bp3-heading{
      color:#0d8050; }
    .bp3-dark .bp3-callout.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-success[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-success > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-success .bp3-heading{
        color:#3dcc91; }
  .bp3-callout.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15); }
    .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-warning .bp3-heading{
      color:#bf7326; }
    .bp3-dark .bp3-callout.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-warning[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-warning > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-warning .bp3-heading{
        color:#ffb366; }
  .bp3-callout.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15); }
    .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
    .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
    .bp3-callout.bp3-intent-danger .bp3-heading{
      color:#c23030; }
    .bp3-dark .bp3-callout.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25); }
      .bp3-dark .bp3-callout.bp3-intent-danger[class*="bp3-icon-"]::before,
      .bp3-dark .bp3-callout.bp3-intent-danger > .bp3-icon:first-child,
      .bp3-dark .bp3-callout.bp3-intent-danger .bp3-heading{
        color:#ff7373; }
  .bp3-running-text .bp3-callout{
    margin:20px 0; }
.bp3-card{
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
  background-color:#ffffff;
  padding:20px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-card.bp3-dark,
  .bp3-dark .bp3-card{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
    background-color:#30404d; }

.bp3-elevation-0{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.15), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }
  .bp3-elevation-0.bp3-dark,
  .bp3-dark .bp3-elevation-0{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), 0 0 0 rgba(16, 22, 26, 0), 0 0 0 rgba(16, 22, 26, 0); }

.bp3-elevation-1{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-1.bp3-dark,
  .bp3-dark .bp3-elevation-1{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-elevation-2{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 1px 1px rgba(16, 22, 26, 0.2), 0 2px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-2.bp3-dark,
  .bp3-dark .bp3-elevation-2{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.4), 0 2px 6px rgba(16, 22, 26, 0.4); }

.bp3-elevation-3{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-3.bp3-dark,
  .bp3-dark .bp3-elevation-3{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-elevation-4{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2); }
  .bp3-elevation-4.bp3-dark,
  .bp3-dark .bp3-elevation-4{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:hover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  cursor:pointer; }
  .bp3-card.bp3-interactive:hover.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }

.bp3-card.bp3-interactive:active{
  opacity:0.9;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  -webkit-transition-duration:0;
          transition-duration:0; }
  .bp3-card.bp3-interactive:active.bp3-dark,
  .bp3-dark .bp3-card.bp3-interactive:active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-collapse{
  height:0;
  overflow-y:hidden;
  -webkit-transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:height 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-collapse .bp3-collapse-body{
    -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-collapse .bp3-collapse-body[aria-hidden="true"]{
      display:none; }

.bp3-context-menu .bp3-popover-target{
  display:block; }

.bp3-context-menu-popover-target{
  position:fixed; }

.bp3-divider{
  margin:5px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  border-bottom:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-divider{
    border-color:rgba(16, 22, 26, 0.4); }
.bp3-dialog-container{
  opacity:1;
  -webkit-transform:scale(1);
          transform:scale(1);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  min-height:100%;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-dialog-container.bp3-overlay-enter > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5); }
  .bp3-dialog-container.bp3-overlay-enter-active > .bp3-dialog, .bp3-dialog-container.bp3-overlay-appear-active > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-dialog-container.bp3-overlay-exit > .bp3-dialog{
    opacity:1;
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-dialog-container.bp3-overlay-exit-active > .bp3-dialog{
    opacity:0;
    -webkit-transform:scale(0.5);
            transform:scale(0.5);
    -webkit-transition-property:opacity, -webkit-transform;
    transition-property:opacity, -webkit-transform;
    transition-property:opacity, transform;
    transition-property:opacity, transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }

.bp3-dialog{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:30px 0;
  border-radius:6px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ebf1f5;
  width:500px;
  padding-bottom:20px;
  pointer-events:all;
  -webkit-user-select:text;
     -moz-user-select:text;
      -ms-user-select:text;
          user-select:text; }
  .bp3-dialog:focus{
    outline:0; }
  .bp3-dialog.bp3-dark,
  .bp3-dark .bp3-dialog{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#293742;
    color:#f5f8fa; }

.bp3-dialog-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  border-radius:6px 6px 0 0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  background:#ffffff;
  min-height:40px;
  padding-right:5px;
  padding-left:20px; }
  .bp3-dialog-header .bp3-icon-large,
  .bp3-dialog-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-dialog-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-dialog-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-dialog-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
    background:#30404d; }
    .bp3-dark .bp3-dialog-header .bp3-icon-large,
    .bp3-dark .bp3-dialog-header .bp3-icon{
      color:#a7b6c2; }

.bp3-dialog-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  margin:20px;
  line-height:18px; }

.bp3-dialog-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  margin:0 20px; }

.bp3-dialog-footer-actions{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-pack:end;
      -ms-flex-pack:end;
          justify-content:flex-end; }
  .bp3-dialog-footer-actions .bp3-button{
    margin-left:10px; }
.bp3-drawer{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  padding:0; }
  .bp3-drawer:focus{
    outline:0; }
  .bp3-drawer.bp3-position-top{
    top:0;
    right:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter, .bp3-drawer.bp3-position-top.bp3-overlay-appear{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%); }
    .bp3-drawer.bp3-position-top.bp3-overlay-enter-active, .bp3-drawer.bp3-position-top.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-top.bp3-overlay-exit-active{
      -webkit-transform:translateY(-100%);
              transform:translateY(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-bottom{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-enter-active, .bp3-drawer.bp3-position-bottom.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer.bp3-position-bottom.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-left{
    top:0;
    bottom:0;
    left:0;
    width:50%; }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter, .bp3-drawer.bp3-position-left.bp3-overlay-appear{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%); }
    .bp3-drawer.bp3-position-left.bp3-overlay-enter-active, .bp3-drawer.bp3-position-left.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-left.bp3-overlay-exit-active{
      -webkit-transform:translateX(-100%);
              transform:translateX(-100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-position-right{
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter, .bp3-drawer.bp3-position-right.bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer.bp3-position-right.bp3-overlay-enter-active, .bp3-drawer.bp3-position-right.bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer.bp3-position-right.bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right):not(.bp3-vertical){
    top:0;
    right:0;
    bottom:0;
    width:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear{
      -webkit-transform:translateX(100%);
              transform:translateX(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-appear-active{
      -webkit-transform:translateX(0);
              transform:translateX(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit{
      -webkit-transform:translateX(0);
              transform:translateX(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right):not(.bp3-vertical).bp3-overlay-exit-active{
      -webkit-transform:translateX(100%);
              transform:translateX(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
  .bp3-position-right).bp3-vertical{
    right:0;
    bottom:0;
    left:0;
    height:50%; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear{
      -webkit-transform:translateY(100%);
              transform:translateY(100%); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-enter-active, .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-appear-active{
      -webkit-transform:translateY(0);
              transform:translateY(0);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:200ms;
              transition-duration:200ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit{
      -webkit-transform:translateY(0);
              transform:translateY(0); }
    .bp3-drawer:not(.bp3-position-top):not(.bp3-position-bottom):not(.bp3-position-left):not(
    .bp3-position-right).bp3-vertical.bp3-overlay-exit-active{
      -webkit-transform:translateY(100%);
              transform:translateY(100%);
      -webkit-transition-property:-webkit-transform;
      transition-property:-webkit-transform;
      transition-property:transform;
      transition-property:transform, -webkit-transform;
      -webkit-transition-duration:100ms;
              transition-duration:100ms;
      -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
              transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
      -webkit-transition-delay:0;
              transition-delay:0; }
  .bp3-drawer.bp3-dark,
  .bp3-dark .bp3-drawer{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background:#30404d;
    color:#f5f8fa; }

.bp3-drawer-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border-radius:0;
  -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:0 1px 0 rgba(16, 22, 26, 0.15);
  min-height:40px;
  padding:5px;
  padding-left:20px; }
  .bp3-drawer-header .bp3-icon-large,
  .bp3-drawer-header .bp3-icon{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    margin-right:10px;
    color:#5c7080; }
  .bp3-drawer-header .bp3-heading{
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    margin:0;
    line-height:inherit; }
    .bp3-drawer-header .bp3-heading:last-child{
      margin-right:20px; }
  .bp3-dark .bp3-drawer-header{
    -webkit-box-shadow:0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:0 1px 0 rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-drawer-header .bp3-icon-large,
    .bp3-dark .bp3-drawer-header .bp3-icon{
      color:#a7b6c2; }

.bp3-drawer-body{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  overflow:auto;
  line-height:18px; }

.bp3-drawer-footer{
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
  padding:10px 20px; }
  .bp3-dark .bp3-drawer-footer{
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.4); }
.bp3-editable-text{
  display:inline-block;
  position:relative;
  cursor:text;
  max-width:100%;
  vertical-align:top;
  white-space:nowrap; }
  .bp3-editable-text::before{
    position:absolute;
    top:-3px;
    right:-3px;
    bottom:-3px;
    left:-3px;
    border-radius:3px;
    content:"";
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9), box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
  .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#137cbd; }
  .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(19, 124, 189, 0.4); }
  .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#0f9960; }
  .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px rgba(15, 153, 96, 0.4); }
  .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#d9822b; }
  .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px rgba(217, 130, 43, 0.4); }
  .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-input,
  .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#db3737; }
  .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px rgba(219, 55, 55, 0.4); }
  .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-editable-text:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(255, 255, 255, 0.15); }
  .bp3-dark .bp3-editable-text.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
  .bp3-dark .bp3-editable-text.bp3-disabled::before{
    -webkit-box-shadow:none;
            box-shadow:none; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary .bp3-editable-text-content{
    color:#48aff0; }
  .bp3-dark .bp3-editable-text.bp3-intent-primary:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4);
            box-shadow:0 0 0 0 rgba(72, 175, 240, 0), 0 0 0 0 rgba(72, 175, 240, 0), inset 0 0 0 1px rgba(72, 175, 240, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-primary.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #48aff0, 0 0 0 3px rgba(72, 175, 240, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success .bp3-editable-text-content{
    color:#3dcc91; }
  .bp3-dark .bp3-editable-text.bp3-intent-success:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4);
            box-shadow:0 0 0 0 rgba(61, 204, 145, 0), 0 0 0 0 rgba(61, 204, 145, 0), inset 0 0 0 1px rgba(61, 204, 145, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-success.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #3dcc91, 0 0 0 3px rgba(61, 204, 145, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning .bp3-editable-text-content{
    color:#ffb366; }
  .bp3-dark .bp3-editable-text.bp3-intent-warning:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4);
            box-shadow:0 0 0 0 rgba(255, 179, 102, 0), 0 0 0 0 rgba(255, 179, 102, 0), inset 0 0 0 1px rgba(255, 179, 102, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-warning.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ffb366, 0 0 0 3px rgba(255, 179, 102, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger .bp3-editable-text-content{
    color:#ff7373; }
  .bp3-dark .bp3-editable-text.bp3-intent-danger:hover::before{
    -webkit-box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4);
            box-shadow:0 0 0 0 rgba(255, 115, 115, 0), 0 0 0 0 rgba(255, 115, 115, 0), inset 0 0 0 1px rgba(255, 115, 115, 0.4); }
  .bp3-dark .bp3-editable-text.bp3-intent-danger.bp3-editable-text-editing::before{
    -webkit-box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #ff7373, 0 0 0 3px rgba(255, 115, 115, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-editable-text-input,
.bp3-editable-text-content{
  display:inherit;
  position:relative;
  min-width:inherit;
  max-width:inherit;
  vertical-align:top;
  text-transform:inherit;
  letter-spacing:inherit;
  color:inherit;
  font:inherit;
  resize:none; }

.bp3-editable-text-input{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  width:100%;
  padding:0;
  white-space:pre-wrap; }
  .bp3-editable-text-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-editable-text-input:focus{
    outline:none; }
  .bp3-editable-text-input::-ms-clear{
    display:none; }

.bp3-editable-text-content{
  overflow:hidden;
  padding-right:2px;
  text-overflow:ellipsis;
  white-space:pre; }
  .bp3-editable-text-editing > .bp3-editable-text-content{
    position:absolute;
    left:0;
    visibility:hidden; }
  .bp3-editable-text-placeholder > .bp3-editable-text-content{
    color:rgba(92, 112, 128, 0.6); }
    .bp3-dark .bp3-editable-text-placeholder > .bp3-editable-text-content{
      color:rgba(167, 182, 194, 0.6); }

.bp3-editable-text.bp3-multiline{
  display:block; }
  .bp3-editable-text.bp3-multiline .bp3-editable-text-content{
    overflow:auto;
    white-space:pre-wrap;
    word-wrap:break-word; }
.bp3-control-group{
  -webkit-transform:translateZ(0);
          transform:translateZ(0);
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:stretch;
      -ms-flex-align:stretch;
          align-items:stretch; }
  .bp3-control-group > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select,
  .bp3-control-group .bp3-input,
  .bp3-control-group .bp3-select{
    position:relative; }
  .bp3-control-group .bp3-input{
    z-index:2;
    border-radius:inherit; }
    .bp3-control-group .bp3-input:focus{
      z-index:14;
      border-radius:3px; }
    .bp3-control-group .bp3-input[class*="bp3-intent"]{
      z-index:13; }
      .bp3-control-group .bp3-input[class*="bp3-intent"]:focus{
        z-index:15; }
    .bp3-control-group .bp3-input[readonly], .bp3-control-group .bp3-input:disabled, .bp3-control-group .bp3-input.bp3-disabled{
      z-index:1; }
  .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input{
    z-index:13; }
    .bp3-control-group .bp3-input-group[class*="bp3-intent"] .bp3-input:focus{
      z-index:15; }
  .bp3-control-group .bp3-button,
  .bp3-control-group .bp3-html-select select,
  .bp3-control-group .bp3-select select{
    -webkit-transform:translateZ(0);
            transform:translateZ(0);
    z-index:4;
    border-radius:inherit; }
    .bp3-control-group .bp3-button:focus,
    .bp3-control-group .bp3-html-select select:focus,
    .bp3-control-group .bp3-select select:focus{
      z-index:5; }
    .bp3-control-group .bp3-button:hover,
    .bp3-control-group .bp3-html-select select:hover,
    .bp3-control-group .bp3-select select:hover{
      z-index:6; }
    .bp3-control-group .bp3-button:active,
    .bp3-control-group .bp3-html-select select:active,
    .bp3-control-group .bp3-select select:active{
      z-index:7; }
    .bp3-control-group .bp3-button[readonly], .bp3-control-group .bp3-button:disabled, .bp3-control-group .bp3-button.bp3-disabled,
    .bp3-control-group .bp3-html-select select[readonly],
    .bp3-control-group .bp3-html-select select:disabled,
    .bp3-control-group .bp3-html-select select.bp3-disabled,
    .bp3-control-group .bp3-select select[readonly],
    .bp3-control-group .bp3-select select:disabled,
    .bp3-control-group .bp3-select select.bp3-disabled{
      z-index:3; }
    .bp3-control-group .bp3-button[class*="bp3-intent"],
    .bp3-control-group .bp3-html-select select[class*="bp3-intent"],
    .bp3-control-group .bp3-select select[class*="bp3-intent"]{
      z-index:9; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:focus,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:focus{
        z-index:10; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:hover,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:hover{
        z-index:11; }
      .bp3-control-group .bp3-button[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:active,
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:active{
        z-index:12; }
      .bp3-control-group .bp3-button[class*="bp3-intent"][readonly], .bp3-control-group .bp3-button[class*="bp3-intent"]:disabled, .bp3-control-group .bp3-button[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-html-select select[class*="bp3-intent"].bp3-disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"][readonly],
      .bp3-control-group .bp3-select select[class*="bp3-intent"]:disabled,
      .bp3-control-group .bp3-select select[class*="bp3-intent"].bp3-disabled{
        z-index:8; }
  .bp3-control-group .bp3-input-group > .bp3-icon,
  .bp3-control-group .bp3-input-group > .bp3-button,
  .bp3-control-group .bp3-input-group > .bp3-input-action{
    z-index:16; }
  .bp3-control-group .bp3-select::after,
  .bp3-control-group .bp3-html-select::after,
  .bp3-control-group .bp3-select > .bp3-icon,
  .bp3-control-group .bp3-html-select > .bp3-icon{
    z-index:17; }
  .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:-1px; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > *{
    margin-right:0; }
  .bp3-dark .bp3-control-group:not(.bp3-vertical) > .bp3-button + .bp3-button{
    margin-left:1px; }
  .bp3-control-group .bp3-popover-wrapper,
  .bp3-control-group .bp3-popover-target{
    border-radius:inherit; }
  .bp3-control-group > :first-child{
    border-radius:3px 0 0 3px; }
  .bp3-control-group > :last-child{
    margin-right:0;
    border-radius:0 3px 3px 0; }
  .bp3-control-group > :only-child{
    margin-right:0;
    border-radius:3px; }
  .bp3-control-group .bp3-input-group .bp3-button{
    border-radius:3px; }
  .bp3-control-group > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-fill > *:not(.bp3-fixed){
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto; }
  .bp3-control-group.bp3-vertical{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column; }
    .bp3-control-group.bp3-vertical > *{
      margin-top:-1px; }
    .bp3-control-group.bp3-vertical > :first-child{
      margin-top:0;
      border-radius:3px 3px 0 0; }
    .bp3-control-group.bp3-vertical > :last-child{
      border-radius:0 0 3px 3px; }
.bp3-control{
  display:block;
  position:relative;
  margin-bottom:10px;
  cursor:pointer;
  text-transform:none; }
  .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control:hover input:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control input:not(:disabled):active:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control input:disabled:checked ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control:not(.bp3-align-right){
    padding-left:26px; }
    .bp3-control:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-26px; }
  .bp3-control.bp3-align-right{
    padding-right:26px; }
    .bp3-control.bp3-align-right .bp3-control-indicator{
      margin-right:-26px; }
  .bp3-control.bp3-disabled{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-control.bp3-inline{
    display:inline-block;
    margin-right:20px; }
  .bp3-control input{
    position:absolute;
    top:0;
    left:0;
    opacity:0;
    z-index:-1; }
  .bp3-control .bp3-control-indicator{
    display:inline-block;
    position:relative;
    margin-top:-3px;
    margin-right:10px;
    border:none;
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    cursor:pointer;
    width:1em;
    height:1em;
    vertical-align:middle;
    font-size:16px;
    -webkit-user-select:none;
       -moz-user-select:none;
        -ms-user-select:none;
            user-select:none; }
    .bp3-control .bp3-control-indicator::before{
      display:block;
      width:1em;
      height:1em;
      content:""; }
  .bp3-control:hover .bp3-control-indicator{
    background-color:#ebf1f5; }
  .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#d8e1e8; }
  .bp3-control input:disabled ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed; }
  .bp3-control input:focus ~ .bp3-control-indicator{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:2px;
    -moz-outline-radius:6px; }
  .bp3-control.bp3-align-right .bp3-control-indicator{
    float:right;
    margin-top:1px;
    margin-left:10px; }
  .bp3-control.bp3-large{
    font-size:16px; }
    .bp3-control.bp3-large:not(.bp3-align-right){
      padding-left:30px; }
      .bp3-control.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
        margin-left:-30px; }
    .bp3-control.bp3-large.bp3-align-right{
      padding-right:30px; }
      .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
        margin-right:-30px; }
    .bp3-control.bp3-large .bp3-control-indicator{
      font-size:20px; }
    .bp3-control.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-top:0; }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#137cbd;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.1)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.1), rgba(255, 255, 255, 0));
    color:#ffffff; }
  .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 -1px 0 rgba(16, 22, 26, 0.2);
    background-color:#106ba3; }
  .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background:#0e5a8a; }
  .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(19, 124, 189, 0.5); }
  .bp3-dark .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-checkbox:hover input:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#106ba3; }
  .bp3-dark .bp3-control.bp3-checkbox input:not(:disabled):active:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(14, 90, 138, 0.5); }
  .bp3-control.bp3-checkbox .bp3-control-indicator{
    border-radius:3px; }
  .bp3-control.bp3-checkbox input:checked ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M12 5c-.28 0-.53.11-.71.29L7 9.59l-2.29-2.3a1.003 1.003 0 0 0-1.42 1.42l3 3c.18.18.43.29.71.29s.53-.11.71-.29l5-5A1.003 1.003 0 0 0 12 5z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-checkbox input:indeterminate ~ .bp3-control-indicator::before{
    background-image:url("data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 16 16'%3e%3cpath fill-rule='evenodd' clip-rule='evenodd' d='M11 7H5c-.55 0-1 .45-1 1s.45 1 1 1h6c.55 0 1-.45 1-1s-.45-1-1-1z' fill='white'/%3e%3c/svg%3e"); }
  .bp3-control.bp3-radio .bp3-control-indicator{
    border-radius:50%; }
  .bp3-control.bp3-radio input:checked ~ .bp3-control-indicator::before{
    background-image:radial-gradient(#ffffff, #ffffff 28%, transparent 32%); }
  .bp3-control.bp3-radio input:checked:disabled ~ .bp3-control-indicator::before{
    opacity:0.5; }
  .bp3-control.bp3-radio input:focus ~ .bp3-control-indicator{
    -moz-outline-radius:16px; }
  .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(167, 182, 194, 0.5); }
  .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(115, 134, 148, 0.5); }
  .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(92, 112, 128, 0.5); }
  .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(206, 217, 224, 0.5); }
    .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(19, 124, 189, 0.5); }
    .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(255, 255, 255, 0.8); }
  .bp3-control.bp3-switch:not(.bp3-align-right){
    padding-left:38px; }
    .bp3-control.bp3-switch:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-38px; }
  .bp3-control.bp3-switch.bp3-align-right{
    padding-right:38px; }
    .bp3-control.bp3-switch.bp3-align-right .bp3-control-indicator{
      margin-right:-38px; }
  .bp3-control.bp3-switch .bp3-control-indicator{
    border:none;
    border-radius:1.75em;
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    width:auto;
    min-width:1.75em;
    -webkit-transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:background-color 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
    .bp3-control.bp3-switch .bp3-control-indicator::before{
      position:absolute;
      left:0;
      margin:2px;
      border-radius:50%;
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
      background:#ffffff;
      width:calc(1em - 4px);
      height:calc(1em - 4px);
      -webkit-transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
      transition:left 100ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    left:calc(100% - 1em); }
  .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right){
    padding-left:45px; }
    .bp3-control.bp3-switch.bp3-large:not(.bp3-align-right) .bp3-control-indicator{
      margin-left:-45px; }
  .bp3-control.bp3-switch.bp3-large.bp3-align-right{
    padding-right:45px; }
    .bp3-control.bp3-switch.bp3-large.bp3-align-right .bp3-control-indicator{
      margin-right:-45px; }
  .bp3-dark .bp3-control.bp3-switch input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-control.bp3-switch:hover input ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.7); }
  .bp3-dark .bp3-control.bp3-switch input:not(:disabled):active ~ .bp3-control-indicator{
    background:rgba(16, 22, 26, 0.9); }
  .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator{
    background:rgba(57, 75, 89, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator{
    background:#137cbd; }
  .bp3-dark .bp3-control.bp3-switch:hover input:checked ~ .bp3-control-indicator{
    background:#106ba3; }
  .bp3-dark .bp3-control.bp3-switch input:checked:not(:disabled):active ~ .bp3-control-indicator{
    background:#0e5a8a; }
  .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator{
    background:rgba(14, 90, 138, 0.5); }
    .bp3-dark .bp3-control.bp3-switch input:checked:disabled ~ .bp3-control-indicator::before{
      background:rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-control.bp3-switch .bp3-control-indicator::before{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background:#394b59; }
  .bp3-dark .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator::before{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
  .bp3-control.bp3-switch .bp3-switch-inner-text{
    text-align:center;
    font-size:0.7em; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:first-child{
    visibility:hidden;
    margin-right:1.2em;
    margin-left:0.5em;
    line-height:0; }
  .bp3-control.bp3-switch .bp3-control-indicator-child:last-child{
    visibility:visible;
    margin-right:0.5em;
    margin-left:1.2em;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:first-child{
    visibility:visible;
    line-height:1em; }
  .bp3-control.bp3-switch input:checked ~ .bp3-control-indicator .bp3-control-indicator-child:last-child{
    visibility:hidden;
    line-height:0; }
  .bp3-dark .bp3-control{
    color:#f5f8fa; }
    .bp3-dark .bp3-control.bp3-disabled{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-control .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0)); }
    .bp3-dark .bp3-control:hover .bp3-control-indicator{
      background-color:#30404d; }
    .bp3-dark .bp3-control input:not(:disabled):active ~ .bp3-control-indicator{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background:#202b33; }
    .bp3-dark .bp3-control input:disabled ~ .bp3-control-indicator{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      cursor:not-allowed; }
    .bp3-dark .bp3-control.bp3-checkbox input:disabled:checked ~ .bp3-control-indicator, .bp3-dark .bp3-control.bp3-checkbox input:disabled:indeterminate ~ .bp3-control-indicator{
      color:rgba(167, 182, 194, 0.6); }
.bp3-file-input{
  display:inline-block;
  position:relative;
  cursor:pointer;
  height:30px; }
  .bp3-file-input input{
    opacity:0;
    margin:0;
    min-width:200px; }
    .bp3-file-input input:disabled + .bp3-file-upload-input,
    .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(206, 217, 224, 0.5);
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6);
      resize:none; }
      .bp3-file-input input:disabled + .bp3-file-upload-input::after,
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
        outline:none;
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(206, 217, 224, 0.5);
        background-image:none;
        cursor:not-allowed;
        color:rgba(92, 112, 128, 0.6); }
        .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active:hover,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active,
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active:hover{
          background:rgba(206, 217, 224, 0.7); }
      .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input, .bp3-dark
      .bp3-file-input input.bp3-disabled + .bp3-file-upload-input{
        -webkit-box-shadow:none;
                box-shadow:none;
        background:rgba(57, 75, 89, 0.5);
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after, .bp3-dark
        .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after{
          -webkit-box-shadow:none;
                  box-shadow:none;
          background-color:rgba(57, 75, 89, 0.5);
          background-image:none;
          color:rgba(167, 182, 194, 0.6); }
          .bp3-dark .bp3-file-input input:disabled + .bp3-file-upload-input::after.bp3-active, .bp3-dark
          .bp3-file-input input.bp3-disabled + .bp3-file-upload-input::after.bp3-active{
            background:rgba(57, 75, 89, 0.7); }
  .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#182026; }
  .bp3-dark .bp3-file-input.bp3-file-input-has-selection .bp3-file-upload-input{
    color:#f5f8fa; }
  .bp3-file-input.bp3-fill{
    width:100%; }
  .bp3-file-input.bp3-large,
  .bp3-large .bp3-file-input{
    height:40px; }
  .bp3-file-input .bp3-file-upload-input-custom-text::after{
    content:attr(bp3-button-text); }

.bp3-file-upload-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none;
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  position:absolute;
  top:0;
  right:0;
  left:0;
  padding-right:80px;
  color:rgba(92, 112, 128, 0.6);
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-file-upload-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-file-upload-input:focus, .bp3-file-upload-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-file-upload-input[type="search"], .bp3-file-upload-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-file-upload-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-file-upload-input:disabled, .bp3-file-upload-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-file-upload-input::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-color:#f5f8fa;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
    color:#182026;
    min-width:24px;
    min-height:24px;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    position:absolute;
    top:0;
    right:0;
    margin:3px;
    border-radius:3px;
    width:70px;
    text-align:center;
    line-height:24px;
    content:"Browse"; }
    .bp3-file-upload-input::after:hover{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
      background-clip:padding-box;
      background-color:#ebf1f5; }
    .bp3-file-upload-input::after:active, .bp3-file-upload-input::after.bp3-active{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#d8e1e8;
      background-image:none; }
    .bp3-file-upload-input::after:disabled, .bp3-file-upload-input::after.bp3-disabled{
      outline:none;
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(206, 217, 224, 0.5);
      background-image:none;
      cursor:not-allowed;
      color:rgba(92, 112, 128, 0.6); }
      .bp3-file-upload-input::after:disabled.bp3-active, .bp3-file-upload-input::after:disabled.bp3-active:hover, .bp3-file-upload-input::after.bp3-disabled.bp3-active, .bp3-file-upload-input::after.bp3-disabled.bp3-active:hover{
        background:rgba(206, 217, 224, 0.7); }
  .bp3-file-upload-input:hover::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-file-upload-input:active::after{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-large .bp3-file-upload-input{
    height:40px;
    line-height:40px;
    font-size:16px;
    padding-right:95px; }
    .bp3-large .bp3-file-upload-input[type="search"], .bp3-large .bp3-file-upload-input.bp3-round{
      padding:0 15px; }
    .bp3-large .bp3-file-upload-input::after{
      min-width:30px;
      min-height:30px;
      margin:5px;
      width:85px;
      line-height:30px; }
  .bp3-dark .bp3-file-upload-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-file-upload-input:disabled, .bp3-dark .bp3-file-upload-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-file-upload-input::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#394b59;
      background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
      background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
      color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover, .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        color:#f5f8fa; }
      .bp3-dark .bp3-file-upload-input::after:hover{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
        background-color:#30404d; }
      .bp3-dark .bp3-file-upload-input::after:active, .bp3-dark .bp3-file-upload-input::after.bp3-active{
        -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
                box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
        background-color:#202b33;
        background-image:none; }
      .bp3-dark .bp3-file-upload-input::after:disabled, .bp3-dark .bp3-file-upload-input::after.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(57, 75, 89, 0.5);
        background-image:none;
        color:rgba(167, 182, 194, 0.6); }
        .bp3-dark .bp3-file-upload-input::after:disabled.bp3-active, .bp3-dark .bp3-file-upload-input::after.bp3-disabled.bp3-active{
          background:rgba(57, 75, 89, 0.7); }
      .bp3-dark .bp3-file-upload-input::after .bp3-button-spinner .bp3-spinner-head{
        background:rgba(16, 22, 26, 0.5);
        stroke:#8a9ba8; }
    .bp3-dark .bp3-file-upload-input:hover::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-file-upload-input:active::after{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }

.bp3-file-upload-input::after{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1); }
.bp3-form-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin:0 0 15px; }
  .bp3-form-group label.bp3-label{
    margin-bottom:5px; }
  .bp3-form-group .bp3-control{
    margin-top:7px; }
  .bp3-form-group .bp3-form-helper-text{
    margin-top:5px;
    color:#5c7080;
    font-size:12px; }
  .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#106ba3; }
  .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#0d8050; }
  .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#bf7326; }
  .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#c23030; }
  .bp3-form-group.bp3-inline{
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-form-group.bp3-inline.bp3-large label.bp3-label{
      margin:0 10px 0 0;
      line-height:40px; }
    .bp3-form-group.bp3-inline label.bp3-label{
      margin:0 10px 0 0;
      line-height:30px; }
  .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-dark .bp3-form-group.bp3-intent-primary .bp3-form-helper-text{
    color:#48aff0; }
  .bp3-dark .bp3-form-group.bp3-intent-success .bp3-form-helper-text{
    color:#3dcc91; }
  .bp3-dark .bp3-form-group.bp3-intent-warning .bp3-form-helper-text{
    color:#ffb366; }
  .bp3-dark .bp3-form-group.bp3-intent-danger .bp3-form-helper-text{
    color:#ff7373; }
  .bp3-dark .bp3-form-group .bp3-form-helper-text{
    color:#a7b6c2; }
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-label,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-text-muted,
  .bp3-dark .bp3-form-group.bp3-disabled .bp3-form-helper-text{
    color:rgba(167, 182, 194, 0.6) !important; }
.bp3-input-group{
  display:block;
  position:relative; }
  .bp3-input-group .bp3-input{
    position:relative;
    width:100%; }
    .bp3-input-group .bp3-input:not(:first-child){
      padding-left:30px; }
    .bp3-input-group .bp3-input:not(:last-child){
      padding-right:30px; }
  .bp3-input-group .bp3-input-action,
  .bp3-input-group > .bp3-button,
  .bp3-input-group > .bp3-icon{
    position:absolute;
    top:0; }
    .bp3-input-group .bp3-input-action:first-child,
    .bp3-input-group > .bp3-button:first-child,
    .bp3-input-group > .bp3-icon:first-child{
      left:0; }
    .bp3-input-group .bp3-input-action:last-child,
    .bp3-input-group > .bp3-button:last-child,
    .bp3-input-group > .bp3-icon:last-child{
      right:0; }
  .bp3-input-group .bp3-button{
    min-width:24px;
    min-height:24px;
    margin:3px;
    padding:0 7px; }
    .bp3-input-group .bp3-button:empty{
      padding:0; }
  .bp3-input-group > .bp3-icon{
    z-index:1;
    color:#5c7080; }
    .bp3-input-group > .bp3-icon:empty{
      line-height:1;
      font-family:"Icons16", sans-serif;
      font-size:16px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased; }
  .bp3-input-group > .bp3-icon,
  .bp3-input-group .bp3-input-action > .bp3-spinner{
    margin:7px; }
  .bp3-input-group .bp3-tag{
    margin:5px; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus),
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
    color:#5c7080; }
    .bp3-dark .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus), .bp3-dark
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus){
      color:#a7b6c2; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:not(:hover):not(:focus) .bp3-icon-large{
      color:#5c7080; }
  .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled,
  .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled{
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-standard, .bp3-input-group .bp3-input:not(:focus) + .bp3-button.bp3-minimal:disabled .bp3-icon-large,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-standard,
    .bp3-input-group .bp3-input:not(:focus) + .bp3-input-action .bp3-button.bp3-minimal:disabled .bp3-icon-large{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-input-group.bp3-disabled{
    cursor:not-allowed; }
    .bp3-input-group.bp3-disabled .bp3-icon{
      color:rgba(92, 112, 128, 0.6); }
  .bp3-input-group.bp3-large .bp3-button{
    min-width:30px;
    min-height:30px;
    margin:5px; }
  .bp3-input-group.bp3-large > .bp3-icon,
  .bp3-input-group.bp3-large .bp3-input-action > .bp3-spinner{
    margin:12px; }
  .bp3-input-group.bp3-large .bp3-input{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input-group.bp3-large .bp3-input[type="search"], .bp3-input-group.bp3-large .bp3-input.bp3-round{
      padding:0 15px; }
    .bp3-input-group.bp3-large .bp3-input:not(:first-child){
      padding-left:40px; }
    .bp3-input-group.bp3-large .bp3-input:not(:last-child){
      padding-right:40px; }
  .bp3-input-group.bp3-small .bp3-button{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small .bp3-tag{
    min-width:20px;
    min-height:20px;
    margin:2px; }
  .bp3-input-group.bp3-small > .bp3-icon,
  .bp3-input-group.bp3-small .bp3-input-action > .bp3-spinner{
    margin:4px; }
  .bp3-input-group.bp3-small .bp3-input{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input-group.bp3-small .bp3-input[type="search"], .bp3-input-group.bp3-small .bp3-input.bp3-round{
      padding:0 12px; }
    .bp3-input-group.bp3-small .bp3-input:not(:first-child){
      padding-left:24px; }
    .bp3-input-group.bp3-small .bp3-input:not(:last-child){
      padding-right:24px; }
  .bp3-input-group.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-input-group.bp3-round .bp3-button,
  .bp3-input-group.bp3-round .bp3-input,
  .bp3-input-group.bp3-round .bp3-tag{
    border-radius:30px; }
  .bp3-dark .bp3-input-group .bp3-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-input-group.bp3-disabled .bp3-icon{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-input-group.bp3-intent-primary .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-primary .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input-group.bp3-intent-primary .bp3-input:disabled, .bp3-input-group.bp3-intent-primary .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-primary > .bp3-icon{
    color:#106ba3; }
    .bp3-dark .bp3-input-group.bp3-intent-primary > .bp3-icon{
      color:#48aff0; }
  .bp3-input-group.bp3-intent-success .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-success .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input-group.bp3-intent-success .bp3-input:disabled, .bp3-input-group.bp3-intent-success .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-success > .bp3-icon{
    color:#0d8050; }
    .bp3-dark .bp3-input-group.bp3-intent-success > .bp3-icon{
      color:#3dcc91; }
  .bp3-input-group.bp3-intent-warning .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-warning .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input-group.bp3-intent-warning .bp3-input:disabled, .bp3-input-group.bp3-intent-warning .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-warning > .bp3-icon{
    color:#bf7326; }
    .bp3-dark .bp3-input-group.bp3-intent-warning > .bp3-icon{
      color:#ffb366; }
  .bp3-input-group.bp3-intent-danger .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input-group.bp3-intent-danger .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input-group.bp3-intent-danger .bp3-input:disabled, .bp3-input-group.bp3-intent-danger .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-input-group.bp3-intent-danger > .bp3-icon{
    color:#c23030; }
    .bp3-dark .bp3-input-group.bp3-intent-danger > .bp3-icon{
      color:#ff7373; }
.bp3-input{
  outline:none;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
  background:#ffffff;
  height:30px;
  padding:0 10px;
  vertical-align:middle;
  line-height:30px;
  color:#182026;
  font-size:14px;
  font-weight:400;
  -webkit-transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-box-shadow 100ms cubic-bezier(0.4, 1, 0.75, 0.9);
  -webkit-appearance:none;
     -moz-appearance:none;
          appearance:none; }
  .bp3-input::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input:focus, .bp3-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-input[type="search"], .bp3-input.bp3-round{
    border-radius:30px;
    -webkit-box-sizing:border-box;
            box-sizing:border-box;
    padding-left:10px; }
  .bp3-input[readonly]{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.15); }
  .bp3-input:disabled, .bp3-input.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(206, 217, 224, 0.5);
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6);
    resize:none; }
  .bp3-input.bp3-large{
    height:40px;
    line-height:40px;
    font-size:16px; }
    .bp3-input.bp3-large[type="search"], .bp3-input.bp3-large.bp3-round{
      padding:0 15px; }
  .bp3-input.bp3-small{
    height:24px;
    padding-right:8px;
    padding-left:8px;
    line-height:24px;
    font-size:12px; }
    .bp3-input.bp3-small[type="search"], .bp3-input.bp3-small.bp3-round{
      padding:0 12px; }
  .bp3-input.bp3-fill{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:100%; }
  .bp3-dark .bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark .bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-input:disabled, .bp3-dark .bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
  .bp3-input.bp3-intent-primary{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-primary[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #137cbd;
              box-shadow:inset 0 0 0 1px #137cbd; }
    .bp3-input.bp3-intent-primary:disabled, .bp3-input.bp3-intent-primary.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px #137cbd, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary:focus{
        -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-primary[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #137cbd;
                box-shadow:inset 0 0 0 1px #137cbd; }
      .bp3-dark .bp3-input.bp3-intent-primary:disabled, .bp3-dark .bp3-input.bp3-intent-primary.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-success{
    -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success:focus{
      -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-success[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #0f9960;
              box-shadow:inset 0 0 0 1px #0f9960; }
    .bp3-input.bp3-intent-success:disabled, .bp3-input.bp3-intent-success.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-success{
      -webkit-box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), 0 0 0 0 rgba(15, 153, 96, 0), inset 0 0 0 1px #0f9960, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success:focus{
        -webkit-box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #0f9960, 0 0 0 1px #0f9960, 0 0 0 3px rgba(15, 153, 96, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-success[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #0f9960;
                box-shadow:inset 0 0 0 1px #0f9960; }
      .bp3-dark .bp3-input.bp3-intent-success:disabled, .bp3-dark .bp3-input.bp3-intent-success.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-warning{
    -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning:focus{
      -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-warning[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #d9822b;
              box-shadow:inset 0 0 0 1px #d9822b; }
    .bp3-input.bp3-intent-warning:disabled, .bp3-input.bp3-intent-warning.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), 0 0 0 0 rgba(217, 130, 43, 0), inset 0 0 0 1px #d9822b, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning:focus{
        -webkit-box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #d9822b, 0 0 0 1px #d9822b, 0 0 0 3px rgba(217, 130, 43, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-warning[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #d9822b;
                box-shadow:inset 0 0 0 1px #d9822b; }
      .bp3-dark .bp3-input.bp3-intent-warning:disabled, .bp3-dark .bp3-input.bp3-intent-warning.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input.bp3-intent-danger{
    -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.15), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger:focus{
      -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-input.bp3-intent-danger[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px #db3737;
              box-shadow:inset 0 0 0 1px #db3737; }
    .bp3-input.bp3-intent-danger:disabled, .bp3-input.bp3-intent-danger.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none; }
    .bp3-dark .bp3-input.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), 0 0 0 0 rgba(219, 55, 55, 0), inset 0 0 0 1px #db3737, inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger:focus{
        -webkit-box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
                box-shadow:0 0 0 1px #db3737, 0 0 0 1px #db3737, 0 0 0 3px rgba(219, 55, 55, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
      .bp3-dark .bp3-input.bp3-intent-danger[readonly]{
        -webkit-box-shadow:inset 0 0 0 1px #db3737;
                box-shadow:inset 0 0 0 1px #db3737; }
      .bp3-dark .bp3-input.bp3-intent-danger:disabled, .bp3-dark .bp3-input.bp3-intent-danger.bp3-disabled{
        -webkit-box-shadow:none;
                box-shadow:none; }
  .bp3-input::-ms-clear{
    display:none; }
textarea.bp3-input{
  max-width:100%;
  padding:10px; }
  textarea.bp3-input, textarea.bp3-input.bp3-large, textarea.bp3-input.bp3-small{
    height:auto;
    line-height:inherit; }
  textarea.bp3-input.bp3-small{
    padding:8px; }
  .bp3-dark textarea.bp3-input{
    -webkit-box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), 0 0 0 0 rgba(19, 124, 189, 0), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background:rgba(16, 22, 26, 0.3);
    color:#f5f8fa; }
    .bp3-dark textarea.bp3-input::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input::placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark textarea.bp3-input:focus{
      -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input[readonly]{
      -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark textarea.bp3-input:disabled, .bp3-dark textarea.bp3-input.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:rgba(57, 75, 89, 0.5);
      color:rgba(167, 182, 194, 0.6); }
label.bp3-label{
  display:block;
  margin-top:0;
  margin-bottom:15px; }
  label.bp3-label .bp3-html-select,
  label.bp3-label .bp3-input,
  label.bp3-label .bp3-select,
  label.bp3-label .bp3-slider,
  label.bp3-label .bp3-popover-wrapper{
    display:block;
    margin-top:5px;
    text-transform:none; }
  label.bp3-label .bp3-button-group{
    margin-top:5px; }
  label.bp3-label .bp3-select select,
  label.bp3-label .bp3-html-select select{
    width:100%;
    vertical-align:top;
    font-weight:400; }
  label.bp3-label.bp3-disabled,
  label.bp3-label.bp3-disabled .bp3-text-muted{
    color:rgba(92, 112, 128, 0.6); }
  label.bp3-label.bp3-inline{
    line-height:30px; }
    label.bp3-label.bp3-inline .bp3-html-select,
    label.bp3-label.bp3-inline .bp3-input,
    label.bp3-label.bp3-inline .bp3-input-group,
    label.bp3-label.bp3-inline .bp3-select,
    label.bp3-label.bp3-inline .bp3-popover-wrapper{
      display:inline-block;
      margin:0 0 0 5px;
      vertical-align:top; }
    label.bp3-label.bp3-inline .bp3-button-group{
      margin:0 0 0 5px; }
    label.bp3-label.bp3-inline .bp3-input-group .bp3-input{
      margin-left:0; }
    label.bp3-label.bp3-inline.bp3-large{
      line-height:40px; }
  label.bp3-label:not(.bp3-inline) .bp3-popover-target{
    display:block; }
  .bp3-dark label.bp3-label{
    color:#f5f8fa; }
    .bp3-dark label.bp3-label.bp3-disabled,
    .bp3-dark label.bp3-label.bp3-disabled .bp3-text-muted{
      color:rgba(167, 182, 194, 0.6); }
.bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button{
  -webkit-box-flex:1;
      -ms-flex:1 1 14px;
          flex:1 1 14px;
  width:30px;
  min-height:0;
  padding:0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:first-child{
    border-radius:0 3px 0 0; }
  .bp3-numeric-input .bp3-button-group.bp3-vertical > .bp3-button:last-child{
    border-radius:0 0 3px 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:first-child{
  border-radius:3px 0 0 0; }

.bp3-numeric-input .bp3-button-group.bp3-vertical:first-child > .bp3-button:last-child{
  border-radius:0 0 0 3px; }

.bp3-numeric-input.bp3-large .bp3-button-group.bp3-vertical > .bp3-button{
  width:40px; }

form{
  display:block; }
.bp3-html-select select,
.bp3-select select{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  border:none;
  border-radius:3px;
  cursor:pointer;
  padding:5px 10px;
  vertical-align:middle;
  text-align:left;
  font-size:14px;
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  border-radius:3px;
  width:100%;
  height:30px;
  padding:0 25px 0 10px;
  -moz-appearance:none;
  -webkit-appearance:none; }
  .bp3-html-select select > *, .bp3-select select > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-html-select select > .bp3-fill, .bp3-select select > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-html-select select::before,
  .bp3-select select::before, .bp3-html-select select > *, .bp3-select select > *{
    margin-right:7px; }
  .bp3-html-select select:empty::before,
  .bp3-select select:empty::before,
  .bp3-html-select select > :last-child,
  .bp3-select select > :last-child{
    margin-right:0; }
  .bp3-html-select select:hover,
  .bp3-select select:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-html-select select:active,
  .bp3-select select:active, .bp3-html-select select.bp3-active,
  .bp3-select select.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-html-select select:disabled,
  .bp3-select select:disabled, .bp3-html-select select.bp3-disabled,
  .bp3-select select.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select select:disabled.bp3-active,
    .bp3-select select:disabled.bp3-active, .bp3-html-select select:disabled.bp3-active:hover,
    .bp3-select select:disabled.bp3-active:hover, .bp3-html-select select.bp3-disabled.bp3-active,
    .bp3-select select.bp3-disabled.bp3-active, .bp3-html-select select.bp3-disabled.bp3-active:hover,
    .bp3-select select.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }

.bp3-html-select.bp3-minimal select,
.bp3-select.bp3-minimal select{
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none; }
  .bp3-html-select.bp3-minimal select:hover,
  .bp3-select.bp3-minimal select:hover{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(167, 182, 194, 0.3);
    text-decoration:none;
    color:#182026; }
  .bp3-html-select.bp3-minimal select:active,
  .bp3-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal select.bp3-active,
  .bp3-select.bp3-minimal select.bp3-active{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:rgba(115, 134, 148, 0.3);
    color:#182026; }
  .bp3-html-select.bp3-minimal select:disabled,
  .bp3-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal select:disabled:hover,
  .bp3-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal select.bp3-disabled,
  .bp3-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal select.bp3-disabled:hover,
  .bp3-select.bp3-minimal select.bp3-disabled:hover{
    background:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-html-select.bp3-minimal select:disabled.bp3-active,
    .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active,
    .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active{
      background:rgba(115, 134, 148, 0.3); }
  .bp3-dark .bp3-html-select.bp3-minimal select, .bp3-html-select.bp3-minimal .bp3-dark select,
  .bp3-dark .bp3-select.bp3-minimal select, .bp3-select.bp3-minimal .bp3-dark select{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:none;
    color:inherit; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover, .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none; }
    .bp3-dark .bp3-html-select.bp3-minimal select:hover, .bp3-html-select.bp3-minimal .bp3-dark select:hover,
    .bp3-dark .bp3-select.bp3-minimal select:hover, .bp3-select.bp3-minimal .bp3-dark select:hover{
      background:rgba(138, 155, 168, 0.15); }
    .bp3-dark .bp3-html-select.bp3-minimal select:active, .bp3-html-select.bp3-minimal .bp3-dark select:active,
    .bp3-dark .bp3-select.bp3-minimal select:active, .bp3-select.bp3-minimal .bp3-dark select:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-active,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-active{
      background:rgba(138, 155, 168, 0.3);
      color:#f5f8fa; }
    .bp3-dark .bp3-html-select.bp3-minimal select:disabled, .bp3-html-select.bp3-minimal .bp3-dark select:disabled,
    .bp3-dark .bp3-select.bp3-minimal select:disabled, .bp3-select.bp3-minimal .bp3-dark select:disabled, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select:disabled:hover, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover{
      background:none;
      cursor:not-allowed;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-html-select.bp3-minimal select:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select:disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select:disabled:hover.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-disabled:hover.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-disabled:hover.bp3-active{
        background:rgba(138, 155, 168, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-primary,
  .bp3-select.bp3-minimal select.bp3-intent-primary{
    color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover,
    .bp3-select.bp3-minimal select.bp3-intent-primary:hover{
      background:rgba(19, 124, 189, 0.15);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:active,
    .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active{
      background:rgba(19, 124, 189, 0.3);
      color:#106ba3; }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled{
      background:none;
      color:rgba(16, 107, 163, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active{
        background:rgba(19, 124, 189, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-primary .bp3-button-spinner .bp3-spinner-head{
      stroke:#106ba3; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary{
      color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:hover{
        background:rgba(19, 124, 189, 0.2);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-active{
        background:rgba(19, 124, 189, 0.3);
        color:#48aff0; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled{
        background:none;
        color:rgba(72, 175, 240, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-primary.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-primary.bp3-disabled.bp3-active{
          background:rgba(19, 124, 189, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-success,
  .bp3-select.bp3-minimal select.bp3-intent-success{
    color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:hover,
    .bp3-select.bp3-minimal select.bp3-intent-success:hover{
      background:rgba(15, 153, 96, 0.15);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:active,
    .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active{
      background:rgba(15, 153, 96, 0.3);
      color:#0d8050; }
    .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled{
      background:none;
      color:rgba(13, 128, 80, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active{
        background:rgba(15, 153, 96, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-success .bp3-button-spinner .bp3-spinner-head{
      stroke:#0d8050; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success{
      color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:hover{
        background:rgba(15, 153, 96, 0.2);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-active{
        background:rgba(15, 153, 96, 0.3);
        color:#3dcc91; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled{
        background:none;
        color:rgba(61, 204, 145, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-success.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-success.bp3-disabled.bp3-active{
          background:rgba(15, 153, 96, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-warning,
  .bp3-select.bp3-minimal select.bp3-intent-warning{
    color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover,
    .bp3-select.bp3-minimal select.bp3-intent-warning:hover{
      background:rgba(217, 130, 43, 0.15);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:active,
    .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active{
      background:rgba(217, 130, 43, 0.3);
      color:#bf7326; }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled{
      background:none;
      color:rgba(191, 115, 38, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active{
        background:rgba(217, 130, 43, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-warning .bp3-button-spinner .bp3-spinner-head{
      stroke:#bf7326; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning{
      color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:hover{
        background:rgba(217, 130, 43, 0.2);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-active{
        background:rgba(217, 130, 43, 0.3);
        color:#ffb366; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled{
        background:none;
        color:rgba(255, 179, 102, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-warning.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-warning.bp3-disabled.bp3-active{
          background:rgba(217, 130, 43, 0.3); }
  .bp3-html-select.bp3-minimal select.bp3-intent-danger,
  .bp3-select.bp3-minimal select.bp3-intent-danger{
    color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      -webkit-box-shadow:none;
              box-shadow:none;
      background:none;
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover,
    .bp3-select.bp3-minimal select.bp3-intent-danger:hover{
      background:rgba(219, 55, 55, 0.15);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:active,
    .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active{
      background:rgba(219, 55, 55, 0.3);
      color:#c23030; }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled,
    .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled{
      background:none;
      color:rgba(194, 48, 48, 0.5); }
      .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active,
      .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active{
        background:rgba(219, 55, 55, 0.3); }
    .bp3-html-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head, .bp3-select.bp3-minimal select.bp3-intent-danger .bp3-button-spinner .bp3-spinner-head{
      stroke:#c23030; }
    .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger,
    .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger{
      color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:hover, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:hover{
        background:rgba(219, 55, 55, 0.2);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-active{
        background:rgba(219, 55, 55, 0.3);
        color:#ff7373; }
      .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled,
      .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled{
        background:none;
        color:rgba(255, 115, 115, 0.5); }
        .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger:disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger:disabled.bp3-active, .bp3-dark .bp3-html-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-html-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active,
        .bp3-dark .bp3-select.bp3-minimal select.bp3-intent-danger.bp3-disabled.bp3-active, .bp3-select.bp3-minimal .bp3-dark select.bp3-intent-danger.bp3-disabled.bp3-active{
          background:rgba(219, 55, 55, 0.3); }

.bp3-html-select.bp3-large select,
.bp3-select.bp3-large select{
  height:40px;
  padding-right:35px;
  font-size:16px; }

.bp3-dark .bp3-html-select select, .bp3-dark .bp3-select select{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
  background-color:#394b59;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
  color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover, .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select select:hover, .bp3-dark .bp3-select select:hover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }
  .bp3-dark .bp3-html-select select:active, .bp3-dark .bp3-select select:active, .bp3-dark .bp3-html-select select.bp3-active, .bp3-dark .bp3-select select.bp3-active{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#202b33;
    background-image:none; }
  .bp3-dark .bp3-html-select select:disabled, .bp3-dark .bp3-select select:disabled, .bp3-dark .bp3-html-select select.bp3-disabled, .bp3-dark .bp3-select select.bp3-disabled{
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(57, 75, 89, 0.5);
    background-image:none;
    color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-html-select select:disabled.bp3-active, .bp3-dark .bp3-select select:disabled.bp3-active, .bp3-dark .bp3-html-select select.bp3-disabled.bp3-active, .bp3-dark .bp3-select select.bp3-disabled.bp3-active{
      background:rgba(57, 75, 89, 0.7); }
  .bp3-dark .bp3-html-select select .bp3-button-spinner .bp3-spinner-head, .bp3-dark .bp3-select select .bp3-button-spinner .bp3-spinner-head{
    background:rgba(16, 22, 26, 0.5);
    stroke:#8a9ba8; }

.bp3-html-select select:disabled,
.bp3-select select:disabled{
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:rgba(206, 217, 224, 0.5);
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-html-select .bp3-icon,
.bp3-select .bp3-icon, .bp3-select::after{
  position:absolute;
  top:7px;
  right:7px;
  color:#5c7080;
  pointer-events:none; }
  .bp3-html-select .bp3-disabled.bp3-icon,
  .bp3-select .bp3-disabled.bp3-icon, .bp3-disabled.bp3-select::after{
    color:rgba(92, 112, 128, 0.6); }
.bp3-html-select,
.bp3-select{
  display:inline-block;
  position:relative;
  vertical-align:middle;
  letter-spacing:normal; }
  .bp3-html-select select::-ms-expand,
  .bp3-select select::-ms-expand{
    display:none; }
  .bp3-html-select .bp3-icon,
  .bp3-select .bp3-icon{
    color:#5c7080; }
    .bp3-html-select .bp3-icon:hover,
    .bp3-select .bp3-icon:hover{
      color:#182026; }
    .bp3-dark .bp3-html-select .bp3-icon, .bp3-dark
    .bp3-select .bp3-icon{
      color:#a7b6c2; }
      .bp3-dark .bp3-html-select .bp3-icon:hover, .bp3-dark
      .bp3-select .bp3-icon:hover{
        color:#f5f8fa; }
  .bp3-html-select.bp3-large::after,
  .bp3-html-select.bp3-large .bp3-icon,
  .bp3-select.bp3-large::after,
  .bp3-select.bp3-large .bp3-icon{
    top:12px;
    right:12px; }
  .bp3-html-select.bp3-fill,
  .bp3-html-select.bp3-fill select,
  .bp3-select.bp3-fill,
  .bp3-select.bp3-fill select{
    width:100%; }
  .bp3-dark .bp3-html-select option, .bp3-dark
  .bp3-select option{
    background-color:#30404d;
    color:#f5f8fa; }
  .bp3-dark .bp3-html-select::after, .bp3-dark
  .bp3-select::after{
    color:#a7b6c2; }

.bp3-select::after{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  content:""; }
.bp3-running-text table, table.bp3-html-table{
  border-spacing:0;
  font-size:14px; }
  .bp3-running-text table th, table.bp3-html-table th,
  .bp3-running-text table td,
  table.bp3-html-table td{
    padding:11px;
    vertical-align:top;
    text-align:left; }
  .bp3-running-text table th, table.bp3-html-table th{
    color:#182026;
    font-weight:600; }
  
  .bp3-running-text table td,
  table.bp3-html-table td{
    color:#182026; }
  .bp3-running-text table tbody tr:first-child th, table.bp3-html-table tbody tr:first-child th,
  .bp3-running-text table tbody tr:first-child td,
  table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-running-text table th, .bp3-running-text .bp3-dark table th, .bp3-dark table.bp3-html-table th{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table td, .bp3-running-text .bp3-dark table td, .bp3-dark table.bp3-html-table td{
    color:#f5f8fa; }
  .bp3-dark .bp3-running-text table tbody tr:first-child th, .bp3-running-text .bp3-dark table tbody tr:first-child th, .bp3-dark table.bp3-html-table tbody tr:first-child th,
  .bp3-dark .bp3-running-text table tbody tr:first-child td,
  .bp3-running-text .bp3-dark table tbody tr:first-child td,
  .bp3-dark table.bp3-html-table tbody tr:first-child td{
    -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }

table.bp3-html-table.bp3-html-table-condensed th,
table.bp3-html-table.bp3-html-table-condensed td, table.bp3-html-table.bp3-small th,
table.bp3-html-table.bp3-small td{
  padding-top:6px;
  padding-bottom:6px; }

table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(191, 204, 214, 0.15); }

table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(16, 22, 26, 0.15); }
  table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:none;
          box-shadow:none; }
  table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:not(:first-child){
    -webkit-box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 1px 0 0 0 rgba(16, 22, 26, 0.15); }

table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(191, 204, 214, 0.3);
  cursor:pointer; }

table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(191, 204, 214, 0.4); }

.bp3-dark table.bp3-html-table.bp3-html-table-striped tbody tr:nth-child(odd) td{
  background:rgba(92, 112, 128, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered th:not(:first-child){
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td{
  -webkit-box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 0 1px 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered tbody tr td:not(:first-child){
    -webkit-box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15);
            box-shadow:inset 1px 1px 0 0 rgba(255, 255, 255, 0.15); }

.bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td{
  -webkit-box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15);
          box-shadow:inset 1px 0 0 0 rgba(255, 255, 255, 0.15); }
  .bp3-dark table.bp3-html-table.bp3-html-table-bordered.bp3-html-table-striped tbody tr:not(:first-child) td:first-child{
    -webkit-box-shadow:none;
            box-shadow:none; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:hover td{
  background-color:rgba(92, 112, 128, 0.3);
  cursor:pointer; }

.bp3-dark table.bp3-html-table.bp3-interactive tbody tr:active td{
  background-color:rgba(92, 112, 128, 0.4); }

.bp3-key-combo{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center; }
  .bp3-key-combo > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-key-combo > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-key-combo::before,
  .bp3-key-combo > *{
    margin-right:5px; }
  .bp3-key-combo:empty::before,
  .bp3-key-combo > :last-child{
    margin-right:0; }

.bp3-hotkey-dialog{
  top:40px;
  padding-bottom:0; }
  .bp3-hotkey-dialog .bp3-dialog-body{
    margin:0;
    padding:0; }
  .bp3-hotkey-dialog .bp3-hotkey-label{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1; }

.bp3-hotkey-column{
  margin:auto;
  max-height:80vh;
  overflow-y:auto;
  padding:30px; }
  .bp3-hotkey-column .bp3-heading{
    margin-bottom:20px; }
    .bp3-hotkey-column .bp3-heading:not(:first-child){
      margin-top:40px; }

.bp3-hotkey{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:justify;
      -ms-flex-pack:justify;
          justify-content:space-between;
  margin-right:0;
  margin-left:0; }
  .bp3-hotkey:not(:last-child){
    margin-bottom:10px; }
.bp3-icon{
  display:inline-block;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  vertical-align:text-bottom; }
  .bp3-icon:not(:empty)::before{
    content:"" !important;
    content:unset !important; }
  .bp3-icon > svg{
    display:block; }
    .bp3-icon > svg:not([fill]){
      fill:currentColor; }

.bp3-icon.bp3-intent-primary, .bp3-icon-standard.bp3-intent-primary, .bp3-icon-large.bp3-intent-primary{
  color:#106ba3; }
  .bp3-dark .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-icon-large.bp3-intent-primary{
    color:#48aff0; }

.bp3-icon.bp3-intent-success, .bp3-icon-standard.bp3-intent-success, .bp3-icon-large.bp3-intent-success{
  color:#0d8050; }
  .bp3-dark .bp3-icon.bp3-intent-success, .bp3-dark .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-icon-large.bp3-intent-success{
    color:#3dcc91; }

.bp3-icon.bp3-intent-warning, .bp3-icon-standard.bp3-intent-warning, .bp3-icon-large.bp3-intent-warning{
  color:#bf7326; }
  .bp3-dark .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-icon-large.bp3-intent-warning{
    color:#ffb366; }

.bp3-icon.bp3-intent-danger, .bp3-icon-standard.bp3-intent-danger, .bp3-icon-large.bp3-intent-danger{
  color:#c23030; }
  .bp3-dark .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-icon-large.bp3-intent-danger{
    color:#ff7373; }

span.bp3-icon-standard{
  line-height:1;
  font-family:"Icons16", sans-serif;
  font-size:16px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon-large{
  line-height:1;
  font-family:"Icons20", sans-serif;
  font-size:20px;
  font-weight:400;
  font-style:normal;
  -moz-osx-font-smoothing:grayscale;
  -webkit-font-smoothing:antialiased;
  display:inline-block; }

span.bp3-icon:empty{
  line-height:1;
  font-family:"Icons20";
  font-size:inherit;
  font-weight:400;
  font-style:normal; }
  span.bp3-icon:empty::before{
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased; }

.bp3-icon-add::before{
  content:""; }

.bp3-icon-add-column-left::before{
  content:""; }

.bp3-icon-add-column-right::before{
  content:""; }

.bp3-icon-add-row-bottom::before{
  content:""; }

.bp3-icon-add-row-top::before{
  content:""; }

.bp3-icon-add-to-artifact::before{
  content:""; }

.bp3-icon-add-to-folder::before{
  content:""; }

.bp3-icon-airplane::before{
  content:""; }

.bp3-icon-align-center::before{
  content:""; }

.bp3-icon-align-justify::before{
  content:""; }

.bp3-icon-align-left::before{
  content:""; }

.bp3-icon-align-right::before{
  content:""; }

.bp3-icon-alignment-bottom::before{
  content:""; }

.bp3-icon-alignment-horizontal-center::before{
  content:""; }

.bp3-icon-alignment-left::before{
  content:""; }

.bp3-icon-alignment-right::before{
  content:""; }

.bp3-icon-alignment-top::before{
  content:""; }

.bp3-icon-alignment-vertical-center::before{
  content:""; }

.bp3-icon-annotation::before{
  content:""; }

.bp3-icon-application::before{
  content:""; }

.bp3-icon-applications::before{
  content:""; }

.bp3-icon-archive::before{
  content:""; }

.bp3-icon-arrow-bottom-left::before{
  content:"↙"; }

.bp3-icon-arrow-bottom-right::before{
  content:"↘"; }

.bp3-icon-arrow-down::before{
  content:"↓"; }

.bp3-icon-arrow-left::before{
  content:"←"; }

.bp3-icon-arrow-right::before{
  content:"→"; }

.bp3-icon-arrow-top-left::before{
  content:"↖"; }

.bp3-icon-arrow-top-right::before{
  content:"↗"; }

.bp3-icon-arrow-up::before{
  content:"↑"; }

.bp3-icon-arrows-horizontal::before{
  content:"↔"; }

.bp3-icon-arrows-vertical::before{
  content:"↕"; }

.bp3-icon-asterisk::before{
  content:"*"; }

.bp3-icon-automatic-updates::before{
  content:""; }

.bp3-icon-badge::before{
  content:""; }

.bp3-icon-ban-circle::before{
  content:""; }

.bp3-icon-bank-account::before{
  content:""; }

.bp3-icon-barcode::before{
  content:""; }

.bp3-icon-blank::before{
  content:""; }

.bp3-icon-blocked-person::before{
  content:""; }

.bp3-icon-bold::before{
  content:""; }

.bp3-icon-book::before{
  content:""; }

.bp3-icon-bookmark::before{
  content:""; }

.bp3-icon-box::before{
  content:""; }

.bp3-icon-briefcase::before{
  content:""; }

.bp3-icon-bring-data::before{
  content:""; }

.bp3-icon-build::before{
  content:""; }

.bp3-icon-calculator::before{
  content:""; }

.bp3-icon-calendar::before{
  content:""; }

.bp3-icon-camera::before{
  content:""; }

.bp3-icon-caret-down::before{
  content:"⌄"; }

.bp3-icon-caret-left::before{
  content:"〈"; }

.bp3-icon-caret-right::before{
  content:"〉"; }

.bp3-icon-caret-up::before{
  content:"⌃"; }

.bp3-icon-cell-tower::before{
  content:""; }

.bp3-icon-changes::before{
  content:""; }

.bp3-icon-chart::before{
  content:""; }

.bp3-icon-chat::before{
  content:""; }

.bp3-icon-chevron-backward::before{
  content:""; }

.bp3-icon-chevron-down::before{
  content:""; }

.bp3-icon-chevron-forward::before{
  content:""; }

.bp3-icon-chevron-left::before{
  content:""; }

.bp3-icon-chevron-right::before{
  content:""; }

.bp3-icon-chevron-up::before{
  content:""; }

.bp3-icon-circle::before{
  content:""; }

.bp3-icon-circle-arrow-down::before{
  content:""; }

.bp3-icon-circle-arrow-left::before{
  content:""; }

.bp3-icon-circle-arrow-right::before{
  content:""; }

.bp3-icon-circle-arrow-up::before{
  content:""; }

.bp3-icon-citation::before{
  content:""; }

.bp3-icon-clean::before{
  content:""; }

.bp3-icon-clipboard::before{
  content:""; }

.bp3-icon-cloud::before{
  content:"☁"; }

.bp3-icon-cloud-download::before{
  content:""; }

.bp3-icon-cloud-upload::before{
  content:""; }

.bp3-icon-code::before{
  content:""; }

.bp3-icon-code-block::before{
  content:""; }

.bp3-icon-cog::before{
  content:""; }

.bp3-icon-collapse-all::before{
  content:""; }

.bp3-icon-column-layout::before{
  content:""; }

.bp3-icon-comment::before{
  content:""; }

.bp3-icon-comparison::before{
  content:""; }

.bp3-icon-compass::before{
  content:""; }

.bp3-icon-compressed::before{
  content:""; }

.bp3-icon-confirm::before{
  content:""; }

.bp3-icon-console::before{
  content:""; }

.bp3-icon-contrast::before{
  content:""; }

.bp3-icon-control::before{
  content:""; }

.bp3-icon-credit-card::before{
  content:""; }

.bp3-icon-cross::before{
  content:"✗"; }

.bp3-icon-crown::before{
  content:""; }

.bp3-icon-cube::before{
  content:""; }

.bp3-icon-cube-add::before{
  content:""; }

.bp3-icon-cube-remove::before{
  content:""; }

.bp3-icon-curved-range-chart::before{
  content:""; }

.bp3-icon-cut::before{
  content:""; }

.bp3-icon-dashboard::before{
  content:""; }

.bp3-icon-data-lineage::before{
  content:""; }

.bp3-icon-database::before{
  content:""; }

.bp3-icon-delete::before{
  content:""; }

.bp3-icon-delta::before{
  content:"Δ"; }

.bp3-icon-derive-column::before{
  content:""; }

.bp3-icon-desktop::before{
  content:""; }

.bp3-icon-diagram-tree::before{
  content:""; }

.bp3-icon-direction-left::before{
  content:""; }

.bp3-icon-direction-right::before{
  content:""; }

.bp3-icon-disable::before{
  content:""; }

.bp3-icon-document::before{
  content:""; }

.bp3-icon-document-open::before{
  content:""; }

.bp3-icon-document-share::before{
  content:""; }

.bp3-icon-dollar::before{
  content:"$"; }

.bp3-icon-dot::before{
  content:"•"; }

.bp3-icon-double-caret-horizontal::before{
  content:""; }

.bp3-icon-double-caret-vertical::before{
  content:""; }

.bp3-icon-double-chevron-down::before{
  content:""; }

.bp3-icon-double-chevron-left::before{
  content:""; }

.bp3-icon-double-chevron-right::before{
  content:""; }

.bp3-icon-double-chevron-up::before{
  content:""; }

.bp3-icon-doughnut-chart::before{
  content:""; }

.bp3-icon-download::before{
  content:""; }

.bp3-icon-drag-handle-horizontal::before{
  content:""; }

.bp3-icon-drag-handle-vertical::before{
  content:""; }

.bp3-icon-draw::before{
  content:""; }

.bp3-icon-drive-time::before{
  content:""; }

.bp3-icon-duplicate::before{
  content:""; }

.bp3-icon-edit::before{
  content:"✎"; }

.bp3-icon-eject::before{
  content:"⏏"; }

.bp3-icon-endorsed::before{
  content:""; }

.bp3-icon-envelope::before{
  content:"✉"; }

.bp3-icon-equals::before{
  content:""; }

.bp3-icon-eraser::before{
  content:""; }

.bp3-icon-error::before{
  content:""; }

.bp3-icon-euro::before{
  content:"€"; }

.bp3-icon-exchange::before{
  content:""; }

.bp3-icon-exclude-row::before{
  content:""; }

.bp3-icon-expand-all::before{
  content:""; }

.bp3-icon-export::before{
  content:""; }

.bp3-icon-eye-off::before{
  content:""; }

.bp3-icon-eye-on::before{
  content:""; }

.bp3-icon-eye-open::before{
  content:""; }

.bp3-icon-fast-backward::before{
  content:""; }

.bp3-icon-fast-forward::before{
  content:""; }

.bp3-icon-feed::before{
  content:""; }

.bp3-icon-feed-subscribed::before{
  content:""; }

.bp3-icon-film::before{
  content:""; }

.bp3-icon-filter::before{
  content:""; }

.bp3-icon-filter-keep::before{
  content:""; }

.bp3-icon-filter-list::before{
  content:""; }

.bp3-icon-filter-open::before{
  content:""; }

.bp3-icon-filter-remove::before{
  content:""; }

.bp3-icon-flag::before{
  content:"⚑"; }

.bp3-icon-flame::before{
  content:""; }

.bp3-icon-flash::before{
  content:""; }

.bp3-icon-floppy-disk::before{
  content:""; }

.bp3-icon-flow-branch::before{
  content:""; }

.bp3-icon-flow-end::before{
  content:""; }

.bp3-icon-flow-linear::before{
  content:""; }

.bp3-icon-flow-review::before{
  content:""; }

.bp3-icon-flow-review-branch::before{
  content:""; }

.bp3-icon-flows::before{
  content:""; }

.bp3-icon-folder-close::before{
  content:""; }

.bp3-icon-folder-new::before{
  content:""; }

.bp3-icon-folder-open::before{
  content:""; }

.bp3-icon-folder-shared::before{
  content:""; }

.bp3-icon-folder-shared-open::before{
  content:""; }

.bp3-icon-follower::before{
  content:""; }

.bp3-icon-following::before{
  content:""; }

.bp3-icon-font::before{
  content:""; }

.bp3-icon-fork::before{
  content:""; }

.bp3-icon-form::before{
  content:""; }

.bp3-icon-full-circle::before{
  content:""; }

.bp3-icon-full-stacked-chart::before{
  content:""; }

.bp3-icon-fullscreen::before{
  content:""; }

.bp3-icon-function::before{
  content:""; }

.bp3-icon-gantt-chart::before{
  content:""; }

.bp3-icon-geolocation::before{
  content:""; }

.bp3-icon-geosearch::before{
  content:""; }

.bp3-icon-git-branch::before{
  content:""; }

.bp3-icon-git-commit::before{
  content:""; }

.bp3-icon-git-merge::before{
  content:""; }

.bp3-icon-git-new-branch::before{
  content:""; }

.bp3-icon-git-pull::before{
  content:""; }

.bp3-icon-git-push::before{
  content:""; }

.bp3-icon-git-repo::before{
  content:""; }

.bp3-icon-glass::before{
  content:""; }

.bp3-icon-globe::before{
  content:""; }

.bp3-icon-globe-network::before{
  content:""; }

.bp3-icon-graph::before{
  content:""; }

.bp3-icon-graph-remove::before{
  content:""; }

.bp3-icon-greater-than::before{
  content:""; }

.bp3-icon-greater-than-or-equal-to::before{
  content:""; }

.bp3-icon-grid::before{
  content:""; }

.bp3-icon-grid-view::before{
  content:""; }

.bp3-icon-group-objects::before{
  content:""; }

.bp3-icon-grouped-bar-chart::before{
  content:""; }

.bp3-icon-hand::before{
  content:""; }

.bp3-icon-hand-down::before{
  content:""; }

.bp3-icon-hand-left::before{
  content:""; }

.bp3-icon-hand-right::before{
  content:""; }

.bp3-icon-hand-up::before{
  content:""; }

.bp3-icon-header::before{
  content:""; }

.bp3-icon-header-one::before{
  content:""; }

.bp3-icon-header-two::before{
  content:""; }

.bp3-icon-headset::before{
  content:""; }

.bp3-icon-heart::before{
  content:"♥"; }

.bp3-icon-heart-broken::before{
  content:""; }

.bp3-icon-heat-grid::before{
  content:""; }

.bp3-icon-heatmap::before{
  content:""; }

.bp3-icon-help::before{
  content:"?"; }

.bp3-icon-helper-management::before{
  content:""; }

.bp3-icon-highlight::before{
  content:""; }

.bp3-icon-history::before{
  content:""; }

.bp3-icon-home::before{
  content:"⌂"; }

.bp3-icon-horizontal-bar-chart::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-asc::before{
  content:""; }

.bp3-icon-horizontal-bar-chart-desc::before{
  content:""; }

.bp3-icon-horizontal-distribution::before{
  content:""; }

.bp3-icon-id-number::before{
  content:""; }

.bp3-icon-image-rotate-left::before{
  content:""; }

.bp3-icon-image-rotate-right::before{
  content:""; }

.bp3-icon-import::before{
  content:""; }

.bp3-icon-inbox::before{
  content:""; }

.bp3-icon-inbox-filtered::before{
  content:""; }

.bp3-icon-inbox-geo::before{
  content:""; }

.bp3-icon-inbox-search::before{
  content:""; }

.bp3-icon-inbox-update::before{
  content:""; }

.bp3-icon-info-sign::before{
  content:"ℹ"; }

.bp3-icon-inheritance::before{
  content:""; }

.bp3-icon-inner-join::before{
  content:""; }

.bp3-icon-insert::before{
  content:""; }

.bp3-icon-intersection::before{
  content:""; }

.bp3-icon-ip-address::before{
  content:""; }

.bp3-icon-issue::before{
  content:""; }

.bp3-icon-issue-closed::before{
  content:""; }

.bp3-icon-issue-new::before{
  content:""; }

.bp3-icon-italic::before{
  content:""; }

.bp3-icon-join-table::before{
  content:""; }

.bp3-icon-key::before{
  content:""; }

.bp3-icon-key-backspace::before{
  content:""; }

.bp3-icon-key-command::before{
  content:""; }

.bp3-icon-key-control::before{
  content:""; }

.bp3-icon-key-delete::before{
  content:""; }

.bp3-icon-key-enter::before{
  content:""; }

.bp3-icon-key-escape::before{
  content:""; }

.bp3-icon-key-option::before{
  content:""; }

.bp3-icon-key-shift::before{
  content:""; }

.bp3-icon-key-tab::before{
  content:""; }

.bp3-icon-known-vehicle::before{
  content:""; }

.bp3-icon-label::before{
  content:""; }

.bp3-icon-layer::before{
  content:""; }

.bp3-icon-layers::before{
  content:""; }

.bp3-icon-layout::before{
  content:""; }

.bp3-icon-layout-auto::before{
  content:""; }

.bp3-icon-layout-balloon::before{
  content:""; }

.bp3-icon-layout-circle::before{
  content:""; }

.bp3-icon-layout-grid::before{
  content:""; }

.bp3-icon-layout-group-by::before{
  content:""; }

.bp3-icon-layout-hierarchy::before{
  content:""; }

.bp3-icon-layout-linear::before{
  content:""; }

.bp3-icon-layout-skew-grid::before{
  content:""; }

.bp3-icon-layout-sorted-clusters::before{
  content:""; }

.bp3-icon-learning::before{
  content:""; }

.bp3-icon-left-join::before{
  content:""; }

.bp3-icon-less-than::before{
  content:""; }

.bp3-icon-less-than-or-equal-to::before{
  content:""; }

.bp3-icon-lifesaver::before{
  content:""; }

.bp3-icon-lightbulb::before{
  content:""; }

.bp3-icon-link::before{
  content:""; }

.bp3-icon-list::before{
  content:"☰"; }

.bp3-icon-list-columns::before{
  content:""; }

.bp3-icon-list-detail-view::before{
  content:""; }

.bp3-icon-locate::before{
  content:""; }

.bp3-icon-lock::before{
  content:""; }

.bp3-icon-log-in::before{
  content:""; }

.bp3-icon-log-out::before{
  content:""; }

.bp3-icon-manual::before{
  content:""; }

.bp3-icon-manually-entered-data::before{
  content:""; }

.bp3-icon-map::before{
  content:""; }

.bp3-icon-map-create::before{
  content:""; }

.bp3-icon-map-marker::before{
  content:""; }

.bp3-icon-maximize::before{
  content:""; }

.bp3-icon-media::before{
  content:""; }

.bp3-icon-menu::before{
  content:""; }

.bp3-icon-menu-closed::before{
  content:""; }

.bp3-icon-menu-open::before{
  content:""; }

.bp3-icon-merge-columns::before{
  content:""; }

.bp3-icon-merge-links::before{
  content:""; }

.bp3-icon-minimize::before{
  content:""; }

.bp3-icon-minus::before{
  content:"−"; }

.bp3-icon-mobile-phone::before{
  content:""; }

.bp3-icon-mobile-video::before{
  content:""; }

.bp3-icon-moon::before{
  content:""; }

.bp3-icon-more::before{
  content:""; }

.bp3-icon-mountain::before{
  content:""; }

.bp3-icon-move::before{
  content:""; }

.bp3-icon-mugshot::before{
  content:""; }

.bp3-icon-multi-select::before{
  content:""; }

.bp3-icon-music::before{
  content:""; }

.bp3-icon-new-drawing::before{
  content:""; }

.bp3-icon-new-grid-item::before{
  content:""; }

.bp3-icon-new-layer::before{
  content:""; }

.bp3-icon-new-layers::before{
  content:""; }

.bp3-icon-new-link::before{
  content:""; }

.bp3-icon-new-object::before{
  content:""; }

.bp3-icon-new-person::before{
  content:""; }

.bp3-icon-new-prescription::before{
  content:""; }

.bp3-icon-new-text-box::before{
  content:""; }

.bp3-icon-ninja::before{
  content:""; }

.bp3-icon-not-equal-to::before{
  content:""; }

.bp3-icon-notifications::before{
  content:""; }

.bp3-icon-notifications-updated::before{
  content:""; }

.bp3-icon-numbered-list::before{
  content:""; }

.bp3-icon-numerical::before{
  content:""; }

.bp3-icon-office::before{
  content:""; }

.bp3-icon-offline::before{
  content:""; }

.bp3-icon-oil-field::before{
  content:""; }

.bp3-icon-one-column::before{
  content:""; }

.bp3-icon-outdated::before{
  content:""; }

.bp3-icon-page-layout::before{
  content:""; }

.bp3-icon-panel-stats::before{
  content:""; }

.bp3-icon-panel-table::before{
  content:""; }

.bp3-icon-paperclip::before{
  content:""; }

.bp3-icon-paragraph::before{
  content:""; }

.bp3-icon-path::before{
  content:""; }

.bp3-icon-path-search::before{
  content:""; }

.bp3-icon-pause::before{
  content:""; }

.bp3-icon-people::before{
  content:""; }

.bp3-icon-percentage::before{
  content:""; }

.bp3-icon-person::before{
  content:""; }

.bp3-icon-phone::before{
  content:"☎"; }

.bp3-icon-pie-chart::before{
  content:""; }

.bp3-icon-pin::before{
  content:""; }

.bp3-icon-pivot::before{
  content:""; }

.bp3-icon-pivot-table::before{
  content:""; }

.bp3-icon-play::before{
  content:""; }

.bp3-icon-plus::before{
  content:"+"; }

.bp3-icon-polygon-filter::before{
  content:""; }

.bp3-icon-power::before{
  content:""; }

.bp3-icon-predictive-analysis::before{
  content:""; }

.bp3-icon-prescription::before{
  content:""; }

.bp3-icon-presentation::before{
  content:""; }

.bp3-icon-print::before{
  content:"⎙"; }

.bp3-icon-projects::before{
  content:""; }

.bp3-icon-properties::before{
  content:""; }

.bp3-icon-property::before{
  content:""; }

.bp3-icon-publish-function::before{
  content:""; }

.bp3-icon-pulse::before{
  content:""; }

.bp3-icon-random::before{
  content:""; }

.bp3-icon-record::before{
  content:""; }

.bp3-icon-redo::before{
  content:""; }

.bp3-icon-refresh::before{
  content:""; }

.bp3-icon-regression-chart::before{
  content:""; }

.bp3-icon-remove::before{
  content:""; }

.bp3-icon-remove-column::before{
  content:""; }

.bp3-icon-remove-column-left::before{
  content:""; }

.bp3-icon-remove-column-right::before{
  content:""; }

.bp3-icon-remove-row-bottom::before{
  content:""; }

.bp3-icon-remove-row-top::before{
  content:""; }

.bp3-icon-repeat::before{
  content:""; }

.bp3-icon-reset::before{
  content:""; }

.bp3-icon-resolve::before{
  content:""; }

.bp3-icon-rig::before{
  content:""; }

.bp3-icon-right-join::before{
  content:""; }

.bp3-icon-ring::before{
  content:""; }

.bp3-icon-rotate-document::before{
  content:""; }

.bp3-icon-rotate-page::before{
  content:""; }

.bp3-icon-satellite::before{
  content:""; }

.bp3-icon-saved::before{
  content:""; }

.bp3-icon-scatter-plot::before{
  content:""; }

.bp3-icon-search::before{
  content:""; }

.bp3-icon-search-around::before{
  content:""; }

.bp3-icon-search-template::before{
  content:""; }

.bp3-icon-search-text::before{
  content:""; }

.bp3-icon-segmented-control::before{
  content:""; }

.bp3-icon-select::before{
  content:""; }

.bp3-icon-selection::before{
  content:"⦿"; }

.bp3-icon-send-to::before{
  content:""; }

.bp3-icon-send-to-graph::before{
  content:""; }

.bp3-icon-send-to-map::before{
  content:""; }

.bp3-icon-series-add::before{
  content:""; }

.bp3-icon-series-configuration::before{
  content:""; }

.bp3-icon-series-derived::before{
  content:""; }

.bp3-icon-series-filtered::before{
  content:""; }

.bp3-icon-series-search::before{
  content:""; }

.bp3-icon-settings::before{
  content:""; }

.bp3-icon-share::before{
  content:""; }

.bp3-icon-shield::before{
  content:""; }

.bp3-icon-shop::before{
  content:""; }

.bp3-icon-shopping-cart::before{
  content:""; }

.bp3-icon-signal-search::before{
  content:""; }

.bp3-icon-sim-card::before{
  content:""; }

.bp3-icon-slash::before{
  content:""; }

.bp3-icon-small-cross::before{
  content:""; }

.bp3-icon-small-minus::before{
  content:""; }

.bp3-icon-small-plus::before{
  content:""; }

.bp3-icon-small-tick::before{
  content:""; }

.bp3-icon-snowflake::before{
  content:""; }

.bp3-icon-social-media::before{
  content:""; }

.bp3-icon-sort::before{
  content:""; }

.bp3-icon-sort-alphabetical::before{
  content:""; }

.bp3-icon-sort-alphabetical-desc::before{
  content:""; }

.bp3-icon-sort-asc::before{
  content:""; }

.bp3-icon-sort-desc::before{
  content:""; }

.bp3-icon-sort-numerical::before{
  content:""; }

.bp3-icon-sort-numerical-desc::before{
  content:""; }

.bp3-icon-split-columns::before{
  content:""; }

.bp3-icon-square::before{
  content:""; }

.bp3-icon-stacked-chart::before{
  content:""; }

.bp3-icon-star::before{
  content:"★"; }

.bp3-icon-star-empty::before{
  content:"☆"; }

.bp3-icon-step-backward::before{
  content:""; }

.bp3-icon-step-chart::before{
  content:""; }

.bp3-icon-step-forward::before{
  content:""; }

.bp3-icon-stop::before{
  content:""; }

.bp3-icon-stopwatch::before{
  content:""; }

.bp3-icon-strikethrough::before{
  content:""; }

.bp3-icon-style::before{
  content:""; }

.bp3-icon-swap-horizontal::before{
  content:""; }

.bp3-icon-swap-vertical::before{
  content:""; }

.bp3-icon-symbol-circle::before{
  content:""; }

.bp3-icon-symbol-cross::before{
  content:""; }

.bp3-icon-symbol-diamond::before{
  content:""; }

.bp3-icon-symbol-square::before{
  content:""; }

.bp3-icon-symbol-triangle-down::before{
  content:""; }

.bp3-icon-symbol-triangle-up::before{
  content:""; }

.bp3-icon-tag::before{
  content:""; }

.bp3-icon-take-action::before{
  content:""; }

.bp3-icon-taxi::before{
  content:""; }

.bp3-icon-text-highlight::before{
  content:""; }

.bp3-icon-th::before{
  content:""; }

.bp3-icon-th-derived::before{
  content:""; }

.bp3-icon-th-disconnect::before{
  content:""; }

.bp3-icon-th-filtered::before{
  content:""; }

.bp3-icon-th-list::before{
  content:""; }

.bp3-icon-thumbs-down::before{
  content:""; }

.bp3-icon-thumbs-up::before{
  content:""; }

.bp3-icon-tick::before{
  content:"✓"; }

.bp3-icon-tick-circle::before{
  content:""; }

.bp3-icon-time::before{
  content:"⏲"; }

.bp3-icon-timeline-area-chart::before{
  content:""; }

.bp3-icon-timeline-bar-chart::before{
  content:""; }

.bp3-icon-timeline-events::before{
  content:""; }

.bp3-icon-timeline-line-chart::before{
  content:""; }

.bp3-icon-tint::before{
  content:""; }

.bp3-icon-torch::before{
  content:""; }

.bp3-icon-tractor::before{
  content:""; }

.bp3-icon-train::before{
  content:""; }

.bp3-icon-translate::before{
  content:""; }

.bp3-icon-trash::before{
  content:""; }

.bp3-icon-tree::before{
  content:""; }

.bp3-icon-trending-down::before{
  content:""; }

.bp3-icon-trending-up::before{
  content:""; }

.bp3-icon-truck::before{
  content:""; }

.bp3-icon-two-columns::before{
  content:""; }

.bp3-icon-unarchive::before{
  content:""; }

.bp3-icon-underline::before{
  content:"⎁"; }

.bp3-icon-undo::before{
  content:"⎌"; }

.bp3-icon-ungroup-objects::before{
  content:""; }

.bp3-icon-unknown-vehicle::before{
  content:""; }

.bp3-icon-unlock::before{
  content:""; }

.bp3-icon-unpin::before{
  content:""; }

.bp3-icon-unresolve::before{
  content:""; }

.bp3-icon-updated::before{
  content:""; }

.bp3-icon-upload::before{
  content:""; }

.bp3-icon-user::before{
  content:""; }

.bp3-icon-variable::before{
  content:""; }

.bp3-icon-vertical-bar-chart-asc::before{
  content:""; }

.bp3-icon-vertical-bar-chart-desc::before{
  content:""; }

.bp3-icon-vertical-distribution::before{
  content:""; }

.bp3-icon-video::before{
  content:""; }

.bp3-icon-volume-down::before{
  content:""; }

.bp3-icon-volume-off::before{
  content:""; }

.bp3-icon-volume-up::before{
  content:""; }

.bp3-icon-walk::before{
  content:""; }

.bp3-icon-warning-sign::before{
  content:""; }

.bp3-icon-waterfall-chart::before{
  content:""; }

.bp3-icon-widget::before{
  content:""; }

.bp3-icon-widget-button::before{
  content:""; }

.bp3-icon-widget-footer::before{
  content:""; }

.bp3-icon-widget-header::before{
  content:""; }

.bp3-icon-wrench::before{
  content:""; }

.bp3-icon-zoom-in::before{
  content:""; }

.bp3-icon-zoom-out::before{
  content:""; }

.bp3-icon-zoom-to-fit::before{
  content:""; }
.bp3-submenu > .bp3-popover-wrapper{
  display:block; }

.bp3-submenu .bp3-popover-target{
  display:block; }

.bp3-submenu.bp3-popover{
  -webkit-box-shadow:none;
          box-shadow:none;
  padding:0 5px; }
  .bp3-submenu.bp3-popover > .bp3-popover-content{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-submenu.bp3-popover, .bp3-submenu.bp3-popover.bp3-dark{
    -webkit-box-shadow:none;
            box-shadow:none; }
    .bp3-dark .bp3-submenu.bp3-popover > .bp3-popover-content, .bp3-submenu.bp3-popover.bp3-dark > .bp3-popover-content{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
.bp3-menu{
  margin:0;
  border-radius:3px;
  background:#ffffff;
  min-width:180px;
  padding:5px;
  list-style:none;
  text-align:left;
  color:#182026; }

.bp3-menu-divider{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15); }
  .bp3-dark .bp3-menu-divider{
    border-top-color:rgba(255, 255, 255, 0.15); }

.bp3-menu-item{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  border-radius:2px;
  padding:5px 7px;
  text-decoration:none;
  line-height:20px;
  color:inherit;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-menu-item > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-menu-item > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-menu-item::before,
  .bp3-menu-item > *{
    margin-right:7px; }
  .bp3-menu-item:empty::before,
  .bp3-menu-item > :last-child{
    margin-right:0; }
  .bp3-menu-item > .bp3-fill{
    word-break:break-word; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    background-color:rgba(167, 182, 194, 0.3);
    cursor:pointer;
    text-decoration:none; }
  .bp3-menu-item.bp3-disabled{
    background-color:inherit;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-dark .bp3-menu-item{
    color:inherit; }
    .bp3-dark .bp3-menu-item:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
      background-color:rgba(138, 155, 168, 0.15);
      color:inherit; }
    .bp3-dark .bp3-menu-item.bp3-disabled{
      background-color:inherit;
      color:rgba(167, 182, 194, 0.6); }
  .bp3-menu-item.bp3-intent-primary{
    color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-primary::before, .bp3-menu-item.bp3-intent-primary::after,
    .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
      color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary.bp3-active{
      background-color:#137cbd; }
    .bp3-menu-item.bp3-intent-primary:active{
      background-color:#106ba3; }
    .bp3-menu-item.bp3-intent-primary:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary:active, .bp3-menu-item.bp3-intent-primary:active::before, .bp3-menu-item.bp3-intent-primary:active::after,
    .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-menu-item.bp3-intent-primary.bp3-active::after,
    .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-success{
    color:#0d8050; }
    .bp3-menu-item.bp3-intent-success .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-success::before, .bp3-menu-item.bp3-intent-success::after,
    .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
      color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success.bp3-active{
      background-color:#0f9960; }
    .bp3-menu-item.bp3-intent-success:active{
      background-color:#0d8050; }
    .bp3-menu-item.bp3-intent-success:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-menu-item.bp3-intent-success:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-menu-item.bp3-intent-success:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success:active, .bp3-menu-item.bp3-intent-success:active::before, .bp3-menu-item.bp3-intent-success:active::after,
    .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-menu-item.bp3-intent-success.bp3-active::after,
    .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-warning{
    color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-warning::before, .bp3-menu-item.bp3-intent-warning::after,
    .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
      color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning.bp3-active{
      background-color:#d9822b; }
    .bp3-menu-item.bp3-intent-warning:active{
      background-color:#bf7326; }
    .bp3-menu-item.bp3-intent-warning:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning:active, .bp3-menu-item.bp3-intent-warning:active::before, .bp3-menu-item.bp3-intent-warning:active::after,
    .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-menu-item.bp3-intent-warning.bp3-active::after,
    .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item.bp3-intent-danger{
    color:#c23030; }
    .bp3-menu-item.bp3-intent-danger .bp3-icon{
      color:inherit; }
    .bp3-menu-item.bp3-intent-danger::before, .bp3-menu-item.bp3-intent-danger::after,
    .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
      color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger.bp3-active{
      background-color:#db3737; }
    .bp3-menu-item.bp3-intent-danger:active{
      background-color:#c23030; }
    .bp3-menu-item.bp3-intent-danger:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
    .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
    .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger:active, .bp3-menu-item.bp3-intent-danger:active::before, .bp3-menu-item.bp3-intent-danger:active::after,
    .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-menu-item.bp3-intent-danger.bp3-active::after,
    .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
      color:#ffffff; }
  .bp3-menu-item::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    margin-right:7px; }
  .bp3-menu-item::before,
  .bp3-menu-item > .bp3-icon{
    margin-top:2px;
    color:#5c7080; }
  .bp3-menu-item .bp3-menu-item-label{
    color:#5c7080; }
  .bp3-menu-item:hover, .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-menu-item{
    color:inherit; }
  .bp3-menu-item.bp3-active, .bp3-menu-item:active{
    background-color:rgba(115, 134, 148, 0.3); }
  .bp3-menu-item.bp3-disabled{
    outline:none !important;
    background-color:inherit !important;
    cursor:not-allowed !important;
    color:rgba(92, 112, 128, 0.6) !important; }
    .bp3-menu-item.bp3-disabled::before,
    .bp3-menu-item.bp3-disabled > .bp3-icon,
    .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
      color:rgba(92, 112, 128, 0.6) !important; }
  .bp3-large .bp3-menu-item{
    padding:9px 7px;
    line-height:22px;
    font-size:16px; }
    .bp3-large .bp3-menu-item .bp3-icon{
      margin-top:3px; }
    .bp3-large .bp3-menu-item::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal;
      -moz-osx-font-smoothing:grayscale;
      -webkit-font-smoothing:antialiased;
      margin-top:1px;
      margin-right:10px; }

button.bp3-menu-item{
  border:none;
  background:none;
  width:100%;
  text-align:left; }
.bp3-menu-header{
  display:block;
  margin:5px;
  border-top:1px solid rgba(16, 22, 26, 0.15);
  cursor:default;
  padding-left:2px; }
  .bp3-dark .bp3-menu-header{
    border-top-color:rgba(255, 255, 255, 0.15); }
  .bp3-menu-header:first-of-type{
    border-top:none; }
  .bp3-menu-header > h6{
    color:#182026;
    font-weight:600;
    overflow:hidden;
    text-overflow:ellipsis;
    white-space:nowrap;
    word-wrap:normal;
    margin:0;
    padding:10px 7px 0 1px;
    line-height:17px; }
    .bp3-dark .bp3-menu-header > h6{
      color:#f5f8fa; }
  .bp3-menu-header:first-of-type > h6{
    padding-top:0; }
  .bp3-large .bp3-menu-header > h6{
    padding-top:15px;
    padding-bottom:5px;
    font-size:18px; }
  .bp3-large .bp3-menu-header:first-of-type > h6{
    padding-top:0; }

.bp3-dark .bp3-menu{
  background:#30404d;
  color:#f5f8fa; }

.bp3-dark .bp3-menu-item.bp3-intent-primary{
  color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary::before, .bp3-dark .bp3-menu-item.bp3-intent-primary::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary .bp3-menu-item-label{
    color:#48aff0; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active{
    background-color:#137cbd; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active{
    background-color:#106ba3; }
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-primary.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary:active, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-primary.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-success{
  color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-success::before, .bp3-dark .bp3-menu-item.bp3-intent-success::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success .bp3-menu-item-label{
    color:#3dcc91; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active{
    background-color:#0f9960; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:active{
    background-color:#0d8050; }
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-success:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-success.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success:active, .bp3-dark .bp3-menu-item.bp3-intent-success:active::before, .bp3-dark .bp3-menu-item.bp3-intent-success:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-success.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-warning{
  color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning::before, .bp3-dark .bp3-menu-item.bp3-intent-warning::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning .bp3-menu-item-label{
    color:#ffb366; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active{
    background-color:#d9822b; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active{
    background-color:#bf7326; }
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-warning.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning:active, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-warning.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item.bp3-intent-danger{
  color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-icon{
    color:inherit; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger::before, .bp3-dark .bp3-menu-item.bp3-intent-danger::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger .bp3-menu-item-label{
    color:#ff7373; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active{
    background-color:#db3737; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active{
    background-color:#c23030; }
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::before, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:hover::after, .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after, .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:hover .bp3-menu-item-label,
  .bp3-dark .bp3-submenu .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label,
  .bp3-submenu .bp3-dark .bp3-popover-target.bp3-popover-open > .bp3-intent-danger.bp3-menu-item .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger:active, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger:active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger:active .bp3-menu-item-label, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::before, .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active::after,
  .bp3-dark .bp3-menu-item.bp3-intent-danger.bp3-active .bp3-menu-item-label{
    color:#ffffff; }

.bp3-dark .bp3-menu-item::before,
.bp3-dark .bp3-menu-item > .bp3-icon{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item .bp3-menu-item-label{
  color:#a7b6c2; }

.bp3-dark .bp3-menu-item.bp3-active, .bp3-dark .bp3-menu-item:active{
  background-color:rgba(138, 155, 168, 0.3); }

.bp3-dark .bp3-menu-item.bp3-disabled{
  color:rgba(167, 182, 194, 0.6) !important; }
  .bp3-dark .bp3-menu-item.bp3-disabled::before,
  .bp3-dark .bp3-menu-item.bp3-disabled > .bp3-icon,
  .bp3-dark .bp3-menu-item.bp3-disabled .bp3-menu-item-label{
    color:rgba(167, 182, 194, 0.6) !important; }

.bp3-dark .bp3-menu-divider,
.bp3-dark .bp3-menu-header{
  border-color:rgba(255, 255, 255, 0.15); }

.bp3-dark .bp3-menu-header > h6{
  color:#f5f8fa; }

.bp3-label .bp3-menu{
  margin-top:5px; }
.bp3-navbar{
  position:relative;
  z-index:10;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:100%;
  height:50px;
  padding:0 15px; }
  .bp3-navbar.bp3-dark,
  .bp3-dark .bp3-navbar{
    background-color:#394b59; }
  .bp3-navbar.bp3-dark{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-dark .bp3-navbar{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 0 0 rgba(16, 22, 26, 0), 0 1px 1px rgba(16, 22, 26, 0.4); }
  .bp3-navbar.bp3-fixed-top{
    position:fixed;
    top:0;
    right:0;
    left:0; }

.bp3-navbar-heading{
  margin-right:15px;
  font-size:16px; }

.bp3-navbar-group{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  height:50px; }
  .bp3-navbar-group.bp3-align-left{
    float:left; }
  .bp3-navbar-group.bp3-align-right{
    float:right; }

.bp3-navbar-divider{
  margin:0 10px;
  border-left:1px solid rgba(16, 22, 26, 0.15);
  height:20px; }
  .bp3-dark .bp3-navbar-divider{
    border-left-color:rgba(255, 255, 255, 0.15); }
.bp3-non-ideal-state{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  width:100%;
  height:100%;
  text-align:center; }
  .bp3-non-ideal-state > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-non-ideal-state > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-non-ideal-state::before,
  .bp3-non-ideal-state > *{
    margin-bottom:20px; }
  .bp3-non-ideal-state:empty::before,
  .bp3-non-ideal-state > :last-child{
    margin-bottom:0; }
  .bp3-non-ideal-state > *{
    max-width:400px; }

.bp3-non-ideal-state-visual{
  color:rgba(92, 112, 128, 0.6);
  font-size:60px; }
  .bp3-dark .bp3-non-ideal-state-visual{
    color:rgba(167, 182, 194, 0.6); }

.bp3-overflow-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-wrap:nowrap;
      flex-wrap:nowrap;
  min-width:0; }

.bp3-overflow-list-spacer{
  -ms-flex-negative:1;
      flex-shrink:1;
  width:1px; }

body.bp3-overlay-open{
  overflow:hidden; }

.bp3-overlay{
  position:static;
  top:0;
  right:0;
  bottom:0;
  left:0;
  z-index:20; }
  .bp3-overlay:not(.bp3-overlay-open){
    pointer-events:none; }
  .bp3-overlay.bp3-overlay-container{
    position:fixed;
    overflow:hidden; }
    .bp3-overlay.bp3-overlay-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-scroll-container{
    position:fixed;
    overflow:auto; }
    .bp3-overlay.bp3-overlay-scroll-container.bp3-overlay-inline{
      position:absolute; }
  .bp3-overlay.bp3-overlay-inline{
    display:inline;
    overflow:visible; }

.bp3-overlay-content{
  position:fixed;
  z-index:20; }
  .bp3-overlay-inline .bp3-overlay-content,
  .bp3-overlay-scroll-container .bp3-overlay-content{
    position:absolute; }

.bp3-overlay-backdrop{
  position:fixed;
  top:0;
  right:0;
  bottom:0;
  left:0;
  opacity:1;
  z-index:20;
  background-color:rgba(16, 22, 26, 0.7);
  overflow:auto;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-overlay-backdrop.bp3-overlay-enter, .bp3-overlay-backdrop.bp3-overlay-appear{
    opacity:0; }
  .bp3-overlay-backdrop.bp3-overlay-enter-active, .bp3-overlay-backdrop.bp3-overlay-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop.bp3-overlay-exit{
    opacity:1; }
  .bp3-overlay-backdrop.bp3-overlay-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-overlay-backdrop:focus{
    outline:none; }
  .bp3-overlay-inline .bp3-overlay-backdrop{
    position:absolute; }
.bp3-panel-stack{
  position:relative;
  overflow:hidden; }

.bp3-panel-stack-header{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -ms-flex-negative:0;
      flex-shrink:0;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  z-index:1;
  -webkit-box-shadow:0 1px rgba(16, 22, 26, 0.15);
          box-shadow:0 1px rgba(16, 22, 26, 0.15);
  height:30px; }
  .bp3-dark .bp3-panel-stack-header{
    -webkit-box-shadow:0 1px rgba(255, 255, 255, 0.15);
            box-shadow:0 1px rgba(255, 255, 255, 0.15); }
  .bp3-panel-stack-header > span{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-flex:1;
        -ms-flex:1;
            flex:1;
    -webkit-box-align:stretch;
        -ms-flex-align:stretch;
            align-items:stretch; }
  .bp3-panel-stack-header .bp3-heading{
    margin:0 5px; }

.bp3-button.bp3-panel-stack-header-back{
  margin-left:5px;
  padding-left:0;
  white-space:nowrap; }
  .bp3-button.bp3-panel-stack-header-back .bp3-icon{
    margin:0 2px; }

.bp3-panel-stack-view{
  position:absolute;
  top:0;
  right:0;
  bottom:0;
  left:0;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  margin-right:-1px;
  border-right:1px solid rgba(16, 22, 26, 0.15);
  background-color:#ffffff;
  overflow-y:auto; }
  .bp3-dark .bp3-panel-stack-view{
    background-color:#30404d; }

.bp3-panel-stack-push .bp3-panel-stack-enter, .bp3-panel-stack-push .bp3-panel-stack-appear{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0; }

.bp3-panel-stack-push .bp3-panel-stack-enter-active, .bp3-panel-stack-push .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-push .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-push .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter, .bp3-panel-stack-pop .bp3-panel-stack-appear{
  -webkit-transform:translateX(-50%);
          transform:translateX(-50%);
  opacity:0; }

.bp3-panel-stack-pop .bp3-panel-stack-enter-active, .bp3-panel-stack-pop .bp3-panel-stack-appear-active{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }

.bp3-panel-stack-pop .bp3-panel-stack-exit{
  -webkit-transform:translate(0%);
          transform:translate(0%);
  opacity:1; }

.bp3-panel-stack-pop .bp3-panel-stack-exit-active{
  -webkit-transform:translateX(100%);
          transform:translateX(100%);
  opacity:0;
  -webkit-transition-property:opacity, -webkit-transform;
  transition-property:opacity, -webkit-transform;
  transition-property:transform, opacity;
  transition-property:transform, opacity, -webkit-transform;
  -webkit-transition-duration:400ms;
          transition-duration:400ms;
  -webkit-transition-timing-function:ease;
          transition-timing-function:ease;
  -webkit-transition-delay:0;
          transition-delay:0; }
.bp3-popover{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1);
  display:inline-block;
  z-index:20;
  border-radius:3px; }
  .bp3-popover .bp3-popover-arrow{
    position:absolute;
    width:30px;
    height:30px; }
    .bp3-popover .bp3-popover-arrow::before{
      margin:5px;
      width:20px;
      height:20px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover{
    margin-top:-17px;
    margin-bottom:17px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
      bottom:-11px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover{
    margin-left:17px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
      left:-11px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover{
    margin-top:17px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
      top:-11px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover{
    margin-right:17px;
    margin-left:-17px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
      right:-11px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-popover > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-popover > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-popover > .bp3-popover-arrow{
    top:-0.3934px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-popover > .bp3-popover-arrow{
    right:-0.3934px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-popover > .bp3-popover-arrow{
    left:-0.3934px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-popover > .bp3-popover-arrow{
    bottom:-0.3934px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-popover{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-popover{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-popover{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-popover .bp3-popover-content{
    background:#ffffff;
    color:inherit; }
  .bp3-popover .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-popover .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-popover .bp3-popover-arrow-fill{
    fill:#ffffff; }
  .bp3-popover-enter > .bp3-popover, .bp3-popover-appear > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3); }
  .bp3-popover-enter-active > .bp3-popover, .bp3-popover-appear-active > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-popover{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-popover{
    -webkit-transform:scale(0.3);
            transform:scale(0.3);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover .bp3-popover-content{
    position:relative;
    border-radius:3px; }
  .bp3-popover.bp3-popover-content-sizing .bp3-popover-content{
    max-width:350px;
    padding:20px; }
  .bp3-popover-target + .bp3-overlay .bp3-popover.bp3-popover-content-sizing{
    width:350px; }
  .bp3-popover.bp3-minimal{
    margin:0 !important; }
    .bp3-popover.bp3-minimal .bp3-popover-arrow{
      display:none; }
    .bp3-popover.bp3-minimal.bp3-popover{
      -webkit-transform:scale(1);
              transform:scale(1); }
      .bp3-popover-enter > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-enter-active > .bp3-popover.bp3-minimal.bp3-popover, .bp3-popover-appear-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
      .bp3-popover-exit > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1); }
      .bp3-popover-exit-active > .bp3-popover.bp3-minimal.bp3-popover{
        -webkit-transform:scale(1);
                transform:scale(1);
        -webkit-transition-property:-webkit-transform;
        transition-property:-webkit-transform;
        transition-property:transform;
        transition-property:transform, -webkit-transform;
        -webkit-transition-duration:100ms;
                transition-duration:100ms;
        -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
                transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
        -webkit-transition-delay:0;
                transition-delay:0; }
  .bp3-popover.bp3-dark,
  .bp3-dark .bp3-popover{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-popover .bp3-popover-content{
      background:#30404d;
      color:inherit; }
    .bp3-popover.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-popover .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-popover.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-popover .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-popover.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-popover .bp3-popover-arrow-fill{
      fill:#30404d; }

.bp3-popover-arrow::before{
  display:block;
  position:absolute;
  -webkit-transform:rotate(45deg);
          transform:rotate(45deg);
  border-radius:2px;
  content:""; }

.bp3-tether-pinned .bp3-popover-arrow{
  display:none; }

.bp3-popover-backdrop{
  background:rgba(255, 255, 255, 0); }

.bp3-transition-container{
  opacity:1;
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  z-index:20; }
  .bp3-transition-container.bp3-popover-enter, .bp3-transition-container.bp3-popover-appear{
    opacity:0; }
  .bp3-transition-container.bp3-popover-enter-active, .bp3-transition-container.bp3-popover-appear-active{
    opacity:1;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container.bp3-popover-exit{
    opacity:1; }
  .bp3-transition-container.bp3-popover-exit-active{
    opacity:0;
    -webkit-transition-property:opacity;
    transition-property:opacity;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-transition-container:focus{
    outline:none; }
  .bp3-transition-container.bp3-popover-leave .bp3-popover-content{
    pointer-events:none; }
  .bp3-transition-container[data-x-out-of-boundaries]{
    display:none; }

span.bp3-popover-target{
  display:inline-block; }

.bp3-popover-wrapper.bp3-fill{
  width:100%; }

.bp3-portal{
  position:absolute;
  top:0;
  right:0;
  left:0; }
@-webkit-keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }
@keyframes linear-progress-bar-stripes{
  from{
    background-position:0 0; }
  to{
    background-position:30px 0; } }

.bp3-progress-bar{
  display:block;
  position:relative;
  border-radius:40px;
  background:rgba(92, 112, 128, 0.2);
  width:100%;
  height:8px;
  overflow:hidden; }
  .bp3-progress-bar .bp3-progress-meter{
    position:absolute;
    border-radius:40px;
    background:linear-gradient(-45deg, rgba(255, 255, 255, 0.2) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.2) 50%, rgba(255, 255, 255, 0.2) 75%, transparent 75%);
    background-color:rgba(92, 112, 128, 0.8);
    background-size:30px 30px;
    width:100%;
    height:100%;
    -webkit-transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:width 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-progress-bar:not(.bp3-no-animation):not(.bp3-no-stripes) .bp3-progress-meter{
    animation:linear-progress-bar-stripes 300ms linear infinite reverse; }
  .bp3-progress-bar.bp3-no-stripes .bp3-progress-meter{
    background-image:none; }

.bp3-dark .bp3-progress-bar{
  background:rgba(16, 22, 26, 0.5); }
  .bp3-dark .bp3-progress-bar .bp3-progress-meter{
    background-color:#8a9ba8; }

.bp3-progress-bar.bp3-intent-primary .bp3-progress-meter{
  background-color:#137cbd; }

.bp3-progress-bar.bp3-intent-success .bp3-progress-meter{
  background-color:#0f9960; }

.bp3-progress-bar.bp3-intent-warning .bp3-progress-meter{
  background-color:#d9822b; }

.bp3-progress-bar.bp3-intent-danger .bp3-progress-meter{
  background-color:#db3737; }
@-webkit-keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
@keyframes skeleton-glow{
  from{
    border-color:rgba(206, 217, 224, 0.2);
    background:rgba(206, 217, 224, 0.2); }
  to{
    border-color:rgba(92, 112, 128, 0.2);
    background:rgba(92, 112, 128, 0.2); } }
.bp3-skeleton{
  border-color:rgba(206, 217, 224, 0.2) !important;
  border-radius:2px;
  -webkit-box-shadow:none !important;
          box-shadow:none !important;
  background:rgba(206, 217, 224, 0.2);
  background-clip:padding-box !important;
  cursor:default;
  color:transparent !important;
  -webkit-animation:1000ms linear infinite alternate skeleton-glow;
          animation:1000ms linear infinite alternate skeleton-glow;
  pointer-events:none;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-skeleton::before, .bp3-skeleton::after,
  .bp3-skeleton *{
    visibility:hidden !important; }
.bp3-slider{
  width:100%;
  min-width:150px;
  height:40px;
  position:relative;
  outline:none;
  cursor:default;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-slider:hover{
    cursor:pointer; }
  .bp3-slider:active{
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-slider.bp3-disabled{
    opacity:0.5;
    cursor:not-allowed; }
  .bp3-slider.bp3-slider-unlabeled{
    height:16px; }

.bp3-slider-track,
.bp3-slider-progress{
  top:5px;
  right:0;
  left:0;
  height:6px;
  position:absolute; }

.bp3-slider-track{
  border-radius:3px;
  overflow:hidden; }

.bp3-slider-progress{
  background:rgba(92, 112, 128, 0.2); }
  .bp3-dark .bp3-slider-progress{
    background:rgba(16, 22, 26, 0.5); }
  .bp3-slider-progress.bp3-intent-primary{
    background-color:#137cbd; }
  .bp3-slider-progress.bp3-intent-success{
    background-color:#0f9960; }
  .bp3-slider-progress.bp3-intent-warning{
    background-color:#d9822b; }
  .bp3-slider-progress.bp3-intent-danger{
    background-color:#db3737; }

.bp3-slider-handle{
  -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
          box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
  background-color:#f5f8fa;
  background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.8)), to(rgba(255, 255, 255, 0)));
  background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0));
  color:#182026;
  position:absolute;
  top:0;
  left:0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
  cursor:pointer;
  width:16px;
  height:16px; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5; }
  .bp3-slider-handle:active, .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none; }
  .bp3-slider-handle:disabled, .bp3-slider-handle.bp3-disabled{
    outline:none;
    -webkit-box-shadow:none;
            box-shadow:none;
    background-color:rgba(206, 217, 224, 0.5);
    background-image:none;
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
    .bp3-slider-handle:disabled.bp3-active, .bp3-slider-handle:disabled.bp3-active:hover, .bp3-slider-handle.bp3-disabled.bp3-active, .bp3-slider-handle.bp3-disabled.bp3-active:hover{
      background:rgba(206, 217, 224, 0.7); }
  .bp3-slider-handle:focus{
    z-index:1; }
  .bp3-slider-handle:hover{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 -1px 0 rgba(16, 22, 26, 0.1);
    background-clip:padding-box;
    background-color:#ebf1f5;
    z-index:2;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 1px 1px rgba(16, 22, 26, 0.2);
    cursor:-webkit-grab;
    cursor:grab; }
  .bp3-slider-handle.bp3-active{
    -webkit-box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
            box-shadow:inset 0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 2px rgba(16, 22, 26, 0.2);
    background-color:#d8e1e8;
    background-image:none;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), inset 0 1px 1px rgba(16, 22, 26, 0.1);
    cursor:-webkit-grabbing;
    cursor:grabbing; }
  .bp3-disabled .bp3-slider-handle{
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#bfccd6;
    pointer-events:none; }
  .bp3-dark .bp3-slider-handle{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
    background-color:#394b59;
    background-image:-webkit-gradient(linear, left top, left bottom, from(rgba(255, 255, 255, 0.05)), to(rgba(255, 255, 255, 0)));
    background-image:linear-gradient(to bottom, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0));
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover, .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle:hover{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.4);
      background-color:#30404d; }
    .bp3-dark .bp3-slider-handle:active, .bp3-dark .bp3-slider-handle.bp3-active{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.6), inset 0 1px 2px rgba(16, 22, 26, 0.2);
      background-color:#202b33;
      background-image:none; }
    .bp3-dark .bp3-slider-handle:disabled, .bp3-dark .bp3-slider-handle.bp3-disabled{
      -webkit-box-shadow:none;
              box-shadow:none;
      background-color:rgba(57, 75, 89, 0.5);
      background-image:none;
      color:rgba(167, 182, 194, 0.6); }
      .bp3-dark .bp3-slider-handle:disabled.bp3-active, .bp3-dark .bp3-slider-handle.bp3-disabled.bp3-active{
        background:rgba(57, 75, 89, 0.7); }
    .bp3-dark .bp3-slider-handle .bp3-button-spinner .bp3-spinner-head{
      background:rgba(16, 22, 26, 0.5);
      stroke:#8a9ba8; }
    .bp3-dark .bp3-slider-handle, .bp3-dark .bp3-slider-handle:hover{
      background-color:#394b59; }
    .bp3-dark .bp3-slider-handle.bp3-active{
      background-color:#293742; }
  .bp3-dark .bp3-disabled .bp3-slider-handle{
    border-color:#5c7080;
    -webkit-box-shadow:none;
            box-shadow:none;
    background:#5c7080; }
  .bp3-slider-handle .bp3-slider-label{
    margin-left:8px;
    border-radius:3px;
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
    background:#394b59;
    color:#f5f8fa; }
    .bp3-dark .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
      background:#e1e8ed;
      color:#394b59; }
    .bp3-disabled .bp3-slider-handle .bp3-slider-label{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-slider-handle.bp3-start, .bp3-slider-handle.bp3-end{
    width:8px; }
  .bp3-slider-handle.bp3-start{
    border-top-right-radius:0;
    border-bottom-right-radius:0; }
  .bp3-slider-handle.bp3-end{
    margin-left:8px;
    border-top-left-radius:0;
    border-bottom-left-radius:0; }
    .bp3-slider-handle.bp3-end .bp3-slider-label{
      margin-left:0; }

.bp3-slider-label{
  -webkit-transform:translate(-50%, 20px);
          transform:translate(-50%, 20px);
  display:inline-block;
  position:absolute;
  padding:2px 5px;
  vertical-align:top;
  line-height:1;
  font-size:12px; }

.bp3-slider.bp3-vertical{
  width:40px;
  min-width:40px;
  height:150px; }
  .bp3-slider.bp3-vertical .bp3-slider-track,
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:0;
    bottom:0;
    left:5px;
    width:6px;
    height:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-progress{
    top:auto; }
  .bp3-slider.bp3-vertical .bp3-slider-label{
    -webkit-transform:translate(20px, 50%);
            transform:translate(20px, 50%); }
  .bp3-slider.bp3-vertical .bp3-slider-handle{
    top:auto; }
    .bp3-slider.bp3-vertical .bp3-slider-handle .bp3-slider-label{
      margin-top:-8px;
      margin-left:0; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end, .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      margin-left:0;
      width:16px;
      height:8px; }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start{
      border-top-left-radius:0;
      border-bottom-right-radius:3px; }
      .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-start .bp3-slider-label{
        -webkit-transform:translate(20px);
                transform:translate(20px); }
    .bp3-slider.bp3-vertical .bp3-slider-handle.bp3-end{
      margin-bottom:8px;
      border-top-left-radius:3px;
      border-bottom-left-radius:0;
      border-bottom-right-radius:0; }

@-webkit-keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

@keyframes pt-spinner-animation{
  from{
    -webkit-transform:rotate(0deg);
            transform:rotate(0deg); }
  to{
    -webkit-transform:rotate(360deg);
            transform:rotate(360deg); } }

.bp3-spinner{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  -webkit-box-pack:center;
      -ms-flex-pack:center;
          justify-content:center;
  overflow:visible;
  vertical-align:middle; }
  .bp3-spinner svg{
    display:block; }
  .bp3-spinner path{
    fill-opacity:0; }
  .bp3-spinner .bp3-spinner-head{
    -webkit-transform-origin:center;
            transform-origin:center;
    -webkit-transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    transition:stroke-dashoffset 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
    stroke:rgba(92, 112, 128, 0.8);
    stroke-linecap:round; }
  .bp3-spinner .bp3-spinner-track{
    stroke:rgba(92, 112, 128, 0.2); }

.bp3-spinner-animation{
  -webkit-animation:pt-spinner-animation 500ms linear infinite;
          animation:pt-spinner-animation 500ms linear infinite; }
  .bp3-no-spin > .bp3-spinner-animation{
    -webkit-animation:none;
            animation:none; }

.bp3-dark .bp3-spinner .bp3-spinner-head{
  stroke:#8a9ba8; }

.bp3-dark .bp3-spinner .bp3-spinner-track{
  stroke:rgba(16, 22, 26, 0.5); }

.bp3-spinner.bp3-intent-primary .bp3-spinner-head{
  stroke:#137cbd; }

.bp3-spinner.bp3-intent-success .bp3-spinner-head{
  stroke:#0f9960; }

.bp3-spinner.bp3-intent-warning .bp3-spinner-head{
  stroke:#d9822b; }

.bp3-spinner.bp3-intent-danger .bp3-spinner-head{
  stroke:#db3737; }
.bp3-tabs.bp3-vertical{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex; }
  .bp3-tabs.bp3-vertical > .bp3-tab-list{
    -webkit-box-orient:vertical;
    -webkit-box-direction:normal;
        -ms-flex-direction:column;
            flex-direction:column;
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab{
      border-radius:3px;
      width:100%;
      padding:0 10px; }
      .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab[aria-selected="true"]{
        -webkit-box-shadow:none;
                box-shadow:none;
        background-color:rgba(19, 124, 189, 0.2); }
    .bp3-tabs.bp3-vertical > .bp3-tab-list .bp3-tab-indicator-wrapper .bp3-tab-indicator{
      top:0;
      right:0;
      bottom:0;
      left:0;
      border-radius:3px;
      background-color:rgba(19, 124, 189, 0.2);
      height:auto; }
  .bp3-tabs.bp3-vertical > .bp3-tab-panel{
    margin-top:0;
    padding-left:20px; }

.bp3-tab-list{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  -webkit-box-align:end;
      -ms-flex-align:end;
          align-items:flex-end;
  position:relative;
  margin:0;
  border:none;
  padding:0;
  list-style:none; }
  .bp3-tab-list > *:not(:last-child){
    margin-right:20px; }

.bp3-tab{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:0;
      -ms-flex:0 0 auto;
          flex:0 0 auto;
  position:relative;
  cursor:pointer;
  max-width:100%;
  vertical-align:top;
  line-height:30px;
  color:#182026;
  font-size:14px; }
  .bp3-tab a{
    display:block;
    text-decoration:none;
    color:inherit; }
  .bp3-tab-indicator-wrapper ~ .bp3-tab{
    -webkit-box-shadow:none !important;
            box-shadow:none !important;
    background-color:transparent !important; }
  .bp3-tab[aria-disabled="true"]{
    cursor:not-allowed;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-tab[aria-selected="true"]{
    border-radius:0;
    -webkit-box-shadow:inset 0 -3px 0 #106ba3;
            box-shadow:inset 0 -3px 0 #106ba3; }
  .bp3-tab[aria-selected="true"], .bp3-tab:not([aria-disabled="true"]):hover{
    color:#106ba3; }
  .bp3-tab:focus{
    -moz-outline-radius:0; }
  .bp3-large > .bp3-tab{
    line-height:40px;
    font-size:16px; }

.bp3-tab-panel{
  margin-top:20px; }
  .bp3-tab-panel[aria-hidden="true"]{
    display:none; }

.bp3-tab-indicator-wrapper{
  position:absolute;
  top:0;
  left:0;
  -webkit-transform:translateX(0), translateY(0);
          transform:translateX(0), translateY(0);
  -webkit-transition:height, width, -webkit-transform;
  transition:height, width, -webkit-transform;
  transition:height, transform, width;
  transition:height, transform, width, -webkit-transform;
  -webkit-transition-duration:200ms;
          transition-duration:200ms;
  -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
          transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
  pointer-events:none; }
  .bp3-tab-indicator-wrapper .bp3-tab-indicator{
    position:absolute;
    right:0;
    bottom:0;
    left:0;
    background-color:#106ba3;
    height:3px; }
  .bp3-tab-indicator-wrapper.bp3-no-animation{
    -webkit-transition:none;
    transition:none; }

.bp3-dark .bp3-tab{
  color:#f5f8fa; }
  .bp3-dark .bp3-tab[aria-disabled="true"]{
    color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tab[aria-selected="true"]{
    -webkit-box-shadow:inset 0 -3px 0 #48aff0;
            box-shadow:inset 0 -3px 0 #48aff0; }
  .bp3-dark .bp3-tab[aria-selected="true"], .bp3-dark .bp3-tab:not([aria-disabled="true"]):hover{
    color:#48aff0; }

.bp3-dark .bp3-tab-indicator{
  background-color:#48aff0; }

.bp3-flex-expander{
  -webkit-box-flex:1;
      -ms-flex:1 1;
          flex:1 1; }
.bp3-tag{
  display:-webkit-inline-box;
  display:-ms-inline-flexbox;
  display:inline-flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:relative;
  border:none;
  border-radius:3px;
  -webkit-box-shadow:none;
          box-shadow:none;
  background-color:#5c7080;
  min-width:20px;
  max-width:100%;
  min-height:20px;
  padding:2px 6px;
  line-height:16px;
  color:#f5f8fa;
  font-size:12px; }
  .bp3-tag.bp3-interactive{
    cursor:pointer; }
    .bp3-tag.bp3-interactive:hover{
      background-color:rgba(92, 112, 128, 0.85); }
    .bp3-tag.bp3-interactive.bp3-active, .bp3-tag.bp3-interactive:active{
      background-color:rgba(92, 112, 128, 0.7); }
  .bp3-tag > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag > .bp3-fill{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag::before,
  .bp3-tag > *{
    margin-right:4px; }
  .bp3-tag:empty::before,
  .bp3-tag > :last-child{
    margin-right:0; }
  .bp3-tag:focus{
    outline:rgba(19, 124, 189, 0.6) auto 2px;
    outline-offset:0;
    -moz-outline-radius:6px; }
  .bp3-tag.bp3-round{
    border-radius:30px;
    padding-right:8px;
    padding-left:8px; }
  .bp3-dark .bp3-tag{
    background-color:#bfccd6;
    color:#182026; }
    .bp3-dark .bp3-tag.bp3-interactive{
      cursor:pointer; }
      .bp3-dark .bp3-tag.bp3-interactive:hover{
        background-color:rgba(191, 204, 214, 0.85); }
      .bp3-dark .bp3-tag.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-interactive:active{
        background-color:rgba(191, 204, 214, 0.7); }
    .bp3-dark .bp3-tag > .bp3-icon, .bp3-dark .bp3-tag .bp3-icon-standard, .bp3-dark .bp3-tag .bp3-icon-large{
      fill:currentColor; }
  .bp3-tag > .bp3-icon, .bp3-tag .bp3-icon-standard, .bp3-tag .bp3-icon-large{
    fill:#ffffff; }
  .bp3-tag.bp3-large,
  .bp3-large .bp3-tag{
    min-width:30px;
    min-height:30px;
    padding:0 10px;
    line-height:20px;
    font-size:14px; }
    .bp3-tag.bp3-large::before,
    .bp3-tag.bp3-large > *,
    .bp3-large .bp3-tag::before,
    .bp3-large .bp3-tag > *{
      margin-right:7px; }
    .bp3-tag.bp3-large:empty::before,
    .bp3-tag.bp3-large > :last-child,
    .bp3-large .bp3-tag:empty::before,
    .bp3-large .bp3-tag > :last-child{
      margin-right:0; }
    .bp3-tag.bp3-large.bp3-round,
    .bp3-large .bp3-tag.bp3-round{
      padding-right:12px;
      padding-left:12px; }
  .bp3-tag.bp3-intent-primary{
    background:#137cbd;
    color:#ffffff; }
    .bp3-tag.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.85); }
      .bp3-tag.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.7); }
  .bp3-tag.bp3-intent-success{
    background:#0f9960;
    color:#ffffff; }
    .bp3-tag.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.85); }
      .bp3-tag.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.7); }
  .bp3-tag.bp3-intent-warning{
    background:#d9822b;
    color:#ffffff; }
    .bp3-tag.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.85); }
      .bp3-tag.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.7); }
  .bp3-tag.bp3-intent-danger{
    background:#db3737;
    color:#ffffff; }
    .bp3-tag.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.85); }
      .bp3-tag.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.7); }
  .bp3-tag.bp3-fill{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    width:100%; }
  .bp3-tag.bp3-minimal > .bp3-icon, .bp3-tag.bp3-minimal .bp3-icon-standard, .bp3-tag.bp3-minimal .bp3-icon-large{
    fill:#5c7080; }
  .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
    background-color:rgba(138, 155, 168, 0.2);
    color:#182026; }
    .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
        background-color:rgba(92, 112, 128, 0.3); }
      .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
        background-color:rgba(92, 112, 128, 0.4); }
    .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]){
      color:#f5f8fa; }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:hover{
          background-color:rgba(191, 204, 214, 0.3); }
        .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]).bp3-interactive:active{
          background-color:rgba(191, 204, 214, 0.4); }
      .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) > .bp3-icon, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-standard, .bp3-dark .bp3-tag.bp3-minimal:not([class*="bp3-intent-"]) .bp3-icon-large{
        fill:#a7b6c2; }
  .bp3-tag.bp3-minimal.bp3-intent-primary{
    background-color:rgba(19, 124, 189, 0.15);
    color:#106ba3; }
    .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
        background-color:rgba(19, 124, 189, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
        background-color:rgba(19, 124, 189, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-primary > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-primary .bp3-icon-large{
      fill:#137cbd; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary{
      background-color:rgba(19, 124, 189, 0.25);
      color:#48aff0; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:hover{
          background-color:rgba(19, 124, 189, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-primary.bp3-interactive:active{
          background-color:rgba(19, 124, 189, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-success{
    background-color:rgba(15, 153, 96, 0.15);
    color:#0d8050; }
    .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
        background-color:rgba(15, 153, 96, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
        background-color:rgba(15, 153, 96, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-success > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-success .bp3-icon-large{
      fill:#0f9960; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success{
      background-color:rgba(15, 153, 96, 0.25);
      color:#3dcc91; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:hover{
          background-color:rgba(15, 153, 96, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-success.bp3-interactive:active{
          background-color:rgba(15, 153, 96, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-warning{
    background-color:rgba(217, 130, 43, 0.15);
    color:#bf7326; }
    .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
        background-color:rgba(217, 130, 43, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
        background-color:rgba(217, 130, 43, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-warning > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-warning .bp3-icon-large{
      fill:#d9822b; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning{
      background-color:rgba(217, 130, 43, 0.25);
      color:#ffb366; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:hover{
          background-color:rgba(217, 130, 43, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-warning.bp3-interactive:active{
          background-color:rgba(217, 130, 43, 0.45); }
  .bp3-tag.bp3-minimal.bp3-intent-danger{
    background-color:rgba(219, 55, 55, 0.15);
    color:#c23030; }
    .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
      cursor:pointer; }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
        background-color:rgba(219, 55, 55, 0.25); }
      .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
        background-color:rgba(219, 55, 55, 0.35); }
    .bp3-tag.bp3-minimal.bp3-intent-danger > .bp3-icon, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-standard, .bp3-tag.bp3-minimal.bp3-intent-danger .bp3-icon-large{
      fill:#db3737; }
    .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger{
      background-color:rgba(219, 55, 55, 0.25);
      color:#ff7373; }
      .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive{
        cursor:pointer; }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:hover{
          background-color:rgba(219, 55, 55, 0.35); }
        .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive.bp3-active, .bp3-dark .bp3-tag.bp3-minimal.bp3-intent-danger.bp3-interactive:active{
          background-color:rgba(219, 55, 55, 0.45); }

.bp3-tag-remove{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  opacity:0.5;
  margin-top:-2px;
  margin-right:-6px !important;
  margin-bottom:-2px;
  border:none;
  background:none;
  cursor:pointer;
  padding:2px;
  padding-left:0;
  color:inherit; }
  .bp3-tag-remove:hover{
    opacity:0.8;
    background:none;
    text-decoration:none; }
  .bp3-tag-remove:active{
    opacity:1; }
  .bp3-tag-remove:empty::before{
    line-height:1;
    font-family:"Icons16", sans-serif;
    font-size:16px;
    font-weight:400;
    font-style:normal;
    -moz-osx-font-smoothing:grayscale;
    -webkit-font-smoothing:antialiased;
    content:""; }
  .bp3-large .bp3-tag-remove{
    margin-right:-10px !important;
    padding:5px;
    padding-left:0; }
    .bp3-large .bp3-tag-remove:empty::before{
      line-height:1;
      font-family:"Icons20", sans-serif;
      font-size:20px;
      font-weight:400;
      font-style:normal; }
.bp3-tag-input{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-orient:horizontal;
  -webkit-box-direction:normal;
      -ms-flex-direction:row;
          flex-direction:row;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  cursor:text;
  height:auto;
  min-height:30px;
  padding-right:0;
  padding-left:5px;
  line-height:inherit; }
  .bp3-tag-input > *{
    -webkit-box-flex:0;
        -ms-flex-positive:0;
            flex-grow:0;
    -ms-flex-negative:0;
        flex-shrink:0; }
  .bp3-tag-input > .bp3-tag-input-values{
    -webkit-box-flex:1;
        -ms-flex-positive:1;
            flex-grow:1;
    -ms-flex-negative:1;
        flex-shrink:1; }
  .bp3-tag-input .bp3-tag-input-icon{
    margin-top:7px;
    margin-right:7px;
    margin-left:2px;
    color:#5c7080; }
  .bp3-tag-input .bp3-tag-input-values{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-orient:horizontal;
    -webkit-box-direction:normal;
        -ms-flex-direction:row;
            flex-direction:row;
    -ms-flex-wrap:wrap;
        flex-wrap:wrap;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center;
    -ms-flex-item-align:stretch;
        align-self:stretch;
    margin-top:5px;
    margin-right:7px;
    min-width:0; }
    .bp3-tag-input .bp3-tag-input-values > *{
      -webkit-box-flex:0;
          -ms-flex-positive:0;
              flex-grow:0;
      -ms-flex-negative:0;
          flex-shrink:0; }
    .bp3-tag-input .bp3-tag-input-values > .bp3-fill{
      -webkit-box-flex:1;
          -ms-flex-positive:1;
              flex-grow:1;
      -ms-flex-negative:1;
          flex-shrink:1; }
    .bp3-tag-input .bp3-tag-input-values::before,
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-right:5px; }
    .bp3-tag-input .bp3-tag-input-values:empty::before,
    .bp3-tag-input .bp3-tag-input-values > :last-child{
      margin-right:0; }
    .bp3-tag-input .bp3-tag-input-values:first-child .bp3-input-ghost:first-child{
      padding-left:5px; }
    .bp3-tag-input .bp3-tag-input-values > *{
      margin-bottom:5px; }
  .bp3-tag-input .bp3-tag{
    overflow-wrap:break-word; }
    .bp3-tag-input .bp3-tag.bp3-active{
      outline:rgba(19, 124, 189, 0.6) auto 2px;
      outline-offset:0;
      -moz-outline-radius:6px; }
  .bp3-tag-input .bp3-input-ghost{
    -webkit-box-flex:1;
        -ms-flex:1 1 auto;
            flex:1 1 auto;
    width:80px;
    line-height:20px; }
    .bp3-tag-input .bp3-input-ghost:disabled, .bp3-tag-input .bp3-input-ghost.bp3-disabled{
      cursor:not-allowed; }
  .bp3-tag-input .bp3-button,
  .bp3-tag-input .bp3-spinner{
    margin:3px;
    margin-left:0; }
  .bp3-tag-input .bp3-button{
    min-width:24px;
    min-height:24px;
    padding:0 7px; }
  .bp3-tag-input.bp3-large{
    height:auto;
    min-height:40px; }
    .bp3-tag-input.bp3-large::before,
    .bp3-tag-input.bp3-large > *{
      margin-right:10px; }
    .bp3-tag-input.bp3-large:empty::before,
    .bp3-tag-input.bp3-large > :last-child{
      margin-right:0; }
    .bp3-tag-input.bp3-large .bp3-tag-input-icon{
      margin-top:10px;
      margin-left:5px; }
    .bp3-tag-input.bp3-large .bp3-input-ghost{
      line-height:30px; }
    .bp3-tag-input.bp3-large .bp3-button{
      min-width:30px;
      min-height:30px;
      padding:5px 10px;
      margin:5px;
      margin-left:0; }
    .bp3-tag-input.bp3-large .bp3-spinner{
      margin:8px;
      margin-left:0; }
  .bp3-tag-input.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
    background-color:#ffffff; }
    .bp3-tag-input.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
    .bp3-tag-input.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.2); }
  .bp3-dark .bp3-tag-input .bp3-tag-input-icon, .bp3-tag-input.bp3-dark .bp3-tag-input-icon{
    color:#a7b6c2; }
  .bp3-dark .bp3-tag-input .bp3-input-ghost, .bp3-tag-input.bp3-dark .bp3-input-ghost{
    color:#f5f8fa; }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-webkit-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-webkit-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-moz-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-moz-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost:-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost:-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::-ms-input-placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::-ms-input-placeholder{
      color:rgba(167, 182, 194, 0.6); }
    .bp3-dark .bp3-tag-input .bp3-input-ghost::placeholder, .bp3-tag-input.bp3-dark .bp3-input-ghost::placeholder{
      color:rgba(167, 182, 194, 0.6); }
  .bp3-dark .bp3-tag-input.bp3-active, .bp3-tag-input.bp3-dark.bp3-active{
    -webkit-box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px #137cbd, 0 0 0 1px #137cbd, 0 0 0 3px rgba(19, 124, 189, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
    background-color:rgba(16, 22, 26, 0.3); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-primary, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-primary{
      -webkit-box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #106ba3, 0 0 0 3px rgba(16, 107, 163, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-success, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-success{
      -webkit-box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #0d8050, 0 0 0 3px rgba(13, 128, 80, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-warning, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-warning{
      -webkit-box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #bf7326, 0 0 0 3px rgba(191, 115, 38, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }
    .bp3-dark .bp3-tag-input.bp3-active.bp3-intent-danger, .bp3-tag-input.bp3-dark.bp3-active.bp3-intent-danger{
      -webkit-box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4);
              box-shadow:0 0 0 1px #c23030, 0 0 0 3px rgba(194, 48, 48, 0.3), inset 0 0 0 1px rgba(16, 22, 26, 0.3), inset 0 1px 1px rgba(16, 22, 26, 0.4); }

.bp3-input-ghost{
  border:none;
  -webkit-box-shadow:none;
          box-shadow:none;
  background:none;
  padding:0; }
  .bp3-input-ghost::-webkit-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-moz-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::-ms-input-placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost::placeholder{
    opacity:1;
    color:rgba(92, 112, 128, 0.6); }
  .bp3-input-ghost:focus{
    outline:none !important; }
.bp3-toast{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:start;
      -ms-flex-align:start;
          align-items:flex-start;
  position:relative !important;
  margin:20px 0 0;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  min-width:300px;
  max-width:500px;
  pointer-events:all; }
  .bp3-toast.bp3-toast-enter, .bp3-toast.bp3-toast-appear{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active, .bp3-toast.bp3-toast-appear-active{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-enter ~ .bp3-toast, .bp3-toast.bp3-toast-appear ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px); }
  .bp3-toast.bp3-toast-enter-active ~ .bp3-toast, .bp3-toast.bp3-toast-appear-active ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
            transition-timing-function:cubic-bezier(0.54, 1.12, 0.38, 1.11);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit{
    opacity:1;
    -webkit-filter:blur(0);
            filter:blur(0); }
  .bp3-toast.bp3-toast-exit-active{
    opacity:0;
    -webkit-filter:blur(10px);
            filter:blur(10px);
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:opacity, filter;
    transition-property:opacity, filter, -webkit-filter;
    -webkit-transition-duration:300ms;
            transition-duration:300ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-toast.bp3-toast-exit ~ .bp3-toast{
    -webkit-transform:translateY(0);
            transform:translateY(0); }
  .bp3-toast.bp3-toast-exit-active ~ .bp3-toast{
    -webkit-transform:translateY(-40px);
            transform:translateY(-40px);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:50ms;
            transition-delay:50ms; }
  .bp3-toast .bp3-button-group{
    -webkit-box-flex:0;
        -ms-flex:0 0 auto;
            flex:0 0 auto;
    padding:5px;
    padding-left:0; }
  .bp3-toast > .bp3-icon{
    margin:12px;
    margin-right:0;
    color:#5c7080; }
  .bp3-toast.bp3-dark,
  .bp3-dark .bp3-toast{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
    background-color:#394b59; }
    .bp3-toast.bp3-dark > .bp3-icon,
    .bp3-dark .bp3-toast > .bp3-icon{
      color:#a7b6c2; }
  .bp3-toast[class*="bp3-intent-"] a{
    color:rgba(255, 255, 255, 0.7); }
    .bp3-toast[class*="bp3-intent-"] a:hover{
      color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] > .bp3-icon{
    color:#ffffff; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button, .bp3-toast[class*="bp3-intent-"] .bp3-button::before,
  .bp3-toast[class*="bp3-intent-"] .bp3-button .bp3-icon, .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    color:rgba(255, 255, 255, 0.7) !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:focus{
    outline-color:rgba(255, 255, 255, 0.5); }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:hover{
    background-color:rgba(255, 255, 255, 0.15) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button:active{
    background-color:rgba(255, 255, 255, 0.3) !important;
    color:#ffffff !important; }
  .bp3-toast[class*="bp3-intent-"] .bp3-button::after{
    background:rgba(255, 255, 255, 0.3) !important; }
  .bp3-toast.bp3-intent-primary{
    background-color:#137cbd;
    color:#ffffff; }
  .bp3-toast.bp3-intent-success{
    background-color:#0f9960;
    color:#ffffff; }
  .bp3-toast.bp3-intent-warning{
    background-color:#d9822b;
    color:#ffffff; }
  .bp3-toast.bp3-intent-danger{
    background-color:#db3737;
    color:#ffffff; }

.bp3-toast-message{
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  padding:11px;
  word-break:break-word; }

.bp3-toast-container{
  display:-webkit-box !important;
  display:-ms-flexbox !important;
  display:flex !important;
  -webkit-box-orient:vertical;
  -webkit-box-direction:normal;
      -ms-flex-direction:column;
          flex-direction:column;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  position:fixed;
  right:0;
  left:0;
  z-index:40;
  overflow:hidden;
  padding:0 20px 20px;
  pointer-events:none; }
  .bp3-toast-container.bp3-toast-container-top{
    top:0;
    bottom:auto; }
  .bp3-toast-container.bp3-toast-container-bottom{
    -webkit-box-orient:vertical;
    -webkit-box-direction:reverse;
        -ms-flex-direction:column-reverse;
            flex-direction:column-reverse;
    top:auto;
    bottom:0; }
  .bp3-toast-container.bp3-toast-container-left{
    -webkit-box-align:start;
        -ms-flex-align:start;
            align-items:flex-start; }
  .bp3-toast-container.bp3-toast-container-right{
    -webkit-box-align:end;
        -ms-flex-align:end;
            align-items:flex-end; }

.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-enter:not(.bp3-toast-enter-active) ~ .bp3-toast, .bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active),
.bp3-toast-container-bottom .bp3-toast.bp3-toast-appear:not(.bp3-toast-appear-active) ~ .bp3-toast,
.bp3-toast-container-bottom .bp3-toast.bp3-toast-leave-active ~ .bp3-toast{
  -webkit-transform:translateY(60px);
          transform:translateY(60px); }
.bp3-tooltip{
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 2px 4px rgba(16, 22, 26, 0.2), 0 8px 24px rgba(16, 22, 26, 0.2);
  -webkit-transform:scale(1);
          transform:scale(1); }
  .bp3-tooltip .bp3-popover-arrow{
    position:absolute;
    width:22px;
    height:22px; }
    .bp3-tooltip .bp3-popover-arrow::before{
      margin:4px;
      width:14px;
      height:14px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip{
    margin-top:-11px;
    margin-bottom:11px; }
    .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
      bottom:-8px; }
      .bp3-tether-element-attached-bottom.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(-90deg);
                transform:rotate(-90deg); }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip{
    margin-left:11px; }
    .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
      left:-8px; }
      .bp3-tether-element-attached-left.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(0);
                transform:rotate(0); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip{
    margin-top:11px; }
    .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
      top:-8px; }
      .bp3-tether-element-attached-top.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(90deg);
                transform:rotate(90deg); }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip{
    margin-right:11px;
    margin-left:-11px; }
    .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
      right:-8px; }
      .bp3-tether-element-attached-right.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow svg{
        -webkit-transform:rotate(180deg);
                transform:rotate(180deg); }
  .bp3-tether-element-attached-middle > .bp3-tooltip > .bp3-popover-arrow{
    top:50%;
    -webkit-transform:translateY(-50%);
            transform:translateY(-50%); }
  .bp3-tether-element-attached-center > .bp3-tooltip > .bp3-popover-arrow{
    right:50%;
    -webkit-transform:translateX(50%);
            transform:translateX(50%); }
  .bp3-tether-element-attached-top.bp3-tether-target-attached-top > .bp3-tooltip > .bp3-popover-arrow{
    top:-0.22183px; }
  .bp3-tether-element-attached-right.bp3-tether-target-attached-right > .bp3-tooltip > .bp3-popover-arrow{
    right:-0.22183px; }
  .bp3-tether-element-attached-left.bp3-tether-target-attached-left > .bp3-tooltip > .bp3-popover-arrow{
    left:-0.22183px; }
  .bp3-tether-element-attached-bottom.bp3-tether-target-attached-bottom > .bp3-tooltip > .bp3-popover-arrow{
    bottom:-0.22183px; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:top left;
            transform-origin:top left; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:top center;
            transform-origin:top center; }
  .bp3-tether-element-attached-top.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:top right;
            transform-origin:top right; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:center left;
            transform-origin:center left; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:center center;
            transform-origin:center center; }
  .bp3-tether-element-attached-middle.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:center right;
            transform-origin:center right; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-left > .bp3-tooltip{
    -webkit-transform-origin:bottom left;
            transform-origin:bottom left; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-center > .bp3-tooltip{
    -webkit-transform-origin:bottom center;
            transform-origin:bottom center; }
  .bp3-tether-element-attached-bottom.bp3-tether-element-attached-right > .bp3-tooltip{
    -webkit-transform-origin:bottom right;
            transform-origin:bottom right; }
  .bp3-tooltip .bp3-popover-content{
    background:#394b59;
    color:#f5f8fa; }
  .bp3-tooltip .bp3-popover-arrow::before{
    -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2);
            box-shadow:1px 1px 6px rgba(16, 22, 26, 0.2); }
  .bp3-tooltip .bp3-popover-arrow-border{
    fill:#10161a;
    fill-opacity:0.1; }
  .bp3-tooltip .bp3-popover-arrow-fill{
    fill:#394b59; }
  .bp3-popover-enter > .bp3-tooltip, .bp3-popover-appear > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8); }
  .bp3-popover-enter-active > .bp3-tooltip, .bp3-popover-appear-active > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-popover-exit > .bp3-tooltip{
    -webkit-transform:scale(1);
            transform:scale(1); }
  .bp3-popover-exit-active > .bp3-tooltip{
    -webkit-transform:scale(0.8);
            transform:scale(0.8);
    -webkit-transition-property:-webkit-transform;
    transition-property:-webkit-transform;
    transition-property:transform;
    transition-property:transform, -webkit-transform;
    -webkit-transition-duration:100ms;
            transition-duration:100ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-tooltip .bp3-popover-content{
    padding:10px 12px; }
  .bp3-tooltip.bp3-dark,
  .bp3-dark .bp3-tooltip{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 2px 4px rgba(16, 22, 26, 0.4), 0 8px 24px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-content,
    .bp3-dark .bp3-tooltip .bp3-popover-content{
      background:#e1e8ed;
      color:#394b59; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow::before,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow::before{
      -webkit-box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4);
              box-shadow:1px 1px 6px rgba(16, 22, 26, 0.4); }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-border,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-border{
      fill:#10161a;
      fill-opacity:0.2; }
    .bp3-tooltip.bp3-dark .bp3-popover-arrow-fill,
    .bp3-dark .bp3-tooltip .bp3-popover-arrow-fill{
      fill:#e1e8ed; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-content{
    background:#137cbd;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-primary .bp3-popover-arrow-fill{
    fill:#137cbd; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-content{
    background:#0f9960;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-success .bp3-popover-arrow-fill{
    fill:#0f9960; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-content{
    background:#d9822b;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-warning .bp3-popover-arrow-fill{
    fill:#d9822b; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-content{
    background:#db3737;
    color:#ffffff; }
  .bp3-tooltip.bp3-intent-danger .bp3-popover-arrow-fill{
    fill:#db3737; }

.bp3-tooltip-indicator{
  border-bottom:dotted 1px;
  cursor:help; }
.bp3-tree .bp3-icon, .bp3-tree .bp3-icon-standard, .bp3-tree .bp3-icon-large{
  color:#5c7080; }
  .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-tree .bp3-icon.bp3-intent-success, .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-tree-node-list{
  margin:0;
  padding-left:0;
  list-style:none; }

.bp3-tree-root{
  position:relative;
  background-color:transparent;
  cursor:default;
  padding-left:0; }

.bp3-tree-node-content-0{
  padding-left:0px; }

.bp3-tree-node-content-1{
  padding-left:23px; }

.bp3-tree-node-content-2{
  padding-left:46px; }

.bp3-tree-node-content-3{
  padding-left:69px; }

.bp3-tree-node-content-4{
  padding-left:92px; }

.bp3-tree-node-content-5{
  padding-left:115px; }

.bp3-tree-node-content-6{
  padding-left:138px; }

.bp3-tree-node-content-7{
  padding-left:161px; }

.bp3-tree-node-content-8{
  padding-left:184px; }

.bp3-tree-node-content-9{
  padding-left:207px; }

.bp3-tree-node-content-10{
  padding-left:230px; }

.bp3-tree-node-content-11{
  padding-left:253px; }

.bp3-tree-node-content-12{
  padding-left:276px; }

.bp3-tree-node-content-13{
  padding-left:299px; }

.bp3-tree-node-content-14{
  padding-left:322px; }

.bp3-tree-node-content-15{
  padding-left:345px; }

.bp3-tree-node-content-16{
  padding-left:368px; }

.bp3-tree-node-content-17{
  padding-left:391px; }

.bp3-tree-node-content-18{
  padding-left:414px; }

.bp3-tree-node-content-19{
  padding-left:437px; }

.bp3-tree-node-content-20{
  padding-left:460px; }

.bp3-tree-node-content{
  display:-webkit-box;
  display:-ms-flexbox;
  display:flex;
  -webkit-box-align:center;
      -ms-flex-align:center;
          align-items:center;
  width:100%;
  height:30px;
  padding-right:5px; }
  .bp3-tree-node-content:hover{
    background-color:rgba(191, 204, 214, 0.4); }

.bp3-tree-node-caret,
.bp3-tree-node-caret-none{
  min-width:30px; }

.bp3-tree-node-caret{
  color:#5c7080;
  -webkit-transform:rotate(0deg);
          transform:rotate(0deg);
  cursor:pointer;
  padding:7px;
  -webkit-transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:-webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9);
  transition:transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9), -webkit-transform 200ms cubic-bezier(0.4, 1, 0.75, 0.9); }
  .bp3-tree-node-caret:hover{
    color:#182026; }
  .bp3-dark .bp3-tree-node-caret{
    color:#a7b6c2; }
    .bp3-dark .bp3-tree-node-caret:hover{
      color:#f5f8fa; }
  .bp3-tree-node-caret.bp3-tree-node-caret-open{
    -webkit-transform:rotate(90deg);
            transform:rotate(90deg); }
  .bp3-tree-node-caret.bp3-icon-standard::before{
    content:""; }

.bp3-tree-node-icon{
  position:relative;
  margin-right:7px; }

.bp3-tree-node-label{
  overflow:hidden;
  text-overflow:ellipsis;
  white-space:nowrap;
  word-wrap:normal;
  -webkit-box-flex:1;
      -ms-flex:1 1 auto;
          flex:1 1 auto;
  position:relative;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-label span{
    display:inline; }

.bp3-tree-node-secondary-label{
  padding:0 5px;
  -webkit-user-select:none;
     -moz-user-select:none;
      -ms-user-select:none;
          user-select:none; }
  .bp3-tree-node-secondary-label .bp3-popover-wrapper,
  .bp3-tree-node-secondary-label .bp3-popover-target{
    display:-webkit-box;
    display:-ms-flexbox;
    display:flex;
    -webkit-box-align:center;
        -ms-flex-align:center;
            align-items:center; }

.bp3-tree-node.bp3-disabled .bp3-tree-node-content{
  background-color:inherit;
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-disabled .bp3-tree-node-caret,
.bp3-tree-node.bp3-disabled .bp3-tree-node-icon{
  cursor:not-allowed;
  color:rgba(92, 112, 128, 0.6); }

.bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content,
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-standard, .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-icon-large{
    color:#ffffff; }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret::before{
    color:rgba(255, 255, 255, 0.7); }
  .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content .bp3-tree-node-caret:hover::before{
    color:#ffffff; }

.bp3-dark .bp3-tree-node-content:hover{
  background-color:rgba(92, 112, 128, 0.3); }

.bp3-dark .bp3-tree .bp3-icon, .bp3-dark .bp3-tree .bp3-icon-standard, .bp3-dark .bp3-tree .bp3-icon-large{
  color:#a7b6c2; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-primary, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-primary{
    color:#137cbd; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-success, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-success{
    color:#0f9960; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-warning, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-warning{
    color:#d9822b; }
  .bp3-dark .bp3-tree .bp3-icon.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-standard.bp3-intent-danger, .bp3-dark .bp3-tree .bp3-icon-large.bp3-intent-danger{
    color:#db3737; }

.bp3-dark .bp3-tree-node.bp3-tree-node-selected > .bp3-tree-node-content{
  background-color:#137cbd; }
/*!

Copyright 2017-present Palantir Technologies, Inc. All rights reserved.
Licensed under the Apache License, Version 2.0.

*/
.bp3-omnibar{
  -webkit-filter:blur(0);
          filter:blur(0);
  opacity:1;
  top:20vh;
  left:calc(50% - 250px);
  z-index:21;
  border-radius:3px;
  -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
          box-shadow:0 0 0 1px rgba(16, 22, 26, 0.1), 0 4px 8px rgba(16, 22, 26, 0.2), 0 18px 46px 6px rgba(16, 22, 26, 0.2);
  background-color:#ffffff;
  width:500px; }
  .bp3-omnibar.bp3-overlay-enter, .bp3-omnibar.bp3-overlay-appear{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2; }
  .bp3-omnibar.bp3-overlay-enter-active, .bp3-omnibar.bp3-overlay-appear-active{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar.bp3-overlay-exit{
    -webkit-filter:blur(0);
            filter:blur(0);
    opacity:1; }
  .bp3-omnibar.bp3-overlay-exit-active{
    -webkit-filter:blur(20px);
            filter:blur(20px);
    opacity:0.2;
    -webkit-transition-property:opacity, -webkit-filter;
    transition-property:opacity, -webkit-filter;
    transition-property:filter, opacity;
    transition-property:filter, opacity, -webkit-filter;
    -webkit-transition-duration:200ms;
            transition-duration:200ms;
    -webkit-transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
            transition-timing-function:cubic-bezier(0.4, 1, 0.75, 0.9);
    -webkit-transition-delay:0;
            transition-delay:0; }
  .bp3-omnibar .bp3-input{
    border-radius:0;
    background-color:transparent; }
    .bp3-omnibar .bp3-input, .bp3-omnibar .bp3-input:focus{
      -webkit-box-shadow:none;
              box-shadow:none; }
  .bp3-omnibar .bp3-menu{
    border-radius:0;
    -webkit-box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
            box-shadow:inset 0 1px 0 rgba(16, 22, 26, 0.15);
    background-color:transparent;
    max-height:calc(60vh - 40px);
    overflow:auto; }
    .bp3-omnibar .bp3-menu:empty{
      display:none; }
  .bp3-dark .bp3-omnibar, .bp3-omnibar.bp3-dark{
    -webkit-box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
            box-shadow:0 0 0 1px rgba(16, 22, 26, 0.2), 0 4px 8px rgba(16, 22, 26, 0.4), 0 18px 46px 6px rgba(16, 22, 26, 0.4);
    background-color:#30404d; }

.bp3-omnibar-overlay .bp3-overlay-backdrop{
  background-color:rgba(16, 22, 26, 0.2); }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }

.bp3-multi-select{
  min-width:150px; }

.bp3-multi-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto; }

.bp3-select-popover .bp3-popover-content{
  padding:5px; }

.bp3-select-popover .bp3-input-group{
  margin-bottom:0; }

.bp3-select-popover .bp3-menu{
  max-width:400px;
  max-height:300px;
  overflow:auto;
  padding:0; }
  .bp3-select-popover .bp3-menu:not(:first-child){
    padding-top:5px; }
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensureUiComponents() in @jupyterlab/buildutils */

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

/* Icons urls */

:root {
  --jp-icon-add: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-bug: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDhoLTIuODFjLS40NS0uNzgtMS4wNy0xLjQ1LTEuODItMS45NkwxNyA0LjQxIDE1LjU5IDNsLTIuMTcgMi4xN0MxMi45NiA1LjA2IDEyLjQ5IDUgMTIgNWMtLjQ5IDAtLjk2LjA2LTEuNDEuMTdMOC40MSAzIDcgNC40MWwxLjYyIDEuNjNDNy44OCA2LjU1IDcuMjYgNy4yMiA2LjgxIDhINHYyaDIuMDljLS4wNS4zMy0uMDkuNjYtLjA5IDF2MUg0djJoMnYxYzAgLjM0LjA0LjY3LjA5IDFINHYyaDIuODFjMS4wNCAxLjc5IDIuOTcgMyA1LjE5IDNzNC4xNS0xLjIxIDUuMTktM0gyMHYtMmgtMi4wOWMuMDUtLjMzLjA5LS42Ni4wOS0xdi0xaDJ2LTJoLTJ2LTFjMC0uMzQtLjA0LS42Ny0uMDktMUgyMFY4em0tNiA4aC00di0yaDR2MnptMC00aC00di0yaDR2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-build: url(data:image/svg+xml;base64,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);
  --jp-icon-caret-down-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-caret-down: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-left: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-right: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-caret-up-empty-thin: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);
  --jp-icon-caret-up: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-case-sensitive: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-check: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTYuMTdMNC44MyAxMmwtMS40MiAxLjQxTDkgMTkgMjEgN2wtMS40MS0xLjQxeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle-empty: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-circle: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-clear: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-close: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-console: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1pY29uLWJyYW5kMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNmZmYiPgogICAgPHBhdGggZD0iTTEwNSAxMjcuM2g0MHYxMi44aC00MHpNNTEuMSA3N0w3NCA5OS45bC0yMy4zIDIzLjMgMTAuNSAxMC41IDIzLjMtMjMuM0w5NSA5OS45IDg0LjUgODkuNCA2MS42IDY2LjV6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-copy: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-cut: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-download: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-edit: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-ellipses: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-extension: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-fast-forward: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-file-upload: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-file: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-filter-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-html5: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);
  --jp-icon-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-inspector: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);
  --jp-icon-json: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMSBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNGOUE4MjUiPgogICAgPHBhdGggZD0iTTIwLjIgMTEuOGMtMS42IDAtMS43LjUtMS43IDEgMCAuNC4xLjkuMSAxLjMuMS41LjEuOS4xIDEuMyAwIDEuNy0xLjQgMi4zLTMuNSAyLjNoLS45di0xLjloLjVjMS4xIDAgMS40IDAgMS40LS44IDAtLjMgMC0uNi0uMS0xIDAtLjQtLjEtLjgtLjEtMS4yIDAtMS4zIDAtMS44IDEuMy0yLTEuMy0uMi0xLjMtLjctMS4zLTIgMC0uNC4xLS44LjEtMS4yLjEtLjQuMS0uNy4xLTEgMC0uOC0uNC0uNy0xLjQtLjhoLS41VjQuMWguOWMyLjIgMCAzLjUuNyAzLjUgMi4zIDAgLjQtLjEuOS0uMSAxLjMtLjEuNS0uMS45LS4xIDEuMyAwIC41LjIgMSAxLjcgMXYxLjh6TTEuOCAxMC4xYzEuNiAwIDEuNy0uNSAxLjctMSAwLS40LS4xLS45LS4xLTEuMy0uMS0uNS0uMS0uOS0uMS0xLjMgMC0xLjYgMS40LTIuMyAzLjUtMi4zaC45djEuOWgtLjVjLTEgMC0xLjQgMC0xLjQuOCAwIC4zIDAgLjYuMSAxIDAgLjIuMS42LjEgMSAwIDEuMyAwIDEuOC0xLjMgMkM2IDExLjIgNiAxMS43IDYgMTNjMCAuNC0uMS44LS4xIDEuMi0uMS4zLS4xLjctLjEgMSAwIC44LjMuOCAxLjQuOGguNXYxLjloLS45Yy0yLjEgMC0zLjUtLjYtMy41LTIuMyAwLS40LjEtLjkuMS0xLjMuMS0uNS4xLS45LjEtMS4zIDAtLjUtLjItMS0xLjctMXYtMS45eiIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSIxMy44IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY3g9IjExIiBjeT0iOC4yIiByPSIyLjEiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter-favicon: url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-jupyter: url(data:image/svg+xml;base64,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);
  --jp-icon-jupyterlab-wordmark: url(data:image/svg+xml;base64,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);
  --jp-icon-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);
  --jp-icon-keyboard: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);
  --jp-icon-launcher: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);
  --jp-icon-line-form: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-link: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-list: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4=);
  --jp-icon-listings-info: url(data:image/svg+xml;base64,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);
  --jp-icon-markdown: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);
  --jp-icon-new-folder: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-not-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);
  --jp-icon-notebook: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi13YXJuMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-palette: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-paste: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-python: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMEQ0N0ExIj4KICAgIDxwYXRoIGQ9Ik0xMS4xIDYuOVY1LjhINi45YzAtLjUgMC0xLjMuMi0xLjYuNC0uNy44LTEuMSAxLjctMS40IDEuNy0uMyAyLjUtLjMgMy45LS4xIDEgLjEgMS45LjkgMS45IDEuOXY0LjJjMCAuNS0uOSAxLjYtMiAxLjZIOC44Yy0xLjUgMC0yLjQgMS40LTIuNCAyLjh2Mi4ySDQuN0MzLjUgMTUuMSAzIDE0IDMgMTMuMVY5Yy0uMS0xIC42LTIgMS44LTIgMS41LS4xIDYuMy0uMSA2LjMtLjF6Ii8+CiAgICA8cGF0aCBkPSJNMTAuOSAxNS4xdjEuMWg0LjJjMCAuNSAwIDEuMy0uMiAxLjYtLjQuNy0uOCAxLjEtMS43IDEuNC0xLjcuMy0yLjUuMy0zLjkuMS0xLS4xLTEuOS0uOS0xLjktMS45di00LjJjMC0uNS45LTEuNiAyLTEuNmgzLjhjMS41IDAgMi40LTEuNCAyLjQtMi44VjYuNmgxLjdDMTguNSA2LjkgMTkgOCAxOSA4LjlWMTNjMCAxLS43IDIuMS0xLjkgMi4xaC02LjJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-r-kernel: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);
  --jp-icon-react: url(data:image/svg+xml;base64,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);
  --jp-icon-refresh: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);
  --jp-icon-regex: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-run: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-running: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-save: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);
  --jp-icon-search: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-settings: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);
  --jp-icon-spreadsheet: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-stop: url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-tab: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);
  --jp-icon-terminal: url(data:image/svg+xml;base64,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);
  --jp-icon-text-editor: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTUgMTVIM3YyaDEydi0yem0wLThIM3YyaDEyVjd6TTMgMTNoMTh2LTJIM3Yyem0wIDhoMTh2LTJIM3Yyek0zIDN2MmgxOFYzSDN6Ii8+Cjwvc3ZnPgo=);
  --jp-icon-trusted: url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);
  --jp-icon-undo: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-vega: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);
  --jp-icon-yaml: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K);
}

/* Icon CSS class declarations */

.jp-AddIcon {
  background-image: var(--jp-icon-add);
}
.jp-BugIcon {
  background-image: var(--jp-icon-bug);
}
.jp-BuildIcon {
  background-image: var(--jp-icon-build);
}
.jp-CaretDownEmptyIcon {
  background-image: var(--jp-icon-caret-down-empty);
}
.jp-CaretDownEmptyThinIcon {
  background-image: var(--jp-icon-caret-down-empty-thin);
}
.jp-CaretDownIcon {
  background-image: var(--jp-icon-caret-down);
}
.jp-CaretLeftIcon {
  background-image: var(--jp-icon-caret-left);
}
.jp-CaretRightIcon {
  background-image: var(--jp-icon-caret-right);
}
.jp-CaretUpEmptyThinIcon {
  background-image: var(--jp-icon-caret-up-empty-thin);
}
.jp-CaretUpIcon {
  background-image: var(--jp-icon-caret-up);
}
.jp-CaseSensitiveIcon {
  background-image: var(--jp-icon-case-sensitive);
}
.jp-CheckIcon {
  background-image: var(--jp-icon-check);
}
.jp-CircleEmptyIcon {
  background-image: var(--jp-icon-circle-empty);
}
.jp-CircleIcon {
  background-image: var(--jp-icon-circle);
}
.jp-ClearIcon {
  background-image: var(--jp-icon-clear);
}
.jp-CloseIcon {
  background-image: var(--jp-icon-close);
}
.jp-ConsoleIcon {
  background-image: var(--jp-icon-console);
}
.jp-CopyIcon {
  background-image: var(--jp-icon-copy);
}
.jp-CutIcon {
  background-image: var(--jp-icon-cut);
}
.jp-DownloadIcon {
  background-image: var(--jp-icon-download);
}
.jp-EditIcon {
  background-image: var(--jp-icon-edit);
}
.jp-EllipsesIcon {
  background-image: var(--jp-icon-ellipses);
}
.jp-ExtensionIcon {
  background-image: var(--jp-icon-extension);
}
.jp-FastForwardIcon {
  background-image: var(--jp-icon-fast-forward);
}
.jp-FileIcon {
  background-image: var(--jp-icon-file);
}
.jp-FileUploadIcon {
  background-image: var(--jp-icon-file-upload);
}
.jp-FilterListIcon {
  background-image: var(--jp-icon-filter-list);
}
.jp-FolderIcon {
  background-image: var(--jp-icon-folder);
}
.jp-Html5Icon {
  background-image: var(--jp-icon-html5);
}
.jp-ImageIcon {
  background-image: var(--jp-icon-image);
}
.jp-InspectorIcon {
  background-image: var(--jp-icon-inspector);
}
.jp-JsonIcon {
  background-image: var(--jp-icon-json);
}
.jp-JupyterFaviconIcon {
  background-image: var(--jp-icon-jupyter-favicon);
}
.jp-JupyterIcon {
  background-image: var(--jp-icon-jupyter);
}
.jp-JupyterlabWordmarkIcon {
  background-image: var(--jp-icon-jupyterlab-wordmark);
}
.jp-KernelIcon {
  background-image: var(--jp-icon-kernel);
}
.jp-KeyboardIcon {
  background-image: var(--jp-icon-keyboard);
}
.jp-LauncherIcon {
  background-image: var(--jp-icon-launcher);
}
.jp-LineFormIcon {
  background-image: var(--jp-icon-line-form);
}
.jp-LinkIcon {
  background-image: var(--jp-icon-link);
}
.jp-ListIcon {
  background-image: var(--jp-icon-list);
}
.jp-ListingsInfoIcon {
  background-image: var(--jp-icon-listings-info);
}
.jp-MarkdownIcon {
  background-image: var(--jp-icon-markdown);
}
.jp-NewFolderIcon {
  background-image: var(--jp-icon-new-folder);
}
.jp-NotTrustedIcon {
  background-image: var(--jp-icon-not-trusted);
}
.jp-NotebookIcon {
  background-image: var(--jp-icon-notebook);
}
.jp-PaletteIcon {
  background-image: var(--jp-icon-palette);
}
.jp-PasteIcon {
  background-image: var(--jp-icon-paste);
}
.jp-PythonIcon {
  background-image: var(--jp-icon-python);
}
.jp-RKernelIcon {
  background-image: var(--jp-icon-r-kernel);
}
.jp-ReactIcon {
  background-image: var(--jp-icon-react);
}
.jp-RefreshIcon {
  background-image: var(--jp-icon-refresh);
}
.jp-RegexIcon {
  background-image: var(--jp-icon-regex);
}
.jp-RunIcon {
  background-image: var(--jp-icon-run);
}
.jp-RunningIcon {
  background-image: var(--jp-icon-running);
}
.jp-SaveIcon {
  background-image: var(--jp-icon-save);
}
.jp-SearchIcon {
  background-image: var(--jp-icon-search);
}
.jp-SettingsIcon {
  background-image: var(--jp-icon-settings);
}
.jp-SpreadsheetIcon {
  background-image: var(--jp-icon-spreadsheet);
}
.jp-StopIcon {
  background-image: var(--jp-icon-stop);
}
.jp-TabIcon {
  background-image: var(--jp-icon-tab);
}
.jp-TerminalIcon {
  background-image: var(--jp-icon-terminal);
}
.jp-TextEditorIcon {
  background-image: var(--jp-icon-text-editor);
}
.jp-TrustedIcon {
  background-image: var(--jp-icon-trusted);
}
.jp-UndoIcon {
  background-image: var(--jp-icon-undo);
}
.jp-VegaIcon {
  background-image: var(--jp-icon-vega);
}
.jp-YamlIcon {
  background-image: var(--jp-icon-yaml);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * (DEPRECATED) Support for consuming icons as CSS background images
 */

:root {
  --jp-icon-search-white: url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);
}

.jp-Icon,
.jp-MaterialIcon {
  background-position: center;
  background-repeat: no-repeat;
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-cover {
  background-position: center;
  background-repeat: no-repeat;
  background-size: cover;
}

/**
 * (DEPRECATED) Support for specific CSS icon sizes
 */

.jp-Icon-16 {
  background-size: 16px;
  min-width: 16px;
  min-height: 16px;
}

.jp-Icon-18 {
  background-size: 18px;
  min-width: 18px;
  min-height: 18px;
}

.jp-Icon-20 {
  background-size: 20px;
  min-width: 20px;
  min-height: 20px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for icons as inline SVG HTMLElements
 */

/* recolor the primary elements of an icon */
.jp-icon0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}
/* recolor the accent elements of an icon */
.jp-icon-accent0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-accent1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-accent2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-accent3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-accent4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-accent0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-accent1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-accent2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-accent3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-accent4[stroke] {
  stroke: var(--jp-layout-color4);
}
/* set the color of an icon to transparent */
.jp-icon-none[fill] {
  fill: none;
}

.jp-icon-none[stroke] {
  stroke: none;
}
/* brand icon colors. Same for light and dark */
.jp-icon-brand0[fill] {
  fill: var(--jp-brand-color0);
}
.jp-icon-brand1[fill] {
  fill: var(--jp-brand-color1);
}
.jp-icon-brand2[fill] {
  fill: var(--jp-brand-color2);
}
.jp-icon-brand3[fill] {
  fill: var(--jp-brand-color3);
}
.jp-icon-brand4[fill] {
  fill: var(--jp-brand-color4);
}

.jp-icon-brand0[stroke] {
  stroke: var(--jp-brand-color0);
}
.jp-icon-brand1[stroke] {
  stroke: var(--jp-brand-color1);
}
.jp-icon-brand2[stroke] {
  stroke: var(--jp-brand-color2);
}
.jp-icon-brand3[stroke] {
  stroke: var(--jp-brand-color3);
}
.jp-icon-brand4[stroke] {
  stroke: var(--jp-brand-color4);
}
/* warn icon colors. Same for light and dark */
.jp-icon-warn0[fill] {
  fill: var(--jp-warn-color0);
}
.jp-icon-warn1[fill] {
  fill: var(--jp-warn-color1);
}
.jp-icon-warn2[fill] {
  fill: var(--jp-warn-color2);
}
.jp-icon-warn3[fill] {
  fill: var(--jp-warn-color3);
}

.jp-icon-warn0[stroke] {
  stroke: var(--jp-warn-color0);
}
.jp-icon-warn1[stroke] {
  stroke: var(--jp-warn-color1);
}
.jp-icon-warn2[stroke] {
  stroke: var(--jp-warn-color2);
}
.jp-icon-warn3[stroke] {
  stroke: var(--jp-warn-color3);
}
/* icon colors that contrast well with each other and most backgrounds */
.jp-icon-contrast0[fill] {
  fill: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[fill] {
  fill: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[fill] {
  fill: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[fill] {
  fill: var(--jp-icon-contrast-color3);
}

.jp-icon-contrast0[stroke] {
  stroke: var(--jp-icon-contrast-color0);
}
.jp-icon-contrast1[stroke] {
  stroke: var(--jp-icon-contrast-color1);
}
.jp-icon-contrast2[stroke] {
  stroke: var(--jp-icon-contrast-color2);
}
.jp-icon-contrast3[stroke] {
  stroke: var(--jp-icon-contrast-color3);
}

/* CSS for icons in selected items in the settings editor */
#setting-editor .jp-PluginList .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
#setting-editor
  .jp-PluginList
  .jp-mod-selected
  .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected filebrowser listing items */
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}
.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}

/* CSS for icons in selected tabs in the sidebar tab manager */
#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable[fill] {
  fill: #fff;
}

#tab-manager .lm-TabBar-tab.jp-mod-active .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable[fill] {
  fill: var(--jp-brand-color1);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-active
  .jp-icon-hover
  :hover
  .jp-icon-selectable-inverse[fill] {
  fill: #fff;
}

/**
 * TODO: come up with non css-hack solution for showing the busy icon on top
 *  of the close icon
 * CSS for complex behavior of close icon of tabs in the sidebar tab manager
 */
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
#tab-manager
  .lm-TabBar-tab.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

#tab-manager
  .lm-TabBar-tab.jp-mod-dirty.jp-mod-active
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: #fff;
}

/**
* TODO: come up with non css-hack solution for showing the busy icon on top
*  of the close icon
* CSS for complex behavior of close icon of tabs in the main area tabbar
*/
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon3[fill] {
  fill: none;
}
.lm-DockPanel-tabBar
  .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty
  > .lm-TabBar-tabCloseIcon
  > :not(:hover)
  > .jp-icon-busy[fill] {
  fill: var(--jp-inverse-layout-color3);
}

/* CSS for icons in status bar */
#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill] {
  fill: #fff;
}

#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill] {
  fill: var(--jp-brand-color1);
}
/* special handling for splash icon CSS. While the theme CSS reloads during
   splash, the splash icon can loose theming. To prevent that, we set a
   default for its color variable */
:root {
  --jp-warn-color0: var(--md-orange-700);
}

/* not sure what to do with this one, used in filebrowser listing */
.jp-DragIcon {
  margin-right: 4px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/**
 * Support for alt colors for icons as inline SVG HTMLElements
 */

/* alt recolor the primary elements of an icon */
.jp-icon-alt .jp-icon0[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-alt .jp-icon0[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-alt .jp-icon1[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-alt .jp-icon2[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-alt .jp-icon3[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-alt .jp-icon4[stroke] {
  stroke: var(--jp-layout-color4);
}

/* alt recolor the accent elements of an icon */
.jp-icon-alt .jp-icon-accent0[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-alt .jp-icon-accent0[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-alt .jp-icon-accent1[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-alt .jp-icon-accent2[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-alt .jp-icon-accent3[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-alt .jp-icon-accent4[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-icon-hoverShow:not(:hover) svg {
  display: none !important;
}

/**
 * Support for hover colors for icons as inline SVG HTMLElements
 */

/**
 * regular colors
 */

/* recolor the primary elements of an icon */
.jp-icon-hover :hover .jp-icon0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/* recolor the accent elements of an icon */
.jp-icon-hover :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* set the color of an icon to transparent */
.jp-icon-hover :hover .jp-icon-none-hover[fill] {
  fill: none;
}

.jp-icon-hover :hover .jp-icon-none-hover[stroke] {
  stroke: none;
}

/**
 * inverse colors
 */

/* inverse recolor the primary elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill] {
  fill: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill] {
  fill: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill] {
  fill: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill] {
  fill: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill] {
  fill: var(--jp-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke] {
  stroke: var(--jp-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke] {
  stroke: var(--jp-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke] {
  stroke: var(--jp-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke] {
  stroke: var(--jp-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke] {
  stroke: var(--jp-layout-color4);
}

/* inverse recolor the accent elements of an icon */
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill] {
  fill: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill] {
  fill: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill] {
  fill: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill] {
  fill: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill] {
  fill: var(--jp-inverse-layout-color4);
}

.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke] {
  stroke: var(--jp-inverse-layout-color0);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke] {
  stroke: var(--jp-inverse-layout-color1);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke] {
  stroke: var(--jp-inverse-layout-color2);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke] {
  stroke: var(--jp-inverse-layout-color3);
}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke] {
  stroke: var(--jp-inverse-layout-color4);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* Sibling imports */

/* Override Blueprint's _reset.scss styles */
html {
  box-sizing: unset;
}

*,
*::before,
*::after {
  box-sizing: unset;
}

body {
  color: unset;
  font-family: var(--jp-ui-font-family);
}

p {
  margin-top: unset;
  margin-bottom: unset;
}

small {
  font-size: unset;
}

strong {
  font-weight: unset;
}

/* Override Blueprint's _typography.scss styles */
a {
  text-decoration: unset;
  color: unset;
}
a:hover {
  text-decoration: unset;
  color: unset;
}

/* Override Blueprint's _accessibility.scss styles */
:focus {
  outline: unset;
  outline-offset: unset;
  -moz-outline-radius: unset;
}

/* Styles for ui-components */
.jp-Button {
  border-radius: var(--jp-border-radius);
  padding: 0px 12px;
  font-size: var(--jp-ui-font-size1);
}

/* Use our own theme for hover styles */
button.jp-Button.bp3-button.bp3-minimal:hover {
  background-color: var(--jp-layout-color2);
}
.jp-Button.minimal {
  color: unset !important;
}

.jp-Button.jp-ToolbarButtonComponent {
  text-transform: none;
}

.jp-InputGroup input {
  box-sizing: border-box;
  border-radius: 0;
  background-color: transparent;
  color: var(--jp-ui-font-color0);
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.jp-InputGroup input:focus {
  box-shadow: inset 0 0 0 var(--jp-border-width)
      var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.jp-InputGroup input::placeholder,
input::placeholder {
  color: var(--jp-ui-font-color3);
}

.jp-BPIcon {
  display: inline-block;
  vertical-align: middle;
  margin: auto;
}

/* Stop blueprint futzing with our icon fills */
.bp3-icon.jp-BPIcon > svg:not([fill]) {
  fill: var(--jp-inverse-layout-color3);
}

.jp-InputGroupAction {
  padding: 6px;
}

.jp-HTMLSelect.jp-DefaultStyle select {
  background-color: initial;
  border: none;
  border-radius: 0;
  box-shadow: none;
  color: var(--jp-ui-font-color0);
  display: block;
  font-size: var(--jp-ui-font-size1);
  height: 24px;
  line-height: 14px;
  padding: 0 25px 0 10px;
  text-align: left;
  -moz-appearance: none;
  -webkit-appearance: none;
}

/* Use our own theme for hover and option styles */
.jp-HTMLSelect.jp-DefaultStyle select:hover,
.jp-HTMLSelect.jp-DefaultStyle select > option {
  background-color: var(--jp-layout-color2);
  color: var(--jp-ui-font-color0);
}
select {
  box-sizing: border-box;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapse {
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-top: 1px solid var(--jp-border-color2);
  border-bottom: 1px solid var(--jp-border-color2);
}

.jp-Collapse-header {
  padding: 1px 12px;
  color: var(--jp-ui-font-color1);
  background-color: var(--jp-layout-color1);
  font-size: var(--jp-ui-font-size2);
}

.jp-Collapse-header:hover {
  background-color: var(--jp-layout-color2);
}

.jp-Collapse-contents {
  padding: 0px 12px 0px 12px;
  background-color: var(--jp-layout-color1);
  color: var(--jp-ui-font-color1);
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-commandpalette-search-height: 28px;
}

/*-----------------------------------------------------------------------------
| Overall styles
|----------------------------------------------------------------------------*/

.lm-CommandPalette {
  padding-bottom: 0px;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Search
|----------------------------------------------------------------------------*/

.lm-CommandPalette-search {
  padding: 4px;
  background-color: var(--jp-layout-color1);
  z-index: 2;
}

.lm-CommandPalette-wrapper {
  overflow: overlay;
  padding: 0px 9px;
  background-color: var(--jp-input-active-background);
  height: 30px;
  box-shadow: inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);
}

.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper {
  box-shadow: inset 0 0 0 1px var(--jp-input-active-box-shadow-color),
    inset 0 0 0 3px var(--jp-input-active-box-shadow-color);
}

.lm-CommandPalette-wrapper::after {
  content: ' ';
  color: white;
  background-color: var(--jp-brand-color1);
  position: absolute;
  top: 4px;
  right: 4px;
  height: 30px;
  width: 10px;
  padding: 0px 10px;
  background-image: var(--jp-icon-search-white);
  background-size: 20px;
  background-repeat: no-repeat;
  background-position: center;
}

.lm-CommandPalette-input {
  background: transparent;
  width: calc(100% - 18px);
  float: left;
  border: none;
  outline: none;
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  line-height: var(--jp-private-commandpalette-search-height);
}

.lm-CommandPalette-input::-webkit-input-placeholder,
.lm-CommandPalette-input::-moz-placeholder,
.lm-CommandPalette-input:-ms-input-placeholder {
  color: var(--jp-ui-font-color3);
  font-size: var(--jp-ui-font-size1);
}

/*-----------------------------------------------------------------------------
| Results
|----------------------------------------------------------------------------*/

.lm-CommandPalette-header:first-child {
  margin-top: 0px;
}

.lm-CommandPalette-header {
  border-bottom: solid var(--jp-border-width) var(--jp-border-color2);
  color: var(--jp-ui-font-color1);
  cursor: pointer;
  display: flex;
  font-size: var(--jp-ui-font-size0);
  font-weight: 600;
  letter-spacing: 1px;
  margin-top: 8px;
  padding: 8px 0 8px 12px;
  text-transform: uppercase;
}

.lm-CommandPalette-header.lm-mod-active {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-header > mark {
  background-color: transparent;
  font-weight: bold;
  color: var(--jp-ui-font-color1);
}

.lm-CommandPalette-item {
  padding: 4px 12px 4px 4px;
  color: var(--jp-ui-font-color1);
  font-size: var(--jp-ui-font-size1);
  font-weight: 400;
  display: flex;
}

.lm-CommandPalette-item.lm-mod-disabled {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item.lm-mod-active {
  background: var(--jp-layout-color3);
}

.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled) {
  background: var(--jp-layout-color4);
}

.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled) {
  background: var(--jp-layout-color2);
}

.lm-CommandPalette-itemContent {
  overflow: hidden;
}

.lm-CommandPalette-itemLabel > mark {
  color: var(--jp-ui-font-color0);
  background-color: transparent;
  font-weight: bold;
}

.lm-CommandPalette-item.lm-mod-disabled mark {
  color: var(--jp-ui-font-color3);
}

.lm-CommandPalette-item .lm-CommandPalette-itemIcon {
  margin: 0 4px 0 0;
  position: relative;
  width: 16px;
  top: 2px;
  flex: 0 0 auto;
}

.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon {
  opacity: 0.4;
}

.lm-CommandPalette-item .lm-CommandPalette-itemShortcut {
  flex: 0 0 auto;
}

.lm-CommandPalette-itemCaption {
  display: none;
}

.lm-CommandPalette-content {
  background-color: var(--jp-layout-color1);
}

.lm-CommandPalette-content:empty:after {
  content: 'No results';
  margin: auto;
  margin-top: 20px;
  width: 100px;
  display: block;
  font-size: var(--jp-ui-font-size2);
  font-family: var(--jp-ui-font-family);
  font-weight: lighter;
}

.lm-CommandPalette-emptyMessage {
  text-align: center;
  margin-top: 24px;
  line-height: 1.32;
  padding: 0px 8px;
  color: var(--jp-content-font-color3);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Dialog {
  position: absolute;
  z-index: 10000;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  top: 0px;
  left: 0px;
  margin: 0;
  padding: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-dialog-background);
}

.jp-Dialog-content {
  display: flex;
  flex-direction: column;
  margin-left: auto;
  margin-right: auto;
  background: var(--jp-layout-color1);
  padding: 24px;
  padding-bottom: 12px;
  min-width: 300px;
  min-height: 150px;
  max-width: 1000px;
  max-height: 500px;
  box-sizing: border-box;
  box-shadow: var(--jp-elevation-z20);
  word-wrap: break-word;
  border-radius: var(--jp-border-radius);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color1);
}

.jp-Dialog-button {
  overflow: visible;
}

button.jp-Dialog-button:focus {
  outline: 1px solid var(--jp-brand-color1);
  outline-offset: 4px;
  -moz-outline-radius: 0px;
}

button.jp-Dialog-button:focus::-moz-focus-inner {
  border: 0;
}

.jp-Dialog-header {
  flex: 0 0 auto;
  padding-bottom: 12px;
  font-size: var(--jp-ui-font-size3);
  font-weight: 400;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-body {
  display: flex;
  flex-direction: column;
  flex: 1 1 auto;
  font-size: var(--jp-ui-font-size1);
  background: var(--jp-layout-color1);
  overflow: auto;
}

.jp-Dialog-footer {
  display: flex;
  flex-direction: row;
  justify-content: flex-end;
  flex: 0 0 auto;
  margin-left: -12px;
  margin-right: -12px;
  padding: 12px;
}

.jp-Dialog-title {
  overflow: hidden;
  white-space: nowrap;
  text-overflow: ellipsis;
}

.jp-Dialog-body > .jp-select-wrapper {
  width: 100%;
}

.jp-Dialog-body > button {
  padding: 0px 16px;
}

.jp-Dialog-body > label {
  line-height: 1.4;
  color: var(--jp-ui-font-color0);
}

.jp-Dialog-button.jp-mod-styled:not(:last-child) {
  margin-right: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-HoverBox {
  position: fixed;
}

.jp-HoverBox.jp-mod-outofview {
  display: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-IFrame {
  width: 100%;
  height: 100%;
}

.jp-IFrame > iframe {
  border: none;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-IFrame {
  position: relative;
}

body.lm-mod-override-cursor .jp-IFrame:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MainAreaWidget > :focus {
  outline: none;
}

/**
 * google-material-color v1.2.6
 * https://github.com/danlevan/google-material-color
 */
:root {
  --md-red-50: #ffebee;
  --md-red-100: #ffcdd2;
  --md-red-200: #ef9a9a;
  --md-red-300: #e57373;
  --md-red-400: #ef5350;
  --md-red-500: #f44336;
  --md-red-600: #e53935;
  --md-red-700: #d32f2f;
  --md-red-800: #c62828;
  --md-red-900: #b71c1c;
  --md-red-A100: #ff8a80;
  --md-red-A200: #ff5252;
  --md-red-A400: #ff1744;
  --md-red-A700: #d50000;

  --md-pink-50: #fce4ec;
  --md-pink-100: #f8bbd0;
  --md-pink-200: #f48fb1;
  --md-pink-300: #f06292;
  --md-pink-400: #ec407a;
  --md-pink-500: #e91e63;
  --md-pink-600: #d81b60;
  --md-pink-700: #c2185b;
  --md-pink-800: #ad1457;
  --md-pink-900: #880e4f;
  --md-pink-A100: #ff80ab;
  --md-pink-A200: #ff4081;
  --md-pink-A400: #f50057;
  --md-pink-A700: #c51162;

  --md-purple-50: #f3e5f5;
  --md-purple-100: #e1bee7;
  --md-purple-200: #ce93d8;
  --md-purple-300: #ba68c8;
  --md-purple-400: #ab47bc;
  --md-purple-500: #9c27b0;
  --md-purple-600: #8e24aa;
  --md-purple-700: #7b1fa2;
  --md-purple-800: #6a1b9a;
  --md-purple-900: #4a148c;
  --md-purple-A100: #ea80fc;
  --md-purple-A200: #e040fb;
  --md-purple-A400: #d500f9;
  --md-purple-A700: #aa00ff;

  --md-deep-purple-50: #ede7f6;
  --md-deep-purple-100: #d1c4e9;
  --md-deep-purple-200: #b39ddb;
  --md-deep-purple-300: #9575cd;
  --md-deep-purple-400: #7e57c2;
  --md-deep-purple-500: #673ab7;
  --md-deep-purple-600: #5e35b1;
  --md-deep-purple-700: #512da8;
  --md-deep-purple-800: #4527a0;
  --md-deep-purple-900: #311b92;
  --md-deep-purple-A100: #b388ff;
  --md-deep-purple-A200: #7c4dff;
  --md-deep-purple-A400: #651fff;
  --md-deep-purple-A700: #6200ea;

  --md-indigo-50: #e8eaf6;
  --md-indigo-100: #c5cae9;
  --md-indigo-200: #9fa8da;
  --md-indigo-300: #7986cb;
  --md-indigo-400: #5c6bc0;
  --md-indigo-500: #3f51b5;
  --md-indigo-600: #3949ab;
  --md-indigo-700: #303f9f;
  --md-indigo-800: #283593;
  --md-indigo-900: #1a237e;
  --md-indigo-A100: #8c9eff;
  --md-indigo-A200: #536dfe;
  --md-indigo-A400: #3d5afe;
  --md-indigo-A700: #304ffe;

  --md-blue-50: #e3f2fd;
  --md-blue-100: #bbdefb;
  --md-blue-200: #90caf9;
  --md-blue-300: #64b5f6;
  --md-blue-400: #42a5f5;
  --md-blue-500: #2196f3;
  --md-blue-600: #1e88e5;
  --md-blue-700: #1976d2;
  --md-blue-800: #1565c0;
  --md-blue-900: #0d47a1;
  --md-blue-A100: #82b1ff;
  --md-blue-A200: #448aff;
  --md-blue-A400: #2979ff;
  --md-blue-A700: #2962ff;

  --md-light-blue-50: #e1f5fe;
  --md-light-blue-100: #b3e5fc;
  --md-light-blue-200: #81d4fa;
  --md-light-blue-300: #4fc3f7;
  --md-light-blue-400: #29b6f6;
  --md-light-blue-500: #03a9f4;
  --md-light-blue-600: #039be5;
  --md-light-blue-700: #0288d1;
  --md-light-blue-800: #0277bd;
  --md-light-blue-900: #01579b;
  --md-light-blue-A100: #80d8ff;
  --md-light-blue-A200: #40c4ff;
  --md-light-blue-A400: #00b0ff;
  --md-light-blue-A700: #0091ea;

  --md-cyan-50: #e0f7fa;
  --md-cyan-100: #b2ebf2;
  --md-cyan-200: #80deea;
  --md-cyan-300: #4dd0e1;
  --md-cyan-400: #26c6da;
  --md-cyan-500: #00bcd4;
  --md-cyan-600: #00acc1;
  --md-cyan-700: #0097a7;
  --md-cyan-800: #00838f;
  --md-cyan-900: #006064;
  --md-cyan-A100: #84ffff;
  --md-cyan-A200: #18ffff;
  --md-cyan-A400: #00e5ff;
  --md-cyan-A700: #00b8d4;

  --md-teal-50: #e0f2f1;
  --md-teal-100: #b2dfdb;
  --md-teal-200: #80cbc4;
  --md-teal-300: #4db6ac;
  --md-teal-400: #26a69a;
  --md-teal-500: #009688;
  --md-teal-600: #00897b;
  --md-teal-700: #00796b;
  --md-teal-800: #00695c;
  --md-teal-900: #004d40;
  --md-teal-A100: #a7ffeb;
  --md-teal-A200: #64ffda;
  --md-teal-A400: #1de9b6;
  --md-teal-A700: #00bfa5;

  --md-green-50: #e8f5e9;
  --md-green-100: #c8e6c9;
  --md-green-200: #a5d6a7;
  --md-green-300: #81c784;
  --md-green-400: #66bb6a;
  --md-green-500: #4caf50;
  --md-green-600: #43a047;
  --md-green-700: #388e3c;
  --md-green-800: #2e7d32;
  --md-green-900: #1b5e20;
  --md-green-A100: #b9f6ca;
  --md-green-A200: #69f0ae;
  --md-green-A400: #00e676;
  --md-green-A700: #00c853;

  --md-light-green-50: #f1f8e9;
  --md-light-green-100: #dcedc8;
  --md-light-green-200: #c5e1a5;
  --md-light-green-300: #aed581;
  --md-light-green-400: #9ccc65;
  --md-light-green-500: #8bc34a;
  --md-light-green-600: #7cb342;
  --md-light-green-700: #689f38;
  --md-light-green-800: #558b2f;
  --md-light-green-900: #33691e;
  --md-light-green-A100: #ccff90;
  --md-light-green-A200: #b2ff59;
  --md-light-green-A400: #76ff03;
  --md-light-green-A700: #64dd17;

  --md-lime-50: #f9fbe7;
  --md-lime-100: #f0f4c3;
  --md-lime-200: #e6ee9c;
  --md-lime-300: #dce775;
  --md-lime-400: #d4e157;
  --md-lime-500: #cddc39;
  --md-lime-600: #c0ca33;
  --md-lime-700: #afb42b;
  --md-lime-800: #9e9d24;
  --md-lime-900: #827717;
  --md-lime-A100: #f4ff81;
  --md-lime-A200: #eeff41;
  --md-lime-A400: #c6ff00;
  --md-lime-A700: #aeea00;

  --md-yellow-50: #fffde7;
  --md-yellow-100: #fff9c4;
  --md-yellow-200: #fff59d;
  --md-yellow-300: #fff176;
  --md-yellow-400: #ffee58;
  --md-yellow-500: #ffeb3b;
  --md-yellow-600: #fdd835;
  --md-yellow-700: #fbc02d;
  --md-yellow-800: #f9a825;
  --md-yellow-900: #f57f17;
  --md-yellow-A100: #ffff8d;
  --md-yellow-A200: #ffff00;
  --md-yellow-A400: #ffea00;
  --md-yellow-A700: #ffd600;

  --md-amber-50: #fff8e1;
  --md-amber-100: #ffecb3;
  --md-amber-200: #ffe082;
  --md-amber-300: #ffd54f;
  --md-amber-400: #ffca28;
  --md-amber-500: #ffc107;
  --md-amber-600: #ffb300;
  --md-amber-700: #ffa000;
  --md-amber-800: #ff8f00;
  --md-amber-900: #ff6f00;
  --md-amber-A100: #ffe57f;
  --md-amber-A200: #ffd740;
  --md-amber-A400: #ffc400;
  --md-amber-A700: #ffab00;

  --md-orange-50: #fff3e0;
  --md-orange-100: #ffe0b2;
  --md-orange-200: #ffcc80;
  --md-orange-300: #ffb74d;
  --md-orange-400: #ffa726;
  --md-orange-500: #ff9800;
  --md-orange-600: #fb8c00;
  --md-orange-700: #f57c00;
  --md-orange-800: #ef6c00;
  --md-orange-900: #e65100;
  --md-orange-A100: #ffd180;
  --md-orange-A200: #ffab40;
  --md-orange-A400: #ff9100;
  --md-orange-A700: #ff6d00;

  --md-deep-orange-50: #fbe9e7;
  --md-deep-orange-100: #ffccbc;
  --md-deep-orange-200: #ffab91;
  --md-deep-orange-300: #ff8a65;
  --md-deep-orange-400: #ff7043;
  --md-deep-orange-500: #ff5722;
  --md-deep-orange-600: #f4511e;
  --md-deep-orange-700: #e64a19;
  --md-deep-orange-800: #d84315;
  --md-deep-orange-900: #bf360c;
  --md-deep-orange-A100: #ff9e80;
  --md-deep-orange-A200: #ff6e40;
  --md-deep-orange-A400: #ff3d00;
  --md-deep-orange-A700: #dd2c00;

  --md-brown-50: #efebe9;
  --md-brown-100: #d7ccc8;
  --md-brown-200: #bcaaa4;
  --md-brown-300: #a1887f;
  --md-brown-400: #8d6e63;
  --md-brown-500: #795548;
  --md-brown-600: #6d4c41;
  --md-brown-700: #5d4037;
  --md-brown-800: #4e342e;
  --md-brown-900: #3e2723;

  --md-grey-50: #fafafa;
  --md-grey-100: #f5f5f5;
  --md-grey-200: #eeeeee;
  --md-grey-300: #e0e0e0;
  --md-grey-400: #bdbdbd;
  --md-grey-500: #9e9e9e;
  --md-grey-600: #757575;
  --md-grey-700: #616161;
  --md-grey-800: #424242;
  --md-grey-900: #212121;

  --md-blue-grey-50: #eceff1;
  --md-blue-grey-100: #cfd8dc;
  --md-blue-grey-200: #b0bec5;
  --md-blue-grey-300: #90a4ae;
  --md-blue-grey-400: #78909c;
  --md-blue-grey-500: #607d8b;
  --md-blue-grey-600: #546e7a;
  --md-blue-grey-700: #455a64;
  --md-blue-grey-800: #37474f;
  --md-blue-grey-900: #263238;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Spinner {
  position: absolute;
  display: flex;
  justify-content: center;
  align-items: center;
  z-index: 10;
  left: 0;
  top: 0;
  width: 100%;
  height: 100%;
  background: var(--jp-layout-color0);
  outline: none;
}

.jp-SpinnerContent {
  font-size: 10px;
  margin: 50px auto;
  text-indent: -9999em;
  width: 3em;
  height: 3em;
  border-radius: 50%;
  background: var(--jp-brand-color3);
  background: linear-gradient(
    to right,
    #f37626 10%,
    rgba(255, 255, 255, 0) 42%
  );
  position: relative;
  animation: load3 1s infinite linear, fadeIn 1s;
}

.jp-SpinnerContent:before {
  width: 50%;
  height: 50%;
  background: #f37626;
  border-radius: 100% 0 0 0;
  position: absolute;
  top: 0;
  left: 0;
  content: '';
}

.jp-SpinnerContent:after {
  background: var(--jp-layout-color0);
  width: 75%;
  height: 75%;
  border-radius: 50%;
  content: '';
  margin: auto;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  right: 0;
}

@keyframes fadeIn {
  0% {
    opacity: 0;
  }
  100% {
    opacity: 1;
  }
}

@keyframes load3 {
  0% {
    transform: rotate(0deg);
  }
  100% {
    transform: rotate(360deg);
  }
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

button.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: none;
  box-sizing: border-box;
  text-align: center;
  line-height: 32px;
  height: 32px;
  padding: 0px 12px;
  letter-spacing: 0.8px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled {
  background: var(--jp-input-background);
  height: 28px;
  box-sizing: border-box;
  border: var(--jp-border-width) solid var(--jp-border-color1);
  padding-left: 7px;
  padding-right: 7px;
  font-size: var(--jp-ui-font-size2);
  color: var(--jp-ui-font-color0);
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

input.jp-mod-styled:focus {
  border: var(--jp-border-width) solid var(--md-blue-500);
  box-shadow: inset 0 0 4px var(--md-blue-300);
}

.jp-select-wrapper {
  display: flex;
  position: relative;
  flex-direction: column;
  padding: 1px;
  background-color: var(--jp-layout-color1);
  height: 28px;
  box-sizing: border-box;
  margin-bottom: 12px;
}

.jp-select-wrapper.jp-mod-focused select.jp-mod-styled {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-input-active-background);
}

select.jp-mod-styled:hover {
  background-color: var(--jp-layout-color1);
  cursor: pointer;
  color: var(--jp-ui-font-color0);
  background-color: var(--jp-input-hover-background);
  box-shadow: inset 0 0px 1px rgba(0, 0, 0, 0.5);
}

select.jp-mod-styled {
  flex: 1 1 auto;
  height: 32px;
  width: 100%;
  font-size: var(--jp-ui-font-size2);
  background: var(--jp-input-background);
  color: var(--jp-ui-font-color0);
  padding: 0 25px 0 8px;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

:root {
  --jp-private-toolbar-height: calc(
    28px + var(--jp-border-width)
  ); /* leave 28px for content */
}

.jp-Toolbar {
  color: var(--jp-ui-font-color1);
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  border-bottom: var(--jp-border-width) solid var(--jp-toolbar-border-color);
  box-shadow: var(--jp-toolbar-box-shadow);
  background: var(--jp-toolbar-background);
  min-height: var(--jp-toolbar-micro-height);
  padding: 2px;
  z-index: 1;
}

/* Toolbar items */

.jp-Toolbar > .jp-Toolbar-item.jp-Toolbar-spacer {
  flex-grow: 1;
  flex-shrink: 1;
}

.jp-Toolbar-item.jp-Toolbar-kernelStatus {
  display: inline-block;
  width: 32px;
  background-repeat: no-repeat;
  background-position: center;
  background-size: 16px;
}

.jp-Toolbar > .jp-Toolbar-item {
  flex: 0 0 auto;
  display: flex;
  padding-left: 1px;
  padding-right: 1px;
  font-size: var(--jp-ui-font-size1);
  line-height: var(--jp-private-toolbar-height);
  height: 100%;
}

/* Toolbar buttons */

/* This is the div we use to wrap the react component into a Widget */
div.jp-ToolbarButton {
  color: transparent;
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px;
  margin: 0px;
}

button.jp-ToolbarButtonComponent {
  background: var(--jp-layout-color1);
  border: none;
  box-sizing: border-box;
  outline: none;
  appearance: none;
  -webkit-appearance: none;
  -moz-appearance: none;
  padding: 0px 6px;
  margin: 0px;
  height: 24px;
  border-radius: var(--jp-border-radius);
  display: flex;
  align-items: center;
  text-align: center;
  font-size: 14px;
  min-width: unset;
  min-height: unset;
}

button.jp-ToolbarButtonComponent:disabled {
  opacity: 0.4;
}

button.jp-ToolbarButtonComponent span {
  padding: 0px;
  flex: 0 0 auto;
}

button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label {
  font-size: var(--jp-ui-font-size1);
  line-height: 100%;
  padding-left: 2px;
  color: var(--jp-ui-font-color1);
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2017, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Copyright (c) 2014-2017, PhosphorJS Contributors
|
| Distributed under the terms of the BSD 3-Clause License.
|
| The full license is in the file LICENSE, distributed with this software.
|----------------------------------------------------------------------------*/


/* <DEPRECATED> */ body.p-mod-override-cursor *, /* </DEPRECATED> */
body.lm-mod-override-cursor * {
  cursor: inherit !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) 2014-2016, Jupyter Development Team.
|
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-JSONEditor {
  display: flex;
  flex-direction: column;
  width: 100%;
}

.jp-JSONEditor-host {
  flex: 1 1 auto;
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  border-radius: 0px;
  background: var(--jp-layout-color0);
  min-height: 50px;
  padding: 1px;
}

.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host {
  border-color: red;
  outline-color: red;
}

.jp-JSONEditor-header {
  display: flex;
  flex: 1 0 auto;
  padding: 0 0 0 12px;
}

.jp-JSONEditor-header label {
  flex: 0 0 auto;
}

.jp-JSONEditor-commitButton {
  height: 16px;
  width: 16px;
  background-size: 18px;
  background-repeat: no-repeat;
  background-position: center;
}

.jp-JSONEditor-host.jp-mod-focused {
  background-color: var(--jp-input-active-background);
  border: 1px solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

.jp-Editor.jp-mod-dropTarget {
  border: var(--jp-border-width) solid var(--jp-input-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* BASICS */

.CodeMirror {
  /* Set height, width, borders, and global font properties here */
  font-family: monospace;
  height: 300px;
  color: black;
  direction: ltr;
}

/* PADDING */

.CodeMirror-lines {
  padding: 4px 0; /* Vertical padding around content */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  padding: 0 4px; /* Horizontal padding of content */
}

.CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  background-color: white; /* The little square between H and V scrollbars */
}

/* GUTTER */

.CodeMirror-gutters {
  border-right: 1px solid #ddd;
  background-color: #f7f7f7;
  white-space: nowrap;
}
.CodeMirror-linenumbers {}
.CodeMirror-linenumber {
  padding: 0 3px 0 5px;
  min-width: 20px;
  text-align: right;
  color: #999;
  white-space: nowrap;
}

.CodeMirror-guttermarker { color: black; }
.CodeMirror-guttermarker-subtle { color: #999; }

/* CURSOR */

.CodeMirror-cursor {
  border-left: 1px solid black;
  border-right: none;
  width: 0;
}
/* Shown when moving in bi-directional text */
.CodeMirror div.CodeMirror-secondarycursor {
  border-left: 1px solid silver;
}
.cm-fat-cursor .CodeMirror-cursor {
  width: auto;
  border: 0 !important;
  background: #7e7;
}
.cm-fat-cursor div.CodeMirror-cursors {
  z-index: 1;
}
.cm-fat-cursor-mark {
  background-color: rgba(20, 255, 20, 0.5);
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
}
.cm-animate-fat-cursor {
  width: auto;
  border: 0;
  -webkit-animation: blink 1.06s steps(1) infinite;
  -moz-animation: blink 1.06s steps(1) infinite;
  animation: blink 1.06s steps(1) infinite;
  background-color: #7e7;
}
@-moz-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@-webkit-keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}
@keyframes blink {
  0% {}
  50% { background-color: transparent; }
  100% {}
}

/* Can style cursor different in overwrite (non-insert) mode */
.CodeMirror-overwrite .CodeMirror-cursor {}

.cm-tab { display: inline-block; text-decoration: inherit; }

.CodeMirror-rulers {
  position: absolute;
  left: 0; right: 0; top: -50px; bottom: 0;
  overflow: hidden;
}
.CodeMirror-ruler {
  border-left: 1px solid #ccc;
  top: 0; bottom: 0;
  position: absolute;
}

/* DEFAULT THEME */

.cm-s-default .cm-header {color: blue;}
.cm-s-default .cm-quote {color: #090;}
.cm-negative {color: #d44;}
.cm-positive {color: #292;}
.cm-header, .cm-strong {font-weight: bold;}
.cm-em {font-style: italic;}
.cm-link {text-decoration: underline;}
.cm-strikethrough {text-decoration: line-through;}

.cm-s-default .cm-keyword {color: #708;}
.cm-s-default .cm-atom {color: #219;}
.cm-s-default .cm-number {color: #164;}
.cm-s-default .cm-def {color: #00f;}
.cm-s-default .cm-variable,
.cm-s-default .cm-punctuation,
.cm-s-default .cm-property,
.cm-s-default .cm-operator {}
.cm-s-default .cm-variable-2 {color: #05a;}
.cm-s-default .cm-variable-3, .cm-s-default .cm-type {color: #085;}
.cm-s-default .cm-comment {color: #a50;}
.cm-s-default .cm-string {color: #a11;}
.cm-s-default .cm-string-2 {color: #f50;}
.cm-s-default .cm-meta {color: #555;}
.cm-s-default .cm-qualifier {color: #555;}
.cm-s-default .cm-builtin {color: #30a;}
.cm-s-default .cm-bracket {color: #997;}
.cm-s-default .cm-tag {color: #170;}
.cm-s-default .cm-attribute {color: #00c;}
.cm-s-default .cm-hr {color: #999;}
.cm-s-default .cm-link {color: #00c;}

.cm-s-default .cm-error {color: #f00;}
.cm-invalidchar {color: #f00;}

.CodeMirror-composing { border-bottom: 2px solid; }

/* Default styles for common addons */

div.CodeMirror span.CodeMirror-matchingbracket {color: #0b0;}
div.CodeMirror span.CodeMirror-nonmatchingbracket {color: #a22;}
.CodeMirror-matchingtag { background: rgba(255, 150, 0, .3); }
.CodeMirror-activeline-background {background: #e8f2ff;}

/* STOP */

/* The rest of this file contains styles related to the mechanics of
   the editor. You probably shouldn't touch them. */

.CodeMirror {
  position: relative;
  overflow: hidden;
  background: white;
}

.CodeMirror-scroll {
  overflow: scroll !important; /* Things will break if this is overridden */
  /* 30px is the magic margin used to hide the element's real scrollbars */
  /* See overflow: hidden in .CodeMirror */
  margin-bottom: -30px; margin-right: -30px;
  padding-bottom: 30px;
  height: 100%;
  outline: none; /* Prevent dragging from highlighting the element */
  position: relative;
}
.CodeMirror-sizer {
  position: relative;
  border-right: 30px solid transparent;
}

/* The fake, visible scrollbars. Used to force redraw during scrolling
   before actual scrolling happens, thus preventing shaking and
   flickering artifacts. */
.CodeMirror-vscrollbar, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-gutter-filler {
  position: absolute;
  z-index: 6;
  display: none;
}
.CodeMirror-vscrollbar {
  right: 0; top: 0;
  overflow-x: hidden;
  overflow-y: scroll;
}
.CodeMirror-hscrollbar {
  bottom: 0; left: 0;
  overflow-y: hidden;
  overflow-x: scroll;
}
.CodeMirror-scrollbar-filler {
  right: 0; bottom: 0;
}
.CodeMirror-gutter-filler {
  left: 0; bottom: 0;
}

.CodeMirror-gutters {
  position: absolute; left: 0; top: 0;
  min-height: 100%;
  z-index: 3;
}
.CodeMirror-gutter {
  white-space: normal;
  height: 100%;
  display: inline-block;
  vertical-align: top;
  margin-bottom: -30px;
}
.CodeMirror-gutter-wrapper {
  position: absolute;
  z-index: 4;
  background: none !important;
  border: none !important;
}
.CodeMirror-gutter-background {
  position: absolute;
  top: 0; bottom: 0;
  z-index: 4;
}
.CodeMirror-gutter-elt {
  position: absolute;
  cursor: default;
  z-index: 4;
}
.CodeMirror-gutter-wrapper ::selection { background-color: transparent }
.CodeMirror-gutter-wrapper ::-moz-selection { background-color: transparent }

.CodeMirror-lines {
  cursor: text;
  min-height: 1px; /* prevents collapsing before first draw */
}
.CodeMirror pre.CodeMirror-line,
.CodeMirror pre.CodeMirror-line-like {
  /* Reset some styles that the rest of the page might have set */
  -moz-border-radius: 0; -webkit-border-radius: 0; border-radius: 0;
  border-width: 0;
  background: transparent;
  font-family: inherit;
  font-size: inherit;
  margin: 0;
  white-space: pre;
  word-wrap: normal;
  line-height: inherit;
  color: inherit;
  z-index: 2;
  position: relative;
  overflow: visible;
  -webkit-tap-highlight-color: transparent;
  -webkit-font-variant-ligatures: contextual;
  font-variant-ligatures: contextual;
}
.CodeMirror-wrap pre.CodeMirror-line,
.CodeMirror-wrap pre.CodeMirror-line-like {
  word-wrap: break-word;
  white-space: pre-wrap;
  word-break: normal;
}

.CodeMirror-linebackground {
  position: absolute;
  left: 0; right: 0; top: 0; bottom: 0;
  z-index: 0;
}

.CodeMirror-linewidget {
  position: relative;
  z-index: 2;
  padding: 0.1px; /* Force widget margins to stay inside of the container */
}

.CodeMirror-widget {}

.CodeMirror-rtl pre { direction: rtl; }

.CodeMirror-code {
  outline: none;
}

/* Force content-box sizing for the elements where we expect it */
.CodeMirror-scroll,
.CodeMirror-sizer,
.CodeMirror-gutter,
.CodeMirror-gutters,
.CodeMirror-linenumber {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
}

.CodeMirror-measure {
  position: absolute;
  width: 100%;
  height: 0;
  overflow: hidden;
  visibility: hidden;
}

.CodeMirror-cursor {
  position: absolute;
  pointer-events: none;
}
.CodeMirror-measure pre { position: static; }

div.CodeMirror-cursors {
  visibility: hidden;
  position: relative;
  z-index: 3;
}
div.CodeMirror-dragcursors {
  visibility: visible;
}

.CodeMirror-focused div.CodeMirror-cursors {
  visibility: visible;
}

.CodeMirror-selected { background: #d9d9d9; }
.CodeMirror-focused .CodeMirror-selected { background: #d7d4f0; }
.CodeMirror-crosshair { cursor: crosshair; }
.CodeMirror-line::selection, .CodeMirror-line > span::selection, .CodeMirror-line > span > span::selection { background: #d7d4f0; }
.CodeMirror-line::-moz-selection, .CodeMirror-line > span::-moz-selection, .CodeMirror-line > span > span::-moz-selection { background: #d7d4f0; }

.cm-searching {
  background-color: #ffa;
  background-color: rgba(255, 255, 0, .4);
}

/* Used to force a border model for a node */
.cm-force-border { padding-right: .1px; }

@media print {
  /* Hide the cursor when printing */
  .CodeMirror div.CodeMirror-cursors {
    visibility: hidden;
  }
}

/* See issue #2901 */
.cm-tab-wrap-hack:after { content: ''; }

/* Help users use markselection to safely style text background */
span.CodeMirror-selectedtext { background: none; }

.CodeMirror-dialog {
  position: absolute;
  left: 0; right: 0;
  background: inherit;
  z-index: 15;
  padding: .1em .8em;
  overflow: hidden;
  color: inherit;
}

.CodeMirror-dialog-top {
  border-bottom: 1px solid #eee;
  top: 0;
}

.CodeMirror-dialog-bottom {
  border-top: 1px solid #eee;
  bottom: 0;
}

.CodeMirror-dialog input {
  border: none;
  outline: none;
  background: transparent;
  width: 20em;
  color: inherit;
  font-family: monospace;
}

.CodeMirror-dialog button {
  font-size: 70%;
}

.CodeMirror-foldmarker {
  color: blue;
  text-shadow: #b9f 1px 1px 2px, #b9f -1px -1px 2px, #b9f 1px -1px 2px, #b9f -1px 1px 2px;
  font-family: arial;
  line-height: .3;
  cursor: pointer;
}
.CodeMirror-foldgutter {
  width: .7em;
}
.CodeMirror-foldgutter-open,
.CodeMirror-foldgutter-folded {
  cursor: pointer;
}
.CodeMirror-foldgutter-open:after {
  content: "\25BE";
}
.CodeMirror-foldgutter-folded:after {
  content: "\25B8";
}

/*
  Name:       material
  Author:     Mattia Astorino (http://github.com/equinusocio)
  Website:    https://material-theme.site/
*/

.cm-s-material.CodeMirror {
  background-color: #263238;
  color: #EEFFFF;
}

.cm-s-material .CodeMirror-gutters {
  background: #263238;
  color: #546E7A;
  border: none;
}

.cm-s-material .CodeMirror-guttermarker,
.cm-s-material .CodeMirror-guttermarker-subtle,
.cm-s-material .CodeMirror-linenumber {
  color: #546E7A;
}

.cm-s-material .CodeMirror-cursor {
  border-left: 1px solid #FFCC00;
}

.cm-s-material div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material.CodeMirror-focused div.CodeMirror-selected {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::selection,
.cm-s-material .CodeMirror-line>span::selection,
.cm-s-material .CodeMirror-line>span>span::selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-line::-moz-selection,
.cm-s-material .CodeMirror-line>span::-moz-selection,
.cm-s-material .CodeMirror-line>span>span::-moz-selection {
  background: rgba(128, 203, 196, 0.2);
}

.cm-s-material .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.5);
}

.cm-s-material .cm-keyword {
  color: #C792EA;
}

.cm-s-material .cm-operator {
  color: #89DDFF;
}

.cm-s-material .cm-variable-2 {
  color: #EEFFFF;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #f07178;
}

.cm-s-material .cm-builtin {
  color: #FFCB6B;
}

.cm-s-material .cm-atom {
  color: #F78C6C;
}

.cm-s-material .cm-number {
  color: #FF5370;
}

.cm-s-material .cm-def {
  color: #82AAFF;
}

.cm-s-material .cm-string {
  color: #C3E88D;
}

.cm-s-material .cm-string-2 {
  color: #f07178;
}

.cm-s-material .cm-comment {
  color: #546E7A;
}

.cm-s-material .cm-variable {
  color: #f07178;
}

.cm-s-material .cm-tag {
  color: #FF5370;
}

.cm-s-material .cm-meta {
  color: #FFCB6B;
}

.cm-s-material .cm-attribute {
  color: #C792EA;
}

.cm-s-material .cm-property {
  color: #C792EA;
}

.cm-s-material .cm-qualifier {
  color: #DECB6B;
}

.cm-s-material .cm-variable-3,
.cm-s-material .cm-type {
  color: #DECB6B;
}


.cm-s-material .cm-error {
  color: rgba(255, 255, 255, 1.0);
  background-color: #FF5370;
}

.cm-s-material .CodeMirror-matchingbracket {
  text-decoration: underline;
  color: white !important;
}
/**
 * "
 *  Using Zenburn color palette from the Emacs Zenburn Theme
 *  https://github.com/bbatsov/zenburn-emacs/blob/master/zenburn-theme.el
 *
 *  Also using parts of https://github.com/xavi/coderay-lighttable-theme
 * "
 * From: https://github.com/wisenomad/zenburn-lighttable-theme/blob/master/zenburn.css
 */

.cm-s-zenburn .CodeMirror-gutters { background: #3f3f3f !important; }
.cm-s-zenburn .CodeMirror-foldgutter-open, .CodeMirror-foldgutter-folded { color: #999; }
.cm-s-zenburn .CodeMirror-cursor { border-left: 1px solid white; }
.cm-s-zenburn { background-color: #3f3f3f; color: #dcdccc; }
.cm-s-zenburn span.cm-builtin { color: #dcdccc; font-weight: bold; }
.cm-s-zenburn span.cm-comment { color: #7f9f7f; }
.cm-s-zenburn span.cm-keyword { color: #f0dfaf; font-weight: bold; }
.cm-s-zenburn span.cm-atom { color: #bfebbf; }
.cm-s-zenburn span.cm-def { color: #dcdccc; }
.cm-s-zenburn span.cm-variable { color: #dfaf8f; }
.cm-s-zenburn span.cm-variable-2 { color: #dcdccc; }
.cm-s-zenburn span.cm-string { color: #cc9393; }
.cm-s-zenburn span.cm-string-2 { color: #cc9393; }
.cm-s-zenburn span.cm-number { color: #dcdccc; }
.cm-s-zenburn span.cm-tag { color: #93e0e3; }
.cm-s-zenburn span.cm-property { color: #dfaf8f; }
.cm-s-zenburn span.cm-attribute { color: #dfaf8f; }
.cm-s-zenburn span.cm-qualifier { color: #7cb8bb; }
.cm-s-zenburn span.cm-meta { color: #f0dfaf; }
.cm-s-zenburn span.cm-header { color: #f0efd0; }
.cm-s-zenburn span.cm-operator { color: #f0efd0; }
.cm-s-zenburn span.CodeMirror-matchingbracket { box-sizing: border-box; background: transparent; border-bottom: 1px solid; }
.cm-s-zenburn span.CodeMirror-nonmatchingbracket { border-bottom: 1px solid; background: none; }
.cm-s-zenburn .CodeMirror-activeline { background: #000000; }
.cm-s-zenburn .CodeMirror-activeline-background { background: #000000; }
.cm-s-zenburn div.CodeMirror-selected { background: #545454; }
.cm-s-zenburn .CodeMirror-focused div.CodeMirror-selected { background: #4f4f4f; }

.cm-s-abcdef.CodeMirror { background: #0f0f0f; color: #defdef; }
.cm-s-abcdef div.CodeMirror-selected { background: #515151; }
.cm-s-abcdef .CodeMirror-line::selection, .cm-s-abcdef .CodeMirror-line > span::selection, .cm-s-abcdef .CodeMirror-line > span > span::selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-line::-moz-selection, .cm-s-abcdef .CodeMirror-line > span::-moz-selection, .cm-s-abcdef .CodeMirror-line > span > span::-moz-selection { background: rgba(56, 56, 56, 0.99); }
.cm-s-abcdef .CodeMirror-gutters { background: #555; border-right: 2px solid #314151; }
.cm-s-abcdef .CodeMirror-guttermarker { color: #222; }
.cm-s-abcdef .CodeMirror-guttermarker-subtle { color: azure; }
.cm-s-abcdef .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-abcdef .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-abcdef span.cm-keyword { color: darkgoldenrod; font-weight: bold; }
.cm-s-abcdef span.cm-atom { color: #77F; }
.cm-s-abcdef span.cm-number { color: violet; }
.cm-s-abcdef span.cm-def { color: #fffabc; }
.cm-s-abcdef span.cm-variable { color: #abcdef; }
.cm-s-abcdef span.cm-variable-2 { color: #cacbcc; }
.cm-s-abcdef span.cm-variable-3, .cm-s-abcdef span.cm-type { color: #def; }
.cm-s-abcdef span.cm-property { color: #fedcba; }
.cm-s-abcdef span.cm-operator { color: #ff0; }
.cm-s-abcdef span.cm-comment { color: #7a7b7c; font-style: italic;}
.cm-s-abcdef span.cm-string { color: #2b4; }
.cm-s-abcdef span.cm-meta { color: #C9F; }
.cm-s-abcdef span.cm-qualifier { color: #FFF700; }
.cm-s-abcdef span.cm-builtin { color: #30aabc; }
.cm-s-abcdef span.cm-bracket { color: #8a8a8a; }
.cm-s-abcdef span.cm-tag { color: #FFDD44; }
.cm-s-abcdef span.cm-attribute { color: #DDFF00; }
.cm-s-abcdef span.cm-error { color: #FF0000; }
.cm-s-abcdef span.cm-header { color: aquamarine; font-weight: bold; }
.cm-s-abcdef span.cm-link { color: blueviolet; }

.cm-s-abcdef .CodeMirror-activeline-background { background: #314151; }

/*

    Name:       Base16 Default Light
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-light.CodeMirror { background: #f5f5f5; color: #202020; }
.cm-s-base16-light div.CodeMirror-selected { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::selection, .cm-s-base16-light .CodeMirror-line > span::selection, .cm-s-base16-light .CodeMirror-line > span > span::selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-line::-moz-selection, .cm-s-base16-light .CodeMirror-line > span::-moz-selection, .cm-s-base16-light .CodeMirror-line > span > span::-moz-selection { background: #e0e0e0; }
.cm-s-base16-light .CodeMirror-gutters { background: #f5f5f5; border-right: 0px; }
.cm-s-base16-light .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-light .CodeMirror-guttermarker-subtle { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-linenumber { color: #b0b0b0; }
.cm-s-base16-light .CodeMirror-cursor { border-left: 1px solid #505050; }

.cm-s-base16-light span.cm-comment { color: #8f5536; }
.cm-s-base16-light span.cm-atom { color: #aa759f; }
.cm-s-base16-light span.cm-number { color: #aa759f; }

.cm-s-base16-light span.cm-property, .cm-s-base16-light span.cm-attribute { color: #90a959; }
.cm-s-base16-light span.cm-keyword { color: #ac4142; }
.cm-s-base16-light span.cm-string { color: #f4bf75; }

.cm-s-base16-light span.cm-variable { color: #90a959; }
.cm-s-base16-light span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-light span.cm-def { color: #d28445; }
.cm-s-base16-light span.cm-bracket { color: #202020; }
.cm-s-base16-light span.cm-tag { color: #ac4142; }
.cm-s-base16-light span.cm-link { color: #aa759f; }
.cm-s-base16-light span.cm-error { background: #ac4142; color: #505050; }

.cm-s-base16-light .CodeMirror-activeline-background { background: #DDDCDC; }
.cm-s-base16-light .CodeMirror-matchingbracket { color: #f5f5f5 !important; background-color: #6A9FB5 !important}

/*

    Name:       Base16 Default Dark
    Author:     Chris Kempson (http://chriskempson.com)

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-base16-dark.CodeMirror { background: #151515; color: #e0e0e0; }
.cm-s-base16-dark div.CodeMirror-selected { background: #303030; }
.cm-s-base16-dark .CodeMirror-line::selection, .cm-s-base16-dark .CodeMirror-line > span::selection, .cm-s-base16-dark .CodeMirror-line > span > span::selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-line::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span::-moz-selection, .cm-s-base16-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(48, 48, 48, .99); }
.cm-s-base16-dark .CodeMirror-gutters { background: #151515; border-right: 0px; }
.cm-s-base16-dark .CodeMirror-guttermarker { color: #ac4142; }
.cm-s-base16-dark .CodeMirror-guttermarker-subtle { color: #505050; }
.cm-s-base16-dark .CodeMirror-linenumber { color: #505050; }
.cm-s-base16-dark .CodeMirror-cursor { border-left: 1px solid #b0b0b0; }

.cm-s-base16-dark span.cm-comment { color: #8f5536; }
.cm-s-base16-dark span.cm-atom { color: #aa759f; }
.cm-s-base16-dark span.cm-number { color: #aa759f; }

.cm-s-base16-dark span.cm-property, .cm-s-base16-dark span.cm-attribute { color: #90a959; }
.cm-s-base16-dark span.cm-keyword { color: #ac4142; }
.cm-s-base16-dark span.cm-string { color: #f4bf75; }

.cm-s-base16-dark span.cm-variable { color: #90a959; }
.cm-s-base16-dark span.cm-variable-2 { color: #6a9fb5; }
.cm-s-base16-dark span.cm-def { color: #d28445; }
.cm-s-base16-dark span.cm-bracket { color: #e0e0e0; }
.cm-s-base16-dark span.cm-tag { color: #ac4142; }
.cm-s-base16-dark span.cm-link { color: #aa759f; }
.cm-s-base16-dark span.cm-error { background: #ac4142; color: #b0b0b0; }

.cm-s-base16-dark .CodeMirror-activeline-background { background: #202020; }
.cm-s-base16-dark .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       dracula
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original dracula color scheme by Zeno Rocha (https://github.com/zenorocha/dracula-theme)

*/


.cm-s-dracula.CodeMirror, .cm-s-dracula .CodeMirror-gutters {
  background-color: #282a36 !important;
  color: #f8f8f2 !important;
  border: none;
}
.cm-s-dracula .CodeMirror-gutters { color: #282a36; }
.cm-s-dracula .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-dracula .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-dracula .CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::selection, .cm-s-dracula .CodeMirror-line > span::selection, .cm-s-dracula .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula .CodeMirror-line::-moz-selection, .cm-s-dracula .CodeMirror-line > span::-moz-selection, .cm-s-dracula .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-dracula span.cm-comment { color: #6272a4; }
.cm-s-dracula span.cm-string, .cm-s-dracula span.cm-string-2 { color: #f1fa8c; }
.cm-s-dracula span.cm-number { color: #bd93f9; }
.cm-s-dracula span.cm-variable { color: #50fa7b; }
.cm-s-dracula span.cm-variable-2 { color: white; }
.cm-s-dracula span.cm-def { color: #50fa7b; }
.cm-s-dracula span.cm-operator { color: #ff79c6; }
.cm-s-dracula span.cm-keyword { color: #ff79c6; }
.cm-s-dracula span.cm-atom { color: #bd93f9; }
.cm-s-dracula span.cm-meta { color: #f8f8f2; }
.cm-s-dracula span.cm-tag { color: #ff79c6; }
.cm-s-dracula span.cm-attribute { color: #50fa7b; }
.cm-s-dracula span.cm-qualifier { color: #50fa7b; }
.cm-s-dracula span.cm-property { color: #66d9ef; }
.cm-s-dracula span.cm-builtin { color: #50fa7b; }
.cm-s-dracula span.cm-variable-3, .cm-s-dracula span.cm-type { color: #ffb86c; }

.cm-s-dracula .CodeMirror-activeline-background { background: rgba(255,255,255,0.1); }
.cm-s-dracula .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*

    Name:       Hopscotch
    Author:     Jan T. Sott

    CodeMirror template by Jan T. Sott (https://github.com/idleberg/base16-codemirror)
    Original Base16 color scheme by Chris Kempson (https://github.com/chriskempson/base16)

*/

.cm-s-hopscotch.CodeMirror {background: #322931; color: #d5d3d5;}
.cm-s-hopscotch div.CodeMirror-selected {background: #433b42 !important;}
.cm-s-hopscotch .CodeMirror-gutters {background: #322931; border-right: 0px;}
.cm-s-hopscotch .CodeMirror-linenumber {color: #797379;}
.cm-s-hopscotch .CodeMirror-cursor {border-left: 1px solid #989498 !important;}

.cm-s-hopscotch span.cm-comment {color: #b33508;}
.cm-s-hopscotch span.cm-atom {color: #c85e7c;}
.cm-s-hopscotch span.cm-number {color: #c85e7c;}

.cm-s-hopscotch span.cm-property, .cm-s-hopscotch span.cm-attribute {color: #8fc13e;}
.cm-s-hopscotch span.cm-keyword {color: #dd464c;}
.cm-s-hopscotch span.cm-string {color: #fdcc59;}

.cm-s-hopscotch span.cm-variable {color: #8fc13e;}
.cm-s-hopscotch span.cm-variable-2 {color: #1290bf;}
.cm-s-hopscotch span.cm-def {color: #fd8b19;}
.cm-s-hopscotch span.cm-error {background: #dd464c; color: #989498;}
.cm-s-hopscotch span.cm-bracket {color: #d5d3d5;}
.cm-s-hopscotch span.cm-tag {color: #dd464c;}
.cm-s-hopscotch span.cm-link {color: #c85e7c;}

.cm-s-hopscotch .CodeMirror-matchingbracket { text-decoration: underline; color: white !important;}
.cm-s-hopscotch .CodeMirror-activeline-background { background: #302020; }

/****************************************************************/
/*   Based on mbonaci's Brackets mbo theme                      */
/*   https://github.com/mbonaci/global/blob/master/Mbo.tmTheme  */
/*   Create your own: http://tmtheme-editor.herokuapp.com       */
/****************************************************************/

.cm-s-mbo.CodeMirror { background: #2c2c2c; color: #ffffec; }
.cm-s-mbo div.CodeMirror-selected { background: #716C62; }
.cm-s-mbo .CodeMirror-line::selection, .cm-s-mbo .CodeMirror-line > span::selection, .cm-s-mbo .CodeMirror-line > span > span::selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-line::-moz-selection, .cm-s-mbo .CodeMirror-line > span::-moz-selection, .cm-s-mbo .CodeMirror-line > span > span::-moz-selection { background: rgba(113, 108, 98, .99); }
.cm-s-mbo .CodeMirror-gutters { background: #4e4e4e; border-right: 0px; }
.cm-s-mbo .CodeMirror-guttermarker { color: white; }
.cm-s-mbo .CodeMirror-guttermarker-subtle { color: grey; }
.cm-s-mbo .CodeMirror-linenumber { color: #dadada; }
.cm-s-mbo .CodeMirror-cursor { border-left: 1px solid #ffffec; }

.cm-s-mbo span.cm-comment { color: #95958a; }
.cm-s-mbo span.cm-atom { color: #00a8c6; }
.cm-s-mbo span.cm-number { color: #00a8c6; }

.cm-s-mbo span.cm-property, .cm-s-mbo span.cm-attribute { color: #9ddfe9; }
.cm-s-mbo span.cm-keyword { color: #ffb928; }
.cm-s-mbo span.cm-string { color: #ffcf6c; }
.cm-s-mbo span.cm-string.cm-property { color: #ffffec; }

.cm-s-mbo span.cm-variable { color: #ffffec; }
.cm-s-mbo span.cm-variable-2 { color: #00a8c6; }
.cm-s-mbo span.cm-def { color: #ffffec; }
.cm-s-mbo span.cm-bracket { color: #fffffc; font-weight: bold; }
.cm-s-mbo span.cm-tag { color: #9ddfe9; }
.cm-s-mbo span.cm-link { color: #f54b07; }
.cm-s-mbo span.cm-error { border-bottom: #636363; color: #ffffec; }
.cm-s-mbo span.cm-qualifier { color: #ffffec; }

.cm-s-mbo .CodeMirror-activeline-background { background: #494b41; }
.cm-s-mbo .CodeMirror-matchingbracket { color: #ffb928 !important; }
.cm-s-mbo .CodeMirror-matchingtag { background: rgba(255, 255, 255, .37); }

/*
  MDN-LIKE Theme - Mozilla
  Ported to CodeMirror by Peter Kroon <plakroon@gmail.com>
  Report bugs/issues here: https://github.com/codemirror/CodeMirror/issues
  GitHub: @peterkroon

  The mdn-like theme is inspired on the displayed code examples at: https://developer.mozilla.org/en-US/docs/Web/CSS/animation

*/
.cm-s-mdn-like.CodeMirror { color: #999; background-color: #fff; }
.cm-s-mdn-like div.CodeMirror-selected { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::selection, .cm-s-mdn-like .CodeMirror-line > span::selection, .cm-s-mdn-like .CodeMirror-line > span > span::selection { background: #cfc; }
.cm-s-mdn-like .CodeMirror-line::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span::-moz-selection, .cm-s-mdn-like .CodeMirror-line > span > span::-moz-selection { background: #cfc; }

.cm-s-mdn-like .CodeMirror-gutters { background: #f8f8f8; border-left: 6px solid rgba(0,83,159,0.65); color: #333; }
.cm-s-mdn-like .CodeMirror-linenumber { color: #aaa; padding-left: 8px; }
.cm-s-mdn-like .CodeMirror-cursor { border-left: 2px solid #222; }

.cm-s-mdn-like .cm-keyword { color: #6262FF; }
.cm-s-mdn-like .cm-atom { color: #F90; }
.cm-s-mdn-like .cm-number { color:  #ca7841; }
.cm-s-mdn-like .cm-def { color: #8DA6CE; }
.cm-s-mdn-like span.cm-variable-2, .cm-s-mdn-like span.cm-tag { color: #690; }
.cm-s-mdn-like span.cm-variable-3, .cm-s-mdn-like span.cm-def, .cm-s-mdn-like span.cm-type { color: #07a; }

.cm-s-mdn-like .cm-variable { color: #07a; }
.cm-s-mdn-like .cm-property { color: #905; }
.cm-s-mdn-like .cm-qualifier { color: #690; }

.cm-s-mdn-like .cm-operator { color: #cda869; }
.cm-s-mdn-like .cm-comment { color:#777; font-weight:normal; }
.cm-s-mdn-like .cm-string { color:#07a; font-style:italic; }
.cm-s-mdn-like .cm-string-2 { color:#bd6b18; } /*?*/
.cm-s-mdn-like .cm-meta { color: #000; } /*?*/
.cm-s-mdn-like .cm-builtin { color: #9B7536; } /*?*/
.cm-s-mdn-like .cm-tag { color: #997643; }
.cm-s-mdn-like .cm-attribute { color: #d6bb6d; } /*?*/
.cm-s-mdn-like .cm-header { color: #FF6400; }
.cm-s-mdn-like .cm-hr { color: #AEAEAE; }
.cm-s-mdn-like .cm-link { color:#ad9361; font-style:italic; text-decoration:none; }
.cm-s-mdn-like .cm-error { border-bottom: 1px solid red; }

div.cm-s-mdn-like .CodeMirror-activeline-background { background: #efefff; }
div.cm-s-mdn-like span.CodeMirror-matchingbracket { outline:1px solid grey; color: inherit; }

.cm-s-mdn-like.CodeMirror { background-image: url(data:image/png;base64,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); }

/*

    Name:       seti
    Author:     Michael Kaminsky (http://github.com/mkaminsky11)

    Original seti color scheme by Jesse Weed (https://github.com/jesseweed/seti-syntax)

*/


.cm-s-seti.CodeMirror {
  background-color: #151718 !important;
  color: #CFD2D1 !important;
  border: none;
}
.cm-s-seti .CodeMirror-gutters {
  color: #404b53;
  background-color: #0E1112;
  border: none;
}
.cm-s-seti .CodeMirror-cursor { border-left: solid thin #f8f8f0; }
.cm-s-seti .CodeMirror-linenumber { color: #6D8A88; }
.cm-s-seti.CodeMirror-focused div.CodeMirror-selected { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::selection, .cm-s-seti .CodeMirror-line > span::selection, .cm-s-seti .CodeMirror-line > span > span::selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti .CodeMirror-line::-moz-selection, .cm-s-seti .CodeMirror-line > span::-moz-selection, .cm-s-seti .CodeMirror-line > span > span::-moz-selection { background: rgba(255, 255, 255, 0.10); }
.cm-s-seti span.cm-comment { color: #41535b; }
.cm-s-seti span.cm-string, .cm-s-seti span.cm-string-2 { color: #55b5db; }
.cm-s-seti span.cm-number { color: #cd3f45; }
.cm-s-seti span.cm-variable { color: #55b5db; }
.cm-s-seti span.cm-variable-2 { color: #a074c4; }
.cm-s-seti span.cm-def { color: #55b5db; }
.cm-s-seti span.cm-keyword { color: #ff79c6; }
.cm-s-seti span.cm-operator { color: #9fca56; }
.cm-s-seti span.cm-keyword { color: #e6cd69; }
.cm-s-seti span.cm-atom { color: #cd3f45; }
.cm-s-seti span.cm-meta { color: #55b5db; }
.cm-s-seti span.cm-tag { color: #55b5db; }
.cm-s-seti span.cm-attribute { color: #9fca56; }
.cm-s-seti span.cm-qualifier { color: #9fca56; }
.cm-s-seti span.cm-property { color: #a074c4; }
.cm-s-seti span.cm-variable-3, .cm-s-seti span.cm-type { color: #9fca56; }
.cm-s-seti span.cm-builtin { color: #9fca56; }
.cm-s-seti .CodeMirror-activeline-background { background: #101213; }
.cm-s-seti .CodeMirror-matchingbracket { text-decoration: underline; color: white !important; }

/*
Solarized theme for code-mirror
http://ethanschoonover.com/solarized
*/

/*
Solarized color palette
http://ethanschoonover.com/solarized/img/solarized-palette.png
*/

.solarized.base03 { color: #002b36; }
.solarized.base02 { color: #073642; }
.solarized.base01 { color: #586e75; }
.solarized.base00 { color: #657b83; }
.solarized.base0 { color: #839496; }
.solarized.base1 { color: #93a1a1; }
.solarized.base2 { color: #eee8d5; }
.solarized.base3  { color: #fdf6e3; }
.solarized.solar-yellow  { color: #b58900; }
.solarized.solar-orange  { color: #cb4b16; }
.solarized.solar-red { color: #dc322f; }
.solarized.solar-magenta { color: #d33682; }
.solarized.solar-violet  { color: #6c71c4; }
.solarized.solar-blue { color: #268bd2; }
.solarized.solar-cyan { color: #2aa198; }
.solarized.solar-green { color: #859900; }

/* Color scheme for code-mirror */

.cm-s-solarized {
  line-height: 1.45em;
  color-profile: sRGB;
  rendering-intent: auto;
}
.cm-s-solarized.cm-s-dark {
  color: #839496;
  background-color: #002b36;
  text-shadow: #002b36 0 1px;
}
.cm-s-solarized.cm-s-light {
  background-color: #fdf6e3;
  color: #657b83;
  text-shadow: #eee8d5 0 1px;
}

.cm-s-solarized .CodeMirror-widget {
  text-shadow: none;
}

.cm-s-solarized .cm-header { color: #586e75; }
.cm-s-solarized .cm-quote { color: #93a1a1; }

.cm-s-solarized .cm-keyword { color: #cb4b16; }
.cm-s-solarized .cm-atom { color: #d33682; }
.cm-s-solarized .cm-number { color: #d33682; }
.cm-s-solarized .cm-def { color: #2aa198; }

.cm-s-solarized .cm-variable { color: #839496; }
.cm-s-solarized .cm-variable-2 { color: #b58900; }
.cm-s-solarized .cm-variable-3, .cm-s-solarized .cm-type { color: #6c71c4; }

.cm-s-solarized .cm-property { color: #2aa198; }
.cm-s-solarized .cm-operator { color: #6c71c4; }

.cm-s-solarized .cm-comment { color: #586e75; font-style:italic; }

.cm-s-solarized .cm-string { color: #859900; }
.cm-s-solarized .cm-string-2 { color: #b58900; }

.cm-s-solarized .cm-meta { color: #859900; }
.cm-s-solarized .cm-qualifier { color: #b58900; }
.cm-s-solarized .cm-builtin { color: #d33682; }
.cm-s-solarized .cm-bracket { color: #cb4b16; }
.cm-s-solarized .CodeMirror-matchingbracket { color: #859900; }
.cm-s-solarized .CodeMirror-nonmatchingbracket { color: #dc322f; }
.cm-s-solarized .cm-tag { color: #93a1a1; }
.cm-s-solarized .cm-attribute { color: #2aa198; }
.cm-s-solarized .cm-hr {
  color: transparent;
  border-top: 1px solid #586e75;
  display: block;
}
.cm-s-solarized .cm-link { color: #93a1a1; cursor: pointer; }
.cm-s-solarized .cm-special { color: #6c71c4; }
.cm-s-solarized .cm-em {
  color: #999;
  text-decoration: underline;
  text-decoration-style: dotted;
}
.cm-s-solarized .cm-error,
.cm-s-solarized .cm-invalidchar {
  color: #586e75;
  border-bottom: 1px dotted #dc322f;
}

.cm-s-solarized.cm-s-dark div.CodeMirror-selected { background: #073642; }
.cm-s-solarized.cm-s-dark.CodeMirror ::selection { background: rgba(7, 54, 66, 0.99); }
.cm-s-solarized.cm-s-dark .CodeMirror-line::-moz-selection, .cm-s-dark .CodeMirror-line > span::-moz-selection, .cm-s-dark .CodeMirror-line > span > span::-moz-selection { background: rgba(7, 54, 66, 0.99); }

.cm-s-solarized.cm-s-light div.CodeMirror-selected { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::selection, .cm-s-light .CodeMirror-line > span::selection, .cm-s-light .CodeMirror-line > span > span::selection { background: #eee8d5; }
.cm-s-solarized.cm-s-light .CodeMirror-line::-moz-selection, .cm-s-ligh .CodeMirror-line > span::-moz-selection, .cm-s-ligh .CodeMirror-line > span > span::-moz-selection { background: #eee8d5; }

/* Editor styling */



/* Little shadow on the view-port of the buffer view */
.cm-s-solarized.CodeMirror {
  -moz-box-shadow: inset 7px 0 12px -6px #000;
  -webkit-box-shadow: inset 7px 0 12px -6px #000;
  box-shadow: inset 7px 0 12px -6px #000;
}

/* Remove gutter border */
.cm-s-solarized .CodeMirror-gutters {
  border-right: 0;
}

/* Gutter colors and line number styling based of color scheme (dark / light) */

/* Dark */
.cm-s-solarized.cm-s-dark .CodeMirror-gutters {
  background-color: #073642;
}

.cm-s-solarized.cm-s-dark .CodeMirror-linenumber {
  color: #586e75;
  text-shadow: #021014 0 -1px;
}

/* Light */
.cm-s-solarized.cm-s-light .CodeMirror-gutters {
  background-color: #eee8d5;
}

.cm-s-solarized.cm-s-light .CodeMirror-linenumber {
  color: #839496;
}

/* Common */
.cm-s-solarized .CodeMirror-linenumber {
  padding: 0 5px;
}
.cm-s-solarized .CodeMirror-guttermarker-subtle { color: #586e75; }
.cm-s-solarized.cm-s-dark .CodeMirror-guttermarker { color: #ddd; }
.cm-s-solarized.cm-s-light .CodeMirror-guttermarker { color: #cb4b16; }

.cm-s-solarized .CodeMirror-gutter .CodeMirror-gutter-text {
  color: #586e75;
}

/* Cursor */
.cm-s-solarized .CodeMirror-cursor { border-left: 1px solid #819090; }

/* Fat cursor */
.cm-s-solarized.cm-s-light.cm-fat-cursor .CodeMirror-cursor { background: #77ee77; }
.cm-s-solarized.cm-s-light .cm-animate-fat-cursor { background-color: #77ee77; }
.cm-s-solarized.cm-s-dark.cm-fat-cursor .CodeMirror-cursor { background: #586e75; }
.cm-s-solarized.cm-s-dark .cm-animate-fat-cursor { background-color: #586e75; }

/* Active line */
.cm-s-solarized.cm-s-dark .CodeMirror-activeline-background {
  background: rgba(255, 255, 255, 0.06);
}
.cm-s-solarized.cm-s-light .CodeMirror-activeline-background {
  background: rgba(0, 0, 0, 0.06);
}

.cm-s-the-matrix.CodeMirror { background: #000000; color: #00FF00; }
.cm-s-the-matrix div.CodeMirror-selected { background: #2D2D2D; }
.cm-s-the-matrix .CodeMirror-line::selection, .cm-s-the-matrix .CodeMirror-line > span::selection, .cm-s-the-matrix .CodeMirror-line > span > span::selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-line::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span::-moz-selection, .cm-s-the-matrix .CodeMirror-line > span > span::-moz-selection { background: rgba(45, 45, 45, 0.99); }
.cm-s-the-matrix .CodeMirror-gutters { background: #060; border-right: 2px solid #00FF00; }
.cm-s-the-matrix .CodeMirror-guttermarker { color: #0f0; }
.cm-s-the-matrix .CodeMirror-guttermarker-subtle { color: white; }
.cm-s-the-matrix .CodeMirror-linenumber { color: #FFFFFF; }
.cm-s-the-matrix .CodeMirror-cursor { border-left: 1px solid #00FF00; }

.cm-s-the-matrix span.cm-keyword { color: #008803; font-weight: bold; }
.cm-s-the-matrix span.cm-atom { color: #3FF; }
.cm-s-the-matrix span.cm-number { color: #FFB94F; }
.cm-s-the-matrix span.cm-def { color: #99C; }
.cm-s-the-matrix span.cm-variable { color: #F6C; }
.cm-s-the-matrix span.cm-variable-2 { color: #C6F; }
.cm-s-the-matrix span.cm-variable-3, .cm-s-the-matrix span.cm-type { color: #96F; }
.cm-s-the-matrix span.cm-property { color: #62FFA0; }
.cm-s-the-matrix span.cm-operator { color: #999; }
.cm-s-the-matrix span.cm-comment { color: #CCCCCC; }
.cm-s-the-matrix span.cm-string { color: #39C; }
.cm-s-the-matrix span.cm-meta { color: #C9F; }
.cm-s-the-matrix span.cm-qualifier { color: #FFF700; }
.cm-s-the-matrix span.cm-builtin { color: #30a; }
.cm-s-the-matrix span.cm-bracket { color: #cc7; }
.cm-s-the-matrix span.cm-tag { color: #FFBD40; }
.cm-s-the-matrix span.cm-attribute { color: #FFF700; }
.cm-s-the-matrix span.cm-error { color: #FF0000; }

.cm-s-the-matrix .CodeMirror-activeline-background { background: #040; }

/*
Copyright (C) 2011 by MarkLogic Corporation
Author: Mike Brevoort <mike@brevoort.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.
*/
.cm-s-xq-light span.cm-keyword { line-height: 1em; font-weight: bold; color: #5A5CAD; }
.cm-s-xq-light span.cm-atom { color: #6C8CD5; }
.cm-s-xq-light span.cm-number { color: #164; }
.cm-s-xq-light span.cm-def { text-decoration:underline; }
.cm-s-xq-light span.cm-variable { color: black; }
.cm-s-xq-light span.cm-variable-2 { color:black; }
.cm-s-xq-light span.cm-variable-3, .cm-s-xq-light span.cm-type { color: black; }
.cm-s-xq-light span.cm-property {}
.cm-s-xq-light span.cm-operator {}
.cm-s-xq-light span.cm-comment { color: #0080FF; font-style: italic; }
.cm-s-xq-light span.cm-string { color: red; }
.cm-s-xq-light span.cm-meta { color: yellow; }
.cm-s-xq-light span.cm-qualifier { color: grey; }
.cm-s-xq-light span.cm-builtin { color: #7EA656; }
.cm-s-xq-light span.cm-bracket { color: #cc7; }
.cm-s-xq-light span.cm-tag { color: #3F7F7F; }
.cm-s-xq-light span.cm-attribute { color: #7F007F; }
.cm-s-xq-light span.cm-error { color: #f00; }

.cm-s-xq-light .CodeMirror-activeline-background { background: #e8f2ff; }
.cm-s-xq-light .CodeMirror-matchingbracket { outline:1px solid grey;color:black !important;background:yellow; }

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.CodeMirror {
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  border: 0;
  border-radius: 0;
  height: auto;
  /* Changed to auto to autogrow */
}

.CodeMirror pre {
  padding: 0 var(--jp-code-padding);
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-dialog {
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* This causes https://github.com/jupyter/jupyterlab/issues/522 */
/* May not cause it not because we changed it! */
.CodeMirror-lines {
  padding: var(--jp-code-padding) 0;
}

.CodeMirror-linenumber {
  padding: 0 8px;
}

.jp-CodeMirrorEditor-static {
  margin: var(--jp-code-padding);
}

.jp-CodeMirrorEditor,
.jp-CodeMirrorEditor-static {
  cursor: text;
}

.jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}

/* When zoomed out 67% and 33% on a screen of 1440 width x 900 height */
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width1) solid
      var(--jp-editor-cursor-color);
  }
}

/* When zoomed out less than 33% */
@media screen and (min-width: 4320px) {
  .jp-CodeMirrorEditor[data-type='inline'] .CodeMirror-cursor {
    border-left: var(--jp-code-cursor-width2) solid
      var(--jp-editor-cursor-color);
  }
}

.CodeMirror.jp-mod-readOnly .CodeMirror-cursor {
  display: none;
}

.CodeMirror-gutters {
  border-right: 1px solid var(--jp-border-color2);
  background-color: var(--jp-layout-color0);
}

.jp-CollaboratorCursor {
  border-left: 5px solid transparent;
  border-right: 5px solid transparent;
  border-top: none;
  border-bottom: 3px solid;
  background-clip: content-box;
  margin-left: -5px;
  margin-right: -5px;
}

.CodeMirror-selectedtext.cm-searching {
  background-color: var(--jp-search-selected-match-background-color) !important;
  color: var(--jp-search-selected-match-color) !important;
}

.cm-searching {
  background-color: var(
    --jp-search-unselected-match-background-color
  ) !important;
  color: var(--jp-search-unselected-match-color) !important;
}

.CodeMirror-focused .CodeMirror-selected {
  background-color: var(--jp-editor-selected-focused-background);
}

.CodeMirror-selected {
  background-color: var(--jp-editor-selected-background);
}

.jp-CollaboratorCursor-hover {
  position: absolute;
  z-index: 1;
  transform: translateX(-50%);
  color: white;
  border-radius: 3px;
  padding-left: 4px;
  padding-right: 4px;
  padding-top: 1px;
  padding-bottom: 1px;
  text-align: center;
  font-size: var(--jp-ui-font-size1);
  white-space: nowrap;
}

.jp-CodeMirror-ruler {
  border-left: 1px dashed var(--jp-border-color2);
}

/**
 * Here is our jupyter theme for CodeMirror syntax highlighting
 * This is used in our marked.js syntax highlighting and CodeMirror itself
 * The string "jupyter" is set in ../codemirror/widget.DEFAULT_CODEMIRROR_THEME
 * This came from the classic notebook, which came form highlight.js/GitHub
 */

/**
 * CodeMirror themes are handling the background/color in this way. This works
 * fine for CodeMirror editors outside the notebook, but the notebook styles
 * these things differently.
 */
.CodeMirror.cm-s-jupyter {
  background: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
}

/* In the notebook, we want this styling to be handled by its container */
.jp-CodeConsole .CodeMirror.cm-s-jupyter,
.jp-Notebook .CodeMirror.cm-s-jupyter {
  background: transparent;
}

.cm-s-jupyter .CodeMirror-cursor {
  border-left: var(--jp-code-cursor-width0) solid var(--jp-editor-cursor-color);
}
.cm-s-jupyter span.cm-keyword {
  color: var(--jp-mirror-editor-keyword-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-atom {
  color: var(--jp-mirror-editor-atom-color);
}
.cm-s-jupyter span.cm-number {
  color: var(--jp-mirror-editor-number-color);
}
.cm-s-jupyter span.cm-def {
  color: var(--jp-mirror-editor-def-color);
}
.cm-s-jupyter span.cm-variable {
  color: var(--jp-mirror-editor-variable-color);
}
.cm-s-jupyter span.cm-variable-2 {
  color: var(--jp-mirror-editor-variable-2-color);
}
.cm-s-jupyter span.cm-variable-3 {
  color: var(--jp-mirror-editor-variable-3-color);
}
.cm-s-jupyter span.cm-punctuation {
  color: var(--jp-mirror-editor-punctuation-color);
}
.cm-s-jupyter span.cm-property {
  color: var(--jp-mirror-editor-property-color);
}
.cm-s-jupyter span.cm-operator {
  color: var(--jp-mirror-editor-operator-color);
  font-weight: bold;
}
.cm-s-jupyter span.cm-comment {
  color: var(--jp-mirror-editor-comment-color);
  font-style: italic;
}
.cm-s-jupyter span.cm-string {
  color: var(--jp-mirror-editor-string-color);
}
.cm-s-jupyter span.cm-string-2 {
  color: var(--jp-mirror-editor-string-2-color);
}
.cm-s-jupyter span.cm-meta {
  color: var(--jp-mirror-editor-meta-color);
}
.cm-s-jupyter span.cm-qualifier {
  color: var(--jp-mirror-editor-qualifier-color);
}
.cm-s-jupyter span.cm-builtin {
  color: var(--jp-mirror-editor-builtin-color);
}
.cm-s-jupyter span.cm-bracket {
  color: var(--jp-mirror-editor-bracket-color);
}
.cm-s-jupyter span.cm-tag {
  color: var(--jp-mirror-editor-tag-color);
}
.cm-s-jupyter span.cm-attribute {
  color: var(--jp-mirror-editor-attribute-color);
}
.cm-s-jupyter span.cm-header {
  color: var(--jp-mirror-editor-header-color);
}
.cm-s-jupyter span.cm-quote {
  color: var(--jp-mirror-editor-quote-color);
}
.cm-s-jupyter span.cm-link {
  color: var(--jp-mirror-editor-link-color);
}
.cm-s-jupyter span.cm-error {
  color: var(--jp-mirror-editor-error-color);
}
.cm-s-jupyter span.cm-hr {
  color: #999;
}

.cm-s-jupyter span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}

.cm-s-jupyter .CodeMirror-activeline-background,
.cm-s-jupyter .CodeMirror-gutter {
  background-color: var(--jp-layout-color2);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| RenderedText
|----------------------------------------------------------------------------*/

.jp-RenderedText {
  text-align: left;
  padding-left: var(--jp-code-padding);
  line-height: var(--jp-code-line-height);
  font-family: var(--jp-code-font-family);
}

.jp-RenderedText pre,
.jp-RenderedJavaScript pre,
.jp-RenderedHTMLCommon pre {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-code-font-size);
  border: none;
  margin: 0px;
  padding: 0px;
  line-height: normal;
}

.jp-RenderedText pre a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}
.jp-RenderedText pre a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* console foregrounds and backgrounds */
.jp-RenderedText pre .ansi-black-fg {
  color: #3e424d;
}
.jp-RenderedText pre .ansi-red-fg {
  color: #e75c58;
}
.jp-RenderedText pre .ansi-green-fg {
  color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-fg {
  color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-fg {
  color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-fg {
  color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-fg {
  color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-fg {
  color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-bg {
  background-color: #3e424d;
}
.jp-RenderedText pre .ansi-red-bg {
  background-color: #e75c58;
}
.jp-RenderedText pre .ansi-green-bg {
  background-color: #00a250;
}
.jp-RenderedText pre .ansi-yellow-bg {
  background-color: #ddb62b;
}
.jp-RenderedText pre .ansi-blue-bg {
  background-color: #208ffb;
}
.jp-RenderedText pre .ansi-magenta-bg {
  background-color: #d160c4;
}
.jp-RenderedText pre .ansi-cyan-bg {
  background-color: #60c6c8;
}
.jp-RenderedText pre .ansi-white-bg {
  background-color: #c5c1b4;
}

.jp-RenderedText pre .ansi-black-intense-fg {
  color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-fg {
  color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-fg {
  color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-fg {
  color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-fg {
  color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-fg {
  color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-fg {
  color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-fg {
  color: #a1a6b2;
}

.jp-RenderedText pre .ansi-black-intense-bg {
  background-color: #282c36;
}
.jp-RenderedText pre .ansi-red-intense-bg {
  background-color: #b22b31;
}
.jp-RenderedText pre .ansi-green-intense-bg {
  background-color: #007427;
}
.jp-RenderedText pre .ansi-yellow-intense-bg {
  background-color: #b27d12;
}
.jp-RenderedText pre .ansi-blue-intense-bg {
  background-color: #0065ca;
}
.jp-RenderedText pre .ansi-magenta-intense-bg {
  background-color: #a03196;
}
.jp-RenderedText pre .ansi-cyan-intense-bg {
  background-color: #258f8f;
}
.jp-RenderedText pre .ansi-white-intense-bg {
  background-color: #a1a6b2;
}

.jp-RenderedText pre .ansi-default-inverse-fg {
  color: var(--jp-ui-inverse-font-color0);
}
.jp-RenderedText pre .ansi-default-inverse-bg {
  background-color: var(--jp-inverse-layout-color0);
}

.jp-RenderedText pre .ansi-bold {
  font-weight: bold;
}
.jp-RenderedText pre .ansi-underline {
  text-decoration: underline;
}

.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr'] {
  background: var(--jp-rendermime-error-background);
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| RenderedLatex
|----------------------------------------------------------------------------*/

.jp-RenderedLatex {
  color: var(--jp-content-font-color1);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
}

/* Left-justify outputs.*/
.jp-OutputArea-output.jp-RenderedLatex {
  padding: var(--jp-code-padding);
  text-align: left;
}

/*-----------------------------------------------------------------------------
| RenderedHTML
|----------------------------------------------------------------------------*/

.jp-RenderedHTMLCommon {
  color: var(--jp-content-font-color1);
  font-family: var(--jp-content-font-family);
  font-size: var(--jp-content-font-size1);
  line-height: var(--jp-content-line-height);
  /* Give a bit more R padding on Markdown text to keep line lengths reasonable */
  padding-right: 20px;
}

.jp-RenderedHTMLCommon em {
  font-style: italic;
}

.jp-RenderedHTMLCommon strong {
  font-weight: bold;
}

.jp-RenderedHTMLCommon u {
  text-decoration: underline;
}

.jp-RenderedHTMLCommon a:link {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:hover {
  text-decoration: underline;
  color: var(--jp-content-link-color);
}

.jp-RenderedHTMLCommon a:visited {
  text-decoration: none;
  color: var(--jp-content-link-color);
}

/* Headings */

.jp-RenderedHTMLCommon h1,
.jp-RenderedHTMLCommon h2,
.jp-RenderedHTMLCommon h3,
.jp-RenderedHTMLCommon h4,
.jp-RenderedHTMLCommon h5,
.jp-RenderedHTMLCommon h6 {
  line-height: var(--jp-content-heading-line-height);
  font-weight: var(--jp-content-heading-font-weight);
  font-style: normal;
  margin: var(--jp-content-heading-margin-top) 0
    var(--jp-content-heading-margin-bottom) 0;
}

.jp-RenderedHTMLCommon h1:first-child,
.jp-RenderedHTMLCommon h2:first-child,
.jp-RenderedHTMLCommon h3:first-child,
.jp-RenderedHTMLCommon h4:first-child,
.jp-RenderedHTMLCommon h5:first-child,
.jp-RenderedHTMLCommon h6:first-child {
  margin-top: calc(0.5 * var(--jp-content-heading-margin-top));
}

.jp-RenderedHTMLCommon h1:last-child,
.jp-RenderedHTMLCommon h2:last-child,
.jp-RenderedHTMLCommon h3:last-child,
.jp-RenderedHTMLCommon h4:last-child,
.jp-RenderedHTMLCommon h5:last-child,
.jp-RenderedHTMLCommon h6:last-child {
  margin-bottom: calc(0.5 * var(--jp-content-heading-margin-bottom));
}

.jp-RenderedHTMLCommon h1 {
  font-size: var(--jp-content-font-size5);
}

.jp-RenderedHTMLCommon h2 {
  font-size: var(--jp-content-font-size4);
}

.jp-RenderedHTMLCommon h3 {
  font-size: var(--jp-content-font-size3);
}

.jp-RenderedHTMLCommon h4 {
  font-size: var(--jp-content-font-size2);
}

.jp-RenderedHTMLCommon h5 {
  font-size: var(--jp-content-font-size1);
}

.jp-RenderedHTMLCommon h6 {
  font-size: var(--jp-content-font-size0);
}

/* Lists */

.jp-RenderedHTMLCommon ul:not(.list-inline),
.jp-RenderedHTMLCommon ol:not(.list-inline) {
  padding-left: 2em;
}

.jp-RenderedHTMLCommon ul {
  list-style: disc;
}

.jp-RenderedHTMLCommon ul ul {
  list-style: square;
}

.jp-RenderedHTMLCommon ul ul ul {
  list-style: circle;
}

.jp-RenderedHTMLCommon ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol ol {
  list-style: upper-alpha;
}

.jp-RenderedHTMLCommon ol ol ol {
  list-style: lower-alpha;
}

.jp-RenderedHTMLCommon ol ol ol ol {
  list-style: lower-roman;
}

.jp-RenderedHTMLCommon ol ol ol ol ol {
  list-style: decimal;
}

.jp-RenderedHTMLCommon ol,
.jp-RenderedHTMLCommon ul {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon ul ul,
.jp-RenderedHTMLCommon ul ol,
.jp-RenderedHTMLCommon ol ul,
.jp-RenderedHTMLCommon ol ol {
  margin-bottom: 0em;
}

.jp-RenderedHTMLCommon hr {
  color: var(--jp-border-color2);
  background-color: var(--jp-border-color1);
  margin-top: 1em;
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon > pre {
  margin: 1.5em 2em;
}

.jp-RenderedHTMLCommon pre,
.jp-RenderedHTMLCommon code {
  border: 0;
  background-color: var(--jp-layout-color0);
  color: var(--jp-content-font-color1);
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  line-height: var(--jp-code-line-height);
  padding: 0;
  white-space: pre-wrap;
}

.jp-RenderedHTMLCommon :not(pre) > code {
  background-color: var(--jp-layout-color2);
  padding: 1px 5px;
}

/* Tables */

.jp-RenderedHTMLCommon table {
  border-collapse: collapse;
  border-spacing: 0;
  border: none;
  color: var(--jp-ui-font-color1);
  font-size: 12px;
  table-layout: fixed;
  margin-left: auto;
  margin-right: auto;
}

.jp-RenderedHTMLCommon thead {
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  vertical-align: bottom;
}

.jp-RenderedHTMLCommon td,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon tr {
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}

.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,
.jp-RenderedMarkdown.jp-RenderedHTMLCommon th {
  max-width: none;
}

:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,
:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr {
  text-align: right;
}

.jp-RenderedHTMLCommon th {
  font-weight: bold;
}

.jp-RenderedHTMLCommon tbody tr:nth-child(odd) {
  background: var(--jp-layout-color0);
}

.jp-RenderedHTMLCommon tbody tr:nth-child(even) {
  background: var(--jp-rendermime-table-row-background);
}

.jp-RenderedHTMLCommon tbody tr:hover {
  background: var(--jp-rendermime-table-row-hover-background);
}

.jp-RenderedHTMLCommon table {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon p {
  text-align: left;
  margin: 0px;
}

.jp-RenderedHTMLCommon p {
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon img {
  -moz-force-broken-image-icon: 1;
}

/* Restrict to direct children as other images could be nested in other content. */
.jp-RenderedHTMLCommon > img {
  display: block;
  margin-left: 0;
  margin-right: 0;
  margin-bottom: 1em;
}

/* Change color behind transparent images if they need it... */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background {
  background-color: var(--jp-inverse-layout-color1);
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background {
  background-color: var(--jp-inverse-layout-color1);
}
/* ...or leave it untouched if they don't */
[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-dark-background {
}
[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-light-background {
}

.jp-RenderedHTMLCommon img,
.jp-RenderedImage img,
.jp-RenderedHTMLCommon svg,
.jp-RenderedSVG svg {
  max-width: 100%;
  height: auto;
}

.jp-RenderedHTMLCommon img.jp-mod-unconfined,
.jp-RenderedImage img.jp-mod-unconfined,
.jp-RenderedHTMLCommon svg.jp-mod-unconfined,
.jp-RenderedSVG svg.jp-mod-unconfined {
  max-width: none;
}

.jp-RenderedHTMLCommon .alert {
  padding: var(--jp-notebook-padding);
  border: var(--jp-border-width) solid transparent;
  border-radius: var(--jp-border-radius);
  margin-bottom: 1em;
}

.jp-RenderedHTMLCommon .alert-info {
  color: var(--jp-info-color0);
  background-color: var(--jp-info-color3);
  border-color: var(--jp-info-color2);
}
.jp-RenderedHTMLCommon .alert-info hr {
  border-color: var(--jp-info-color3);
}
.jp-RenderedHTMLCommon .alert-info > p:last-child,
.jp-RenderedHTMLCommon .alert-info > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-warning {
  color: var(--jp-warn-color0);
  background-color: var(--jp-warn-color3);
  border-color: var(--jp-warn-color2);
}
.jp-RenderedHTMLCommon .alert-warning hr {
  border-color: var(--jp-warn-color3);
}
.jp-RenderedHTMLCommon .alert-warning > p:last-child,
.jp-RenderedHTMLCommon .alert-warning > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-success {
  color: var(--jp-success-color0);
  background-color: var(--jp-success-color3);
  border-color: var(--jp-success-color2);
}
.jp-RenderedHTMLCommon .alert-success hr {
  border-color: var(--jp-success-color3);
}
.jp-RenderedHTMLCommon .alert-success > p:last-child,
.jp-RenderedHTMLCommon .alert-success > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon .alert-danger {
  color: var(--jp-error-color0);
  background-color: var(--jp-error-color3);
  border-color: var(--jp-error-color2);
}
.jp-RenderedHTMLCommon .alert-danger hr {
  border-color: var(--jp-error-color3);
}
.jp-RenderedHTMLCommon .alert-danger > p:last-child,
.jp-RenderedHTMLCommon .alert-danger > ul:last-child {
  margin-bottom: 0;
}

.jp-RenderedHTMLCommon blockquote {
  margin: 1em 2em;
  padding: 0 1em;
  border-left: 5px solid var(--jp-border-color2);
}

a.jp-InternalAnchorLink {
  visibility: hidden;
  margin-left: 8px;
  color: var(--md-blue-800);
}

h1:hover .jp-InternalAnchorLink,
h2:hover .jp-InternalAnchorLink,
h3:hover .jp-InternalAnchorLink,
h4:hover .jp-InternalAnchorLink,
h5:hover .jp-InternalAnchorLink,
h6:hover .jp-InternalAnchorLink {
  visibility: visible;
}

.jp-RenderedHTMLCommon kbd {
  background-color: var(--jp-rendermime-table-row-background);
  border: 1px solid var(--jp-border-color0);
  border-bottom-color: var(--jp-border-color2);
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
  display: inline-block;
  font-size: 0.8em;
  line-height: 1em;
  padding: 0.2em 0.5em;
}

/* Most direct children of .jp-RenderedHTMLCommon have a margin-bottom of 1.0.
 * At the bottom of cells this is a bit too much as there is also spacing
 * between cells. Going all the way to 0 gets too tight between markdown and
 * code cells.
 */
.jp-RenderedHTMLCommon > *:last-child {
  margin-bottom: 0.5em;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-MimeDocument {
  outline: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-filebrowser-button-height: 28px;
  --jp-private-filebrowser-button-width: 48px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-FileBrowser {
  display: flex;
  flex-direction: column;
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
   * relative to this base size */
  font-size: var(--jp-ui-font-size1);
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  border-bottom: none;
  height: auto;
  margin: var(--jp-toolbar-header-margin);
  box-shadow: none;
}

.jp-BreadCrumbs {
  flex: 0 0 auto;
  margin: 4px 12px;
}

.jp-BreadCrumbs-item {
  margin: 0px 2px;
  padding: 0px 2px;
  border-radius: var(--jp-border-radius);
  cursor: pointer;
}

.jp-BreadCrumbs-item:hover {
  background-color: var(--jp-layout-color2);
}

.jp-BreadCrumbs-item:first-child {
  margin-left: 0px;
}

.jp-BreadCrumbs-item.jp-mod-dropTarget {
  background-color: var(--jp-brand-color2);
  opacity: 0.7;
}

/*-----------------------------------------------------------------------------
| Buttons
|----------------------------------------------------------------------------*/

.jp-FileBrowser-toolbar.jp-Toolbar {
  padding: 0px;
}

.jp-FileBrowser-toolbar.jp-Toolbar {
  justify-content: space-evenly;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-Toolbar-item {
  flex: 1;
}

.jp-FileBrowser-toolbar.jp-Toolbar .jp-ToolbarButtonComponent {
  width: 100%;
}

/*-----------------------------------------------------------------------------
| DirListing
|----------------------------------------------------------------------------*/

.jp-DirListing {
  flex: 1 1 auto;
  display: flex;
  flex-direction: column;
  outline: 0;
}

.jp-DirListing-header {
  flex: 0 0 auto;
  display: flex;
  flex-direction: row;
  overflow: hidden;
  border-top: var(--jp-border-width) solid var(--jp-border-color2);
  border-bottom: var(--jp-border-width) solid var(--jp-border-color1);
  box-shadow: var(--jp-toolbar-box-shadow);
  z-index: 2;
}

.jp-DirListing-headerItem {
  padding: 4px 12px 2px 12px;
  font-weight: 500;
}

.jp-DirListing-headerItem:hover {
  background: var(--jp-layout-color2);
}

.jp-DirListing-headerItem.jp-id-name {
  flex: 1 0 84px;
}

.jp-DirListing-headerItem.jp-id-modified {
  flex: 0 0 112px;
  border-left: var(--jp-border-width) solid var(--jp-border-color2);
  text-align: right;
}

.jp-DirListing-narrow .jp-id-modified,
.jp-DirListing-narrow .jp-DirListing-itemModified {
  display: none;
}

.jp-DirListing-headerItem.jp-mod-selected {
  font-weight: 600;
}

/* increase specificity to override bundled default */
.jp-DirListing-content {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

/* Style the directory listing content when a user drops a file to upload */
.jp-DirListing.jp-mod-native-drop .jp-DirListing-content {
  outline: 5px dashed rgba(128, 128, 128, 0.5);
  outline-offset: -10px;
  cursor: copy;
}

.jp-DirListing-item {
  display: flex;
  flex-direction: row;
  padding: 4px 12px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-DirListing-item.jp-mod-selected {
  color: white;
  background: var(--jp-brand-color1);
}

.jp-DirListing-item.jp-mod-dropTarget {
  background: var(--jp-brand-color3);
}

.jp-DirListing-item:hover:not(.jp-mod-selected) {
  background: var(--jp-layout-color2);
}

.jp-DirListing-itemIcon {
  flex: 0 0 20px;
  margin-right: 4px;
}

.jp-DirListing-itemText {
  flex: 1 0 64px;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  user-select: none;
}

.jp-DirListing-itemModified {
  flex: 0 0 125px;
  text-align: right;
}

.jp-DirListing-editor {
  flex: 1 0 64px;
  outline: none;
  border: none;
}

.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon:before {
  color: limegreen;
  content: '\25CF';
  font-size: 8px;
  position: absolute;
  left: -8px;
}

.jp-DirListing-item.lm-mod-drag-image,
.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image {
  font-size: var(--jp-ui-font-size1);
  padding-left: 4px;
  margin-left: 4px;
  width: 160px;
  background-color: var(--jp-ui-inverse-font-color2);
  box-shadow: var(--jp-elevation-z2);
  border-radius: 0px;
  color: var(--jp-ui-font-color1);
  transform: translateX(-40%) translateY(-58%);
}

.jp-DirListing-deadSpace {
  flex: 1 1 auto;
  margin: 0;
  padding: 0;
  list-style-type: none;
  overflow: auto;
  background-color: var(--jp-layout-color1);
}

.jp-Document {
  min-width: 120px;
  min-height: 120px;
  outline: none;
}

.jp-FileDialog.jp-mod-conflict input {
  color: red;
}

.jp-FileDialog .jp-new-name-title {
  margin-top: 12px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
}

/*-----------------------------------------------------------------------------
| Main OutputArea
| OutputArea has a list of Outputs
|----------------------------------------------------------------------------*/

.jp-OutputArea {
  overflow-y: auto;
}

.jp-OutputArea-child {
  display: flex;
  flex-direction: row;
}

.jp-OutputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-outprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.jp-OutputArea-output {
  height: auto;
  overflow: auto;
  user-select: text;
  -moz-user-select: text;
  -webkit-user-select: text;
  -ms-user-select: text;
}

.jp-OutputArea-child .jp-OutputArea-output {
  flex-grow: 1;
  flex-shrink: 1;
}

/**
 * Isolated output.
 */
.jp-OutputArea-output.jp-mod-isolated {
  width: 100%;
  display: block;
}

/*
When drag events occur, `p-mod-override-cursor` is added to the body.
Because iframes steal all cursor events, the following two rules are necessary
to suppress pointer events while resize drags are occurring. There may be a
better solution to this problem.
*/
body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated {
  position: relative;
}

body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated:before {
  content: '';
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: transparent;
}

/* pre */

.jp-OutputArea-output pre {
  border: none;
  margin: 0px;
  padding: 0px;
  overflow-x: auto;
  overflow-y: auto;
  word-break: break-all;
  word-wrap: break-word;
  white-space: pre-wrap;
}

/* tables */

.jp-OutputArea-output.jp-RenderedHTMLCommon table {
  margin-left: 0;
  margin-right: 0;
}

/* description lists */

.jp-OutputArea-output dl,
.jp-OutputArea-output dt,
.jp-OutputArea-output dd {
  display: block;
}

.jp-OutputArea-output dl {
  width: 100%;
  overflow: hidden;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dt {
  font-weight: bold;
  float: left;
  width: 20%;
  padding: 0;
  margin: 0;
}

.jp-OutputArea-output dd {
  float: left;
  width: 80%;
  padding: 0;
  margin: 0;
}

/* Hide the gutter in case of
 *  - nested output areas (e.g. in the case of output widgets)
 *  - mirrored output areas
 */
.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt {
  display: none;
}

/*-----------------------------------------------------------------------------
| executeResult is added to any Output-result for the display of the object
| returned by a cell
|----------------------------------------------------------------------------*/

.jp-OutputArea-output.jp-OutputArea-executeResult {
  margin-left: 0px;
  flex: 1 1 auto;
}

.jp-OutputArea-executeResult.jp-RenderedText {
  padding-top: var(--jp-code-padding);
}

/*-----------------------------------------------------------------------------
| The Stdin output
|----------------------------------------------------------------------------*/

.jp-OutputArea-stdin {
  line-height: var(--jp-code-line-height);
  padding-top: var(--jp-code-padding);
  display: flex;
}

.jp-Stdin-prompt {
  color: var(--jp-content-font-color0);
  padding-right: var(--jp-code-padding);
  vertical-align: baseline;
  flex: 0 0 auto;
}

.jp-Stdin-input {
  font-family: var(--jp-code-font-family);
  font-size: inherit;
  color: inherit;
  background-color: inherit;
  width: 42%;
  min-width: 200px;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
  flex: 0 0 70%;
}

.jp-Stdin-input:focus {
  box-shadow: none;
}

/*-----------------------------------------------------------------------------
| Output Area View
|----------------------------------------------------------------------------*/

.jp-LinkedOutputView .jp-OutputArea {
  height: 100%;
  display: block;
}

.jp-LinkedOutputView .jp-OutputArea-output:only-child {
  height: 100%;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

.jp-Collapser {
  flex: 0 0 var(--jp-cell-collapser-width);
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
  border-radius: var(--jp-border-radius);
  opacity: 1;
}

.jp-Collapser-child {
  display: block;
  width: 100%;
  box-sizing: border-box;
  /* height: 100% doesn't work because the height of its parent is computed from content */
  position: absolute;
  top: 0px;
  bottom: 0px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Header/Footer
|----------------------------------------------------------------------------*/

/* Hidden by zero height by default */
.jp-CellHeader,
.jp-CellFooter {
  height: 0px;
  width: 100%;
  padding: 0px;
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Input
|----------------------------------------------------------------------------*/

/* All input areas */
.jp-InputArea {
  display: flex;
  flex-direction: row;
}

.jp-InputArea-editor {
  flex: 1 1 auto;
}

.jp-InputArea-editor {
  /* This is the non-active, default styling */
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  border-radius: 0px;
  background: var(--jp-cell-editor-background);
}

.jp-InputPrompt {
  flex: 0 0 var(--jp-cell-prompt-width);
  color: var(--jp-cell-inprompt-font-color);
  font-family: var(--jp-cell-prompt-font-family);
  padding: var(--jp-code-padding);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  opacity: var(--jp-cell-prompt-opacity);
  line-height: var(--jp-code-line-height);
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
  opacity: var(--jp-cell-prompt-opacity);
  /* Right align prompt text, don't wrap to handle large prompt numbers */
  text-align: right;
  white-space: nowrap;
  overflow: hidden;
  text-overflow: ellipsis;
  /* Disable text selection */
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Placeholder
|----------------------------------------------------------------------------*/

.jp-Placeholder {
  display: flex;
  flex-direction: row;
  flex: 1 1 auto;
}

.jp-Placeholder-prompt {
  box-sizing: border-box;
}

.jp-Placeholder-content {
  flex: 1 1 auto;
  border: none;
  background: transparent;
  height: 20px;
  box-sizing: border-box;
}

.jp-Placeholder-content .jp-MoreHorizIcon {
  width: 32px;
  height: 16px;
  border: 1px solid transparent;
  border-radius: var(--jp-border-radius);
}

.jp-Placeholder-content .jp-MoreHorizIcon:hover {
  border: 1px solid var(--jp-border-color1);
  box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.25);
  background-color: var(--jp-layout-color0);
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-cell-scrolling-output-offset: 5px;
}

/*-----------------------------------------------------------------------------
| Cell
|----------------------------------------------------------------------------*/

.jp-Cell {
  padding: var(--jp-cell-padding);
  margin: 0px;
  border: none;
  outline: none;
  background: transparent;
}

/*-----------------------------------------------------------------------------
| Common input/output
|----------------------------------------------------------------------------*/

.jp-Cell-inputWrapper,
.jp-Cell-outputWrapper {
  display: flex;
  flex-direction: row;
  padding: 0px;
  margin: 0px;
  /* Added to reveal the box-shadow on the input and output collapsers. */
  overflow: visible;
}

/* Only input/output areas inside cells */
.jp-Cell-inputArea,
.jp-Cell-outputArea {
  flex: 1 1 auto;
}

/*-----------------------------------------------------------------------------
| Collapser
|----------------------------------------------------------------------------*/

/* Make the output collapser disappear when there is not output, but do so
 * in a manner that leaves it in the layout and preserves its width.
 */
.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser {
  border: none !important;
  background: transparent !important;
}

.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser {
  min-height: var(--jp-cell-collapser-min-height);
}

/*-----------------------------------------------------------------------------
| Output
|----------------------------------------------------------------------------*/

/* Put a space between input and output when there IS output */
.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper {
  margin-top: 5px;
}

/* Text output with the Out[] prompt needs a top padding to match the
 * alignment of the Out[] prompt itself.
 */
.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output {
  padding-top: var(--jp-code-padding);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea {
  overflow-y: auto;
  max-height: 200px;
  box-shadow: inset 0 0 6px 2px rgba(0, 0, 0, 0.3);
  margin-left: var(--jp-private-cell-scrolling-output-offset);
}

.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt {
  flex: 0 0
    calc(
      var(--jp-cell-prompt-width) -
        var(--jp-private-cell-scrolling-output-offset)
    );
}

/*-----------------------------------------------------------------------------
| CodeCell
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| MarkdownCell
|----------------------------------------------------------------------------*/

.jp-MarkdownOutput {
  flex: 1 1 auto;
  margin-top: 0;
  margin-bottom: 0;
  padding-left: var(--jp-code-padding);
}

.jp-MarkdownOutput.jp-RenderedHTMLCommon {
  overflow: auto;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Variables
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------

/*-----------------------------------------------------------------------------
| Styles
|----------------------------------------------------------------------------*/

.jp-NotebookPanel-toolbar {
  padding: 2px;
}

.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused {
  border: none;
  box-shadow: none;
}

.jp-Notebook-toolbarCellTypeDropdown select {
  height: 24px;
  font-size: var(--jp-ui-font-size1);
  line-height: 14px;
  border-radius: 0;
  display: block;
}

.jp-Notebook-toolbarCellTypeDropdown span {
  top: 5px !important;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Private CSS variables
|----------------------------------------------------------------------------*/

:root {
  --jp-private-notebook-dragImage-width: 304px;
  --jp-private-notebook-dragImage-height: 36px;
  --jp-private-notebook-selected-color: var(--md-blue-400);
  --jp-private-notebook-active-color: var(--md-green-400);
}

/*-----------------------------------------------------------------------------
| Imports
|----------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------
| Notebook
|----------------------------------------------------------------------------*/

.jp-NotebookPanel {
  display: block;
  height: 100%;
}

.jp-NotebookPanel.jp-Document {
  min-width: 240px;
  min-height: 120px;
}

.jp-Notebook {
  padding: var(--jp-notebook-padding);
  outline: none;
  overflow: auto;
  background: var(--jp-layout-color0);
}

.jp-Notebook.jp-mod-scrollPastEnd::after {
  display: block;
  content: '';
  min-height: var(--jp-notebook-scroll-padding);
}

.jp-Notebook .jp-Cell {
  overflow: visible;
}

.jp-Notebook .jp-Cell .jp-InputPrompt {
  cursor: move;
}

/*-----------------------------------------------------------------------------
| Notebook state related styling
|
| The notebook and cells each have states, here are the possibilities:
|
| - Notebook
|   - Command
|   - Edit
| - Cell
|   - None
|   - Active (only one can be active)
|   - Selected (the cells actions are applied to)
|   - Multiselected (when multiple selected, the cursor)
|   - No outputs
|----------------------------------------------------------------------------*/

/* Command or edit modes */

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt {
  opacity: var(--jp-cell-prompt-not-active-opacity);
  color: var(--jp-cell-prompt-not-active-font-color);
}

/* cell is active */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser {
  background: var(--jp-brand-color1);
}

/* collapser is hovered */
.jp-Notebook .jp-Cell .jp-Collapser:hover {
  box-shadow: var(--jp-elevation-z2);
  background: var(--jp-brand-color1);
  opacity: var(--jp-cell-collapser-not-active-hover-opacity);
}

/* cell is active and collapser is hovered */
.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover {
  background: var(--jp-brand-color0);
  opacity: 1;
}

/* Command mode */

.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected {
  background: var(--jp-notebook-multiselected-color);
}

.jp-Notebook.jp-mod-commandMode
  .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected) {
  background: transparent;
}

/* Edit mode */

.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor {
  border: var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);
  box-shadow: var(--jp-input-box-shadow);
  background-color: var(--jp-cell-editor-active-background);
}

/*-----------------------------------------------------------------------------
| Notebook drag and drop
|----------------------------------------------------------------------------*/

.jp-Notebook-cell.jp-mod-dropSource {
  opacity: 0.5;
}

.jp-Notebook-cell.jp-mod-dropTarget,
.jp-Notebook.jp-mod-commandMode
  .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget {
  border-top-color: var(--jp-private-notebook-selected-color);
  border-top-style: solid;
  border-top-width: 2px;
}

.jp-dragImage {
  display: flex;
  flex-direction: row;
  width: var(--jp-private-notebook-dragImage-width);
  height: var(--jp-private-notebook-dragImage-height);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background);
  overflow: visible;
}

.jp-dragImage-singlePrompt {
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

.jp-dragImage .jp-dragImage-content {
  flex: 1 1 auto;
  z-index: 2;
  font-size: var(--jp-code-font-size);
  font-family: var(--jp-code-font-family);
  line-height: var(--jp-code-line-height);
  padding: var(--jp-code-padding);
  border: var(--jp-border-width) solid var(--jp-cell-editor-border-color);
  background: var(--jp-cell-editor-background-color);
  color: var(--jp-content-font-color3);
  text-align: left;
  margin: 4px 4px 4px 0px;
}

.jp-dragImage .jp-dragImage-prompt {
  flex: 0 0 auto;
  min-width: 36px;
  color: var(--jp-cell-inprompt-font-color);
  padding: var(--jp-code-padding);
  padding-left: 12px;
  font-family: var(--jp-cell-prompt-font-family);
  letter-spacing: var(--jp-cell-prompt-letter-spacing);
  line-height: 1.9;
  font-size: var(--jp-code-font-size);
  border: var(--jp-border-width) solid transparent;
}

.jp-dragImage-multipleBack {
  z-index: -1;
  position: absolute;
  height: 32px;
  width: 300px;
  top: 8px;
  left: 8px;
  background: var(--jp-layout-color2);
  border: var(--jp-border-width) solid var(--jp-input-border-color);
  box-shadow: 2px 2px 4px 0px rgba(0, 0, 0, 0.12);
}

/*-----------------------------------------------------------------------------
| Cell toolbar
|----------------------------------------------------------------------------*/

.jp-NotebookTools {
  display: block;
  min-width: var(--jp-sidebar-min-width);
  color: var(--jp-ui-font-color1);
  background: var(--jp-layout-color1);
  /* This is needed so that all font sizing of children done in ems is
    * relative to this base size */
  font-size: var(--jp-ui-font-size1);
  overflow: auto;
}

.jp-NotebookTools-tool {
  padding: 0px 12px 0 12px;
}

.jp-ActiveCellTool {
  padding: 12px;
  background-color: var(--jp-layout-color1);
  border-top: none !important;
}

.jp-ActiveCellTool .jp-InputArea-prompt {
  flex: 0 0 auto;
  padding-left: 0px;
}

.jp-ActiveCellTool .jp-InputArea-editor {
  flex: 1 1 auto;
  background: var(--jp-cell-editor-background);
  border-color: var(--jp-cell-editor-border-color);
}

.jp-ActiveCellTool .jp-InputArea-editor .CodeMirror {
  background: transparent;
}

.jp-MetadataEditorTool {
  flex-direction: column;
  padding: 12px 0px 12px 0px;
}

.jp-RankedPanel > :not(:first-child) {
  margin-top: 12px;
}

.jp-KeySelector select.jp-mod-styled {
  font-size: var(--jp-ui-font-size1);
  color: var(--jp-ui-font-color0);
  border: var(--jp-border-width) solid var(--jp-border-color1);
}

.jp-KeySelector label,
.jp-MetadataEditorTool label {
  line-height: 1.4;
}

/*-----------------------------------------------------------------------------
| Presentation Mode (.jp-mod-presentationMode)
|----------------------------------------------------------------------------*/

.jp-mod-presentationMode .jp-Notebook {
  --jp-content-font-size1: var(--jp-content-presentation-font-size1);
  --jp-code-font-size: var(--jp-code-presentation-font-size);
}

.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,
.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt {
  flex: 0 0 110px;
}

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/* This file was auto-generated by ensurePackage() in @jupyterlab/buildutils */

/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

</style>

    <style type="text/css">
/*-----------------------------------------------------------------------------
| Copyright (c) Jupyter Development Team.
| Distributed under the terms of the Modified BSD License.
|----------------------------------------------------------------------------*/

/*
The following CSS variables define the main, public API for styling JupyterLab.
These variables should be used by all plugins wherever possible. In other
words, plugins should not define custom colors, sizes, etc unless absolutely
necessary. This enables users to change the visual theme of JupyterLab
by changing these variables.

Many variables appear in an ordered sequence (0,1,2,3). These sequences
are designed to work well together, so for example, `--jp-border-color1` should
be used with `--jp-layout-color1`. The numbers have the following meanings:

* 0: super-primary, reserved for special emphasis
* 1: primary, most important under normal situations
* 2: secondary, next most important under normal situations
* 3: tertiary, next most important under normal situations

Throughout JupyterLab, we are mostly following principles from Google's
Material Design when selecting colors. We are not, however, following
all of MD as it is not optimized for dense, information rich UIs.
*/

:root {
  /* Elevation
   *
   * We style box-shadows using Material Design's idea of elevation. These particular numbers are taken from here:
   *
   * https://github.com/material-components/material-components-web
   * https://material-components-web.appspot.com/elevation.html
   */

  --jp-shadow-base-lightness: 0;
  --jp-shadow-umbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.2
  );
  --jp-shadow-penumbra-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.14
  );
  --jp-shadow-ambient-color: rgba(
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    var(--jp-shadow-base-lightness),
    0.12
  );
  --jp-elevation-z0: none;
  --jp-elevation-z1: 0px 2px 1px -1px var(--jp-shadow-umbra-color),
    0px 1px 1px 0px var(--jp-shadow-penumbra-color),
    0px 1px 3px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z2: 0px 3px 1px -2px var(--jp-shadow-umbra-color),
    0px 2px 2px 0px var(--jp-shadow-penumbra-color),
    0px 1px 5px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z4: 0px 2px 4px -1px var(--jp-shadow-umbra-color),
    0px 4px 5px 0px var(--jp-shadow-penumbra-color),
    0px 1px 10px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z6: 0px 3px 5px -1px var(--jp-shadow-umbra-color),
    0px 6px 10px 0px var(--jp-shadow-penumbra-color),
    0px 1px 18px 0px var(--jp-shadow-ambient-color);
  --jp-elevation-z8: 0px 5px 5px -3px var(--jp-shadow-umbra-color),
    0px 8px 10px 1px var(--jp-shadow-penumbra-color),
    0px 3px 14px 2px var(--jp-shadow-ambient-color);
  --jp-elevation-z12: 0px 7px 8px -4px var(--jp-shadow-umbra-color),
    0px 12px 17px 2px var(--jp-shadow-penumbra-color),
    0px 5px 22px 4px var(--jp-shadow-ambient-color);
  --jp-elevation-z16: 0px 8px 10px -5px var(--jp-shadow-umbra-color),
    0px 16px 24px 2px var(--jp-shadow-penumbra-color),
    0px 6px 30px 5px var(--jp-shadow-ambient-color);
  --jp-elevation-z20: 0px 10px 13px -6px var(--jp-shadow-umbra-color),
    0px 20px 31px 3px var(--jp-shadow-penumbra-color),
    0px 8px 38px 7px var(--jp-shadow-ambient-color);
  --jp-elevation-z24: 0px 11px 15px -7px var(--jp-shadow-umbra-color),
    0px 24px 38px 3px var(--jp-shadow-penumbra-color),
    0px 9px 46px 8px var(--jp-shadow-ambient-color);

  /* Borders
   *
   * The following variables, specify the visual styling of borders in JupyterLab.
   */

  --jp-border-width: 1px;
  --jp-border-color0: var(--md-grey-400);
  --jp-border-color1: var(--md-grey-400);
  --jp-border-color2: var(--md-grey-300);
  --jp-border-color3: var(--md-grey-200);
  --jp-border-radius: 2px;

  /* UI Fonts
   *
   * The UI font CSS variables are used for the typography all of the JupyterLab
   * user interface elements that are not directly user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-ui-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-ui-font-scale-factor: 1.2;
  --jp-ui-font-size0: 0.83333em;
  --jp-ui-font-size1: 13px; /* Base font size */
  --jp-ui-font-size2: 1.2em;
  --jp-ui-font-size3: 1.44em;

  --jp-ui-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica,
    Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol';

  /*
   * Use these font colors against the corresponding main layout colors.
   * In a light theme, these go from dark to light.
   */

  /* Defaults use Material Design specification */
  --jp-ui-font-color0: rgba(0, 0, 0, 1);
  --jp-ui-font-color1: rgba(0, 0, 0, 0.87);
  --jp-ui-font-color2: rgba(0, 0, 0, 0.54);
  --jp-ui-font-color3: rgba(0, 0, 0, 0.38);

  /*
   * Use these against the brand/accent/warn/error colors.
   * These will typically go from light to darker, in both a dark and light theme.
   */

  --jp-ui-inverse-font-color0: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color1: rgba(255, 255, 255, 1);
  --jp-ui-inverse-font-color2: rgba(255, 255, 255, 0.7);
  --jp-ui-inverse-font-color3: rgba(255, 255, 255, 0.5);

  /* Content Fonts
   *
   * Content font variables are used for typography of user generated content.
   *
   * The font sizing here is done assuming that the body font size of --jp-content-font-size1
   * is applied to a parent element. When children elements, such as headings, are sized
   * in em all things will be computed relative to that body size.
   */

  --jp-content-line-height: 1.6;
  --jp-content-font-scale-factor: 1.2;
  --jp-content-font-size0: 0.83333em;
  --jp-content-font-size1: 14px; /* Base font size */
  --jp-content-font-size2: 1.2em;
  --jp-content-font-size3: 1.44em;
  --jp-content-font-size4: 1.728em;
  --jp-content-font-size5: 2.0736em;

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-content-presentation-font-size1: 17px;

  --jp-content-heading-line-height: 1;
  --jp-content-heading-margin-top: 1.2em;
  --jp-content-heading-margin-bottom: 0.8em;
  --jp-content-heading-font-weight: 500;

  /* Defaults use Material Design specification */
  --jp-content-font-color0: rgba(0, 0, 0, 1);
  --jp-content-font-color1: rgba(0, 0, 0, 0.87);
  --jp-content-font-color2: rgba(0, 0, 0, 0.54);
  --jp-content-font-color3: rgba(0, 0, 0, 0.38);

  --jp-content-link-color: var(--md-blue-700);

  --jp-content-font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI',
    Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji',
    'Segoe UI Symbol';

  /*
   * Code Fonts
   *
   * Code font variables are used for typography of code and other monospaces content.
   */

  --jp-code-font-size: 13px;
  --jp-code-line-height: 1.3077; /* 17px for 13px base */
  --jp-code-padding: 5px; /* 5px for 13px base, codemirror highlighting needs integer px value */
  --jp-code-font-family-default: Menlo, Consolas, 'DejaVu Sans Mono', monospace;
  --jp-code-font-family: var(--jp-code-font-family-default);

  /* This gives a magnification of about 125% in presentation mode over normal. */
  --jp-code-presentation-font-size: 16px;

  /* may need to tweak cursor width if you change font size */
  --jp-code-cursor-width0: 1.4px;
  --jp-code-cursor-width1: 2px;
  --jp-code-cursor-width2: 4px;

  /* Layout
   *
   * The following are the main layout colors use in JupyterLab. In a light
   * theme these would go from light to dark.
   */

  --jp-layout-color0: white;
  --jp-layout-color1: white;
  --jp-layout-color2: var(--md-grey-200);
  --jp-layout-color3: var(--md-grey-400);
  --jp-layout-color4: var(--md-grey-600);

  /* Inverse Layout
   *
   * The following are the inverse layout colors use in JupyterLab. In a light
   * theme these would go from dark to light.
   */

  --jp-inverse-layout-color0: #111111;
  --jp-inverse-layout-color1: var(--md-grey-900);
  --jp-inverse-layout-color2: var(--md-grey-800);
  --jp-inverse-layout-color3: var(--md-grey-700);
  --jp-inverse-layout-color4: var(--md-grey-600);

  /* Brand/accent */

  --jp-brand-color0: var(--md-blue-700);
  --jp-brand-color1: var(--md-blue-500);
  --jp-brand-color2: var(--md-blue-300);
  --jp-brand-color3: var(--md-blue-100);
  --jp-brand-color4: var(--md-blue-50);

  --jp-accent-color0: var(--md-green-700);
  --jp-accent-color1: var(--md-green-500);
  --jp-accent-color2: var(--md-green-300);
  --jp-accent-color3: var(--md-green-100);

  /* State colors (warn, error, success, info) */

  --jp-warn-color0: var(--md-orange-700);
  --jp-warn-color1: var(--md-orange-500);
  --jp-warn-color2: var(--md-orange-300);
  --jp-warn-color3: var(--md-orange-100);

  --jp-error-color0: var(--md-red-700);
  --jp-error-color1: var(--md-red-500);
  --jp-error-color2: var(--md-red-300);
  --jp-error-color3: var(--md-red-100);

  --jp-success-color0: var(--md-green-700);
  --jp-success-color1: var(--md-green-500);
  --jp-success-color2: var(--md-green-300);
  --jp-success-color3: var(--md-green-100);

  --jp-info-color0: var(--md-cyan-700);
  --jp-info-color1: var(--md-cyan-500);
  --jp-info-color2: var(--md-cyan-300);
  --jp-info-color3: var(--md-cyan-100);

  /* Cell specific styles */

  --jp-cell-padding: 5px;

  --jp-cell-collapser-width: 8px;
  --jp-cell-collapser-min-height: 20px;
  --jp-cell-collapser-not-active-hover-opacity: 0.6;

  --jp-cell-editor-background: var(--md-grey-100);
  --jp-cell-editor-border-color: var(--md-grey-300);
  --jp-cell-editor-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-cell-editor-active-background: var(--jp-layout-color0);
  --jp-cell-editor-active-border-color: var(--jp-brand-color1);

  --jp-cell-prompt-width: 64px;
  --jp-cell-prompt-font-family: 'Source Code Pro', monospace;
  --jp-cell-prompt-letter-spacing: 0px;
  --jp-cell-prompt-opacity: 1;
  --jp-cell-prompt-not-active-opacity: 0.5;
  --jp-cell-prompt-not-active-font-color: var(--md-grey-700);
  /* A custom blend of MD grey and blue 600
   * See https://meyerweb.com/eric/tools/color-blend/#546E7A:1E88E5:5:hex */
  --jp-cell-inprompt-font-color: #307fc1;
  /* A custom blend of MD grey and orange 600
   * https://meyerweb.com/eric/tools/color-blend/#546E7A:F4511E:5:hex */
  --jp-cell-outprompt-font-color: #bf5b3d;

  /* Notebook specific styles */

  --jp-notebook-padding: 10px;
  --jp-notebook-select-background: var(--jp-layout-color1);
  --jp-notebook-multiselected-color: var(--md-blue-50);

  /* The scroll padding is calculated to fill enough space at the bottom of the
  notebook to show one single-line cell (with appropriate padding) at the top
  when the notebook is scrolled all the way to the bottom. We also subtract one
  pixel so that no scrollbar appears if we have just one single-line cell in the
  notebook. This padding is to enable a 'scroll past end' feature in a notebook.
  */
  --jp-notebook-scroll-padding: calc(
    100% - var(--jp-code-font-size) * var(--jp-code-line-height) -
      var(--jp-code-padding) - var(--jp-cell-padding) - 1px
  );

  /* Rendermime styles */

  --jp-rendermime-error-background: #fdd;
  --jp-rendermime-table-row-background: var(--md-grey-100);
  --jp-rendermime-table-row-hover-background: var(--md-light-blue-50);

  /* Dialog specific styles */

  --jp-dialog-background: rgba(0, 0, 0, 0.25);

  /* Console specific styles */

  --jp-console-padding: 10px;

  /* Toolbar specific styles */

  --jp-toolbar-border-color: var(--jp-border-color1);
  --jp-toolbar-micro-height: 8px;
  --jp-toolbar-background: var(--jp-layout-color1);
  --jp-toolbar-box-shadow: 0px 0px 2px 0px rgba(0, 0, 0, 0.24);
  --jp-toolbar-header-margin: 4px 4px 0px 4px;
  --jp-toolbar-active-background: var(--md-grey-300);

  /* Input field styles */

  --jp-input-box-shadow: inset 0 0 2px var(--md-blue-300);
  --jp-input-active-background: var(--jp-layout-color1);
  --jp-input-hover-background: var(--jp-layout-color1);
  --jp-input-background: var(--md-grey-100);
  --jp-input-border-color: var(--jp-border-color1);
  --jp-input-active-border-color: var(--jp-brand-color1);
  --jp-input-active-box-shadow-color: rgba(19, 124, 189, 0.3);

  /* General editor styles */

  --jp-editor-selected-background: #d9d9d9;
  --jp-editor-selected-focused-background: #d7d4f0;
  --jp-editor-cursor-color: var(--jp-ui-font-color0);

  /* Code mirror specific styles */

  --jp-mirror-editor-keyword-color: #008000;
  --jp-mirror-editor-atom-color: #88f;
  --jp-mirror-editor-number-color: #080;
  --jp-mirror-editor-def-color: #00f;
  --jp-mirror-editor-variable-color: var(--md-grey-900);
  --jp-mirror-editor-variable-2-color: #05a;
  --jp-mirror-editor-variable-3-color: #085;
  --jp-mirror-editor-punctuation-color: #05a;
  --jp-mirror-editor-property-color: #05a;
  --jp-mirror-editor-operator-color: #aa22ff;
  --jp-mirror-editor-comment-color: #408080;
  --jp-mirror-editor-string-color: #ba2121;
  --jp-mirror-editor-string-2-color: #708;
  --jp-mirror-editor-meta-color: #aa22ff;
  --jp-mirror-editor-qualifier-color: #555;
  --jp-mirror-editor-builtin-color: #008000;
  --jp-mirror-editor-bracket-color: #997;
  --jp-mirror-editor-tag-color: #170;
  --jp-mirror-editor-attribute-color: #00c;
  --jp-mirror-editor-header-color: blue;
  --jp-mirror-editor-quote-color: #090;
  --jp-mirror-editor-link-color: #00c;
  --jp-mirror-editor-error-color: #f00;
  --jp-mirror-editor-hr-color: #999;

  /* Vega extension styles */

  --jp-vega-background: white;

  /* Sidebar-related styles */

  --jp-sidebar-min-width: 180px;

  /* Search-related styles */

  --jp-search-toggle-off-opacity: 0.5;
  --jp-search-toggle-hover-opacity: 0.8;
  --jp-search-toggle-on-opacity: 1;
  --jp-search-selected-match-background-color: rgb(245, 200, 0);
  --jp-search-selected-match-color: black;
  --jp-search-unselected-match-background-color: var(
    --jp-inverse-layout-color0
  );
  --jp-search-unselected-match-color: var(--jp-ui-inverse-font-color0);

  /* Icon colors that work well with light or dark backgrounds */
  --jp-icon-contrast-color0: var(--md-purple-600);
  --jp-icon-contrast-color1: var(--md-green-600);
  --jp-icon-contrast-color2: var(--md-pink-600);
  --jp-icon-contrast-color3: var(--md-blue-600);
}
</style>

<style type="text/css">
a.anchor-link {
   display: none;
}
.highlight  {
    margin: 0.4em;
}

/* Input area styling */
.jp-InputArea {
    overflow: hidden;
}

.jp-InputArea-editor {
    overflow: hidden;
}

@media print {
  body {
    margin: 0;
  }
}
</style>



<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-MML-AM_CHTML-full,Safe"> </script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: { 
                    automatic: true 
                    }
                },
                "HTML-CSS": {
                    linebreaks: { 
                    automatic: true 
                    }
                }
            });
        
            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script>
    <!-- End of mathjax configuration --></head>
<body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light">
<div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[1]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">experiment_utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">preprocessing</span> <span class="kn">import</span> <span class="n">preprocess</span>
<span class="kn">from</span> <span class="nn">windowfy</span> <span class="kn">import</span> <span class="n">windowfy</span>
<span class="kn">from</span> <span class="nn">featurizing</span> <span class="kn">import</span> <span class="n">featurize</span>
<span class="kn">from</span> <span class="nn">tfidf_featurizer</span> <span class="kn">import</span> <span class="n">combine_features</span><span class="p">,</span> <span class="n">tfidf_featurize</span>
<span class="kn">from</span> <span class="nn">training</span> <span class="kn">import</span> <span class="n">train</span><span class="p">,</span> <span class="n">do_ensemble</span><span class="p">,</span> <span class="n">do_train</span>
<span class="kn">from</span> <span class="nn">training_traditional</span> <span class="kn">import</span> <span class="n">train_and_evaluate</span>
<span class="kn">from</span> <span class="nn">eval_erisk</span> <span class="kn">import</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">ensemble_vote</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">Markdown</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">seed</span>
<span class="kn">import</span> <span class="nn">tensorflow</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.
  warnings.warn(&#34;The twython library has not been installed. &#34;
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[2]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tensorflow</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">logger</span><span class="p">(</span><span class="s2">&quot;Initialized numpy random and tensorflow random seed at 42&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Initialized numpy random and tensorflow random seed at 42
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[3]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># params</span>

<span class="n">first_part</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;include_feats&quot;</span><span class="p">:</span> <span class="p">[[</span><span class="s2">&quot;first_prons&quot;</span><span class="p">,</span> <span class="s2">&quot;nssi&quot;</span><span class="p">],[</span><span class="s2">&quot;first_prons&quot;</span><span class="p">,</span><span class="s2">&quot;sentiment&quot;</span><span class="p">,</span><span class="s2">&quot;nssi&quot;</span><span class="p">]],</span>
    <span class="s2">&quot;feat_window_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span> <span class="c1">#10</span>
    <span class="s2">&quot;max_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">],</span>
    <span class="s2">&quot;sample_weights_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">],</span>
    <span class="s2">&quot;oversample&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;include_new_data&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;tfidf_max_features&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">],</span>
    <span class="s2">&quot;scale&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
    <span class="s2">&quot;normalize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;discretize&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
    <span class="s2">&quot;discretize_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">],</span>
    <span class="s2">&quot;dis_strategy&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;quantile&quot;</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">second_part</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;eval_window_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="s2">&quot;maxlen&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1000</span><span class="p">],</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">32</span><span class="p">],</span>
    <span class="s2">&quot;epochs&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">],</span>
    <span class="s2">&quot;patience&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">],</span>
    <span class="s2">&quot;iterations&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">5</span><span class="p">],</span>
    <span class="s2">&quot;shuffle&quot;</span><span class="p">:</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="s2">&quot;bayes&quot;</span><span class="p">,</span> <span class="s2">&quot;cnn_model&quot;</span><span class="p">]</span>
<span class="n">ensemble_combinations</span> <span class="o">=</span> <span class="p">[[</span><span class="s2">&quot;svm&quot;</span><span class="p">,</span> <span class="s2">&quot;bayes&quot;</span><span class="p">,</span> <span class="s2">&quot;cnn_model&quot;</span><span class="p">]]</span>
<span class="n">weights</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]]</span>
<span class="n">eval_filename</span> <span class="o">=</span> <span class="s2">&quot;experiments_20-nonedata.csv&quot;</span>
</pre></div>

     </div>
</div>
</div>
</div>

</div>
<div class="jp-Cell-inputWrapper"><div class="jp-InputPrompt jp-InputArea-prompt">
</div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput " data-mime-type="text/markdown">
<h2 id="Experiments">Experiments<a class="anchor-link" href="#Experiments">&#182;</a></h2>
</div>
</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell   ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[4]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">experiment</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">ensemble_combinations</span><span class="p">,</span> <span class="n">eval_filename</span><span class="p">)</span>

<span class="n">firstpart_generator</span> <span class="o">=</span> <span class="n">traverse</span><span class="p">(</span><span class="n">first_part</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">firstpart_generator</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;********** CALCULATING FEATURES FOR </span><span class="si">{}</span><span class="s2"> ***********&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
        <span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="s2">&quot;#### Calculating features for </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)))</span>
        
        <span class="n">experiment</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="n">secondpart_generator</span> <span class="o">=</span> <span class="n">traverse</span><span class="p">(</span><span class="n">second_part</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">secondpart_generator</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="n">j</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="n">params</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;************ STARTING EXPERIMENT </span><span class="si">{}</span><span class="s2"> ***************&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="n">display</span><span class="p">(</span><span class="n">Markdown</span><span class="p">(</span><span class="s2">&quot;#### Experiment </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">)))</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">experiment</span><span class="o">.</span><span class="n">train_and_evaluate_model</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;************ FINISHED EXPERIMENT </span><span class="si">{}</span><span class="s2"> ************* </span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;Error during experiment </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
                <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">secondpart_generator</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;General error during experiment </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
        <span class="n">logger</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
</pre></div>

     </div>
</div>
</div>
</div>

<div class="jp-Cell-outputWrapper">


<div class="jp-OutputArea jp-Cell-outputArea">

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 843  205]]
Evaluating after getting time 149.321630079
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 843  205]]
Evaluated with elapsed time 74.327954575
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25325679837577814, &#39;ERDE_50&#39;: 0.14230784277562714, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5508283995846694}
Writing results to CSV file
{&#39;precision&#39;: 0.8974358974358975, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.48951048951048953, &#39;ERDE_5&#39;: 0.248151200039192, &#39;ERDE_50&#39;: 0.16544551190696088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46471355081321036}
Writing results to CSV file
{&#39;precision&#39;: 0.9615384615384616, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.38461538461538464, &#39;ERDE_5&#39;: 0.24643475938467724, &#39;ERDE_50&#39;: 0.18734246544719046, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.36363622788089367}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluating after getting time 228.993800668
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluated with elapsed time 4.269137073999985
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5444 - tp: 1.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1047.0000 - accuracy: 0.7742 - precision: 0.2500 - recall: 9.5420e-04 - f1_metric: 0.0011
Test Score: 0.5444046258926392
Test Accuracy: 1.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.25      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.51      0.50      0.44      4650
weighted avg       0.66      0.77      0.68      4650

[[3599    3]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644382858057864, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.017912139559646656}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5791 - tp: 2.0000 - fp: 9.0000 - tn: 3593.0000 - fn: 1046.0000 - accuracy: 0.7731 - precision: 0.1818 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.5791459679603577
Test Accuracy: 2.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.18      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.48      0.50      0.44      4650
weighted avg       0.64      0.77      0.68      4650

[[3593    9]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827475083865, &#39;ERDE_50&#39;: 0.24171598790581905, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06034880562609424, &#39;speed&#39;: 0.9396511943739058, &#39;latency_weighted_f1&#39;: 0.03512714745323012}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5551 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.555117130279541
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.7023 - tp: 11.0000 - fp: 6.0000 - tn: 3596.0000 - fn: 1037.0000 - accuracy: 0.7757 - precision: 0.6471 - recall: 0.0105 - f1_metric: 0.0093
Test Score: 0.7023020386695862
Test Accuracy: 11.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.65      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.71      0.50      0.45      4650
weighted avg       0.75      0.78      0.68      4650

[[3596    6]
 [1037   11]]
Finished training and evaluation
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07207207207207209, &#39;ERDE_5&#39;: 0.24759848528217568, &#39;ERDE_50&#39;: 0.23815032778364628, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06856145913490026}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330492854118347
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330492854118347
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 62.132334209999954
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07207207207207209, &#39;ERDE_5&#39;: 0.24759848528217568, &#39;ERDE_50&#39;: 0.23815032778364628, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06856145913490026}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702240985105592, &#39;ERDE_50&#39;: 0.24229722403858514, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.03537704511739719}
Writing results to CSV file
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24644381405534319, &#39;ERDE_50&#39;: 0.2417159879058174, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.035271481512620426}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586073037542694, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.018230977114345875}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586286963552104, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.01786058789074134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 62.132334209999954} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 843  205]]
Evaluating after getting time 3308.678046361
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 843  205]]
Evaluated with elapsed time 122.72504040600006
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25325679837577814, &#39;ERDE_50&#39;: 0.14230784277562714, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5508283995846694}
Writing results to CSV file
{&#39;precision&#39;: 0.8974358974358975, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.48951048951048953, &#39;ERDE_5&#39;: 0.248151200039192, &#39;ERDE_50&#39;: 0.16544551190696088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46471355081321036}
Writing results to CSV file
{&#39;precision&#39;: 0.9615384615384616, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.38461538461538464, &#39;ERDE_5&#39;: 0.24643475938467724, &#39;ERDE_50&#39;: 0.18734246544719046, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.36363622788089367}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluating after getting time 3440.362728437
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluated with elapsed time 2.7991100160002134
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.0071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0070804357528687
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.7823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7823413610458374
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.9924 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9924025535583496
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.9036 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9036358594894409
Test Accuracy: 0.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.0371 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370620489120483
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 15ms/step - loss: 1.0371 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370620489120483
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.63530963799985
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.63530963799985} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.91      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.86      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3582   20]
 [ 857  191]]
Evaluating after getting time 5843.167641244
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.91      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.86      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3582   20]
 [ 857  191]]
Evaluated with elapsed time 105.16233584600013
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8135593220338984, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.588957055214724, &#39;ERDE_5&#39;: 0.25211384884922955, &#39;ERDE_50&#39;: 0.13878130431623883, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.563706286234989}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.4347826086956522, &#39;ERDE_5&#39;: 0.24815099696411347, &#39;ERDE_50&#39;: 0.17726584287622718, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41614186891441673}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.2464354058352571, &#39;ERDE_50&#39;: 0.19679873022260408, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3164477988870909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluating after getting time 5952.980915309
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluated with elapsed time 4.305156680000437
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5897975564002991
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5358 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.535826563835144
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.6308 - tp: 1.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1047.0000 - accuracy: 0.7744 - precision: 0.3333 - recall: 9.5420e-04 - f1_metric: 0.0015
Test Score: 0.630774974822998
Test Accuracy: 1.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.33      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.55      0.50      0.44      4650
weighted avg       0.68      0.77      0.68      4650

[[3600    2]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.2464382748487095, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.01813244832033035}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.7462 - tp: 3.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1045.0000 - accuracy: 0.7751 - precision: 0.7500 - recall: 0.0029 - f1_metric: 0.0019
Test Score: 0.7461909055709839
Test Accuracy: 3.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.75      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.76      0.50      0.44      4650
weighted avg       0.77      0.78      0.68      4650

[[3601    1]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643827402766552, &#39;ERDE_50&#39;: 0.23935192171196581, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.05144640698863761}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392681360244751
Test Accuracy: 0.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 20ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392681360244751
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 71.32025368199902
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 71.32025368199902} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.91      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.86      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3582   20]
 [ 857  191]]
Evaluating after getting time 8942.021830731
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.91      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.86      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3582   20]
 [ 857  191]]
Evaluated with elapsed time 105.16744424199896
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8135593220338984, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.588957055214724, &#39;ERDE_5&#39;: 0.25211384884922955, &#39;ERDE_50&#39;: 0.13878130431623883, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.563706286234989}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.4347826086956522, &#39;ERDE_5&#39;: 0.24815099696411347, &#39;ERDE_50&#39;: 0.17726584287622718, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41614186891441673}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.2464354058352571, &#39;ERDE_50&#39;: 0.19679873022260408, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3164477988870909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluating after getting time 9051.394261993
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluated with elapsed time 3.220640718998766
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9753 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9753488302230835
Test Accuracy: 0.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8128407001495361
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.9576 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9575570225715637
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8776159286499023
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 1.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1297900676727295
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 20ms/step - loss: 1.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1297900676727295
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 70.81457579800008
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537286, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 70.81457579800008} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 11284.105525462
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 70.49585798099906
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 11361.205198009
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 4.339905638000346
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533
Test Score: 0.6330819725990295
Test Accuracy: 719.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.67      0.76      3602
           1       0.37      0.69      0.48      1048

    accuracy                           0.67      4650
   macro avg       0.63      0.68      0.62      4650
weighted avg       0.77      0.67      0.70      4650

[[2400 1202]
 [ 329  719]]
Finished training and evaluation
{&#39;precision&#39;: 0.32167832167832167, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4717948717948718, &#39;ERDE_5&#39;: 0.3581736549592459, &#39;ERDE_50&#39;: 0.1411286040831851, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4534041949227219}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8161 - tp: 470.0000 - fp: 551.0000 - tn: 3051.0000 - fn: 578.0000 - accuracy: 0.7572 - precision: 0.4603 - recall: 0.4485 - f1_metric: 0.2777
Test Score: 0.8160936832427979
Test Accuracy: 470.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.85      0.84      3602
           1       0.46      0.45      0.45      1048

    accuracy                           0.76      4650
   macro avg       0.65      0.65      0.65      4650
weighted avg       0.75      0.76      0.76      4650

[[3051  551]
 [ 578  470]]
Finished training and evaluation
{&#39;precision&#39;: 0.4782608695652174, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5454545454545455, &#39;ERDE_5&#39;: 0.2873925599749865, &#39;ERDE_50&#39;: 0.13168351692570837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5241925968968228}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00013: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5845 - tp: 453.0000 - fp: 470.0000 - tn: 3132.0000 - fn: 595.0000 - accuracy: 0.7710 - precision: 0.4908 - recall: 0.4323 - f1_metric: 0.2743
Test Score: 0.584526777267456
Test Accuracy: 453.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.87      0.85      3602
           1       0.49      0.43      0.46      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.65      0.66      4650
weighted avg       0.76      0.77      0.77      4650

[[3132  470]
 [ 595  453]]
Finished training and evaluation
{&#39;precision&#39;: 0.49230769230769234, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5470085470085471, &#39;ERDE_5&#39;: 0.2839230065046203, &#39;ERDE_50&#39;: 0.13292423251680965, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5256860230988081}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 16.8639 - tp: 817.0000 - fp: 1505.0000 - tn: 2097.0000 - fn: 231.0000 - accuracy: 0.6267 - precision: 0.3519 - recall: 0.7796 - f1_metric: 0.3705
Test Score: 16.863901138305664
Test Accuracy: 817.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.58      0.71      3602
           1       0.35      0.78      0.48      1048

    accuracy                           0.63      4650
   macro avg       0.63      0.68      0.60      4650
weighted avg       0.78      0.63      0.66      4650

[[2097 1505]
 [ 231  817]]
Finished training and evaluation
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4842105263157894, &#39;ERDE_5&#39;: 0.3523310172885635, &#39;ERDE_50&#39;: 0.1353162427555075, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4653358842627935}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Finished training and evaluation
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Evaluating for elapsed time
146/146 [==============================] - 3s 13ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Evaluated with elapsed time 61.812771470998996
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Writing results to CSV file
{&#39;precision&#39;: 0.4358974358974359, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5685618729096991, &#39;ERDE_5&#39;: 0.3096505594048397, &#39;ERDE_50&#39;: 0.10885323228766941, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5441855208880834}
Writing results to CSV file
{&#39;precision&#39;: 0.4319526627218935, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.5347985347985348, &#39;ERDE_5&#39;: 0.30161269160171, &#39;ERDE_50&#39;: 0.12908472075516572, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5097882202347925}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 61.812771470998996} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 14303.897715141
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 76.28095245999975
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 14384.269881791
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 2.812042419998761
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 16ms/step - loss: 0.7407 - tp: 666.0000 - fp: 846.0000 - tn: 2756.0000 - fn: 382.0000 - accuracy: 0.7359 - precision: 0.4405 - recall: 0.6355 - f1_metric: 0.3592
Test Score: 0.7407026886940002
Test Accuracy: 666.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.77      0.82      3602
           1       0.44      0.64      0.52      1048

    accuracy                           0.74      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.74      0.75      4650

[[2756  846]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 8s 29ms/step - loss: 1.6687 - tp: 416.0000 - fp: 550.0000 - tn: 3052.0000 - fn: 632.0000 - accuracy: 0.7458 - precision: 0.4306 - recall: 0.3969 - f1_metric: 0.2460
Test Score: 1.6686714887619019
Test Accuracy: 416.0
146/146 [==============================] - 4s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      3602
           1       0.43      0.40      0.41      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.62      0.63      4650
weighted avg       0.74      0.75      0.74      4650

[[3052  550]
 [ 632  416]]
Finished training and evaluation
{&#39;precision&#39;: 0.46923076923076923, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5213675213675213, &#39;ERDE_5&#39;: 0.285674670592364, &#39;ERDE_50&#39;: 0.1417601394966727, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5010444907660513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 7s 22ms/step - loss: 0.6868 - tp: 676.0000 - fp: 937.0000 - tn: 2665.0000 - fn: 372.0000 - accuracy: 0.7185 - precision: 0.4191 - recall: 0.6450 - f1_metric: 0.3559
Test Score: 0.6867886185646057
Test Accuracy: 676.0
146/146 [==============================] - 4s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.74      0.80      3602
           1       0.42      0.65      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2665  937]
 [ 372  676]]
Finished training and evaluation
{&#39;precision&#39;: 0.3853211009174312, &#39;recall&#39;: 0.8076923076923077, &#39;F1&#39;: 0.5217391304347826, &#39;ERDE_5&#39;: 0.3233296196857131, &#39;ERDE_50&#39;: 0.1251669656679475, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5014016144230479}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 2.0980 - tp: 784.0000 - fp: 1296.0000 - tn: 2306.0000 - fn: 264.0000 - accuracy: 0.6645 - precision: 0.3769 - recall: 0.7481 - f1_metric: 0.3727
Test Score: 2.097973585128784
Test Accuracy: 784.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.64      0.75      3602
           1       0.38      0.75      0.50      1048

    accuracy                           0.66      4650
   macro avg       0.64      0.69      0.62      4650
weighted avg       0.78      0.66      0.69      4650

[[2306 1296]
 [ 264  784]]
Finished training and evaluation
{&#39;precision&#39;: 0.3590733590733591, &#39;recall&#39;: 0.8942307692307693, &#39;F1&#39;: 0.512396694214876, &#39;ERDE_5&#39;: 0.3418688719904829, &#39;ERDE_50&#39;: 0.12248992617183534, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4924233486000456}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00016: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Finished training and evaluation
{&#39;precision&#39;: 0.4557823129251701, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5338645418326693, &#39;ERDE_5&#39;: 0.29202788331610346, &#39;ERDE_50&#39;: 0.13396933979399697, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5130543743863989}
Evaluating for elapsed time
146/146 [==============================] - 5s 19ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Evaluated with elapsed time 65.7519890529984
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Writing results to CSV file
{&#39;precision&#39;: 0.4426229508196721, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5644599303135889, &#39;ERDE_5&#39;: 0.3050107563539052, &#39;ERDE_50&#39;: 0.11365960800094416, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.540259443754396}
Writing results to CSV file
{&#39;precision&#39;: 0.42592592592592593, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.518796992481203, &#39;ERDE_5&#39;: 0.2998734202268961, &#39;ERDE_50&#39;: 0.13679727713227546, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49453500383987986}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 65.7519890529984} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 17988.541004228
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 84.14722296500258
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 18078.352685007
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.612816742999712
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 7s 29ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533
Test Score: 0.6330819725990295
Test Accuracy: 719.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.67      0.76      3602
           1       0.37      0.69      0.48      1048

    accuracy                           0.67      4650
   macro avg       0.63      0.68      0.62      4650
weighted avg       0.77      0.67      0.70      4650

[[2400 1202]
 [ 329  719]]
Finished training and evaluation
{&#39;precision&#39;: 0.32167832167832167, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4717948717948718, &#39;ERDE_5&#39;: 0.3581736549592459, &#39;ERDE_50&#39;: 0.1411286040831851, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4534041949227219}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.8161 - tp: 470.0000 - fp: 551.0000 - tn: 3051.0000 - fn: 578.0000 - accuracy: 0.7572 - precision: 0.4603 - recall: 0.4485 - f1_metric: 0.2777
Test Score: 0.8160936832427979
Test Accuracy: 470.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.85      0.84      3602
           1       0.46      0.45      0.45      1048

    accuracy                           0.76      4650
   macro avg       0.65      0.65      0.65      4650
weighted avg       0.75      0.76      0.76      4650

[[3051  551]
 [ 578  470]]
Finished training and evaluation
{&#39;precision&#39;: 0.4782608695652174, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5454545454545455, &#39;ERDE_5&#39;: 0.2873925599749865, &#39;ERDE_50&#39;: 0.13168351692570837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5241925968968228}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00013: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5845 - tp: 453.0000 - fp: 470.0000 - tn: 3132.0000 - fn: 595.0000 - accuracy: 0.7710 - precision: 0.4908 - recall: 0.4323 - f1_metric: 0.2743
Test Score: 0.584526777267456
Test Accuracy: 453.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.87      0.85      3602
           1       0.49      0.43      0.46      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.65      0.66      4650
weighted avg       0.76      0.77      0.77      4650

[[3132  470]
 [ 595  453]]
Finished training and evaluation
{&#39;precision&#39;: 0.49230769230769234, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5470085470085471, &#39;ERDE_5&#39;: 0.2839230065046203, &#39;ERDE_50&#39;: 0.13292423251680965, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5256860230988081}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 16.8639 - tp: 817.0000 - fp: 1505.0000 - tn: 2097.0000 - fn: 231.0000 - accuracy: 0.6267 - precision: 0.3519 - recall: 0.7796 - f1_metric: 0.3705
Test Score: 16.863901138305664
Test Accuracy: 817.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.58      0.71      3602
           1       0.35      0.78      0.48      1048

    accuracy                           0.63      4650
   macro avg       0.63      0.68      0.60      4650
weighted avg       0.78      0.63      0.66      4650

[[2097 1505]
 [ 231  817]]
Finished training and evaluation
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4842105263157894, &#39;ERDE_5&#39;: 0.3523310172885635, &#39;ERDE_50&#39;: 0.1353162427555075, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4653358842627935}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Finished training and evaluation
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Evaluating for elapsed time
146/146 [==============================] - 4s 18ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Evaluated with elapsed time 65.53670203900037
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Writing results to CSV file
{&#39;precision&#39;: 0.4358974358974359, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5685618729096991, &#39;ERDE_5&#39;: 0.3096505594048397, &#39;ERDE_50&#39;: 0.10885323228766941, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5441855208880834}
Writing results to CSV file
{&#39;precision&#39;: 0.4319526627218935, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.5347985347985348, &#39;ERDE_5&#39;: 0.30161269160171, &#39;ERDE_50&#39;: 0.12908472075516572, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5097882202347925}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 65.53670203900037} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 21049.494423969
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 80.9896440909979
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 21136.017050299
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.764956982999138
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.7407 - tp: 666.0000 - fp: 846.0000 - tn: 2756.0000 - fn: 382.0000 - accuracy: 0.7359 - precision: 0.4405 - recall: 0.6355 - f1_metric: 0.3592
Test Score: 0.7407026886940002
Test Accuracy: 666.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.77      0.82      3602
           1       0.44      0.64      0.52      1048

    accuracy                           0.74      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.74      0.75      4650

[[2756  846]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 1.6687 - tp: 416.0000 - fp: 550.0000 - tn: 3052.0000 - fn: 632.0000 - accuracy: 0.7458 - precision: 0.4306 - recall: 0.3969 - f1_metric: 0.2460
Test Score: 1.6686714887619019
Test Accuracy: 416.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      3602
           1       0.43      0.40      0.41      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.62      0.63      4650
weighted avg       0.74      0.75      0.74      4650

[[3052  550]
 [ 632  416]]
Finished training and evaluation
{&#39;precision&#39;: 0.46923076923076923, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5213675213675213, &#39;ERDE_5&#39;: 0.285674670592364, &#39;ERDE_50&#39;: 0.1417601394966727, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5010444907660513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.6868 - tp: 676.0000 - fp: 937.0000 - tn: 2665.0000 - fn: 372.0000 - accuracy: 0.7185 - precision: 0.4191 - recall: 0.6450 - f1_metric: 0.3559
Test Score: 0.6867886185646057
Test Accuracy: 676.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.74      0.80      3602
           1       0.42      0.65      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2665  937]
 [ 372  676]]
Finished training and evaluation
{&#39;precision&#39;: 0.3853211009174312, &#39;recall&#39;: 0.8076923076923077, &#39;F1&#39;: 0.5217391304347826, &#39;ERDE_5&#39;: 0.3233296196857131, &#39;ERDE_50&#39;: 0.1251669656679475, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5014016144230479}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 2.0980 - tp: 784.0000 - fp: 1296.0000 - tn: 2306.0000 - fn: 264.0000 - accuracy: 0.6645 - precision: 0.3769 - recall: 0.7481 - f1_metric: 0.3727
Test Score: 2.097973585128784
Test Accuracy: 784.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.64      0.75      3602
           1       0.38      0.75      0.50      1048

    accuracy                           0.66      4650
   macro avg       0.64      0.69      0.62      4650
weighted avg       0.78      0.66      0.69      4650

[[2306 1296]
 [ 264  784]]
Finished training and evaluation
{&#39;precision&#39;: 0.3590733590733591, &#39;recall&#39;: 0.8942307692307693, &#39;F1&#39;: 0.512396694214876, &#39;ERDE_5&#39;: 0.3418688719904829, &#39;ERDE_50&#39;: 0.12248992617183534, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4924233486000456}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00016: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Finished training and evaluation
{&#39;precision&#39;: 0.4557823129251701, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5338645418326693, &#39;ERDE_5&#39;: 0.29202788331610346, &#39;ERDE_50&#39;: 0.13396933979399697, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5130543743863989}
Evaluating for elapsed time
146/146 [==============================] - 4s 15ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Evaluated with elapsed time 69.75606897500256
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Writing results to CSV file
{&#39;precision&#39;: 0.4426229508196721, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5644599303135889, &#39;ERDE_5&#39;: 0.3050107563539052, &#39;ERDE_50&#39;: 0.11365960800094416, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.540259443754396}
Writing results to CSV file
{&#39;precision&#39;: 0.42592592592592593, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.518796992481203, &#39;ERDE_5&#39;: 0.2998734202268961, &#39;ERDE_50&#39;: 0.13679727713227546, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49453500383987986}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.75606897500256} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluating after getting time 24641.150391718
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluated with elapsed time 71.36771395899996
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.25383215623376204, &#39;ERDE_50&#39;: 0.14525314510224885, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25104606155464504, &#39;ERDE_50&#39;: 0.16362356018309013, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933741372741947, &#39;ERDE_50&#39;: 0.18315644752946808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3868196501364656}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluating after getting time 24716.771073108
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluated with elapsed time 3.2293367909987865
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.581177294254303
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5136 - tp: 1.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1047.0000 - accuracy: 0.7748 - precision: 1.0000 - recall: 9.5420e-04 - f1_metric: 0.0017
Test Score: 0.5136207342147827
Test Accuracy: 1.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       1.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.77      0.68      4650

[[3602    0]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24585703871594175, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.018305138304333494}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.7964 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7964164614677429
Test Accuracy: 8.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.7338 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0175
Test Score: 0.733765184879303
Test Accuracy: 15.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470169125117684, &#39;ERDE_50&#39;: 0.22811282687546647, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 15ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 67.7363880289995
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.7363880289995} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluating after getting time 27855.882677796
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluated with elapsed time 97.13696813800198
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.25383215623376204, &#39;ERDE_50&#39;: 0.14525314510224885, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25104606155464504, &#39;ERDE_50&#39;: 0.16362356018309013, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933741372741947, &#39;ERDE_50&#39;: 0.18315644752946808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3868196501364656}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluating after getting time 27960.21903459
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluated with elapsed time 3.7510723269988375
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.9885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9884927272796631
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5182 - tp: 68.0000 - fp: 22.0000 - tn: 3580.0000 - fn: 980.0000 - accuracy: 0.7845 - precision: 0.7556 - recall: 0.0649 - f1_metric: 0.0606
Test Score: 0.518192708492279
Test Accuracy: 68.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.76      0.06      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.53      0.50      4650
weighted avg       0.78      0.78      0.71      4650

[[3580   22]
 [ 980   68]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3529411764705882, &#39;ERDE_5&#39;: 0.25043131740473284, &#39;ERDE_50&#39;: 0.1937751845704177, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.33918344505088527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.4622 - tp: 228.0000 - fp: 76.0000 - tn: 3526.0000 - fn: 820.0000 - accuracy: 0.8073 - precision: 0.7500 - recall: 0.2176 - f1_metric: 0.1686
Test Score: 0.4621577858924866
Test Accuracy: 228.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.75      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.78      0.60      0.61      4650
weighted avg       0.80      0.81      0.76      4650

[[3526   76]
 [ 820  228]]
Finished training and evaluation
{&#39;precision&#39;: 0.6756756756756757, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5617977528089887, &#39;ERDE_5&#39;: 0.2596397468528691, &#39;ERDE_50&#39;: 0.14160924165451463, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5398987421221957}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.9268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9268305897712708
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 14ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.08097400600309
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.08097400600309} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.82      4650
   macro avg       0.84      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3565   37]
 [ 823  225]]
Evaluating after getting time 31167.061107976
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.82      4650
   macro avg       0.84      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3565   37]
 [ 823  225]]
Evaluated with elapsed time 96.04366892700273
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.2538415612878538, &#39;ERDE_50&#39;: 0.15234534368380914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5133397480997871}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516264638393209, &#39;ERDE_50&#39;: 0.16420479631585944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.248756619191948, &#39;ERDE_50&#39;: 0.17784707900899532, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.41062824485558896}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluating after getting time 31269.741641876
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluated with elapsed time 4.1264786690007895
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.6115 - tp: 3.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1045.0000 - accuracy: 0.7738 - precision: 0.3000 - recall: 0.0029 - f1_metric: 0.0036
Test Score: 0.6114905476570129
Test Accuracy: 3.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.30      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.54      0.50      0.44      4650
weighted avg       0.67      0.77      0.68      4650

[[3595    7]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24644411760456383, &#39;ERDE_50&#39;: 0.2417159879058177, &#39;median_latency_tps&#39;: 19.5, &#39;median_penalty_tps&#39;: 0.07202479246451088, &#39;speed&#39;: 0.9279752075354891, &#39;latency_weighted_f1&#39;: 0.03469066196394351}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 6s 24ms/step - loss: 0.6934 - tp: 2.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1046.0000 - accuracy: 0.7725 - precision: 0.1429 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.6933532953262329
Test Accuracy: 2.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.14      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.46      0.50      0.44      4650
weighted avg       0.63      0.77      0.68      4650

[[3590   12]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24701951071543668, &#39;ERDE_50&#39;: 0.24229722403858575, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05841121951671113, &#39;speed&#39;: 0.9415887804832889, &#39;latency_weighted_f1&#39;: 0.034873658536418106}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 6s 26ms/step - loss: 0.6463 - tp: 10.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1038.0000 - accuracy: 0.7761 - precision: 0.7692 - recall: 0.0095 - f1_metric: 0.0068
Test Score: 0.6463022828102112
Test Accuracy: 10.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.77      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.50      0.45      4650
weighted avg       0.77      0.78      0.68      4650

[[3599    3]
 [1038   10]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 3s 16ms/step - loss: 0.5475 - tp: 2.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1046.0000 - accuracy: 0.7744 - precision: 0.4000 - recall: 0.0019 - f1_metric: 0.0016
Test Score: 0.5475383400917053
Test Accuracy: 2.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.40      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.59      0.50      0.44      4650
weighted avg       0.69      0.77      0.68      4650

[[3599    3]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644411957035114, &#39;ERDE_50&#39;: 0.24408005409967107, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.017472364637650513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.6962 - tp: 3.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1045.0000 - accuracy: 0.7753 - precision: 1.0000 - recall: 0.0029 - f1_metric: 0.0026
Test Score: 0.6962397694587708
Test Accuracy: 3.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       1.00      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.78      0.68      4650

[[3602    0]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03773584905660378, &#39;ERDE_5&#39;: 0.24586277487140254, &#39;ERDE_50&#39;: 0.24113475177304972, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231535911708763, &#39;speed&#39;: 0.9376846408829124, &#39;latency_weighted_f1&#39;: 0.0353843260710533}
Evaluating for elapsed time
146/146 [==============================] - 4s 15ms/step - loss: 0.6962 - tp: 3.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1045.0000 - accuracy: 0.7753 - precision: 1.0000 - recall: 0.0029 - f1_metric: 0.0026
Test Score: 0.6962397694587708
Test Accuracy: 3.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       1.00      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.78      0.68      4650

[[3602    0]
 [1045    3]]
Evaluated with elapsed time 66.37095212499844
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644408081025748, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.01776540835187479}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644410576828876, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.017692091778564536}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644408081025748, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.01776540835187479}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644410576828876, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.017692091778564536}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.2509709536176824, &#39;ERDE_50&#39;: 0.163623560183091, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47410308208223745}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.24817993803972513, &#39;ERDE_50&#39;: 0.2079987033963209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.37095212499844} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.82      4650
   macro avg       0.84      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3565   37]
 [ 823  225]]
Evaluating after getting time 34841.257402464
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.82      4650
   macro avg       0.84      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3565   37]
 [ 823  225]]
Evaluated with elapsed time 74.84627512100269
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7543859649122807, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5341614906832298, &#39;ERDE_5&#39;: 0.2538415612878538, &#39;ERDE_50&#39;: 0.15234534368380914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5133397480997871}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516264638393209, &#39;ERDE_50&#39;: 0.16420479631585944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.248756619191948, &#39;ERDE_50&#39;: 0.17784707900899532, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.41062824485558896}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluating after getting time 34920.17253346
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluated with elapsed time 2.932191125000827
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.4660 - tp: 70.0000 - fp: 33.0000 - tn: 3569.0000 - fn: 978.0000 - accuracy: 0.7826 - precision: 0.6796 - recall: 0.0668 - f1_metric: 0.0575
Test Score: 0.4660346806049347
Test Accuracy: 70.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      0.99      0.88      3602
           1       0.68      0.07      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.73      0.53      0.50      4650
weighted avg       0.76      0.78      0.71      4650

[[3569   33]
 [ 978   70]]
Finished training and evaluation
{&#39;precision&#39;: 0.7096774193548387, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3259259259259259, &#39;ERDE_5&#39;: 0.25103210124884084, &#39;ERDE_50&#39;: 0.19908455309089165, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.311952275067696}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 15ms/step - loss: 0.7347 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.73471599817276
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.4544 - tp: 284.0000 - fp: 131.0000 - tn: 3471.0000 - fn: 764.0000 - accuracy: 0.8075 - precision: 0.6843 - recall: 0.2710 - f1_metric: 0.2022
Test Score: 0.45439842343330383
Test Accuracy: 284.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.89      3602
           1       0.68      0.27      0.39      1048

    accuracy                           0.81      4650
   macro avg       0.75      0.62      0.64      4650
weighted avg       0.79      0.81      0.77      4650

[[3471  131]
 [ 764  284]]
Finished training and evaluation
{&#39;precision&#39;: 0.6043956043956044, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2665707716978174, &#39;ERDE_50&#39;: 0.13676374427845922, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5421137113206458}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.9529 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9528539776802063
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 23ms/step - loss: 1.0928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.092787504196167
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 13ms/step - loss: 1.0928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.092787504196167
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 64.8728478089979
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.6043956043956044, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2665707716978174, &#39;ERDE_50&#39;: 0.13676374427845922, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5421137113206458}
Writing results to CSV file
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2591636979493422, &#39;ERDE_50&#39;: 0.15284833649101473, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5008219003795595}
Writing results to CSV file
{&#39;precision&#39;: 0.6923076923076923, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.46153846153846156, &#39;ERDE_5&#39;: 0.2551417768815796, &#39;ERDE_50&#39;: 0.17005627930631936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43995421746290314}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.2544055579032662, &#39;ERDE_50&#39;: 0.14347031504116317, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25162502712752716, &#39;ERDE_50&#39;: 0.16184073012200792, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933586519672107, &#39;ERDE_50&#39;: 0.18552051372332276, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5419354838709677, &#39;ERDE_5&#39;: 0.25094601071770706, &#39;ERDE_50&#39;: 0.15180322921382386, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5208107091749077}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.2498893419257066, &#39;ERDE_50&#39;: 0.17191735269297162, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4386828868139475}
Writing results to CSV file
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24817705501274134, &#39;ERDE_50&#39;: 0.19381430623319984, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7413793103448276, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5308641975308641, &#39;ERDE_5&#39;: 0.25443050053720084, &#39;ERDE_50&#39;: 0.15292657981657745, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5101709842226279}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.4383561643835617, &#39;ERDE_5&#39;: 0.2516350128986609, &#39;ERDE_50&#39;: 0.1760251272851303, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41956221304248037}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933874848974547, &#39;ERDE_50&#39;: 0.20206897708029664, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.2544055579032662, &#39;ERDE_50&#39;: 0.14347031504116317, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25162502712752716, &#39;ERDE_50&#39;: 0.16184073012200792, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933586519672107, &#39;ERDE_50&#39;: 0.18552051372332276, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7818181818181819, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5408805031446541, &#39;ERDE_5&#39;: 0.25268668250217374, &#39;ERDE_50&#39;: 0.15118287141827536, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.51979685184947}
Writing results to CSV file
{&#39;precision&#39;: 0.8222222222222222, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4966442953020134, &#39;ERDE_5&#39;: 0.25046280843215557, &#39;ERDE_50&#39;: 0.16304232405032437, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4753513160351256}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38235294117647056, &#39;ERDE_5&#39;: 0.2493359587182254, &#39;ERDE_50&#39;: 0.187884579917176, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.36447187623152266}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.2544055579032662, &#39;ERDE_50&#39;: 0.14347031504116317, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25162502712752716, &#39;ERDE_50&#39;: 0.16184073012200792, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933586519672107, &#39;ERDE_50&#39;: 0.18552051372332276, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.2544055579032662, &#39;ERDE_50&#39;: 0.14347031504116317, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25162502712752716, &#39;ERDE_50&#39;: 0.16184073012200792, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933586519672107, &#39;ERDE_50&#39;: 0.18552051372332276, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 64.8728478089979} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 37796.671727517
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 73.51757334399736
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluating after getting time 37880.044401568
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluated with elapsed time 2.5132712129998254
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.8920 - tp: 518.0000 - fp: 557.0000 - tn: 3045.0000 - fn: 530.0000 - accuracy: 0.7662 - precision: 0.4819 - recall: 0.4943 - f1_metric: 0.3068
Test Score: 0.8919793963432312
Test Accuracy: 518.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.85      0.85      0.85      3602
           1       0.48      0.49      0.49      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.67      0.67      4650
weighted avg       0.77      0.77      0.77      4650

[[3045  557]
 [ 530  518]]
Finished training and evaluation
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.7943 - tp: 858.0000 - fp: 1350.0000 - tn: 2252.0000 - fn: 190.0000 - accuracy: 0.6688 - precision: 0.3886 - recall: 0.8187 - f1_metric: 0.4004
Test Score: 1.7942938804626465
Test Accuracy: 858.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75      3602
           1       0.39      0.82      0.53      1048

    accuracy                           0.67      4650
   macro avg       0.66      0.72      0.64      4650
weighted avg       0.80      0.67      0.70      4650

[[2252 1350]
 [ 190  858]]
Finished training and evaluation
{&#39;precision&#39;: 0.352059925093633, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5067385444743935, &#39;ERDE_5&#39;: 0.3459071618282603, &#39;ERDE_50&#39;: 0.12419451290735468, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48698575488887214}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7902 - tp: 598.0000 - fp: 664.0000 - tn: 2938.0000 - fn: 450.0000 - accuracy: 0.7604 - precision: 0.4739 - recall: 0.5706 - f1_metric: 0.3356
Test Score: 0.7902495265007019
Test Accuracy: 598.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.82      0.84      3602
           1       0.47      0.57      0.52      1048

    accuracy                           0.76      4650
   macro avg       0.67      0.69      0.68      4650
weighted avg       0.78      0.76      0.77      4650

[[2938  664]
 [ 450  598]]
Finished training and evaluation
{&#39;precision&#39;: 0.4340659340659341, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5524475524475524, &#39;ERDE_5&#39;: 0.3053317887997231, &#39;ERDE_50&#39;: 0.11896897652141525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5309130148057564}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 22.7635 - tp: 879.0000 - fp: 1843.0000 - tn: 1759.0000 - fn: 169.0000 - accuracy: 0.5673 - precision: 0.3229 - recall: 0.8387 - f1_metric: 0.3672
Test Score: 22.763538360595703
Test Accuracy: 879.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.49      0.64      3602
           1       0.32      0.84      0.47      1048

    accuracy                           0.57      4650
   macro avg       0.62      0.66      0.55      4650
weighted avg       0.78      0.57      0.60      4650

[[1759 1843]
 [ 169  879]]
Finished training and evaluation
{&#39;precision&#39;: 0.30844155844155846, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.46116504854368934, &#39;ERDE_5&#39;: 0.36916429802381256, &#39;ERDE_50&#39;: 0.14507989202421095, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4431887247226374}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 3s 16ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Finished training and evaluation
{&#39;precision&#39;: 0.4672897196261682, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.47393364928909953, &#39;ERDE_5&#39;: 0.2787768471329035, &#39;ERDE_50&#39;: 0.16079003403584705, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.45545960235900873}
Evaluating for elapsed time
146/146 [==============================] - 4s 13ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Evaluated with elapsed time 67.21531218399468
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Writing results to CSV file
{&#39;precision&#39;: 0.48148148148148145, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5439330543933055, &#39;ERDE_5&#39;: 0.2864315401330864, &#39;ERDE_50&#39;: 0.13288511085402835, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5206126309849816}
Writing results to CSV file
{&#39;precision&#39;: 0.46218487394957986, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.4932735426008969, &#39;ERDE_5&#39;: 0.2830258367572126, &#39;ERDE_50&#39;: 0.15303835599595872, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47020518009861845}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2619280279196682, &#39;ERDE_50&#39;: 0.1486623185732894, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5125438725213378}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597451433465313, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.62, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4025974025974026, &#39;ERDE_5&#39;: 0.2568872101025875, &#39;ERDE_50&#39;: 0.18362031867388992, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3837695879600649}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.21531218399468} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 40856.741058742
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 63.48017208300007
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluating after getting time 40924.479568601
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluated with elapsed time 3.2255336250018445
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
146/146 [==============================] - 5s 15ms/step - loss: 1.3284 - tp: 721.0000 - fp: 922.0000 - tn: 2680.0000 - fn: 327.0000 - accuracy: 0.7314 - precision: 0.4388 - recall: 0.6880 - f1_metric: 0.3768
Test Score: 1.3284099102020264
Test Accuracy: 721.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.89      0.74      0.81      3602
           1       0.44      0.69      0.54      1048

    accuracy                           0.73      4650
   macro avg       0.67      0.72      0.67      4650
weighted avg       0.79      0.73      0.75      4650

[[2680  922]
 [ 327  721]]
Finished training and evaluation
{&#39;precision&#39;: 0.40476190476190477, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5414012738853503, &#39;ERDE_5&#39;: 0.31807712046134634, &#39;ERDE_50&#39;: 0.11757177427918346, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.520297322822218}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 27ms/step - loss: 1.9127 - tp: 815.0000 - fp: 1322.0000 - tn: 2280.0000 - fn: 233.0000 - accuracy: 0.6656 - precision: 0.3814 - recall: 0.7777 - f1_metric: 0.3861
Test Score: 1.9127001762390137
Test Accuracy: 815.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.63      0.75      3602
           1       0.38      0.78      0.51      1048

    accuracy                           0.67      4650
   macro avg       0.64      0.71      0.63      4650
weighted avg       0.79      0.67      0.69      4650

[[2280 1322]
 [ 233  815]]
Finished training and evaluation
{&#39;precision&#39;: 0.35019455252918286, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.49861495844875336, &#39;ERDE_5&#39;: 0.3424431096310815, &#39;ERDE_50&#39;: 0.13016336088616165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47917882818823127}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 3s 12ms/step - loss: 1.3329 - tp: 666.0000 - fp: 903.0000 - tn: 2699.0000 - fn: 382.0000 - accuracy: 0.7237 - precision: 0.4245 - recall: 0.6355 - f1_metric: 0.3491
Test Score: 1.332855463027954
Test Accuracy: 666.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.42      0.64      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2699  903]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.405, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5328947368421052, &#39;ERDE_5&#39;: 0.3146110949426674, &#39;ERDE_50&#39;: 0.1235406222579915, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5121223726261722}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00025: early stopping
Evaluating
146/146 [==============================] - 6s 27ms/step - loss: 1.5568 - tp: 586.0000 - fp: 763.0000 - tn: 2839.0000 - fn: 462.0000 - accuracy: 0.7366 - precision: 0.4344 - recall: 0.5592 - f1_metric: 0.3294
Test Score: 1.5567545890808105
Test Accuracy: 586.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.79      0.82      3602
           1       0.43      0.56      0.49      1048

    accuracy                           0.74      4650
   macro avg       0.65      0.67      0.66      4650
weighted avg       0.76      0.74      0.75      4650

[[2839  763]
 [ 462  586]]
Finished training and evaluation
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 8s 29ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 4s 28ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Finished training and evaluation
{&#39;precision&#39;: 0.3910891089108911, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5163398692810458, &#39;ERDE_5&#39;: 0.31694292196479884, &#39;ERDE_50&#39;: 0.13059369917676925, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49621281775962855}
Evaluating for elapsed time
146/146 [==============================] - 9s 22ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 4s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Evaluated with elapsed time 77.69243639399792
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Writing results to CSV file
{&#39;precision&#39;: 0.4339622641509434, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5247148288973384, &#39;ERDE_5&#39;: 0.2980494712945635, &#39;ERDE_50&#39;: 0.13505356873396854, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5022183619522276}
Writing results to CSV file
{&#39;precision&#39;: 0.41843971631205673, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.4816326530612245, &#39;ERDE_5&#39;: 0.29348487737711887, &#39;ERDE_50&#39;: 0.15404434161036268, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.45910868679462136}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6486486486486487, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5393258426966292, &#39;ERDE_5&#39;: 0.2607808163544452, &#39;ERDE_50&#39;: 0.14749984630775392, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5183027924373079}
Writing results to CSV file
{&#39;precision&#39;: 0.6229508196721312, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4606060606060606, &#39;ERDE_5&#39;: 0.2591694679991465, &#39;ERDE_50&#39;: 0.16939679984798553, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4408581738560002}
Writing results to CSV file
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.39215686274509803, &#39;ERDE_5&#39;: 0.25688925727609474, &#39;ERDE_50&#39;: 0.18598438486774335, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3738173089554079}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 77.69243639399792} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 44942.031856709
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 87.03345435200026
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluating after getting time 45035.817711792
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluated with elapsed time 4.637968253002327
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.8920 - tp: 518.0000 - fp: 557.0000 - tn: 3045.0000 - fn: 530.0000 - accuracy: 0.7662 - precision: 0.4819 - recall: 0.4943 - f1_metric: 0.3068
Test Score: 0.8919793963432312
Test Accuracy: 518.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.85      0.85      0.85      3602
           1       0.48      0.49      0.49      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.67      0.67      4650
weighted avg       0.77      0.77      0.77      4650

[[3045  557]
 [ 530  518]]
Finished training and evaluation
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.7943 - tp: 858.0000 - fp: 1350.0000 - tn: 2252.0000 - fn: 190.0000 - accuracy: 0.6688 - precision: 0.3886 - recall: 0.8187 - f1_metric: 0.4004
Test Score: 1.7942938804626465
Test Accuracy: 858.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75      3602
           1       0.39      0.82      0.53      1048

    accuracy                           0.67      4650
   macro avg       0.66      0.72      0.64      4650
weighted avg       0.80      0.67      0.70      4650

[[2252 1350]
 [ 190  858]]
Finished training and evaluation
{&#39;precision&#39;: 0.352059925093633, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5067385444743935, &#39;ERDE_5&#39;: 0.3459071618282603, &#39;ERDE_50&#39;: 0.12419451290735468, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48698575488887214}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7902 - tp: 598.0000 - fp: 664.0000 - tn: 2938.0000 - fn: 450.0000 - accuracy: 0.7604 - precision: 0.4739 - recall: 0.5706 - f1_metric: 0.3356
Test Score: 0.7902495265007019
Test Accuracy: 598.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.82      0.84      3602
           1       0.47      0.57      0.52      1048

    accuracy                           0.76      4650
   macro avg       0.67      0.69      0.68      4650
weighted avg       0.78      0.76      0.77      4650

[[2938  664]
 [ 450  598]]
Finished training and evaluation
{&#39;precision&#39;: 0.4340659340659341, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5524475524475524, &#39;ERDE_5&#39;: 0.3053317887997231, &#39;ERDE_50&#39;: 0.11896897652141525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5309130148057564}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 22.7635 - tp: 879.0000 - fp: 1843.0000 - tn: 1759.0000 - fn: 169.0000 - accuracy: 0.5673 - precision: 0.3229 - recall: 0.8387 - f1_metric: 0.3672
Test Score: 22.763538360595703
Test Accuracy: 879.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.49      0.64      3602
           1       0.32      0.84      0.47      1048

    accuracy                           0.57      4650
   macro avg       0.62      0.66      0.55      4650
weighted avg       0.78      0.57      0.60      4650

[[1759 1843]
 [ 169  879]]
Finished training and evaluation
{&#39;precision&#39;: 0.30844155844155846, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.46116504854368934, &#39;ERDE_5&#39;: 0.36916429802381256, &#39;ERDE_50&#39;: 0.14507989202421095, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4431887247226374}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Finished training and evaluation
{&#39;precision&#39;: 0.4672897196261682, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.47393364928909953, &#39;ERDE_5&#39;: 0.2787768471329035, &#39;ERDE_50&#39;: 0.16079003403584705, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.45545960235900873}
Evaluating for elapsed time
146/146 [==============================] - 4s 14ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Evaluated with elapsed time 63.4278408350001
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Writing results to CSV file
{&#39;precision&#39;: 0.48148148148148145, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5439330543933055, &#39;ERDE_5&#39;: 0.2864315401330864, &#39;ERDE_50&#39;: 0.13288511085402835, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5206126309849816}
Writing results to CSV file
{&#39;precision&#39;: 0.46218487394957986, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.4932735426008969, &#39;ERDE_5&#39;: 0.2830258367572126, &#39;ERDE_50&#39;: 0.15303835599595872, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47020518009861845}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.631578947368421, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5333333333333333, &#39;ERDE_5&#39;: 0.2619280279196682, &#39;ERDE_50&#39;: 0.1486623185732894, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5125438725213378}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597451433465313, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.62, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4025974025974026, &#39;ERDE_5&#39;: 0.2568872101025875, &#39;ERDE_50&#39;: 0.18362031867388992, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3837695879600649}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6233766233766234, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5303867403314918, &#39;ERDE_5&#39;: 0.262503458090888, &#39;ERDE_50&#39;: 0.14924355470605716, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5097121384190101}
Writing results to CSV file
{&#39;precision&#39;: 0.609375, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4642857142857143, &#39;ERDE_5&#39;: 0.26032424021920497, &#39;ERDE_50&#39;: 0.16819520591966797, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44438006716218065}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 63.4278408350001} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 48125.330930658
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 58.40362128500419
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluating after getting time 48188.528380613
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.80      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.80      0.77      4650

[[3391  211]
 [ 741  307]]
Evaluated with elapsed time 3.737938647995179
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.3284 - tp: 721.0000 - fp: 922.0000 - tn: 2680.0000 - fn: 327.0000 - accuracy: 0.7314 - precision: 0.4388 - recall: 0.6880 - f1_metric: 0.3768
Test Score: 1.3284099102020264
Test Accuracy: 721.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.89      0.74      0.81      3602
           1       0.44      0.69      0.54      1048

    accuracy                           0.73      4650
   macro avg       0.67      0.72      0.67      4650
weighted avg       0.79      0.73      0.75      4650

[[2680  922]
 [ 327  721]]
Finished training and evaluation
{&#39;precision&#39;: 0.40476190476190477, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5414012738853503, &#39;ERDE_5&#39;: 0.31807712046134634, &#39;ERDE_50&#39;: 0.11757177427918346, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.520297322822218}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 1.9127 - tp: 815.0000 - fp: 1322.0000 - tn: 2280.0000 - fn: 233.0000 - accuracy: 0.6656 - precision: 0.3814 - recall: 0.7777 - f1_metric: 0.3861
Test Score: 1.9127001762390137
Test Accuracy: 815.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.63      0.75      3602
           1       0.38      0.78      0.51      1048

    accuracy                           0.67      4650
   macro avg       0.64      0.71      0.63      4650
weighted avg       0.79      0.67      0.69      4650

[[2280 1322]
 [ 233  815]]
Finished training and evaluation
{&#39;precision&#39;: 0.35019455252918286, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.49861495844875336, &#39;ERDE_5&#39;: 0.3424431096310815, &#39;ERDE_50&#39;: 0.13016336088616165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47917882818823127}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.3329 - tp: 666.0000 - fp: 903.0000 - tn: 2699.0000 - fn: 382.0000 - accuracy: 0.7237 - precision: 0.4245 - recall: 0.6355 - f1_metric: 0.3491
Test Score: 1.332855463027954
Test Accuracy: 666.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.42      0.64      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2699  903]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.405, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5328947368421052, &#39;ERDE_5&#39;: 0.3146110949426674, &#39;ERDE_50&#39;: 0.1235406222579915, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5121223726261722}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00025: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 1.5568 - tp: 586.0000 - fp: 763.0000 - tn: 2839.0000 - fn: 462.0000 - accuracy: 0.7366 - precision: 0.4344 - recall: 0.5592 - f1_metric: 0.3294
Test Score: 1.5567545890808105
Test Accuracy: 586.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.79      0.82      3602
           1       0.43      0.56      0.49      1048

    accuracy                           0.74      4650
   macro avg       0.65      0.67      0.66      4650
weighted avg       0.76      0.74      0.75      4650

[[2839  763]
 [ 462  586]]
Finished training and evaluation
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Finished training and evaluation
{&#39;precision&#39;: 0.3910891089108911, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5163398692810458, &#39;ERDE_5&#39;: 0.31694292196479884, &#39;ERDE_50&#39;: 0.13059369917676925, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49621281775962855}
Evaluating for elapsed time
146/146 [==============================] - 8s 22ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Evaluated with elapsed time 72.86446655700274
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Writing results to CSV file
{&#39;precision&#39;: 0.4339622641509434, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5247148288973384, &#39;ERDE_5&#39;: 0.2980494712945635, &#39;ERDE_50&#39;: 0.13505356873396854, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5022183619522276}
Writing results to CSV file
{&#39;precision&#39;: 0.41843971631205673, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.4816326530612245, &#39;ERDE_5&#39;: 0.29348487737711887, &#39;ERDE_50&#39;: 0.15404434161036268, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.45910868679462136}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6486486486486487, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5393258426966292, &#39;ERDE_5&#39;: 0.2607808163544452, &#39;ERDE_50&#39;: 0.14749984630775392, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5183027924373079}
Writing results to CSV file
{&#39;precision&#39;: 0.6229508196721312, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4606060606060606, &#39;ERDE_5&#39;: 0.2591694679991465, &#39;ERDE_50&#39;: 0.16939679984798553, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4408581738560002}
Writing results to CSV file
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.39215686274509803, &#39;ERDE_5&#39;: 0.25688925727609474, &#39;ERDE_50&#39;: 0.18598438486774335, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3738173089554079}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.64, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5363128491620112, &#39;ERDE_5&#39;: 0.26135624652566497, &#39;ERDE_50&#39;: 0.14808108244052165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5154072461108425}
Writing results to CSV file
{&#39;precision&#39;: 0.6129032258064516, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.45783132530120485, &#39;ERDE_5&#39;: 0.25974856487182013, &#39;ERDE_50&#39;: 0.16997803598075326, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43820240172433755}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5463917525773195, &#39;recall&#39;: 0.5096153846153846, &#39;F1&#39;: 0.527363184079602, &#39;ERDE_5&#39;: 0.2712211614764609, &#39;ERDE_50&#39;: 0.14614176572830706, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5068064411125169}
Writing results to CSV file
{&#39;precision&#39;: 0.5443037974683544, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.46994535519125685, &#39;ERDE_5&#39;: 0.2667195756714041, &#39;ERDE_50&#39;: 0.16513253860470017, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4497970583129597}
Writing results to CSV file
{&#39;precision&#39;: 0.5692307692307692, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43786982248520706, &#39;ERDE_5&#39;: 0.26211664147520264, &#39;ERDE_50&#39;: 0.17466704670568256, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4173924627212157}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 72.86446655700274} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3578   24]
 [ 842  206]]
Evaluating after getting time 52116.44888954
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3578   24]
 [ 842  206]]
Evaluated with elapsed time 114.43457125100394
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.25325650666283256, &#39;ERDE_50&#39;: 0.13994377658177373, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5591387700232776}
Writing results to CSV file
{&#39;precision&#39;: 0.8974358974358975, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.48951048951048953, &#39;ERDE_5&#39;: 0.248151200039192, &#39;ERDE_50&#39;: 0.16544551190696088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46471355081321036}
Writing results to CSV file
{&#39;precision&#39;: 0.9615384615384616, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.38461538461538464, &#39;ERDE_5&#39;: 0.24643475938467724, &#39;ERDE_50&#39;: 0.18734246544719046, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.36363622788089367}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluating after getting time 52238.013559789
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluated with elapsed time 4.661407808001968
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.8909 - tp: 3.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1045.0000 - accuracy: 0.7746 - precision: 0.5000 - recall: 0.0029 - f1_metric: 0.0034
Test Score: 0.8908883333206177
Test Accuracy: 3.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.50      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.64      0.50      0.44      4650
weighted avg       0.71      0.77      0.68      4650

[[3599    3]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 18ms/step - loss: 0.5811 - tp: 2.0000 - fp: 10.0000 - tn: 3592.0000 - fn: 1046.0000 - accuracy: 0.7729 - precision: 0.1667 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.5810906291007996
Test Accuracy: 2.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.17      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.47      0.50      0.44      4650
weighted avg       0.64      0.77      0.68      4650

[[3592   10]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827475083865, &#39;ERDE_50&#39;: 0.24171598790581905, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06034880562609424, &#39;speed&#39;: 0.9396511943739058, &#39;latency_weighted_f1&#39;: 0.03512714745323012}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5551 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5551328063011169
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.7067 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0080
Test Score: 0.7066572308540344
Test Accuracy: 8.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701724914940792, &#39;ERDE_50&#39;: 0.2375690916508785, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06918474512703571}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330226421356201
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 8s 22ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330226421356201
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 71.990126126002
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701724914940792, &#39;ERDE_50&#39;: 0.2375690916508785, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06918474512703571}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702240985105592, &#39;ERDE_50&#39;: 0.24229722403858514, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.03537704511739719}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.018691588785046728, &#39;ERDE_5&#39;: 0.24702506471334643, &#39;ERDE_50&#39;: 0.24466129023243857, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.01774473638619201}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03773584905660378, &#39;ERDE_5&#39;: 0.24585703799276867, &#39;ERDE_50&#39;: 0.24113475177304985, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03560481295798086}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586073037542694, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.018230977114345875}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24812800272023786, &#39;ERDE_50&#39;: 0.19381430623319892, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701648154497682, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 71.990126126002} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3578   24]
 [ 842  206]]
Evaluating after getting time 55898.605109387
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3578   24]
 [ 842  206]]
Evaluated with elapsed time 118.03167486900202
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.25325650666283256, &#39;ERDE_50&#39;: 0.13994377658177373, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5591387700232776}
Writing results to CSV file
{&#39;precision&#39;: 0.8974358974358975, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.48951048951048953, &#39;ERDE_5&#39;: 0.248151200039192, &#39;ERDE_50&#39;: 0.16544551190696088, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46471355081321036}
Writing results to CSV file
{&#39;precision&#39;: 0.9615384615384616, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.38461538461538464, &#39;ERDE_5&#39;: 0.24643475938467724, &#39;ERDE_50&#39;: 0.18734246544719046, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.36363622788089367}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluating after getting time 56022.395245332
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.85      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3589   13]
 [ 976   72]]
Evaluated with elapsed time 4.367318493001221
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 1.0073 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0072625875473022
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7822611927986145
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 5s 16ms/step - loss: 0.4687 - tp: 136.0000 - fp: 52.0000 - tn: 3550.0000 - fn: 912.0000 - accuracy: 0.7927 - precision: 0.7234 - recall: 0.1298 - f1_metric: 0.1172
Test Score: 0.4687204360961914
Test Accuracy: 136.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.72      0.13      0.22      1048

    accuracy                           0.79      4650
   macro avg       0.76      0.56      0.55      4650
weighted avg       0.78      0.79      0.73      4650

[[3550   52]
 [ 912  136]]
Finished training and evaluation
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25678171523384763, &#39;ERDE_50&#39;: 0.15997965673535694, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.9031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9030778408050537
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 1.0370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370429754257202
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 23ms/step - loss: 1.0370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370429754257202
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.82460284900299
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24812800344341096, &#39;ERDE_50&#39;: 0.19617837242705216, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.3232917661497528}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701859584703958, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14285714285714288, &#39;ERDE_5&#39;: 0.2458619418069205, &#39;ERDE_50&#39;: 0.22695035460993082, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06037624654335805, &#39;speed&#39;: 0.939623753456642, &#39;latency_weighted_f1&#39;: 0.1342319647795203}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.2487081545412454, &#39;ERDE_50&#39;: 0.18730334378440736, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3671716679073117}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701858132180415, &#39;ERDE_50&#39;: 0.22338469448775838, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.1592920353982301, &#39;ERDE_5&#39;: 0.24586193646336427, &#39;ERDE_50&#39;: 0.22458628841607742, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.14936509342257137}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.82460284900299} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3580   22]
 [ 856  192]]
Evaluating after getting time 58611.860624617
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3580   22]
 [ 856  192]]
Evaluated with elapsed time 123.91767529500066
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526947932690517, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873223309688122, &#39;ERDE_50&#39;: 0.17784707900899493, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.2464354058352571, &#39;ERDE_50&#39;: 0.19679873022260408, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3164477988870909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluating after getting time 58742.74584238
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluated with elapsed time 3.963925042000483
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5898103713989258
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5358 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.535814106464386
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.6271 - tp: 1.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1047.0000 - accuracy: 0.7744 - precision: 0.3333 - recall: 9.5420e-04 - f1_metric: 0.0015
Test Score: 0.6271416544914246
Test Accuracy: 1.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.33      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.55      0.50      0.44      4650
weighted avg       0.68      0.77      0.68      4650

[[3600    2]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.2464382748487095, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.01813244832033035}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 6s 21ms/step - loss: 0.7450 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0023
Test Score: 0.7450429201126099
Test Accuracy: 4.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643827385949582, &#39;ERDE_50&#39;: 0.23935192171196482, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.05144640698863761}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392691493034363
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 19ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392691493034363
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.33982688799733
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.33982688799733} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3580   22]
 [ 856  192]]
Evaluating after getting time 61839.890300655
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3580   22]
 [ 856  192]]
Evaluated with elapsed time 241.9174090230008
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526947932690517, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873223309688122, &#39;ERDE_50&#39;: 0.17784707900899493, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.2464354058352571, &#39;ERDE_50&#39;: 0.19679873022260408, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3164477988870909}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluating after getting time 62089.85922793
              precision    recall  f1-score   support

           0       0.79      1.00      0.88      3602
           1       0.87      0.07      0.13      1048

    accuracy                           0.79      4650
   macro avg       0.83      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3591   11]
 [ 977   71]]
Evaluated with elapsed time 2.803060229001858
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 28ms/step - loss: 0.9755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9755200743675232
Test Accuracy: 0.0
146/146 [==============================] - 4s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 8s 35ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.812414288520813
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 10s 28ms/step - loss: 0.9575 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9574721455574036
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8782 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8781750202178955
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 9s 33ms/step - loss: 1.1301 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1301218271255493
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
146/146 [==============================] - 9s 27ms/step - loss: 1.1301 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1301218271255493
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 77.12490947000333
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.9130434782608695, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3307086614173228, &#39;ERDE_5&#39;: 0.24698910545911937, &#39;ERDE_50&#39;: 0.19737996635537292, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.31395608393522395}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.24702076540872125, &#39;ERDE_50&#39;: 0.2281128268754652, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8928571428571429, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37878787878787884, &#39;ERDE_5&#39;: 0.24755775058878443, &#39;ERDE_50&#39;: 0.18850493771272692, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.3595997714626033}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.2470186116233917, &#39;ERDE_50&#39;: 0.22574876068161176, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 77.12490947000333} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluating after getting time 64651.214365967
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluated with elapsed time 106.92053165100515
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152346162586936, &#39;ERDE_50&#39;: 0.15947666392815127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 106.92053165100515}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluating after getting time 64912.724937577
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluated with elapsed time 96.54068188100064
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152346162586936, &#39;ERDE_50&#39;: 0.15947666392815127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 96.54068188100064}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluating after getting time 65234.397669955
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluated with elapsed time 133.443450812003
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152346162586936, &#39;ERDE_50&#39;: 0.15947666392815127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 133.443450812003}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluating after getting time 65593.80974665
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 833  215]]
Evaluated with elapsed time 75.00786287199298
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152346162586936, &#39;ERDE_50&#39;: 0.15947666392815127, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 75.00786287199298}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluating after getting time 65878.902983312
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluated with elapsed time 110.50054520899721
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.25383215623376204, &#39;ERDE_50&#39;: 0.14525314510224885, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25104606155464504, &#39;ERDE_50&#39;: 0.16362356018309013, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933741372741947, &#39;ERDE_50&#39;: 0.18315644752946808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3868196501364656}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluating after getting time 65996.443777675
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluated with elapsed time 4.3197599980048835
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.581177294254303
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5136 - tp: 1.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1047.0000 - accuracy: 0.7748 - precision: 1.0000 - recall: 9.5420e-04 - f1_metric: 0.0017
Test Score: 0.5136207342147827
Test Accuracy: 1.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       1.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.77      0.68      4650

[[3602    0]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24585703871594175, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.018305138304333494}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7964 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7964164614677429
Test Accuracy: 8.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7338 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0175
Test Score: 0.733765184879303
Test Accuracy: 15.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470169125117684, &#39;ERDE_50&#39;: 0.22811282687546647, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 15ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.12796847699792
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.12796847699792} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluating after getting time 69157.812859762
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3558   44]
 [ 815  233]]
Evaluated with elapsed time 189.801190091006
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.25383215623376204, &#39;ERDE_50&#39;: 0.14525314510224885, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.25104606155464504, &#39;ERDE_50&#39;: 0.16362356018309013, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933741372741947, &#39;ERDE_50&#39;: 0.18315644752946808, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3868196501364656}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluating after getting time 69355.881302648
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.72      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.77      0.60      0.61      4650
weighted avg       0.79      0.81      0.76      4650

[[3514   88]
 [ 818  230]]
Evaluated with elapsed time 2.9999745179957245
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 14s 29ms/step - loss: 0.9885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9884927272796631
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.5182 - tp: 68.0000 - fp: 22.0000 - tn: 3580.0000 - fn: 980.0000 - accuracy: 0.7845 - precision: 0.7556 - recall: 0.0649 - f1_metric: 0.0606
Test Score: 0.518192708492279
Test Accuracy: 68.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.76      0.06      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.53      0.50      4650
weighted avg       0.78      0.78      0.71      4650

[[3580   22]
 [ 980   68]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3529411764705882, &#39;ERDE_5&#39;: 0.25043131740473284, &#39;ERDE_50&#39;: 0.1937751845704177, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.33918344505088527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 8s 27ms/step - loss: 0.4622 - tp: 228.0000 - fp: 76.0000 - tn: 3526.0000 - fn: 820.0000 - accuracy: 0.8073 - precision: 0.7500 - recall: 0.2176 - f1_metric: 0.1686
Test Score: 0.4621577858924866
Test Accuracy: 228.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.75      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.78      0.60      0.61      4650
weighted avg       0.80      0.81      0.76      4650

[[3526   76]
 [ 820  228]]
Finished training and evaluation
{&#39;precision&#39;: 0.6756756756756757, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5617977528089887, &#39;ERDE_5&#39;: 0.2596397468528691, &#39;ERDE_50&#39;: 0.14160924165451463, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5398987421221957}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 23ms/step - loss: 0.9268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9268305897712708
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 16ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.1748919239908
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4832214765100672, &#39;ERDE_5&#39;: 0.25096575393293596, &#39;ERDE_50&#39;: 0.16598762637694428, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.46438538785490346}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.24931533100887465, &#39;ERDE_50&#39;: 0.19024864611102962, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3544912216678364}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.296875, &#39;ERDE_5&#39;: 0.24875936978094465, &#39;ERDE_50&#39;: 0.20385180714138237, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2829913846701486}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6935483870967742, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5180722891566264, &#39;ERDE_5&#39;: 0.256729461728593, &#39;ERDE_50&#39;: 0.15525152434764744, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4978777074943717}
Writing results to CSV file
{&#39;precision&#39;: 0.7058823529411765, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4645161290322581, &#39;ERDE_5&#39;: 0.2545306084520961, &#39;ERDE_50&#39;: 0.16947504317355233, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4446006031756607}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.251080933293809, &#39;ERDE_50&#39;: 0.19199235450933402, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.1748919239908} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 820  228]]
Evaluating after getting time 72850.757810061
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 820  228]]
Evaluated with elapsed time 109.03300833499816
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2532580785714253, &#39;ERDE_50&#39;: 0.14940004135718793, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5252778817765262}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.25162596276236, &#39;ERDE_50&#39;: 0.16420479631585944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8285714285714286, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4172661870503597, &#39;ERDE_5&#39;: 0.2493379626482824, &#39;ERDE_50&#39;: 0.1807923813356165, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3977523740611858}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluating after getting time 72968.578639267
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluated with elapsed time 3.4304956830019364
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5841 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5841134190559387
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5165 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5164770483970642
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7063 - tp: 8.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1040.0000 - accuracy: 0.7757 - precision: 0.7273 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7063043117523193
Test Accuracy: 8.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.73      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.75      0.50      0.44      4650
weighted avg       0.76      0.78      0.68      4650

[[3599    3]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.6213 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6213265061378479
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.6667 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0022
Test Score: 0.666702389717102
Test Accuracy: 4.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827288292222, &#39;ERDE_50&#39;: 0.2417159879058175, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054532574873495165, &#39;speed&#39;: 0.9454674251265048, &#39;latency_weighted_f1&#39;: 0.03534457664024317}
Evaluating for elapsed time
146/146 [==============================] - 5s 16ms/step - loss: 0.6667 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0022
Test Score: 0.666702389717102
Test Accuracy: 4.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Evaluated with elapsed time 67.29540502700547
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.29540502700547} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 820  228]]
Evaluating after getting time 75765.655782618
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 820  228]]
Evaluated with elapsed time 126.6127309279982
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2532580785714253, &#39;ERDE_50&#39;: 0.14940004135718793, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5252778817765262}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.25162596276236, &#39;ERDE_50&#39;: 0.16420479631585944, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8285714285714286, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4172661870503597, &#39;ERDE_5&#39;: 0.2493379626482824, &#39;ERDE_50&#39;: 0.1807923813356165, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3977523740611858}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluating after getting time 75900.620787843
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.20      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3513   89]
 [ 834  214]]
Evaluated with elapsed time 4.251412079000147
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.9737 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9736941456794739
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.7244 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7244048118591309
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.4563 - tp: 245.0000 - fp: 121.0000 - tn: 3481.0000 - fn: 803.0000 - accuracy: 0.8013 - precision: 0.6694 - recall: 0.2338 - f1_metric: 0.1768
Test Score: 0.4562739431858063
Test Accuracy: 245.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.67      0.23      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.60      0.61      4650
weighted avg       0.78      0.80      0.76      4650

[[3481  121]
 [ 803  245]]
Finished training and evaluation
{&#39;precision&#39;: 0.5903614457831325, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5240641711229947, &#39;ERDE_5&#39;: 0.26543865041857767, &#39;ERDE_50&#39;: 0.14978566917604483, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5036360244694965}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.9853 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9852736592292786
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 18ms/step - loss: 1.0286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0285693407058716
Test Accuracy: 0.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 17ms/step - loss: 1.0286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0285693407058716
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 72.03859538301185
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515521897504501, &#39;ERDE_50&#39;: 0.16420479631585871, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4709633265717591}
Writing results to CSV file
{&#39;precision&#39;: 0.7878787878787878, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.3795620437956204, &#39;ERDE_5&#39;: 0.24989932779471122, &#39;ERDE_50&#39;: 0.18846581604994578, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36328881403039587}
Writing results to CSV file
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2698412698412698, &#39;ERDE_5&#39;: 0.24876117417249288, &#39;ERDE_50&#39;: 0.20857993952908868, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.25722191020979257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6818181818181818, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5294117647058822, &#39;ERDE_5&#39;: 0.25789977313091667, &#39;ERDE_50&#39;: 0.15168586422547592, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5087751675763279}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.2539557177972436, &#39;ERDE_50&#39;: 0.17598600562234623, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41834659404773805}
Writing results to CSV file
{&#39;precision&#39;: 0.7586206896551724, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3308270676691729, &#39;ERDE_5&#39;: 0.24991917730737118, &#39;ERDE_50&#39;: 0.1979220808253576, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.315355654622532}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 72.03859538301185} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluating after getting time 78610.157797255
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluated with elapsed time 78.84243345700088
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152352565608016, &#39;ERDE_50&#39;: 0.15947666392815102, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.373134328358209, &#39;ERDE_5&#39;: 0.24875639977292358, &#39;ERDE_50&#39;: 0.18966740997826168, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3556843797896605}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 78.84243345700088}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluating after getting time 78845.092915002
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluated with elapsed time 87.55859514400072
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152352565608016, &#39;ERDE_50&#39;: 0.15947666392815102, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.373134328358209, &#39;ERDE_5&#39;: 0.24875639977292358, &#39;ERDE_50&#39;: 0.18966740997826168, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3556843797896605}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 87.55859514400072}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluating after getting time 79104.585375283
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluated with elapsed time 61.94323547699605
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152352565608016, &#39;ERDE_50&#39;: 0.15947666392815102, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.373134328358209, &#39;ERDE_5&#39;: 0.24875639977292358, &#39;ERDE_50&#39;: 0.18966740997826168, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3556843797896605}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 61.94323547699605}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluating after getting time 79272.458944275
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3570   32]
 [ 831  217]]
Evaluated with elapsed time 63.815272965002805
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7959183673469388, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.5098039215686274, &#39;ERDE_5&#39;: 0.25152352565608016, &#39;ERDE_50&#39;: 0.15947666392815102, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48993164285127877}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.373134328358209, &#39;ERDE_5&#39;: 0.24875639977292358, &#39;ERDE_50&#39;: 0.18966740997826168, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3556843797896605}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 63.815272965002805}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.19      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 845  203]]
Evaluating after getting time 79584.177978629
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.19      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 845  203]]
Evaluated with elapsed time 125.50229852899793
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25325679837577814, &#39;ERDE_50&#39;: 0.14230784277562714, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5508283995846694}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24815199309513913, &#39;ERDE_50&#39;: 0.17017364429466714, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.44437350482017013}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643507605565412, &#39;ERDE_50&#39;: 0.1897065316410439, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.3510736437469185}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluating after getting time 79717.681312037
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluated with elapsed time 2.6918070709944004
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 24ms/step - loss: 0.5444 - tp: 1.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1047.0000 - accuracy: 0.7742 - precision: 0.2500 - recall: 9.5420e-04 - f1_metric: 0.0011
Test Score: 0.5444046258926392
Test Accuracy: 1.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.25      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.51      0.50      0.44      4650
weighted avg       0.66      0.77      0.68      4650

[[3599    3]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644382858057864, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.017912139559646656}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 19ms/step - loss: 0.5791 - tp: 2.0000 - fp: 9.0000 - tn: 3593.0000 - fn: 1046.0000 - accuracy: 0.7731 - precision: 0.1818 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.5791459679603577
Test Accuracy: 2.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.18      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.48      0.50      0.44      4650
weighted avg       0.64      0.77      0.68      4650

[[3593    9]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827475083865, &#39;ERDE_50&#39;: 0.24171598790581905, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06034880562609424, &#39;speed&#39;: 0.9396511943739058, &#39;latency_weighted_f1&#39;: 0.03512714745323012}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.5551 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.555117130279541
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 6s 17ms/step - loss: 0.7023 - tp: 11.0000 - fp: 6.0000 - tn: 3596.0000 - fn: 1037.0000 - accuracy: 0.7757 - precision: 0.6471 - recall: 0.0105 - f1_metric: 0.0093
Test Score: 0.7023020386695862
Test Accuracy: 11.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.65      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.71      0.50      0.45      4650
weighted avg       0.75      0.78      0.68      4650

[[3596    6]
 [1037   11]]
Finished training and evaluation
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07207207207207209, &#39;ERDE_5&#39;: 0.24759848528217568, &#39;ERDE_50&#39;: 0.23815032778364628, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06856145913490026}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330492854118347
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 15ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330492854118347
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 64.50757578000776
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.5714285714285714, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07207207207207209, &#39;ERDE_5&#39;: 0.24759848528217568, &#39;ERDE_50&#39;: 0.23815032778364628, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06856145913490026}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702240985105592, &#39;ERDE_50&#39;: 0.24229722403858514, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.03537704511739719}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24644381405534319, &#39;ERDE_50&#39;: 0.2417159879058174, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.035271481512620426}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586073037542694, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.018230977114345875}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586286963552104, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.01786058789074134}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 64.50757578000776} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.19      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 845  203]]
Evaluating after getting time 83149.563549976
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.19      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 845  203]]
Evaluated with elapsed time 101.41815685400798
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7833333333333333, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.573170731707317, &#39;ERDE_5&#39;: 0.25325679837577814, &#39;ERDE_50&#39;: 0.14230784277562714, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5508283995846694}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24815199309513913, &#39;ERDE_50&#39;: 0.17017364429466714, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.44437350482017013}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643507605565412, &#39;ERDE_50&#39;: 0.1897065316410439, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.3510736437469185}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluating after getting time 83257.868332332
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluated with elapsed time 5.58332951599732
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.0071 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0070804357528687
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7823413610458374
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.9924 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9924025535583496
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.9036 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9036358594894409
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0371 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370620489120483
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 19ms/step - loss: 1.0371 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370620489120483
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 67.5416719840141
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.5416719840141} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3581   21]
 [ 855  193]]
Evaluating after getting time 85556.042545967
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3581   21]
 [ 855  193]]
Evaluated with elapsed time 115.41707256399968
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25269480779428716, &#39;ERDE_50&#39;: 0.1393625404490066, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5602690527823366}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.4347826086956522, &#39;ERDE_5&#39;: 0.24815099696411347, &#39;ERDE_50&#39;: 0.17726584287622718, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41614186891441673}
Writing results to CSV file
{&#39;precision&#39;: 0.9565217391304348, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3464566929133859, &#39;ERDE_5&#39;: 0.2464346222270298, &#39;ERDE_50&#39;: 0.19443466402875068, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.32958036030666443}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluating after getting time 85677.682894939
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluated with elapsed time 2.9444611039943993
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701792107953613, &#39;ERDE_50&#39;: 0.22574876068161118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5897975564002991
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5358 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.535826563835144
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.6308 - tp: 1.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1047.0000 - accuracy: 0.7744 - precision: 0.3333 - recall: 9.5420e-04 - f1_metric: 0.0015
Test Score: 0.630774974822998
Test Accuracy: 1.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.33      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.55      0.50      0.44      4650
weighted avg       0.68      0.77      0.68      4650

[[3600    2]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.2464382748487095, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.01813244832033035}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7462 - tp: 3.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1045.0000 - accuracy: 0.7751 - precision: 0.7500 - recall: 0.0029 - f1_metric: 0.0019
Test Score: 0.7461909055709839
Test Accuracy: 3.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.75      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.76      0.50      0.44      4650
weighted avg       0.77      0.78      0.68      4650

[[3601    1]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643827402766552, &#39;ERDE_50&#39;: 0.23935192171196581, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.05144640698863761}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392681360244751
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 15ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392681360244751
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.80405632298789
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701792107953613, &#39;ERDE_50&#39;: 0.22574876068161118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.80405632298789} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3581   21]
 [ 855  193]]
Evaluating after getting time 88759.21097362
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.18      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3581   21]
 [ 855  193]]
Evaluated with elapsed time 130.32914382401214
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5853658536585367, &#39;ERDE_5&#39;: 0.25269480779428716, &#39;ERDE_50&#39;: 0.1393625404490066, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5602690527823366}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.4347826086956522, &#39;ERDE_5&#39;: 0.24815099696411347, &#39;ERDE_50&#39;: 0.17726584287622718, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41614186891441673}
Writing results to CSV file
{&#39;precision&#39;: 0.9565217391304348, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3464566929133859, &#39;ERDE_5&#39;: 0.2464346222270298, &#39;ERDE_50&#39;: 0.19443466402875068, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.32958036030666443}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluating after getting time 88897.998528255
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluated with elapsed time 3.035081554990029
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701792107953613, &#39;ERDE_50&#39;: 0.22574876068161118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.9753 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9753488302230835
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 30ms/step - loss: 0.8128 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8128407001495361
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.9576 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9575570225715637
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 24ms/step - loss: 0.8776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8776159286499023
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 30ms/step - loss: 1.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1297900676727295
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 15s 25ms/step - loss: 1.1298 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1297900676727295
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 83.79154342900438
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470200748648657, &#39;ERDE_50&#39;: 0.2281128268754646, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24701792107953613, &#39;ERDE_50&#39;: 0.22574876068161118, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.14798413447674627}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.1090909090909091, &#39;ERDE_5&#39;: 0.24586098673316553, &#39;ERDE_50&#39;: 0.23167848699763657, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648786953740359, &#39;speed&#39;: 0.9435121304625964, &#39;latency_weighted_f1&#39;: 0.10292859605046507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 83.79154342900438} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 91436.614298446
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 113.26008192099107
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 91556.441303916
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.767669685999863
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533
Test Score: 0.6330819725990295
Test Accuracy: 719.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.67      0.76      3602
           1       0.37      0.69      0.48      1048

    accuracy                           0.67      4650
   macro avg       0.63      0.68      0.62      4650
weighted avg       0.77      0.67      0.70      4650

[[2400 1202]
 [ 329  719]]
Finished training and evaluation
{&#39;precision&#39;: 0.32167832167832167, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4717948717948718, &#39;ERDE_5&#39;: 0.3581736549592459, &#39;ERDE_50&#39;: 0.1411286040831851, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4534041949227219}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.8161 - tp: 470.0000 - fp: 551.0000 - tn: 3051.0000 - fn: 578.0000 - accuracy: 0.7572 - precision: 0.4603 - recall: 0.4485 - f1_metric: 0.2777
Test Score: 0.8160936832427979
Test Accuracy: 470.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.85      0.84      3602
           1       0.46      0.45      0.45      1048

    accuracy                           0.76      4650
   macro avg       0.65      0.65      0.65      4650
weighted avg       0.75      0.76      0.76      4650

[[3051  551]
 [ 578  470]]
Finished training and evaluation
{&#39;precision&#39;: 0.4782608695652174, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5454545454545455, &#39;ERDE_5&#39;: 0.2873925599749865, &#39;ERDE_50&#39;: 0.13168351692570837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5241925968968228}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00013: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5845 - tp: 453.0000 - fp: 470.0000 - tn: 3132.0000 - fn: 595.0000 - accuracy: 0.7710 - precision: 0.4908 - recall: 0.4323 - f1_metric: 0.2743
Test Score: 0.584526777267456
Test Accuracy: 453.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.87      0.85      3602
           1       0.49      0.43      0.46      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.65      0.66      4650
weighted avg       0.76      0.77      0.77      4650

[[3132  470]
 [ 595  453]]
Finished training and evaluation
{&#39;precision&#39;: 0.49230769230769234, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5470085470085471, &#39;ERDE_5&#39;: 0.2839230065046203, &#39;ERDE_50&#39;: 0.13292423251680965, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5256860230988081}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 6s 17ms/step - loss: 16.8639 - tp: 817.0000 - fp: 1505.0000 - tn: 2097.0000 - fn: 231.0000 - accuracy: 0.6267 - precision: 0.3519 - recall: 0.7796 - f1_metric: 0.3705
Test Score: 16.863901138305664
Test Accuracy: 817.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.58      0.71      3602
           1       0.35      0.78      0.48      1048

    accuracy                           0.63      4650
   macro avg       0.63      0.68      0.60      4650
weighted avg       0.78      0.63      0.66      4650

[[2097 1505]
 [ 231  817]]
Finished training and evaluation
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4842105263157894, &#39;ERDE_5&#39;: 0.3523310172885635, &#39;ERDE_50&#39;: 0.1353162427555075, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4653358842627935}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Finished training and evaluation
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Evaluating for elapsed time
146/146 [==============================] - 9s 24ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Evaluated with elapsed time 76.05684691198985
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Writing results to CSV file
{&#39;precision&#39;: 0.4358974358974359, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5685618729096991, &#39;ERDE_5&#39;: 0.3096505594048397, &#39;ERDE_50&#39;: 0.10885323228766941, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5441855208880834}
Writing results to CSV file
{&#39;precision&#39;: 0.4319526627218935, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.5347985347985348, &#39;ERDE_5&#39;: 0.30161269160171, &#39;ERDE_50&#39;: 0.12908472075516572, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5097882202347925}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 76.05684691198985} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 94846.375580623
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 220.77280915099254
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 95075.195575744
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.786418532996322
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 8s 27ms/step - loss: 0.7407 - tp: 666.0000 - fp: 846.0000 - tn: 2756.0000 - fn: 382.0000 - accuracy: 0.7359 - precision: 0.4405 - recall: 0.6355 - f1_metric: 0.3592
Test Score: 0.7407026886940002
Test Accuracy: 666.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.77      0.82      3602
           1       0.44      0.64      0.52      1048

    accuracy                           0.74      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.74      0.75      4650

[[2756  846]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 7s 26ms/step - loss: 1.6687 - tp: 416.0000 - fp: 550.0000 - tn: 3052.0000 - fn: 632.0000 - accuracy: 0.7458 - precision: 0.4306 - recall: 0.3969 - f1_metric: 0.2460
Test Score: 1.6686714887619019
Test Accuracy: 416.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      3602
           1       0.43      0.40      0.41      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.62      0.63      4650
weighted avg       0.74      0.75      0.74      4650

[[3052  550]
 [ 632  416]]
Finished training and evaluation
{&#39;precision&#39;: 0.46923076923076923, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5213675213675213, &#39;ERDE_5&#39;: 0.285674670592364, &#39;ERDE_50&#39;: 0.1417601394966727, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5010444907660513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.6868 - tp: 676.0000 - fp: 937.0000 - tn: 2665.0000 - fn: 372.0000 - accuracy: 0.7185 - precision: 0.4191 - recall: 0.6450 - f1_metric: 0.3559
Test Score: 0.6867886185646057
Test Accuracy: 676.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.74      0.80      3602
           1       0.42      0.65      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2665  937]
 [ 372  676]]
Finished training and evaluation
{&#39;precision&#39;: 0.3853211009174312, &#39;recall&#39;: 0.8076923076923077, &#39;F1&#39;: 0.5217391304347826, &#39;ERDE_5&#39;: 0.3233296196857131, &#39;ERDE_50&#39;: 0.1251669656679475, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5014016144230479}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 7s 24ms/step - loss: 2.0980 - tp: 784.0000 - fp: 1296.0000 - tn: 2306.0000 - fn: 264.0000 - accuracy: 0.6645 - precision: 0.3769 - recall: 0.7481 - f1_metric: 0.3727
Test Score: 2.097973585128784
Test Accuracy: 784.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.64      0.75      3602
           1       0.38      0.75      0.50      1048

    accuracy                           0.66      4650
   macro avg       0.64      0.69      0.62      4650
weighted avg       0.78      0.66      0.69      4650

[[2306 1296]
 [ 264  784]]
Finished training and evaluation
{&#39;precision&#39;: 0.3590733590733591, &#39;recall&#39;: 0.8942307692307693, &#39;F1&#39;: 0.512396694214876, &#39;ERDE_5&#39;: 0.3418688719904829, &#39;ERDE_50&#39;: 0.12248992617183534, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4924233486000456}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00016: early stopping
Evaluating
146/146 [==============================] - 7s 25ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Finished training and evaluation
{&#39;precision&#39;: 0.4557823129251701, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5338645418326693, &#39;ERDE_5&#39;: 0.29202788331610346, &#39;ERDE_50&#39;: 0.13396933979399697, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5130543743863989}
Evaluating for elapsed time
146/146 [==============================] - 8s 20ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 5s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Evaluated with elapsed time 76.45131951000076
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Writing results to CSV file
{&#39;precision&#39;: 0.4426229508196721, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5644599303135889, &#39;ERDE_5&#39;: 0.3050107563539052, &#39;ERDE_50&#39;: 0.11365960800094416, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.540259443754396}
Writing results to CSV file
{&#39;precision&#39;: 0.42592592592592593, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.518796992481203, &#39;ERDE_5&#39;: 0.2998734202268961, &#39;ERDE_50&#39;: 0.13679727713227546, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49453500383987986}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 76.45131951000076} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 98909.981462047
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 180.68255701800808
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 99096.843206675
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.7824090650101425
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 7s 25ms/step - loss: 0.6331 - tp: 719.0000 - fp: 1202.0000 - tn: 2400.0000 - fn: 329.0000 - accuracy: 0.6708 - precision: 0.3743 - recall: 0.6861 - f1_metric: 0.3533
Test Score: 0.6330819725990295
Test Accuracy: 719.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.67      0.76      3602
           1       0.37      0.69      0.48      1048

    accuracy                           0.67      4650
   macro avg       0.63      0.68      0.62      4650
weighted avg       0.77      0.67      0.70      4650

[[2400 1202]
 [ 329  719]]
Finished training and evaluation
{&#39;precision&#39;: 0.32167832167832167, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4717948717948718, &#39;ERDE_5&#39;: 0.3581736549592459, &#39;ERDE_50&#39;: 0.1411286040831851, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4534041949227219}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8161 - tp: 470.0000 - fp: 551.0000 - tn: 3051.0000 - fn: 578.0000 - accuracy: 0.7572 - precision: 0.4603 - recall: 0.4485 - f1_metric: 0.2777
Test Score: 0.8160936832427979
Test Accuracy: 470.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.85      0.84      3602
           1       0.46      0.45      0.45      1048

    accuracy                           0.76      4650
   macro avg       0.65      0.65      0.65      4650
weighted avg       0.75      0.76      0.76      4650

[[3051  551]
 [ 578  470]]
Finished training and evaluation
{&#39;precision&#39;: 0.4782608695652174, &#39;recall&#39;: 0.6346153846153846, &#39;F1&#39;: 0.5454545454545455, &#39;ERDE_5&#39;: 0.2873925599749865, &#39;ERDE_50&#39;: 0.13168351692570837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5241925968968228}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00013: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5845 - tp: 453.0000 - fp: 470.0000 - tn: 3132.0000 - fn: 595.0000 - accuracy: 0.7710 - precision: 0.4908 - recall: 0.4323 - f1_metric: 0.2743
Test Score: 0.584526777267456
Test Accuracy: 453.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.87      0.85      3602
           1       0.49      0.43      0.46      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.65      0.66      4650
weighted avg       0.76      0.77      0.77      4650

[[3132  470]
 [ 595  453]]
Finished training and evaluation
{&#39;precision&#39;: 0.49230769230769234, &#39;recall&#39;: 0.6153846153846154, &#39;F1&#39;: 0.5470085470085471, &#39;ERDE_5&#39;: 0.2839230065046203, &#39;ERDE_50&#39;: 0.13292423251680965, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5256860230988081}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 16.8639 - tp: 817.0000 - fp: 1505.0000 - tn: 2097.0000 - fn: 231.0000 - accuracy: 0.6267 - precision: 0.3519 - recall: 0.7796 - f1_metric: 0.3705
Test Score: 16.863901138305664
Test Accuracy: 817.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.58      0.71      3602
           1       0.35      0.78      0.48      1048

    accuracy                           0.63      4650
   macro avg       0.63      0.68      0.60      4650
weighted avg       0.78      0.63      0.66      4650

[[2097 1505]
 [ 231  817]]
Finished training and evaluation
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.8846153846153846, &#39;F1&#39;: 0.4842105263157894, &#39;ERDE_5&#39;: 0.3523310172885635, &#39;ERDE_50&#39;: 0.1353162427555075, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4653358842627935}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 5s 18ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Finished training and evaluation
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Evaluating for elapsed time
146/146 [==============================] - 8s 16ms/step - loss: 0.8154 - tp: 691.0000 - fp: 904.0000 - tn: 2698.0000 - fn: 357.0000 - accuracy: 0.7288 - precision: 0.4332 - recall: 0.6594 - f1_metric: 0.3706
Test Score: 0.8153931498527527
Test Accuracy: 691.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.43      0.66      0.52      1048

    accuracy                           0.73      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.73      0.75      4650

[[2698  904]
 [ 357  691]]
Evaluated with elapsed time 72.9402564179909
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.40930232558139534, &#39;recall&#39;: 0.8461538461538461, &#39;F1&#39;: 0.5517241379310345, &#39;ERDE_5&#39;: 0.31924666394639944, &#39;ERDE_50&#39;: 0.11164204796315995, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5302177991600047}
Writing results to CSV file
{&#39;precision&#39;: 0.4358974358974359, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5685618729096991, &#39;ERDE_5&#39;: 0.3096505594048397, &#39;ERDE_50&#39;: 0.10885323228766941, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5441855208880834}
Writing results to CSV file
{&#39;precision&#39;: 0.4319526627218935, &#39;recall&#39;: 0.7019230769230769, &#39;F1&#39;: 0.5347985347985348, &#39;ERDE_5&#39;: 0.30161269160171, &#39;ERDE_50&#39;: 0.12908472075516572, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.5097882202347925}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 72.9402564179909} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 102259.653163793
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 107.0885406640009
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluating after getting time 102374.889269015
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 3.888587098001153
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7407 - tp: 666.0000 - fp: 846.0000 - tn: 2756.0000 - fn: 382.0000 - accuracy: 0.7359 - precision: 0.4405 - recall: 0.6355 - f1_metric: 0.3592
Test Score: 0.7407026886940002
Test Accuracy: 666.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.77      0.82      3602
           1       0.44      0.64      0.52      1048

    accuracy                           0.74      4650
   macro avg       0.66      0.70      0.67      4650
weighted avg       0.78      0.74      0.75      4650

[[2756  846]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 1.6687 - tp: 416.0000 - fp: 550.0000 - tn: 3052.0000 - fn: 632.0000 - accuracy: 0.7458 - precision: 0.4306 - recall: 0.3969 - f1_metric: 0.2460
Test Score: 1.6686714887619019
Test Accuracy: 416.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.83      0.85      0.84      3602
           1       0.43      0.40      0.41      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.62      0.63      4650
weighted avg       0.74      0.75      0.74      4650

[[3052  550]
 [ 632  416]]
Finished training and evaluation
{&#39;precision&#39;: 0.46923076923076923, &#39;recall&#39;: 0.5865384615384616, &#39;F1&#39;: 0.5213675213675213, &#39;ERDE_5&#39;: 0.285674670592364, &#39;ERDE_50&#39;: 0.1417601394966727, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5010444907660513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.6868 - tp: 676.0000 - fp: 937.0000 - tn: 2665.0000 - fn: 372.0000 - accuracy: 0.7185 - precision: 0.4191 - recall: 0.6450 - f1_metric: 0.3559
Test Score: 0.6867886185646057
Test Accuracy: 676.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.74      0.80      3602
           1       0.42      0.65      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2665  937]
 [ 372  676]]
Finished training and evaluation
{&#39;precision&#39;: 0.3853211009174312, &#39;recall&#39;: 0.8076923076923077, &#39;F1&#39;: 0.5217391304347826, &#39;ERDE_5&#39;: 0.3233296196857131, &#39;ERDE_50&#39;: 0.1251669656679475, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5014016144230479}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 2.0980 - tp: 784.0000 - fp: 1296.0000 - tn: 2306.0000 - fn: 264.0000 - accuracy: 0.6645 - precision: 0.3769 - recall: 0.7481 - f1_metric: 0.3727
Test Score: 2.097973585128784
Test Accuracy: 784.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.90      0.64      0.75      3602
           1       0.38      0.75      0.50      1048

    accuracy                           0.66      4650
   macro avg       0.64      0.69      0.62      4650
weighted avg       0.78      0.66      0.69      4650

[[2306 1296]
 [ 264  784]]
Finished training and evaluation
{&#39;precision&#39;: 0.3590733590733591, &#39;recall&#39;: 0.8942307692307693, &#39;F1&#39;: 0.512396694214876, &#39;ERDE_5&#39;: 0.3418688719904829, &#39;ERDE_50&#39;: 0.12248992617183534, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4924233486000456}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00016: early stopping
Evaluating
146/146 [==============================] - 6s 21ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Finished training and evaluation
{&#39;precision&#39;: 0.4557823129251701, &#39;recall&#39;: 0.6442307692307693, &#39;F1&#39;: 0.5338645418326693, &#39;ERDE_5&#39;: 0.29202788331610346, &#39;ERDE_50&#39;: 0.13396933979399697, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5130543743863989}
Evaluating for elapsed time
146/146 [==============================] - 4s 15ms/step - loss: 0.8389 - tp: 466.0000 - fp: 618.0000 - tn: 2984.0000 - fn: 582.0000 - accuracy: 0.7419 - precision: 0.4299 - recall: 0.4447 - f1_metric: 0.2720
Test Score: 0.8388985395431519
Test Accuracy: 466.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.84      0.83      0.83      3602
           1       0.43      0.44      0.44      1048

    accuracy                           0.74      4650
   macro avg       0.63      0.64      0.63      4650
weighted avg       0.75      0.74      0.74      4650

[[2984  618]
 [ 582  466]]
Evaluated with elapsed time 67.09436918399297
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.3972602739726027, &#39;recall&#39;: 0.8365384615384616, &#39;F1&#39;: 0.5386996904024768, &#39;ERDE_5&#39;: 0.3221717755204272, &#39;ERDE_50&#39;: 0.11691229482085316, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.517701047709246}
Writing results to CSV file
{&#39;precision&#39;: 0.4426229508196721, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5644599303135889, &#39;ERDE_5&#39;: 0.3050107563539052, &#39;ERDE_50&#39;: 0.11365960800094416, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.540259443754396}
Writing results to CSV file
{&#39;precision&#39;: 0.42592592592592593, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.518796992481203, &#39;ERDE_5&#39;: 0.2998734202268961, &#39;ERDE_50&#39;: 0.13679727713227546, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.49453500383987986}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.09436918399297} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluating after getting time 106132.434408619
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluated with elapsed time 147.96940502899815
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544097007070446, &#39;ERDE_50&#39;: 0.14583438123501657, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510432223029756, &#39;ERDE_50&#39;: 0.1612594939892367, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933716176378123, &#39;ERDE_50&#39;: 0.1855205137233209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluating after getting time 106287.105602645
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluated with elapsed time 2.859213179006474
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.5812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.581177294254303
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.5136 - tp: 1.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1047.0000 - accuracy: 0.7748 - precision: 1.0000 - recall: 9.5420e-04 - f1_metric: 0.0017
Test Score: 0.5136207342147827
Test Accuracy: 1.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       1.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.77      0.68      4650

[[3602    0]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24585703871594175, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.018305138304333494}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7964 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7964164614677429
Test Accuracy: 8.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.7338 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0175
Test Score: 0.733765184879303
Test Accuracy: 15.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470169125117684, &#39;ERDE_50&#39;: 0.22811282687546647, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
146/146 [==============================] - 5s 16ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 64.31286279798951
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 64.31286279798951} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluating after getting time 109517.652944786
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluated with elapsed time 114.16274811699986
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544097007070446, &#39;ERDE_50&#39;: 0.14583438123501657, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510432223029756, &#39;ERDE_50&#39;: 0.1612594939892367, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933716176378123, &#39;ERDE_50&#39;: 0.1855205137233209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluating after getting time 109640.518438159
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluated with elapsed time 5.310575298004551
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.9885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9884927272796631
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5182 - tp: 68.0000 - fp: 22.0000 - tn: 3580.0000 - fn: 980.0000 - accuracy: 0.7845 - precision: 0.7556 - recall: 0.0649 - f1_metric: 0.0606
Test Score: 0.518192708492279
Test Accuracy: 68.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.76      0.06      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.53      0.50      4650
weighted avg       0.78      0.78      0.71      4650

[[3580   22]
 [ 980   68]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3529411764705882, &#39;ERDE_5&#39;: 0.25043131740473284, &#39;ERDE_50&#39;: 0.1937751845704177, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.33918344505088527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.4622 - tp: 228.0000 - fp: 76.0000 - tn: 3526.0000 - fn: 820.0000 - accuracy: 0.8073 - precision: 0.7500 - recall: 0.2176 - f1_metric: 0.1686
Test Score: 0.4621577858924866
Test Accuracy: 228.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.75      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.78      0.60      0.61      4650
weighted avg       0.80      0.81      0.76      4650

[[3526   76]
 [ 820  228]]
Finished training and evaluation
{&#39;precision&#39;: 0.6756756756756757, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5617977528089887, &#39;ERDE_5&#39;: 0.2596397468528691, &#39;ERDE_50&#39;: 0.14160924165451463, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5398987421221957}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.9268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9268305897712708
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 7s 20ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.68524137200438
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.68524137200438} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3565   37]
 [ 826  222]]
Evaluating after getting time 112829.619374935
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3565   37]
 [ 826  222]]
Evaluated with elapsed time 211.58308049499465
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7678571428571429, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5375, &#39;ERDE_5&#39;: 0.25326033433676526, &#39;ERDE_50&#39;: 0.15176410755104142, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5165481215254107}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516264672170899, &#39;ERDE_50&#39;: 0.16420479631585952, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24875664611576662, &#39;ERDE_50&#39;: 0.1802111452028487, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4006346376413393}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3520   82]
 [ 845  203]]
Evaluating after getting time 113048.800029177
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3520   82]
 [ 845  203]]
Evaluated with elapsed time 4.501814290997572
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5121951219512195, &#39;ERDE_5&#39;: 0.25616485692083396, &#39;ERDE_50&#39;: 0.15703435440873398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49222963367140676}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.6115 - tp: 3.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1045.0000 - accuracy: 0.7738 - precision: 0.3000 - recall: 0.0029 - f1_metric: 0.0036
Test Score: 0.6114905476570129
Test Accuracy: 3.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.30      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.54      0.50      0.44      4650
weighted avg       0.67      0.77      0.68      4650

[[3595    7]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24644411760456383, &#39;ERDE_50&#39;: 0.2417159879058177, &#39;median_latency_tps&#39;: 19.5, &#39;median_penalty_tps&#39;: 0.07202479246451088, &#39;speed&#39;: 0.9279752075354891, &#39;latency_weighted_f1&#39;: 0.03469066196394351}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.6934 - tp: 2.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1046.0000 - accuracy: 0.7725 - precision: 0.1429 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.6933532953262329
Test Accuracy: 2.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.14      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.46      0.50      0.44      4650
weighted avg       0.63      0.77      0.68      4650

[[3590   12]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24701951071543668, &#39;ERDE_50&#39;: 0.24229722403858575, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05841121951671113, &#39;speed&#39;: 0.9415887804832889, &#39;latency_weighted_f1&#39;: 0.034873658536418106}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.6463 - tp: 10.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1038.0000 - accuracy: 0.7761 - precision: 0.7692 - recall: 0.0095 - f1_metric: 0.0068
Test Score: 0.6463022828102112
Test Accuracy: 10.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.77      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.50      0.45      4650
weighted avg       0.77      0.78      0.68      4650

[[3599    3]
 [1038   10]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.5475 - tp: 2.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1046.0000 - accuracy: 0.7744 - precision: 0.4000 - recall: 0.0019 - f1_metric: 0.0016
Test Score: 0.5475383400917053
Test Accuracy: 2.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.40      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.59      0.50      0.44      4650
weighted avg       0.69      0.77      0.68      4650

[[3599    3]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644411957035114, &#39;ERDE_50&#39;: 0.24408005409967107, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.017472364637650513}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 8s 30ms/step - loss: 0.6962 - tp: 3.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1045.0000 - accuracy: 0.7753 - precision: 1.0000 - recall: 0.0029 - f1_metric: 0.0026
Test Score: 0.6962397694587708
Test Accuracy: 3.0
146/146 [==============================] - 4s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       1.00      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.78      0.68      4650

[[3602    0]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03773584905660378, &#39;ERDE_5&#39;: 0.24586277487140254, &#39;ERDE_50&#39;: 0.24113475177304972, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231535911708763, &#39;speed&#39;: 0.9376846408829124, &#39;latency_weighted_f1&#39;: 0.0353843260710533}
Evaluating for elapsed time
146/146 [==============================] - 10s 27ms/step - loss: 0.6962 - tp: 3.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1045.0000 - accuracy: 0.7753 - precision: 1.0000 - recall: 0.0029 - f1_metric: 0.0026
Test Score: 0.6962397694587708
Test Accuracy: 3.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       1.00      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.78      0.68      4650

[[3602    0]
 [1045    3]]
Evaluated with elapsed time 73.29417479399126
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644408081025748, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.01776540835187479}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644410576828876, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.017692091778564536}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464439733888199, &#39;ERDE_50&#39;: 0.23935192171196562, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.052309257924964644}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644408081025748, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.01776540835187479}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644410576828876, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.017692091778564536}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.2509794561566155, &#39;ERDE_50&#39;: 0.17307982495850402, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.25806451612903225, &#39;ERDE_5&#39;: 0.2481802297526707, &#39;ERDE_50&#39;: 0.21036276959017433, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24599590653839742}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5121951219512195, &#39;ERDE_5&#39;: 0.25616485692083396, &#39;ERDE_50&#39;: 0.15703435440873398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49222963367140676}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 73.29417479399126} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3565   37]
 [ 826  222]]
Evaluating after getting time 116797.903145333
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3565   37]
 [ 826  222]]
Evaluated with elapsed time 102.35988596800598
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7678571428571429, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5375, &#39;ERDE_5&#39;: 0.25326033433676526, &#39;ERDE_50&#39;: 0.15176410755104142, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5165481215254107}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516264672170899, &#39;ERDE_50&#39;: 0.16420479631585952, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24875664611576662, &#39;ERDE_50&#39;: 0.1802111452028487, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4006346376413393}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3520   82]
 [ 845  203]]
Evaluating after getting time 116910.01095527
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.71      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3520   82]
 [ 845  203]]
Evaluated with elapsed time 3.7361038160015596
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5121951219512195, &#39;ERDE_5&#39;: 0.25616485692083396, &#39;ERDE_50&#39;: 0.15703435440873398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49222963367140676}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.4660 - tp: 70.0000 - fp: 33.0000 - tn: 3569.0000 - fn: 978.0000 - accuracy: 0.7826 - precision: 0.6796 - recall: 0.0668 - f1_metric: 0.0575
Test Score: 0.4660346806049347
Test Accuracy: 70.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      0.99      0.88      3602
           1       0.68      0.07      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.73      0.53      0.50      4650
weighted avg       0.76      0.78      0.71      4650

[[3569   33]
 [ 978   70]]
Finished training and evaluation
{&#39;precision&#39;: 0.7096774193548387, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3259259259259259, &#39;ERDE_5&#39;: 0.25103210124884084, &#39;ERDE_50&#39;: 0.19908455309089165, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.311952275067696}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 20ms/step - loss: 0.7347 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.73471599817276
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 9s 23ms/step - loss: 0.4544 - tp: 284.0000 - fp: 131.0000 - tn: 3471.0000 - fn: 764.0000 - accuracy: 0.8075 - precision: 0.6843 - recall: 0.2710 - f1_metric: 0.2022
Test Score: 0.45439842343330383
Test Accuracy: 284.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.89      3602
           1       0.68      0.27      0.39      1048

    accuracy                           0.81      4650
   macro avg       0.75      0.62      0.64      4650
weighted avg       0.79      0.81      0.77      4650

[[3471  131]
 [ 764  284]]
Finished training and evaluation
{&#39;precision&#39;: 0.6043956043956044, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2665707716978174, &#39;ERDE_50&#39;: 0.13676374427845922, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5421137113206458}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 26ms/step - loss: 0.9529 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9528539776802063
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.0928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.092787504196167
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 13s 35ms/step - loss: 1.0928 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.092787504196167
Test Accuracy: 0.0
146/146 [==============================] - 5s 29ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 74.75412370500271
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.6043956043956044, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5641025641025641, &#39;ERDE_5&#39;: 0.2665707716978174, &#39;ERDE_50&#39;: 0.13676374427845922, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5421137113206458}
Writing results to CSV file
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2591636979493422, &#39;ERDE_50&#39;: 0.15284833649101473, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5008219003795595}
Writing results to CSV file
{&#39;precision&#39;: 0.6923076923076923, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.46153846153846156, &#39;ERDE_5&#39;: 0.2551417768815796, &#39;ERDE_50&#39;: 0.17005627930631936, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43995421746290314}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544077118567655, &#39;ERDE_50&#39;: 0.14583438123501763, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2516228734400685, &#39;ERDE_50&#39;: 0.16184073012200628, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933665264307137, &#39;ERDE_50&#39;: 0.1855205137233228, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.82, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5324675324675324, &#39;ERDE_5&#39;: 0.25094601098374764, &#39;ERDE_50&#39;: 0.15416729540767668, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5117118207802317}
Writing results to CSV file
{&#39;precision&#39;: 0.825, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45833333333333326, &#39;ERDE_5&#39;: 0.2498893419257066, &#39;ERDE_50&#39;: 0.17191735269297162, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4386828868139475}
Writing results to CSV file
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24817705501274134, &#39;ERDE_50&#39;: 0.19381430623319984, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7272727272727273, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5031446540880503, &#39;ERDE_5&#39;: 0.25443929272542143, &#39;ERDE_50&#39;: 0.1600187783981388, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48353195520880926}
Writing results to CSV file
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.2516349063961382, &#39;ERDE_50&#39;: 0.17838919347898188, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.40925400349790214}
Writing results to CSV file
{&#39;precision&#39;: 0.76, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.2945736434108527, &#39;ERDE_5&#39;: 0.24934032872600226, &#39;ERDE_50&#39;: 0.20443304327415016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2807976530060389}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544077118567655, &#39;ERDE_50&#39;: 0.14583438123501763, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2516228734400685, &#39;ERDE_50&#39;: 0.16184073012200628, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933665264307137, &#39;ERDE_50&#39;: 0.1855205137233228, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5316455696202531, &#39;ERDE_5&#39;: 0.25268883628750327, &#39;ERDE_50&#39;: 0.1535469376121288, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5109218982412069}
Writing results to CSV file
{&#39;precision&#39;: 0.8260869565217391, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5066666666666666, &#39;ERDE_5&#39;: 0.250460654646826, &#39;ERDE_50&#39;: 0.16067825785647094, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48494399124160015}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38235294117647056, &#39;ERDE_5&#39;: 0.24933674616457568, &#39;ERDE_50&#39;: 0.18788457991717603, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.36447187623152266}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544077118567655, &#39;ERDE_50&#39;: 0.14583438123501763, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2516228734400685, &#39;ERDE_50&#39;: 0.16184073012200628, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933665264307137, &#39;ERDE_50&#39;: 0.1855205137233228, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544077118567655, &#39;ERDE_50&#39;: 0.14583438123501763, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2516228734400685, &#39;ERDE_50&#39;: 0.16184073012200628, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933665264307137, &#39;ERDE_50&#39;: 0.1855205137233228, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5121951219512195, &#39;ERDE_5&#39;: 0.25616485692083396, &#39;ERDE_50&#39;: 0.15703435440873398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49222963367140676}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 74.75412370500271} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 120174.221337063
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 136.04508119299135
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluating after getting time 120316.602511597
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluated with elapsed time 3.8777374689962016
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.8920 - tp: 518.0000 - fp: 557.0000 - tn: 3045.0000 - fn: 530.0000 - accuracy: 0.7662 - precision: 0.4819 - recall: 0.4943 - f1_metric: 0.3068
Test Score: 0.8919793963432312
Test Accuracy: 518.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.85      0.85      0.85      3602
           1       0.48      0.49      0.49      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.67      0.67      4650
weighted avg       0.77      0.77      0.77      4650

[[3045  557]
 [ 530  518]]
Finished training and evaluation
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.7943 - tp: 858.0000 - fp: 1350.0000 - tn: 2252.0000 - fn: 190.0000 - accuracy: 0.6688 - precision: 0.3886 - recall: 0.8187 - f1_metric: 0.4004
Test Score: 1.7942938804626465
Test Accuracy: 858.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75      3602
           1       0.39      0.82      0.53      1048

    accuracy                           0.67      4650
   macro avg       0.66      0.72      0.64      4650
weighted avg       0.80      0.67      0.70      4650

[[2252 1350]
 [ 190  858]]
Finished training and evaluation
{&#39;precision&#39;: 0.352059925093633, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5067385444743935, &#39;ERDE_5&#39;: 0.3459071618282603, &#39;ERDE_50&#39;: 0.12419451290735468, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48698575488887214}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7902 - tp: 598.0000 - fp: 664.0000 - tn: 2938.0000 - fn: 450.0000 - accuracy: 0.7604 - precision: 0.4739 - recall: 0.5706 - f1_metric: 0.3356
Test Score: 0.7902495265007019
Test Accuracy: 598.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.82      0.84      3602
           1       0.47      0.57      0.52      1048

    accuracy                           0.76      4650
   macro avg       0.67      0.69      0.68      4650
weighted avg       0.78      0.76      0.77      4650

[[2938  664]
 [ 450  598]]
Finished training and evaluation
{&#39;precision&#39;: 0.4340659340659341, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5524475524475524, &#39;ERDE_5&#39;: 0.3053317887997231, &#39;ERDE_50&#39;: 0.11896897652141525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5309130148057564}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 22.7635 - tp: 879.0000 - fp: 1843.0000 - tn: 1759.0000 - fn: 169.0000 - accuracy: 0.5673 - precision: 0.3229 - recall: 0.8387 - f1_metric: 0.3672
Test Score: 22.763538360595703
Test Accuracy: 879.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.49      0.64      3602
           1       0.32      0.84      0.47      1048

    accuracy                           0.57      4650
   macro avg       0.62      0.66      0.55      4650
weighted avg       0.78      0.57      0.60      4650

[[1759 1843]
 [ 169  879]]
Finished training and evaluation
{&#39;precision&#39;: 0.30844155844155846, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.46116504854368934, &#39;ERDE_5&#39;: 0.36916429802381256, &#39;ERDE_50&#39;: 0.14507989202421095, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4431887247226374}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Finished training and evaluation
{&#39;precision&#39;: 0.4672897196261682, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.47393364928909953, &#39;ERDE_5&#39;: 0.2787768471329035, &#39;ERDE_50&#39;: 0.16079003403584705, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.45545960235900873}
Evaluating for elapsed time
146/146 [==============================] - 8s 21ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Evaluated with elapsed time 69.37259240398998
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Writing results to CSV file
{&#39;precision&#39;: 0.48148148148148145, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5439330543933055, &#39;ERDE_5&#39;: 0.2864315401330864, &#39;ERDE_50&#39;: 0.13288511085402835, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5206126309849816}
Writing results to CSV file
{&#39;precision&#39;: 0.46218487394957986, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.4932735426008969, &#39;ERDE_5&#39;: 0.2830258367572126, &#39;ERDE_50&#39;: 0.15303835599595872, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47020518009861845}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6351351351351351, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5280898876404494, &#39;ERDE_5&#39;: 0.2613468991104671, &#39;ERDE_50&#39;: 0.1504451486343751, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.507504817594864}
Writing results to CSV file
{&#39;precision&#39;: 0.6290322580645161, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4698795180722892, &#39;ERDE_5&#39;: 0.25916390721376353, &#39;ERDE_50&#39;: 0.1670327336541325, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44973404387497806}
Writing results to CSV file
{&#39;precision&#39;: 0.62, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4025974025974026, &#39;ERDE_5&#39;: 0.2568872151801032, &#39;ERDE_50&#39;: 0.18362031867389048, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3837695879600649}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.37259240398998} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 123600.977032406
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 136.28418704700016
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluating after getting time 123744.555068408
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluated with elapsed time 5.302924496005289
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
146/146 [==============================] - 7s 17ms/step - loss: 1.3284 - tp: 721.0000 - fp: 922.0000 - tn: 2680.0000 - fn: 327.0000 - accuracy: 0.7314 - precision: 0.4388 - recall: 0.6880 - f1_metric: 0.3768
Test Score: 1.3284099102020264
Test Accuracy: 721.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.89      0.74      0.81      3602
           1       0.44      0.69      0.54      1048

    accuracy                           0.73      4650
   macro avg       0.67      0.72      0.67      4650
weighted avg       0.79      0.73      0.75      4650

[[2680  922]
 [ 327  721]]
Finished training and evaluation
{&#39;precision&#39;: 0.40476190476190477, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5414012738853503, &#39;ERDE_5&#39;: 0.31807712046134634, &#39;ERDE_50&#39;: 0.11757177427918346, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.520297322822218}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.9127 - tp: 815.0000 - fp: 1322.0000 - tn: 2280.0000 - fn: 233.0000 - accuracy: 0.6656 - precision: 0.3814 - recall: 0.7777 - f1_metric: 0.3861
Test Score: 1.9127001762390137
Test Accuracy: 815.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.63      0.75      3602
           1       0.38      0.78      0.51      1048

    accuracy                           0.67      4650
   macro avg       0.64      0.71      0.63      4650
weighted avg       0.79      0.67      0.69      4650

[[2280 1322]
 [ 233  815]]
Finished training and evaluation
{&#39;precision&#39;: 0.35019455252918286, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.49861495844875336, &#39;ERDE_5&#39;: 0.3424431096310815, &#39;ERDE_50&#39;: 0.13016336088616165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47917882818823127}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.3329 - tp: 666.0000 - fp: 903.0000 - tn: 2699.0000 - fn: 382.0000 - accuracy: 0.7237 - precision: 0.4245 - recall: 0.6355 - f1_metric: 0.3491
Test Score: 1.332855463027954
Test Accuracy: 666.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.42      0.64      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2699  903]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.405, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5328947368421052, &#39;ERDE_5&#39;: 0.3146110949426674, &#39;ERDE_50&#39;: 0.1235406222579915, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5121223726261722}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00025: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 1.5568 - tp: 586.0000 - fp: 763.0000 - tn: 2839.0000 - fn: 462.0000 - accuracy: 0.7366 - precision: 0.4344 - recall: 0.5592 - f1_metric: 0.3294
Test Score: 1.5567545890808105
Test Accuracy: 586.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.79      0.82      3602
           1       0.43      0.56      0.49      1048

    accuracy                           0.74      4650
   macro avg       0.65      0.67      0.66      4650
weighted avg       0.76      0.74      0.75      4650

[[2839  763]
 [ 462  586]]
Finished training and evaluation
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Finished training and evaluation
{&#39;precision&#39;: 0.3910891089108911, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5163398692810458, &#39;ERDE_5&#39;: 0.31694292196479884, &#39;ERDE_50&#39;: 0.13059369917676925, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49621281775962855}
Evaluating for elapsed time
146/146 [==============================] - 5s 15ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Evaluated with elapsed time 71.62568385399936
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Writing results to CSV file
{&#39;precision&#39;: 0.4339622641509434, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5247148288973384, &#39;ERDE_5&#39;: 0.2980494712945635, &#39;ERDE_50&#39;: 0.13505356873396854, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5022183619522276}
Writing results to CSV file
{&#39;precision&#39;: 0.41843971631205673, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.4816326530612245, &#39;ERDE_5&#39;: 0.29348487737711887, &#39;ERDE_50&#39;: 0.15404434161036268, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.45910868679462136}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.26019968754524414, &#39;ERDE_50&#39;: 0.1492826763688396, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6271186440677966, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45398773006134974, &#39;ERDE_5&#39;: 0.2585883391899454, &#39;ERDE_50&#39;: 0.1711796299090712, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4345235956394707}
Writing results to CSV file
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.39215686274509803, &#39;ERDE_5&#39;: 0.2568892623536104, &#39;ERDE_50&#39;: 0.1859843848677439, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3738173089554079}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 71.62568385399936} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 127860.520266735
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 86.94113359000767
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluating after getting time 127954.626005404
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluated with elapsed time 5.145012334003695
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.8920 - tp: 518.0000 - fp: 557.0000 - tn: 3045.0000 - fn: 530.0000 - accuracy: 0.7662 - precision: 0.4819 - recall: 0.4943 - f1_metric: 0.3068
Test Score: 0.8919793963432312
Test Accuracy: 518.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.85      0.85      0.85      3602
           1       0.48      0.49      0.49      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.67      0.67      4650
weighted avg       0.77      0.77      0.77      4650

[[3045  557]
 [ 530  518]]
Finished training and evaluation
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 1.7943 - tp: 858.0000 - fp: 1350.0000 - tn: 2252.0000 - fn: 190.0000 - accuracy: 0.6688 - precision: 0.3886 - recall: 0.8187 - f1_metric: 0.4004
Test Score: 1.7942938804626465
Test Accuracy: 858.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.92      0.63      0.75      3602
           1       0.39      0.82      0.53      1048

    accuracy                           0.67      4650
   macro avg       0.66      0.72      0.64      4650
weighted avg       0.80      0.67      0.70      4650

[[2252 1350]
 [ 190  858]]
Finished training and evaluation
{&#39;precision&#39;: 0.352059925093633, &#39;recall&#39;: 0.9038461538461539, &#39;F1&#39;: 0.5067385444743935, &#39;ERDE_5&#39;: 0.3459071618282603, &#39;ERDE_50&#39;: 0.12419451290735468, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48698575488887214}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.7902 - tp: 598.0000 - fp: 664.0000 - tn: 2938.0000 - fn: 450.0000 - accuracy: 0.7604 - precision: 0.4739 - recall: 0.5706 - f1_metric: 0.3356
Test Score: 0.7902495265007019
Test Accuracy: 598.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.82      0.84      3602
           1       0.47      0.57      0.52      1048

    accuracy                           0.76      4650
   macro avg       0.67      0.69      0.68      4650
weighted avg       0.78      0.76      0.77      4650

[[2938  664]
 [ 450  598]]
Finished training and evaluation
{&#39;precision&#39;: 0.4340659340659341, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5524475524475524, &#39;ERDE_5&#39;: 0.3053317887997231, &#39;ERDE_50&#39;: 0.11896897652141525, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5309130148057564}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00012: early stopping
Evaluating
146/146 [==============================] - 6s 15ms/step - loss: 22.7635 - tp: 879.0000 - fp: 1843.0000 - tn: 1759.0000 - fn: 169.0000 - accuracy: 0.5673 - precision: 0.3229 - recall: 0.8387 - f1_metric: 0.3672
Test Score: 22.763538360595703
Test Accuracy: 879.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.49      0.64      3602
           1       0.32      0.84      0.47      1048

    accuracy                           0.57      4650
   macro avg       0.62      0.66      0.55      4650
weighted avg       0.78      0.57      0.60      4650

[[1759 1843]
 [ 169  879]]
Finished training and evaluation
{&#39;precision&#39;: 0.30844155844155846, &#39;recall&#39;: 0.9134615384615384, &#39;F1&#39;: 0.46116504854368934, &#39;ERDE_5&#39;: 0.36916429802381256, &#39;ERDE_50&#39;: 0.14507989202421095, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4431887247226374}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00015: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Finished training and evaluation
{&#39;precision&#39;: 0.4672897196261682, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.47393364928909953, &#39;ERDE_5&#39;: 0.2787768471329035, &#39;ERDE_50&#39;: 0.16079003403584705, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.45545960235900873}
Evaluating for elapsed time
146/146 [==============================] - 4s 13ms/step - loss: 0.8962 - tp: 332.0000 - fp: 431.0000 - tn: 3171.0000 - fn: 716.0000 - accuracy: 0.7533 - precision: 0.4351 - recall: 0.3168 - f1_metric: 0.2011
Test Score: 0.8961533904075623
Test Accuracy: 332.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.88      0.85      3602
           1       0.44      0.32      0.37      1048

    accuracy                           0.75      4650
   macro avg       0.63      0.60      0.61      4650
weighted avg       0.73      0.75      0.74      4650

[[3171  431]
 [ 716  332]]
Evaluated with elapsed time 60.75303918799909
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.4859154929577465, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5609756097560976, &#39;ERDE_5&#39;: 0.287933201214662, &#39;ERDE_50&#39;: 0.1251725544769163, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020169}
Writing results to CSV file
{&#39;precision&#39;: 0.48148148148148145, &#39;recall&#39;: 0.625, &#39;F1&#39;: 0.5439330543933055, &#39;ERDE_5&#39;: 0.2864315401330864, &#39;ERDE_50&#39;: 0.13288511085402835, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5206126309849816}
Writing results to CSV file
{&#39;precision&#39;: 0.46218487394957986, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.4932735426008969, &#39;ERDE_5&#39;: 0.2830258367572126, &#39;ERDE_50&#39;: 0.15303835599595872, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.47020518009861845}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6351351351351351, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5280898876404494, &#39;ERDE_5&#39;: 0.2613468991104671, &#39;ERDE_50&#39;: 0.1504451486343751, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.507504817594864}
Writing results to CSV file
{&#39;precision&#39;: 0.6290322580645161, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.4698795180722892, &#39;ERDE_5&#39;: 0.25916390721376353, &#39;ERDE_50&#39;: 0.1670327336541325, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44973404387497806}
Writing results to CSV file
{&#39;precision&#39;: 0.62, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4025974025974026, &#39;ERDE_5&#39;: 0.2568872151801032, &#39;ERDE_50&#39;: 0.18362031867389048, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3837695879600649}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6266666666666667, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5251396648044693, &#39;ERDE_5&#39;: 0.2619223292816869, &#39;ERDE_50&#39;: 0.15102638476714283, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5046695951501999}
Writing results to CSV file
{&#39;precision&#39;: 0.6190476190476191, &#39;recall&#39;: 0.375, &#39;F1&#39;: 0.46706586826347307, &#39;ERDE_5&#39;: 0.2597430040864372, &#39;ERDE_50&#39;: 0.16761396978690024, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44704102564818177}
Writing results to CSV file
{&#39;precision&#39;: 0.6078431372549019, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4, &#39;ERDE_5&#39;: 0.25746765878900496, &#39;ERDE_50&#39;: 0.18420155480665762, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3812936551345161}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 60.75303918799909} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 131093.157797702
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 108.32032760500442
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluating after getting time 131210.33417377
              precision    recall  f1-score   support

           0       0.82      0.94      0.88      3602
           1       0.59      0.29      0.39      1048

    accuracy                           0.79      4650
   macro avg       0.71      0.62      0.63      4650
weighted avg       0.77      0.79      0.77      4650

[[3391  211]
 [ 744  304]]
Evaluated with elapsed time 3.7000828679883853
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00026: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 1.3284 - tp: 721.0000 - fp: 922.0000 - tn: 2680.0000 - fn: 327.0000 - accuracy: 0.7314 - precision: 0.4388 - recall: 0.6880 - f1_metric: 0.3768
Test Score: 1.3284099102020264
Test Accuracy: 721.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.89      0.74      0.81      3602
           1       0.44      0.69      0.54      1048

    accuracy                           0.73      4650
   macro avg       0.67      0.72      0.67      4650
weighted avg       0.79      0.73      0.75      4650

[[2680  922]
 [ 327  721]]
Finished training and evaluation
{&#39;precision&#39;: 0.40476190476190477, &#39;recall&#39;: 0.8173076923076923, &#39;F1&#39;: 0.5414012738853503, &#39;ERDE_5&#39;: 0.31807712046134634, &#39;ERDE_50&#39;: 0.11757177427918346, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.520297322822218}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 1.9127 - tp: 815.0000 - fp: 1322.0000 - tn: 2280.0000 - fn: 233.0000 - accuracy: 0.6656 - precision: 0.3814 - recall: 0.7777 - f1_metric: 0.3861
Test Score: 1.9127001762390137
Test Accuracy: 815.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.91      0.63      0.75      3602
           1       0.38      0.78      0.51      1048

    accuracy                           0.67      4650
   macro avg       0.64      0.71      0.63      4650
weighted avg       0.79      0.67      0.69      4650

[[2280 1322]
 [ 233  815]]
Finished training and evaluation
{&#39;precision&#39;: 0.35019455252918286, &#39;recall&#39;: 0.8653846153846154, &#39;F1&#39;: 0.49861495844875336, &#39;ERDE_5&#39;: 0.3424431096310815, &#39;ERDE_50&#39;: 0.13016336088616165, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.47917882818823127}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 1.3329 - tp: 666.0000 - fp: 903.0000 - tn: 2699.0000 - fn: 382.0000 - accuracy: 0.7237 - precision: 0.4245 - recall: 0.6355 - f1_metric: 0.3491
Test Score: 1.332855463027954
Test Accuracy: 666.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.88      0.75      0.81      3602
           1       0.42      0.64      0.51      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.69      0.66      4650
weighted avg       0.77      0.72      0.74      4650

[[2699  903]
 [ 382  666]]
Finished training and evaluation
{&#39;precision&#39;: 0.405, &#39;recall&#39;: 0.7788461538461539, &#39;F1&#39;: 0.5328947368421052, &#39;ERDE_5&#39;: 0.3146110949426674, &#39;ERDE_50&#39;: 0.1235406222579915, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5121223726261722}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00025: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.5568 - tp: 586.0000 - fp: 763.0000 - tn: 2839.0000 - fn: 462.0000 - accuracy: 0.7366 - precision: 0.4344 - recall: 0.5592 - f1_metric: 0.3294
Test Score: 1.5567545890808105
Test Accuracy: 586.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.86      0.79      0.82      3602
           1       0.43      0.56      0.49      1048

    accuracy                           0.74      4650
   macro avg       0.65      0.67      0.66      4650
weighted avg       0.76      0.74      0.75      4650

[[2839  763]
 [ 462  586]]
Finished training and evaluation
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00019: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Finished training and evaluation
{&#39;precision&#39;: 0.3910891089108911, &#39;recall&#39;: 0.7596153846153846, &#39;F1&#39;: 0.5163398692810458, &#39;ERDE_5&#39;: 0.31694292196479884, &#39;ERDE_50&#39;: 0.13059369917676925, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49621281775962855}
Evaluating for elapsed time
146/146 [==============================] - 6s 21ms/step - loss: 1.1872 - tp: 644.0000 - fp: 889.0000 - tn: 2713.0000 - fn: 404.0000 - accuracy: 0.7219 - precision: 0.4201 - recall: 0.6145 - f1_metric: 0.3432
Test Score: 1.1872233152389526
Test Accuracy: 644.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.87      0.75      0.81      3602
           1       0.42      0.61      0.50      1048

    accuracy                           0.72      4650
   macro avg       0.65      0.68      0.65      4650
weighted avg       0.77      0.72      0.74      4650

[[2713  889]
 [ 404  644]]
Evaluated with elapsed time 71.59499677299755
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.43333333333333335, &#39;recall&#39;: 0.75, &#39;F1&#39;: 0.5492957746478874, &#39;ERDE_5&#39;: 0.3047523695035165, &#39;ERDE_50&#39;: 0.12075180658249987, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.527884094058068}
Writing results to CSV file
{&#39;precision&#39;: 0.4339622641509434, &#39;recall&#39;: 0.6634615384615384, &#39;F1&#39;: 0.5247148288973384, &#39;ERDE_5&#39;: 0.2980494712945635, &#39;ERDE_50&#39;: 0.13505356873396854, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5022183619522276}
Writing results to CSV file
{&#39;precision&#39;: 0.41843971631205673, &#39;recall&#39;: 0.5673076923076923, &#39;F1&#39;: 0.4816326530612245, &#39;ERDE_5&#39;: 0.29348487737711887, &#39;ERDE_50&#39;: 0.15404434161036268, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.45910868679462136}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.26019968754524414, &#39;ERDE_50&#39;: 0.1492826763688396, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6271186440677966, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45398773006134974, &#39;ERDE_5&#39;: 0.2585883391899454, &#39;ERDE_50&#39;: 0.1711796299090712, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4345235956394707}
Writing results to CSV file
{&#39;precision&#39;: 0.6122448979591837, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.39215686274509803, &#39;ERDE_5&#39;: 0.2568892623536104, &#39;ERDE_50&#39;: 0.1859843848677439, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3738173089554079}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6438356164383562, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5310734463276836, &#39;ERDE_5&#39;: 0.2607751177164639, &#39;ERDE_50&#39;: 0.14986391250160733, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5103720764513321}
Writing results to CSV file
{&#39;precision&#39;: 0.6166666666666667, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.45121951219512196, &#39;ERDE_5&#39;: 0.25916743606261905, &#39;ERDE_50&#39;: 0.17176086604183893, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4318740615197178}
Writing results to CSV file
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.3896103896103896, &#39;ERDE_5&#39;: 0.2574697059625122, &#39;ERDE_50&#39;: 0.18656562100051105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3713899238323208}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.5473684210526316, &#39;recall&#39;: 0.5, &#39;F1&#39;: 0.5226130653266332, &#39;ERDE_5&#39;: 0.27064003266725983, &#39;ERDE_50&#39;: 0.14792459578939274, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502241483123924}
Writing results to CSV file
{&#39;precision&#39;: 0.5454545454545454, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.46408839779005523, &#39;ERDE_5&#39;: 0.266138446862203, &#39;ERDE_50&#39;: 0.16691536866578585, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4441912103550569}
Writing results to CSV file
{&#39;precision&#39;: 0.5606060606060606, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.43529411764705883, &#39;ERDE_5&#39;: 0.26269788268548605, &#39;ERDE_50&#39;: 0.17524828283845087, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41493721294050273}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 71.59499677299755} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 842  206]]
Evaluating after getting time 135269.994741756
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 842  206]]
Evaluated with elapsed time 160.0469026879873
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2532506612180178, &#39;ERDE_50&#39;: 0.1375797103879203, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5673490155168424}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24815199309513913, &#39;ERDE_50&#39;: 0.17017364429466714, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.44437350482017013}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643507605565412, &#39;ERDE_50&#39;: 0.1897065316410439, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.3510736437469185}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluating after getting time 135438.349606289
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluated with elapsed time 4.664891530002933
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 7s 28ms/step - loss: 0.8909 - tp: 3.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1045.0000 - accuracy: 0.7746 - precision: 0.5000 - recall: 0.0029 - f1_metric: 0.0034
Test Score: 0.8908883333206177
Test Accuracy: 3.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.50      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.64      0.50      0.44      4650
weighted avg       0.71      0.77      0.68      4650

[[3599    3]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.5811 - tp: 2.0000 - fp: 10.0000 - tn: 3592.0000 - fn: 1046.0000 - accuracy: 0.7729 - precision: 0.1667 - recall: 0.0019 - f1_metric: 0.0015
Test Score: 0.5810906291007996
Test Accuracy: 2.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.17      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.47      0.50      0.44      4650
weighted avg       0.64      0.77      0.68      4650

[[3592   10]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827475083865, &#39;ERDE_50&#39;: 0.24171598790581905, &#39;median_latency_tps&#39;: 16.5, &#39;median_penalty_tps&#39;: 0.06034880562609424, &#39;speed&#39;: 0.9396511943739058, &#39;latency_weighted_f1&#39;: 0.03512714745323012}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5551 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5551328063011169
Test Accuracy: 0.0
146/146 [==============================] - 4s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7067 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0080
Test Score: 0.7066572308540344
Test Accuracy: 8.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701724914940792, &#39;ERDE_50&#39;: 0.2375690916508785, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06918474512703571}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330226421356201
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
146/146 [==============================] - 4s 14ms/step - loss: 0.5330 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5330226421356201
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.93161156401038
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701724914940792, &#39;ERDE_50&#39;: 0.2375690916508785, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.048709754503259095, &#39;speed&#39;: 0.9512902454967409, &#39;latency_weighted_f1&#39;: 0.06918474512703571}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702240985105592, &#39;ERDE_50&#39;: 0.24229722403858514, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.03537704511739719}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.018691588785046728, &#39;ERDE_5&#39;: 0.24702506471334643, &#39;ERDE_50&#39;: 0.24466129023243857, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.01774473638619201}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.03773584905660378, &#39;ERDE_5&#39;: 0.24585703799276867, &#39;ERDE_50&#39;: 0.24113475177304985, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03560481295798086}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24586073037542694, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.018230977114345875}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.32812500000000006, &#39;ERDE_5&#39;: 0.24755290374523042, &#39;ERDE_50&#39;: 0.19796120248813806, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31277995147753274}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.24701874265387302, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.11713591765366839}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.93161156401038} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 842  206]]
Evaluating after getting time 139236.758613375
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 842  206]]
Evaluated with elapsed time 95.55843446901417
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2532506612180178, &#39;ERDE_50&#39;: 0.1375797103879203, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5673490155168424}
Writing results to CSV file
{&#39;precision&#39;: 0.8918918918918919, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.46808510638297873, &#39;ERDE_5&#39;: 0.24815199309513913, &#39;ERDE_50&#39;: 0.17017364429466714, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.44437350482017013}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643507605565412, &#39;ERDE_50&#39;: 0.1897065316410439, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.3510736437469185}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluating after getting time 139337.924812204
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.49      4650
weighted avg       0.80      0.79      0.70      4650

[[3592   10]
 [ 987   61]]
Evaluated with elapsed time 3.778966843005037
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0073 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0072625875473022
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.7823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7822611927986145
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.4687 - tp: 136.0000 - fp: 52.0000 - tn: 3550.0000 - fn: 912.0000 - accuracy: 0.7927 - precision: 0.7234 - recall: 0.1298 - f1_metric: 0.1172
Test Score: 0.4687204360961914
Test Accuracy: 136.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.72      0.13      0.22      1048

    accuracy                           0.79      4650
   macro avg       0.76      0.56      0.55      4650
weighted avg       0.78      0.79      0.73      4650

[[3550   52]
 [ 912  136]]
Finished training and evaluation
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25678171523384763, &#39;ERDE_50&#39;: 0.15997965673535694, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.9031 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9030778408050537
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370429754257202
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 20ms/step - loss: 1.0370 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0370429754257202
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 72.31288102600956
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8695652173913043, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31496062992125984, &#39;ERDE_5&#39;: 0.24755290446840356, &#39;ERDE_50&#39;: 0.20032526868199121, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.30084416320306273}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8518518518518519, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.35114503816793896, &#39;ERDE_5&#39;: 0.24813305583227857, &#39;ERDE_50&#39;: 0.19381430623319928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3347234377135065}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12389380530973451, &#39;ERDE_5&#39;: 0.2470208569559358, &#39;ERDE_50&#39;: 0.23047689306931865, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.11665427431054062}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.24586198129018733, &#39;ERDE_50&#39;: 0.22931442080378425, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 72.31288102600956} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 853  195]]
Evaluating after getting time 142046.722883371
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 853  195]]
Evaluated with elapsed time 110.20682405401021
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7936507936507936, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5988023952095809, &#39;ERDE_5&#39;: 0.25326990676929456, &#39;ERDE_50&#39;: 0.13521564419406748, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5731295200617715}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873223309688122, &#39;ERDE_50&#39;: 0.17784707900899493, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9565217391304348, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3464566929133859, &#39;ERDE_5&#39;: 0.2464346222270298, &#39;ERDE_50&#39;: 0.19443466402875068, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.32958036030666443}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluating after getting time 142161.526845708
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluated with elapsed time 3.1041171879915055
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701860627983543, &#39;ERDE_50&#39;: 0.22338469448775836, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5898 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5898103713989258
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5358 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.535814106464386
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00017: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.6271 - tp: 1.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1047.0000 - accuracy: 0.7744 - precision: 0.3333 - recall: 9.5420e-04 - f1_metric: 0.0015
Test Score: 0.6271416544914246
Test Accuracy: 1.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.33      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.55      0.50      0.44      4650
weighted avg       0.68      0.77      0.68      4650

[[3600    2]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.2464382748487095, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.01813244832033035}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7450 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0023
Test Score: 0.7450429201126099
Test Accuracy: 4.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643827385949582, &#39;ERDE_50&#39;: 0.23935192171196482, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.05144640698863761}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392691493034363
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 0.5393 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5392691493034363
Test Accuracy: 0.0
146/146 [==============================] - 3s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.28487806100748
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701860627983543, &#39;ERDE_50&#39;: 0.22338469448775836, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.28487806100748} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 853  195]]
Evaluating after getting time 145187.75717861
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.83      0.81      0.76      4650

[[3579   23]
 [ 853  195]]
Evaluated with elapsed time 159.75560013801442
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7936507936507936, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5988023952095809, &#39;ERDE_5&#39;: 0.25326990676929456, &#39;ERDE_50&#39;: 0.13521564419406748, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5731295200617715}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873223309688122, &#39;ERDE_50&#39;: 0.17784707900899493, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9565217391304348, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3464566929133859, &#39;ERDE_5&#39;: 0.2464346222270298, &#39;ERDE_50&#39;: 0.19443466402875068, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.32958036030666443}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluating after getting time 145357.304503475
              precision    recall  f1-score   support

           0       0.78      1.00      0.88      3602
           1       0.86      0.06      0.11      1048

    accuracy                           0.79      4650
   macro avg       0.82      0.53      0.50      4650
weighted avg       0.80      0.79      0.71      4650

[[3592   10]
 [ 984   64]]
Evaluated with elapsed time 2.84294524701545
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701860627983543, &#39;ERDE_50&#39;: 0.22338469448775836, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 30ms/step - loss: 0.9755 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9755200743675232
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.8124 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.812414288520813
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 26ms/step - loss: 0.9575 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9574721455574036
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.8782 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8781750202178955
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 1.1301 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1301218271255493
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 15ms/step - loss: 1.1301 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1301218271255493
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 70.38110572201549
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24700108815956529, &#39;ERDE_50&#39;: 0.20683623113078495, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.26242012590636804}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.08653846153846154, &#39;F1&#39;: 0.15652173913043477, &#39;ERDE_5&#39;: 0.24702076006516502, &#39;ERDE_50&#39;: 0.2257487606816118, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.14737564841468298}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8636363636363636, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.30158730158730157, &#39;ERDE_5&#39;: 0.24757637152395168, &#39;ERDE_50&#39;: 0.20268933487584584, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.28630991327879646}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.1724137931034483, &#39;ERDE_5&#39;: 0.24701860627983543, &#39;ERDE_50&#39;: 0.22338469448775836, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.16267420992583512}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.0673076923076923, &#39;F1&#39;: 0.12612612612612611, &#39;ERDE_5&#39;: 0.2458612388649735, &#39;ERDE_50&#39;: 0.22931442080378478, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231913573607972, &#39;speed&#39;: 0.9376808642639203, &#39;latency_weighted_f1&#39;: 0.11826605495220616}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 70.38110572201549} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluating after getting time 147851.596591651
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluated with elapsed time 79.34288408199791
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.2515234609026963, &#39;ERDE_50&#39;: 0.1571125977342981, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49923104466364077}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 79.34288408199791}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluating after getting time 148066.953758742
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluated with elapsed time 80.50164627699996
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.2515234609026963, &#39;ERDE_50&#39;: 0.1571125977342981, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49923104466364077}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 80.50164627699996}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluating after getting time 148350.512334943
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluated with elapsed time 107.68203186499886
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.2515234609026963, &#39;ERDE_50&#39;: 0.1571125977342981, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49923104466364077}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 107.68203186499886}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluating after getting time 148729.572922486
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 831  217]]
Evaluated with elapsed time 149.47932313001365
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5194805194805195, &#39;ERDE_5&#39;: 0.2515234609026963, &#39;ERDE_50&#39;: 0.1571125977342981, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49923104466364077}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4864864864864865, &#39;ERDE_5&#39;: 0.25046343323846154, &#39;ERDE_50&#39;: 0.16540639024417805, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4656290100826176}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487701820323, &#39;ERDE_50&#39;: 0.18257521139670077, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 149.47932313001365}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluating after getting time 149247.49944077
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluated with elapsed time 190.7213597209775
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544097007070446, &#39;ERDE_50&#39;: 0.14583438123501657, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510432223029756, &#39;ERDE_50&#39;: 0.1612594939892367, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933716176378123, &#39;ERDE_50&#39;: 0.1855205137233209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluating after getting time 149447.09362483
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluated with elapsed time 2.8700473309727386
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 16ms/step - loss: 0.5812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.581177294254303
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.5136 - tp: 1.0000 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1047.0000 - accuracy: 0.7748 - precision: 1.0000 - recall: 9.5420e-04 - f1_metric: 0.0017
Test Score: 0.5136207342147827
Test Accuracy: 1.0
146/146 [==============================] - 4s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       1.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.89      0.50      0.44      4650
weighted avg       0.83      0.77      0.68      4650

[[3602    0]
 [1047    1]]
Finished training and evaluation
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01904761904761905, &#39;ERDE_5&#39;: 0.24585703871594175, &#39;ERDE_50&#39;: 0.24349881796690306, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.018305138304333494}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.7964 - tp: 8.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1040.0000 - accuracy: 0.7748 - precision: 0.5333 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7964164614677429
Test Accuracy: 8.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.53      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.44      4650
weighted avg       0.72      0.77      0.68      4650

[[3595    7]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.7338 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0175
Test Score: 0.733765184879303
Test Accuracy: 15.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.07692307692307693, &#39;F1&#39;: 0.14035087719298248, &#39;ERDE_5&#39;: 0.2470169125117684, &#39;ERDE_50&#39;: 0.22811282687546647, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.13242251474664474}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 19ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 17ms/step - loss: 0.5574 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5574043393135071
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 67.71286397401127
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.71286397401127} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluating after getting time 152841.868215272
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3557   45]
 [ 815  233]]
Evaluated with elapsed time 112.44413294299738
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544097007070446, &#39;ERDE_50&#39;: 0.14583438123501657, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510432223029756, &#39;ERDE_50&#39;: 0.1612594939892367, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.8181818181818182, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.39416058394160586, &#39;ERDE_5&#39;: 0.24933716176378123, &#39;ERDE_50&#39;: 0.1855205137233209, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3757273244026253}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluating after getting time 152961.774440419
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.59      0.60      4650
weighted avg       0.79      0.80      0.76      4650

[[3519   83]
 [ 837  211]]
Evaluated with elapsed time 4.726041635003639
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.9885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9884927272796631
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.5182 - tp: 68.0000 - fp: 22.0000 - tn: 3580.0000 - fn: 980.0000 - accuracy: 0.7845 - precision: 0.7556 - recall: 0.0649 - f1_metric: 0.0606
Test Score: 0.518192708492279
Test Accuracy: 68.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.76      0.06      0.12      1048

    accuracy                           0.78      4650
   macro avg       0.77      0.53      0.50      4650
weighted avg       0.78      0.78      0.71      4650

[[3580   22]
 [ 980   68]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3529411764705882, &#39;ERDE_5&#39;: 0.25043131740473284, &#39;ERDE_50&#39;: 0.1937751845704177, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.33918344505088527}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.4622 - tp: 228.0000 - fp: 76.0000 - tn: 3526.0000 - fn: 820.0000 - accuracy: 0.8073 - precision: 0.7500 - recall: 0.2176 - f1_metric: 0.1686
Test Score: 0.4621577858924866
Test Accuracy: 228.0
146/146 [==============================] - 5s 31ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.98      0.89      3602
           1       0.75      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.78      0.60      0.61      4650
weighted avg       0.80      0.81      0.76      4650

[[3526   76]
 [ 820  228]]
Finished training and evaluation
{&#39;precision&#39;: 0.6756756756756757, &#39;recall&#39;: 0.4807692307692308, &#39;F1&#39;: 0.5617977528089887, &#39;ERDE_5&#39;: 0.2596397468528691, &#39;ERDE_50&#39;: 0.14160924165451463, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5398987421221957}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.9268 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9268305897712708
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 9s 24ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
146/146 [==============================] - 4s 14ms/step - loss: 1.1116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1115691661834717
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.24544606500422
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7906976744186046, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.4625850340136054, &#39;ERDE_5&#39;: 0.2509731500946802, &#39;ERDE_50&#39;: 0.1707157587646513, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4445533588195277}
Writing results to CSV file
{&#39;precision&#39;: 0.7931034482758621, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34586466165413526, &#39;ERDE_5&#39;: 0.24931752552008518, &#39;ERDE_50&#39;: 0.19497677849873662, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3310361633920697}
Writing results to CSV file
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.17307692307692307, &#39;F1&#39;: 0.28346456692913385, &#39;ERDE_5&#39;: 0.2487601717525304, &#39;ERDE_50&#39;: 0.20621587333523583, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2702081020638303}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7017543859649122, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.4968944099378882, &#39;ERDE_5&#39;: 0.25557596416252976, &#39;ERDE_50&#39;: 0.16118125066367261, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4775253470695694}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.2533740162340099, &#39;ERDE_50&#39;: 0.17540476948957803, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4211355713413897}
Writing results to CSV file
{&#39;precision&#39;: 0.71875, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3382352941176471, &#39;ERDE_5&#39;: 0.2510823042805264, &#39;ERDE_50&#39;: 0.19672048689703928, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3224174289740393}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.24544606500422} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 4 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 5 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 822  226]]
Evaluating after getting time 156467.848425784
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 822  226]]
Evaluated with elapsed time 119.27166733698687
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2532543960936193, &#39;ERDE_50&#39;: 0.14940004135718796, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5252778817765262}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516246051447059, &#39;ERDE_50&#39;: 0.16420479631585952, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8285714285714286, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4172661870503597, &#39;ERDE_5&#39;: 0.24933719678219451, &#39;ERDE_50&#39;: 0.18079238133561645, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3977523740611858}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.58      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3522   80]
 [ 847  201]]
Evaluating after getting time 156594.453152425
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.58      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3522   80]
 [ 847  201]]
Evaluated with elapsed time 3.679182542982744
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2567460930536017, &#39;ERDE_50&#39;: 0.15761559054150173, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.489246423770368}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5841 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5841134190559387
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5165 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5164770483970642
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7063 - tp: 8.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1040.0000 - accuracy: 0.7757 - precision: 0.7273 - recall: 0.0076 - f1_metric: 0.0055
Test Score: 0.7063043117523193
Test Accuracy: 8.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.73      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.75      0.50      0.44      4650
weighted avg       0.76      0.78      0.68      4650

[[3599    3]
 [1040    8]]
Finished training and evaluation
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.6213 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6213265061378479
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00020: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.6667 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0022
Test Score: 0.666702389717102
Test Accuracy: 4.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827288292222, &#39;ERDE_50&#39;: 0.2417159879058175, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054532574873495165, &#39;speed&#39;: 0.9454674251265048, &#39;latency_weighted_f1&#39;: 0.03534457664024317}
Evaluating for elapsed time
146/146 [==============================] - 4s 14ms/step - loss: 0.6667 - tp: 4.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1044.0000 - accuracy: 0.7753 - precision: 0.8000 - recall: 0.0038 - f1_metric: 0.0022
Test Score: 0.666702389717102
Test Accuracy: 4.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.80      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.79      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3601    1]
 [1044    4]]
Evaluated with elapsed time 67.30360019599902
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2567460930536017, &#39;ERDE_50&#39;: 0.15761559054150173, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.489246423770368}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.30360019599902} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 822  226]]
Evaluating after getting time 159612.656123527
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3561   41]
 [ 822  226]]
Evaluated with elapsed time 177.56350480299443
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7719298245614035, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5465838509316769, &#39;ERDE_5&#39;: 0.2532543960936193, &#39;ERDE_50&#39;: 0.14940004135718796, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5252778817765262}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516246051447059, &#39;ERDE_50&#39;: 0.16420479631585952, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8285714285714286, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4172661870503597, &#39;ERDE_5&#39;: 0.24933719678219451, &#39;ERDE_50&#39;: 0.18079238133561645, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3977523740611858}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.58      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3522   80]
 [ 847  201]]
Evaluating after getting time 159797.644715248
              precision    recall  f1-score   support

           0       0.81      0.98      0.88      3602
           1       0.72      0.19      0.30      1048

    accuracy                           0.80      4650
   macro avg       0.76      0.58      0.59      4650
weighted avg       0.79      0.80      0.75      4650

[[3522   80]
 [ 847  201]]
Evaluated with elapsed time 3.948629799997434
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2567460930536017, &#39;ERDE_50&#39;: 0.15761559054150173, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.489246423770368}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 16ms/step - loss: 0.9737 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9736941456794739
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.7244 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7244048118591309
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.4563 - tp: 245.0000 - fp: 121.0000 - tn: 3481.0000 - fn: 803.0000 - accuracy: 0.8013 - precision: 0.6694 - recall: 0.2338 - f1_metric: 0.1768
Test Score: 0.4562739431858063
Test Accuracy: 245.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.67      0.23      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.60      0.61      4650
weighted avg       0.78      0.80      0.76      4650

[[3481  121]
 [ 803  245]]
Finished training and evaluation
{&#39;precision&#39;: 0.5903614457831325, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5240641711229947, &#39;ERDE_5&#39;: 0.26543865041857767, &#39;ERDE_50&#39;: 0.14978566917604483, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5036360244694965}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.9853 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9852736592292786
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 1.0286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0285693407058716
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 7s 28ms/step - loss: 1.0286 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0285693407058716
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 76.24968556800741
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7674418604651163, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.4489795918367347, &#39;ERDE_5&#39;: 0.2515606922893832, &#39;ERDE_50&#39;: 0.17366106109127175, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.43147826003071804}
Writing results to CSV file
{&#39;precision&#39;: 0.78125, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36764705882352944, &#39;ERDE_5&#39;: 0.2499000139842242, &#39;ERDE_50&#39;: 0.19082988224379901, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.35188466856733763}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.15384615384615385, &#39;F1&#39;: 0.256, &#39;ERDE_5&#39;: 0.24876146588543846, &#39;ERDE_50&#39;: 0.2109440057229421, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.24402793928609026}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2567460930536017, &#39;ERDE_50&#39;: 0.15761559054150173, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.489246423770368}
Writing results to CSV file
{&#39;precision&#39;: 0.7111111111111111, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.429530201342282, &#39;ERDE_5&#39;: 0.2533743751619531, &#39;ERDE_50&#39;: 0.17776883568343008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41111465170605466}
Writing results to CSV file
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.31818181818181823, &#39;ERDE_5&#39;: 0.24992075754362802, &#39;ERDE_50&#39;: 0.20028614701921105, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3033017711297287}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 76.24968556800741} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluating after getting time 162449.973390387
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluated with elapsed time 89.84947805799311
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2515293711008949, &#39;ERDE_50&#39;: 0.16184073012200442, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4805098804887542}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.2493376359056913, &#39;ERDE_50&#39;: 0.19024864611102937, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3530496806801074}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 89.84947805799311}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluating after getting time 162685.983062277
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluated with elapsed time 72.76932405901607
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2515293711008949, &#39;ERDE_50&#39;: 0.16184073012200442, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4805098804887542}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.2493376359056913, &#39;ERDE_50&#39;: 0.19024864611102937, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3530496806801074}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 72.76932405901607}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating NSSI words
Calculating first prons
Calculating NSSI words
Scaling features
Training features shape: (3926, 7)
Test features shape: (4650, 7)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluating after getting time 162951.16008188
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluated with elapsed time 115.4575870190165
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2515293711008949, &#39;ERDE_50&#39;: 0.16184073012200442, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4805098804887542}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.2493376359056913, &#39;ERDE_50&#39;: 0.19024864611102937, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3530496806801074}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 115.4575870190165}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluating after getting time 163286.642645882
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3568   34]
 [ 830  218]]
Evaluated with elapsed time 105.78824172099121
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.2515293711008949, &#39;ERDE_50&#39;: 0.16184073012200442, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4805098804887542}
Writing results to CSV file
{&#39;precision&#39;: 0.8048780487804879, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45517241379310347, &#39;ERDE_5&#39;: 0.2504654276891166, &#39;ERDE_50&#39;: 0.1724985888257378, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.43565748759454104}
Writing results to CSV file
{&#39;precision&#39;: 0.8064516129032258, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37037037037037035, &#39;ERDE_5&#39;: 0.2493376359056913, &#39;ERDE_50&#39;: 0.19024864611102937, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3530496806801074}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 105.78824172099121}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3577   25]
 [ 838  210]]
Evaluating after getting time 163782.691868001
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3577   25]
 [ 838  210]]
Evaluated with elapsed time 121.09606354299467
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526829310647792, &#39;ERDE_50&#39;: 0.13699847425515232, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.9230769230769231, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.5034965034965035, &#39;ERDE_5&#39;: 0.24756792928093643, &#39;ERDE_50&#39;: 0.16250020958034, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.47897056812526057}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643485696474823, &#39;ERDE_50&#39;: 0.18970653164104523, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.3525204817026225}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluating after getting time 163911.595721724
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluated with elapsed time 3.590657797001768
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7576 - tp: 2.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1046.0000 - accuracy: 0.7748 - precision: 0.6667 - recall: 0.0019 - f1_metric: 0.0020
Test Score: 0.7576147317886353
Test Accuracy: 2.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.67      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.72      0.50      0.44      4650
weighted avg       0.75      0.77      0.68      4650

[[3601    1]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827458266893, &#39;ERDE_50&#39;: 0.241715987905818, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05841121951671113, &#39;speed&#39;: 0.9415887804832889, &#39;latency_weighted_f1&#39;: 0.03519958057881453}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.5245 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5245046615600586
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.5559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5558797717094421
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.7413 - tp: 6.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1042.0000 - accuracy: 0.7755 - precision: 0.7500 - recall: 0.0057 - f1_metric: 0.0048
Test Score: 0.7413125038146973
Test Accuracy: 6.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.75      0.01      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.76      0.50      0.44      4650
weighted avg       0.77      0.78      0.68      4650

[[3600    2]
 [1042    6]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464379824125908, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.05274129981451514}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470939874649048
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 18ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470939874649048
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 67.95181458699517
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464379824125908, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.05274129981451514}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2486934579956276, &#39;ERDE_50&#39;: 0.1754830128151397, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2486934579956276, &#39;ERDE_50&#39;: 0.1754830128151397, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2486934579956276, &#39;ERDE_50&#39;: 0.1754830128151397, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2486934579956276, &#39;ERDE_50&#39;: 0.1754830128151397, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2486934579956276, &#39;ERDE_50&#39;: 0.1754830128151397, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.95181458699517} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3577   25]
 [ 838  210]]
Evaluating after getting time 167194.654702175
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3577   25]
 [ 838  210]]
Evaluated with elapsed time 140.75605745401117
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526829310647792, &#39;ERDE_50&#39;: 0.13699847425515232, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.9230769230769231, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.5034965034965035, &#39;ERDE_5&#39;: 0.24756792928093643, &#39;ERDE_50&#39;: 0.16250020958034, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.47897056812526057}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643485696474823, &#39;ERDE_50&#39;: 0.18970653164104523, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.3525204817026225}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluating after getting time 167341.877321486
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluated with elapsed time 3.6286545089969877
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 15ms/step - loss: 0.9585 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9585027098655701
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 23ms/step - loss: 0.7868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7867793440818787
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 1.0354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0354331731796265
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.9631 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9630653858184814
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 21ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0042067766189575
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 8s 21ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0042067766189575
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 74.8108342619962
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 74.8108342619962} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3576   26]
 [ 857  191]]
Evaluating after getting time 169830.195258021
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3576   26]
 [ 857  191]]
Evaluated with elapsed time 131.6987585129973
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526871577204025, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2487307851155397, &#39;ERDE_50&#39;: 0.17548301281514134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.24643493568110272, &#39;ERDE_50&#39;: 0.1967987302226042, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31774471261209675}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 913  135]]
Evaluating after getting time 169968.586752378
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 913  135]]
Evaluated with elapsed time 3.034730838990072
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.251560081294698, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.5939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5939057469367981
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5348 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.534772515296936
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.6532 - tp: 9.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1039.0000 - accuracy: 0.7761 - precision: 0.8182 - recall: 0.0086 - f1_metric: 0.0071
Test Score: 0.6532244682312012
Test Accuracy: 9.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.82      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.80      0.50      0.45      4650
weighted avg       0.79      0.78      0.68      4650

[[3600    2]
 [1039    9]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07339449541284404, &#39;ERDE_5&#39;: 0.246437372769449, &#39;ERDE_50&#39;: 0.23698785551811063, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.050655834836693225, &#39;speed&#39;: 0.9493441651633068, &#39;latency_weighted_f1&#39;: 0.06967663597528857}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 16ms/step - loss: 0.7660 - tp: 4.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1044.0000 - accuracy: 0.7748 - precision: 0.5714 - recall: 0.0038 - f1_metric: 0.0039
Test Score: 0.7659893035888672
Test Accuracy: 4.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.57      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.50      0.44      4650
weighted avg       0.73      0.77      0.68      4650

[[3599    3]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470193640767729, &#39;ERDE_50&#39;: 0.2375690916508799, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.068618939459625}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5453248620033264
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 7s 15ms/step - loss: 0.5453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5453248620033264
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 70.72917901800247
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.251560081294698, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 70.72917901800247} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3576   26]
 [ 857  191]]
Evaluating after getting time 173128.564564383
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3576   26]
 [ 857  191]]
Evaluated with elapsed time 121.13483379498939
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526871577204025, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.2487307851155397, &#39;ERDE_50&#39;: 0.17548301281514134, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.9545454545454546, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.33333333333333337, &#39;ERDE_5&#39;: 0.24643493568110272, &#39;ERDE_50&#39;: 0.1967987302226042, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31774471261209675}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 913  135]]
Evaluating after getting time 173256.93047882
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 913  135]]
Evaluated with elapsed time 4.5853747540095355
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.251560081294698, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.9674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9673503637313843
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.8130 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8130253553390503
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9554 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9554456472396851
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.9788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9788213968276978
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.1184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1184122562408447
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 14ms/step - loss: 1.1184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1184122562408447
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 68.1125239529938
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2486894256513244, &#39;ERDE_50&#39;: 0.1825752113966999, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3912341074173494}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701096690799276, &#39;ERDE_50&#39;: 0.20683623113078448, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.2464404541109698, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.251560081294698, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.1125239529938} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 175523.901258858
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 62.47463926798082
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 62.47463926798082}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 175695.763097261
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 80.88131443501334
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 80.88131443501334}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 175997.478110383
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 79.19151275898912
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 79.19151275898912}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 176189.084536769
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 61.916780825005844
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 61.916780825005844}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluating after getting time 176475.676971084
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluated with elapsed time 129.91756977399928
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7413793103448276, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5308641975308641, &#39;ERDE_5&#39;: 0.2544112095309191, &#39;ERDE_50&#39;: 0.15292657981657623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5101709842226279}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluating after getting time 176611.84901026
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluated with elapsed time 4.492514184996253
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 7s 28ms/step - loss: 0.5842 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0044
Test Score: 0.5842463374137878
Test Accuracy: 3.0
146/146 [==============================] - 5s 35ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643826878198014, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.051877609680282245}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.5265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5264641046524048
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5304 - tp: 13.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1035.0000 - accuracy: 0.7748 - precision: 0.5200 - recall: 0.0124 - f1_metric: 0.0081
Test Score: 0.5303769707679749
Test Accuracy: 13.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.52      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.45      4650
weighted avg       0.72      0.77      0.68      4650

[[3590   12]
 [1035   13]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 27ms/step - loss: 0.6067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6066854596138
Test Accuracy: 0.0
146/146 [==============================] - 5s 32ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 8s 40ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 6s 40ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 19ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.4484961470007
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.4484961470007} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluating after getting time 179688.071990183
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluated with elapsed time 137.1581625159888
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7413793103448276, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5308641975308641, &#39;ERDE_5&#39;: 0.2544112095309191, &#39;ERDE_50&#39;: 0.15292657981657623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5101709842226279}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluating after getting time 179833.298375425
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluated with elapsed time 4.743732639006339
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.4593 - tp: 221.0000 - fp: 97.0000 - tn: 3505.0000 - fn: 827.0000 - accuracy: 0.8013 - precision: 0.6950 - recall: 0.2109 - f1_metric: 0.1626
Test Score: 0.45927152037620544
Test Accuracy: 221.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3505   97]
 [ 827  221]]
Finished training and evaluation
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2590667709073719, &#39;ERDE_50&#39;: 0.15284833649101234, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502859177255673}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.8116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8116161227226257
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 5s 17ms/step - loss: 0.4668 - tp: 219.0000 - fp: 100.0000 - tn: 3502.0000 - fn: 829.0000 - accuracy: 0.8002 - precision: 0.6865 - recall: 0.2090 - f1_metric: 0.1638
Test Score: 0.4667632579803467
Test Accuracy: 219.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3502  100]
 [ 829  219]]
Finished training and evaluation
{&#39;precision&#39;: 0.5974025974025974, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5082872928176796, &#39;ERDE_5&#39;: 0.263711534955882, &#39;ERDE_50&#39;: 0.15513415935929992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48847413265155126}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.9446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9445651769638062
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Finished training and evaluation
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Evaluating for elapsed time
146/146 [==============================] - 4s 15ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Evaluated with elapsed time 76.07399809200433
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6851851851851852, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.46835443037974683, &#39;ERDE_5&#39;: 0.2556890811233068, &#39;ERDE_50&#39;: 0.16827344924523452, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44827434233692226}
Writing results to CSV file
{&#39;precision&#39;: 0.6153846153846154, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3356643356643356, &#39;ERDE_5&#39;: 0.25456871544294346, &#39;ERDE_50&#39;: 0.19784383749979395, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31996670360938406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.803921568627451, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5290322580645161, &#39;ERDE_5&#39;: 0.2515285254186919, &#39;ERDE_50&#39;: 0.15474853154044504, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5084104541945529}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24988587192831432, &#39;ERDE_50&#39;: 0.1766454850806766, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8214285714285714, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3484848484848485, &#39;ERDE_5&#39;: 0.2487565122337006, &#39;ERDE_50&#39;: 0.19439554236596712, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.33218765409446477}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7321428571428571, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5125, &#39;ERDE_5&#39;: 0.2544274553762648, &#39;ERDE_50&#39;: 0.15765471220428318, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49252262750097303}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.25220569163032525, &#39;ERDE_50&#39;: 0.1695141648363344, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4466589393014739}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.25108090354722484, &#39;ERDE_50&#39;: 0.1919923545093328, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7818181818181819, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5408805031446541, &#39;ERDE_5&#39;: 0.2526767401628713, &#39;ERDE_50&#39;: 0.15118287141827438, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.51979685184947}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.4383561643835617, &#39;ERDE_5&#39;: 0.2516305039545333, &#39;ERDE_50&#39;: 0.1760251272851268, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41956221304248037}
Writing results to CSV file
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.28787878787878785, &#39;ERDE_5&#39;: 0.251083427121902, &#39;ERDE_50&#39;: 0.20617675167245123, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.27441588816499257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 76.07399809200433} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluating after getting time 183733.255038249
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluated with elapsed time 111.7191919790057
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.2544231936533879, &#39;ERDE_50&#39;: 0.14819844742886934, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5273888932193644}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516279637602737, &#39;ERDE_50&#39;: 0.1642047963158586, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875728160948032, &#39;ERDE_50&#39;: 0.18257521139670205, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3888479632549763}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 788  260]]
Evaluating after getting time 183852.223068363
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 788  260]]
Evaluated with elapsed time 3.1448522319842596
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6164383561643836, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5084745762711865, &#39;ERDE_5&#39;: 0.26196791407830955, &#39;ERDE_50&#39;: 0.1557545171548501, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48865411575127554}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5930 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5930377840995789
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.5290 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5289624333381653
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5513 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.551337480545044
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7310 - tp: 14.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1034.0000 - accuracy: 0.7761 - precision: 0.6667 - recall: 0.0134 - f1_metric: 0.0073
Test Score: 0.7310192584991455
Test Accuracy: 14.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.67      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.72      0.51      0.45      4650
weighted avg       0.75      0.78      0.68      4650

[[3595    7]
 [1034   14]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701950881195792, &#39;ERDE_50&#39;: 0.23756909165087897, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.06734802369421651}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 16ms/step - loss: 0.6108 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0028
Test Score: 0.6107832193374634
Test Accuracy: 3.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643242743810748, &#39;ERDE_50&#39;: 0.23935192171196407, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.053389986720972685}
Evaluating for elapsed time
146/146 [==============================] - 4s 14ms/step - loss: 0.6108 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0028
Test Score: 0.6107832193374634
Test Accuracy: 3.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Evaluated with elapsed time 67.8449884429865
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2515556144753578, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24989472778270055, &#39;ERDE_50&#39;: 0.17664548508067612, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3384615384615385, &#39;ERDE_5&#39;: 0.24817832314340055, &#39;ERDE_50&#39;: 0.19617837242705444, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3219746596842029}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6164383561643836, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5084745762711865, &#39;ERDE_5&#39;: 0.26196791407830955, &#39;ERDE_50&#39;: 0.1557545171548501, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48865411575127554}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.8449884429865} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluating after getting time 187173.651523217
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluated with elapsed time 90.22103918599896
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.2544231936533879, &#39;ERDE_50&#39;: 0.14819844742886934, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5273888932193644}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516279637602737, &#39;ERDE_50&#39;: 0.1642047963158586, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875728160948032, &#39;ERDE_50&#39;: 0.18257521139670205, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3888479632549763}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 788  260]]
Evaluating after getting time 187271.633354803
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 788  260]]
Evaluated with elapsed time 4.182611255993834
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6164383561643836, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5084745762711865, &#39;ERDE_5&#39;: 0.26196791407830955, &#39;ERDE_50&#39;: 0.1557545171548501, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48865411575127554}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.4518 - tp: 282.0000 - fp: 141.0000 - tn: 3461.0000 - fn: 766.0000 - accuracy: 0.8049 - precision: 0.6667 - recall: 0.2691 - f1_metric: 0.2141
Test Score: 0.4518105685710907
Test Accuracy: 282.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.27      0.38      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.63      4650
weighted avg       0.78      0.80      0.77      4650

[[3461  141]
 [ 766  282]]
Finished training and evaluation
{&#39;precision&#39;: 0.6111111111111112, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5670103092783506, &#39;ERDE_5&#39;: 0.2659822572483078, &#39;ERDE_50&#39;: 0.1361825081456909, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5449081118944636}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7674042582511902
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.4526 - tp: 284.0000 - fp: 129.0000 - tn: 3473.0000 - fn: 764.0000 - accuracy: 0.8080 - precision: 0.6877 - recall: 0.2710 - f1_metric: 0.2073
Test Score: 0.45255932211875916
Test Accuracy: 284.0
146/146 [==============================] - 4s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.89      3602
           1       0.69      0.27      0.39      1048

    accuracy                           0.81      4650
   macro avg       0.75      0.62      0.64      4650
weighted avg       0.79      0.81      0.77      4650

[[3473  129]
 [ 764  284]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6073298429319371, &#39;ERDE_5&#39;: 0.2624860432742776, &#39;ERDE_50&#39;: 0.12560289276752482, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.583655980488958}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.9993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9993101954460144
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 16ms/step - loss: 0.9868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9867957234382629
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 9s 24ms/step - loss: 0.9868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9867957234382629
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 81.06823335398803
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6073298429319371, &#39;ERDE_5&#39;: 0.2624860432742776, &#39;ERDE_50&#39;: 0.12560289276752482, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.583655980488958}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.6857142857142857, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5517241379310346, &#39;ERDE_5&#39;: 0.2585776141381924, &#39;ERDE_50&#39;: 0.14517490177668715, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5280696819327771}
Writing results to CSV file
{&#39;precision&#39;: 0.6792452830188679, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4585987261146497, &#39;ERDE_5&#39;: 0.25572381629884605, &#39;ERDE_50&#39;: 0.17063751543908998, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43715196130071904}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7424242424242424, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5764705882352942, &#39;ERDE_5&#39;: 0.2555622327236183, &#39;ERDE_50&#39;: 0.1399046549189914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5539996269164461}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.25219980418709026, &#39;ERDE_50&#39;: 0.1553297676732144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510803803294542, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515393353848523, &#39;ERDE_50&#39;: 0.15002039915273763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5242857431291186}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24988816478746012, &#39;ERDE_50&#39;: 0.16482515411140958, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4687965543688939}
Writing results to CSV file
{&#39;precision&#39;: 0.8620689655172413, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.37593984962406013, &#39;ERDE_5&#39;: 0.24817752703923138, &#39;ERDE_50&#39;: 0.189086173845493, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.35689601378243324}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7166666666666667, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.524390243902439, &#39;ERDE_5&#39;: 0.25557850719374064, &#39;ERDE_50&#39;: 0.1540890520821111, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5039493868540593}
Writing results to CSV file
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25220654931695946, &#39;ERDE_50&#39;: 0.16478603244862827, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.3971631205673759, &#39;ERDE_5&#39;: 0.2510812442739233, &#39;ERDE_50&#39;: 0.184900155927776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3785894448144131}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7424242424242424, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5764705882352942, &#39;ERDE_5&#39;: 0.2555622327236183, &#39;ERDE_50&#39;: 0.1399046549189914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5539996269164461}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.25219980418709026, &#39;ERDE_50&#39;: 0.1553297676732144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510803803294542, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7540983606557377, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5575757575757575, &#39;ERDE_5&#39;: 0.2544150826661151, &#39;ERDE_50&#39;: 0.14583438123501644, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5358413212723077}
Writing results to CSV file
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25220501187122263, &#39;ERDE_50&#39;: 0.16478603244862813, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.38848920863309355, &#39;ERDE_5&#39;: 0.2505011237354961, &#39;ERDE_50&#39;: 0.18668298598886, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3703211758500696}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7424242424242424, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5764705882352942, &#39;ERDE_5&#39;: 0.2555622327236183, &#39;ERDE_50&#39;: 0.1399046549189914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5539996269164461}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.25219980418709026, &#39;ERDE_50&#39;: 0.1553297676732144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510803803294542, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7424242424242424, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5764705882352942, &#39;ERDE_5&#39;: 0.2555622327236183, &#39;ERDE_50&#39;: 0.1399046549189914, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5539996269164461}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.25219980418709026, &#39;ERDE_50&#39;: 0.1553297676732144, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510803803294542, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6164383561643836, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5084745762711865, &#39;ERDE_5&#39;: 0.26196791407830955, &#39;ERDE_50&#39;: 0.1557545171548501, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48865411575127554}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 81.06823335398803} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 190481.35205792
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 70.7956882819999
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 70.7956882819999}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 190683.838304068
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 68.34135214000707
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 68.34135214000707}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 190934.910104348
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 87.86683518000063
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 87.86683518000063}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 191199.692403571
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 130.14839559298707
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 130.14839559298707}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3578   24]
 [ 837  211]]
Evaluating after getting time 191654.81291105
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3578   24]
 [ 837  211]]
Evaluated with elapsed time 153.9409145770187
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526829310647792, &#39;ERDE_50&#39;: 0.13699847425515232, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.9230769230769231, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.5034965034965035, &#39;ERDE_5&#39;: 0.24756792928093643, &#39;ERDE_50&#39;: 0.16250020958034, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.47897056812526057}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643485696474823, &#39;ERDE_50&#39;: 0.18970653164104523, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.3525204817026225}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluating after getting time 191813.59740915
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluated with elapsed time 4.10579682799289
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 22ms/step - loss: 0.5956 - tp: 0.0000e+00 - fp: 1.0000 - tn: 3601.0000 - fn: 1048.0000 - accuracy: 0.7744 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.595599889755249
Test Accuracy: 0.0
146/146 [==============================] - 4s 24ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3601    1]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.5245 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.524502694606781
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5558697581291199
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.7403 - tp: 7.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1041.0000 - accuracy: 0.7757 - precision: 0.7778 - recall: 0.0067 - f1_metric: 0.0055
Test Score: 0.7402687072753906
Test Accuracy: 7.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.78      0.01      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.78      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3600    2]
 [1041    7]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07339449541284404, &#39;ERDE_5&#39;: 0.24643798231471994, &#39;ERDE_50&#39;: 0.23698785551811238, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231063877162524, &#39;speed&#39;: 0.9376893612283748, &#39;latency_weighted_f1&#39;: 0.06882123752134861}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470923781394958
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 16ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470923781394958
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 71.31355640399852
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 71.31355640399852} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3578   24]
 [ 837  211]]
Evaluating after getting time 195106.535592196
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.90      0.20      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.77      4650

[[3578   24]
 [ 837  211]]
Evaluated with elapsed time 95.04014944599476
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526829310647792, &#39;ERDE_50&#39;: 0.13699847425515232, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.9230769230769231, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.5034965034965035, &#39;ERDE_5&#39;: 0.24756792928093643, &#39;ERDE_50&#39;: 0.16250020958034, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.47897056812526057}
Writing results to CSV file
{&#39;precision&#39;: 0.96, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.37209302325581395, &#39;ERDE_5&#39;: 0.24643485696474823, &#39;ERDE_50&#39;: 0.18970653164104523, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.3525204817026225}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluating after getting time 195206.466046472
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.79      0.12      0.21      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.56      0.55      4650
weighted avg       0.79      0.79      0.73      4650

[[3567   35]
 [ 920  128]]
Evaluated with elapsed time 4.748245648021111
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.9584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9584147334098816
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7878 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7877808213233948
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 1.0354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0354036092758179
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9631 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.96307772397995
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0041662454605103
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0041662454605103
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 64.35808043499128
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8611111111111112, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4428571428571429, &#39;ERDE_5&#39;: 0.24869345862092987, &#39;ERDE_50&#39;: 0.1754830128151411, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42387021790854157}
Writing results to CSV file
{&#39;precision&#39;: 0.8947368421052632, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2764227642276423, &#39;ERDE_5&#39;: 0.24701228209151668, &#39;ERDE_50&#39;: 0.20683623113078387, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2613450613387886}
Writing results to CSV file
{&#39;precision&#39;: 0.9166666666666666, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.1896551724137931, &#39;ERDE_5&#39;: 0.24644102159130304, &#39;ERDE_50&#39;: 0.2204393921611367, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.17857298395074137}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25215380161488077, &#39;ERDE_50&#39;: 0.16478603244862924, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.2481669511809944, &#39;ERDE_50&#39;: 0.19854243862090565, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.11538461538461539, &#39;F1&#39;: 0.20338983050847456, &#39;ERDE_5&#39;: 0.2470202321308259, &#39;ERDE_50&#39;: 0.218656562100051, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.19348246113534534}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 64.35808043499128} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3574   28]
 [ 857  191]]
Evaluating after getting time 197684.200392686
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3574   28]
 [ 857  191]]
Evaluated with elapsed time 115.88977714398061
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.25268794978713593, &#39;ERDE_50&#39;: 0.13699847425515338, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.2493123122380799, &#39;ERDE_50&#39;: 0.17606424894790929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42086404615032497}
Writing results to CSV file
{&#39;precision&#39;: 0.9523809523809523, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.32, &#39;ERDE_5&#39;: 0.24643648177764904, &#39;ERDE_50&#39;: 0.1991627964164576, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.30316761426425537}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 912  136]]
Evaluating after getting time 197807.808862552
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 912  136]]
Evaluated with elapsed time 2.516134361998411
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2515579669926352, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5938882827758789
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5347 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5347276926040649
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5435420870780945
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7629 - tp: 5.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1043.0000 - accuracy: 0.7751 - precision: 0.6250 - recall: 0.0048 - f1_metric: 0.0051
Test Score: 0.7629133462905884
Test Accuracy: 5.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.62      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.70      0.50      0.44      4650
weighted avg       0.74      0.78      0.68      4650

[[3599    3]
 [1043    5]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470193640767729, &#39;ERDE_50&#39;: 0.2375690916508799, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.068618939459625}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5452309250831604
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 3s 13ms/step - loss: 0.5452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5452309250831604
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 63.923944818991004
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2515579669926352, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 63.923944818991004} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3574   28]
 [ 857  191]]
Evaluating after getting time 200658.792305838
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.87      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3574   28]
 [ 857  191]]
Evaluated with elapsed time 85.9801801959984
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.25268794978713593, &#39;ERDE_50&#39;: 0.13699847425515338, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8378378378378378, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4397163120567376, &#39;ERDE_5&#39;: 0.2493123122380799, &#39;ERDE_50&#39;: 0.17606424894790929, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.42086404615032497}
Writing results to CSV file
{&#39;precision&#39;: 0.9523809523809523, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.32, &#39;ERDE_5&#39;: 0.24643648177764904, &#39;ERDE_50&#39;: 0.1991627964164576, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.30316761426425537}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 912  136]]
Evaluating after getting time 200751.202110363
              precision    recall  f1-score   support

           0       0.80      0.99      0.88      3602
           1       0.81      0.13      0.22      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.56      0.55      4650
weighted avg       0.80      0.80      0.73      4650

[[3571   31]
 [ 912  136]]
Evaluated with elapsed time 3.2612623810127843
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2515579669926352, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.9665 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9664586186408997
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.8136 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.813572108745575
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.9550 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9550172090530396
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.9789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9789014458656311
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 1.1166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1166073083877563
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 1.1166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1166073083877563
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.22454883300816
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8529411764705882, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.42028985507246375, &#39;ERDE_5&#39;: 0.24868938616805764, &#39;ERDE_50&#39;: 0.18021114520284648, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4022704732839361}
Writing results to CSV file
{&#39;precision&#39;: 0.85, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.2741935483870968, &#39;ERDE_5&#39;: 0.24759220304076052, &#39;ERDE_50&#39;: 0.20741746726355217, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.25923743987637904}
Writing results to CSV file
{&#39;precision&#39;: 0.9285714285714286, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.22033898305084745, &#39;ERDE_5&#39;: 0.24644120741760953, &#39;ERDE_50&#39;: 0.21571125977343064, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.20746383651596148}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2515579669926352, &#39;ERDE_50&#39;: 0.1689329287035646, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4514857937478227}
Writing results to CSV file
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3333333333333333, &#39;ERDE_5&#39;: 0.24932927831821036, &#39;ERDE_50&#39;: 0.1973408446925883, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.31579959819193265}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24590163934426226, &#39;ERDE_5&#39;: 0.2476016088027231, &#39;ERDE_50&#39;: 0.21214559965125923, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.23153278097935168}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.22454883300816} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluating after getting time 203028.614368018
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluated with elapsed time 62.77283380800509
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 62.77283380800509}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluating after getting time 203183.867180462
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluated with elapsed time 54.04216916899895
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 54.04216916899895}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluating after getting time 203439.966807199
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluated with elapsed time 60.51712040399434
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 60.51712040399434}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluating after getting time 203601.600566382
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.33      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 831  217]]
Evaluated with elapsed time 59.69458044401836
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 59.69458044401836}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluating after getting time 203907.333871815
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluated with elapsed time 90.46289667498786
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7413793103448276, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5308641975308641, &#39;ERDE_5&#39;: 0.2544112095309191, &#39;ERDE_50&#39;: 0.15292657981657623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5101709842226279}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluating after getting time 204003.338110058
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluated with elapsed time 3.732109394011786
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5842 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0044
Test Score: 0.5842463374137878
Test Accuracy: 3.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643826878198014, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.051877609680282245}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5264641046524048
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5304 - tp: 13.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1035.0000 - accuracy: 0.7748 - precision: 0.5200 - recall: 0.0124 - f1_metric: 0.0081
Test Score: 0.5303769707679749
Test Accuracy: 13.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.52      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.45      4650
weighted avg       0.72      0.77      0.68      4650

[[3590   12]
 [1035   13]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.6067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6066854596138
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 3s 13ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.86276445898693
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7727272727272727, &#39;recall&#39;: 0.3269230769230769, &#39;F1&#39;: 0.45945945945945943, &#39;ERDE_5&#39;: 0.2515541530710786, &#39;ERDE_50&#39;: 0.17129699489741773, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.44154961990858493}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989302382815853, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875806019816332, &#39;ERDE_50&#39;: 0.19675960855982208, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.86276445898693} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluating after getting time 206717.245129308
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.22      0.35      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3560   42]
 [ 813  235]]
Evaluated with elapsed time 66.50381702301092
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7413793103448276, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5308641975308641, &#39;ERDE_5&#39;: 0.2544112095309191, &#39;ERDE_50&#39;: 0.15292657981657623, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5101709842226279}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluating after getting time 206790.445932027
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3475  127]
 [ 787  261]]
Evaluated with elapsed time 3.600708037993172
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 6s 16ms/step - loss: 0.4593 - tp: 221.0000 - fp: 97.0000 - tn: 3505.0000 - fn: 827.0000 - accuracy: 0.8013 - precision: 0.6950 - recall: 0.2109 - f1_metric: 0.1626
Test Score: 0.45927152037620544
Test Accuracy: 221.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3505   97]
 [ 827  221]]
Finished training and evaluation
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2590667709073719, &#39;ERDE_50&#39;: 0.15284833649101234, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502859177255673}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.8116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8116161227226257
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.4668 - tp: 219.0000 - fp: 100.0000 - tn: 3502.0000 - fn: 829.0000 - accuracy: 0.8002 - precision: 0.6865 - recall: 0.2090 - f1_metric: 0.1638
Test Score: 0.4667632579803467
Test Accuracy: 219.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3502  100]
 [ 829  219]]
Finished training and evaluation
{&#39;precision&#39;: 0.5974025974025974, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5082872928176796, &#39;ERDE_5&#39;: 0.263711534955882, &#39;ERDE_50&#39;: 0.15513415935929992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48847413265155126}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9445651769638062
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Finished training and evaluation
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Evaluating for elapsed time
146/146 [==============================] - 4s 13ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Evaluated with elapsed time 67.4076970499882
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6851851851851852, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.46835443037974683, &#39;ERDE_5&#39;: 0.2556890811233068, &#39;ERDE_50&#39;: 0.16827344924523452, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44827434233692226}
Writing results to CSV file
{&#39;precision&#39;: 0.6153846153846154, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3356643356643356, &#39;ERDE_5&#39;: 0.25456871544294346, &#39;ERDE_50&#39;: 0.19784383749979395, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31996670360938406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.803921568627451, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5290322580645161, &#39;ERDE_5&#39;: 0.2515285254186919, &#39;ERDE_50&#39;: 0.15474853154044504, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5084104541945529}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.24988587192831432, &#39;ERDE_50&#39;: 0.1766454850806766, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8214285714285714, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.3484848484848485, &#39;ERDE_5&#39;: 0.2487565122337006, &#39;ERDE_50&#39;: 0.19439554236596712, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.33218765409446477}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7321428571428571, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5125, &#39;ERDE_5&#39;: 0.2544274553762648, &#39;ERDE_50&#39;: 0.15765471220428318, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49252262750097303}
Writing results to CSV file
{&#39;precision&#39;: 0.7608695652173914, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4666666666666667, &#39;ERDE_5&#39;: 0.25220569163032525, &#39;ERDE_50&#39;: 0.1695141648363344, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4466589393014739}
Writing results to CSV file
{&#39;precision&#39;: 0.7352941176470589, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36231884057971014, &#39;ERDE_5&#39;: 0.25108090354722484, &#39;ERDE_50&#39;: 0.1919923545093328, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34537468762184426}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7818181818181819, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5408805031446541, &#39;ERDE_5&#39;: 0.2526767401628713, &#39;ERDE_50&#39;: 0.15118287141827438, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.51979685184947}
Writing results to CSV file
{&#39;precision&#39;: 0.7619047619047619, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.4383561643835617, &#39;ERDE_5&#39;: 0.2516305039545333, &#39;ERDE_50&#39;: 0.1760251272851268, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41956221304248037}
Writing results to CSV file
{&#39;precision&#39;: 0.6785714285714286, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.28787878787878785, &#39;ERDE_5&#39;: 0.251083427121902, &#39;ERDE_50&#39;: 0.20617675167245123, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.27441588816499257}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7580645161290323, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5662650602409639, &#39;ERDE_5&#39;: 0.25440186720714497, &#39;ERDE_50&#39;: 0.1434703150411639, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5441919128426855}
Writing results to CSV file
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25219853973048106, &#39;ERDE_50&#39;: 0.16242196625477356, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4754352855309806}
Writing results to CSV file
{&#39;precision&#39;: 0.7428571428571429, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.37410071942446044, &#39;ERDE_5&#39;: 0.25107935558276206, &#39;ERDE_50&#39;: 0.18962828831547782, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3566055767445114}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6197183098591549, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5028571428571429, &#39;ERDE_5&#39;: 0.2613801199017607, &#39;ERDE_50&#39;: 0.15753734721593576, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4832556512344043}
Writing results to CSV file
{&#39;precision&#39;: 0.6833333333333333, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25685055590566425, &#39;ERDE_50&#39;: 0.15997965673535627, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.717391304347826, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.44, &#39;ERDE_5&#39;: 0.25340319131625794, &#39;ERDE_50&#39;: 0.17540476948957764, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.41942302064796766}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.4076970499882} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.83      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.82      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3557   45]
 [ 822  226]]
Evaluating after getting time 210265.8527321
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.83      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.82      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3557   45]
 [ 822  226]]
Evaluated with elapsed time 155.5085844619898
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7796610169491526, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5644171779141105, &#39;ERDE_5&#39;: 0.2532585676025228, &#39;ERDE_50&#39;: 0.14467190896948043, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5424160614106183}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516272770513196, &#39;ERDE_50&#39;: 0.16420479631585844, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933851711694585, &#39;ERDE_50&#39;: 0.18315644752946836, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3860302243908098}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.97      0.88      3602
           1       0.68      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3477  125]
 [ 787  261]]
Evaluating after getting time 210429.465809205
              precision    recall  f1-score   support

           0       0.82      0.97      0.88      3602
           1       0.68      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3477  125]
 [ 787  261]]
Evaluated with elapsed time 2.733873715013033
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5113636363636364, &#39;ERDE_5&#39;: 0.2613866779455418, &#39;ERDE_50&#39;: 0.15517328102208233, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4914305595907713}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 12ms/step - loss: 0.5917 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.591661810874939
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.5209 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5208550095558167
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 19ms/step - loss: 0.6708 - tp: 5.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1043.0000 - accuracy: 0.7751 - precision: 0.6250 - recall: 0.0048 - f1_metric: 0.0041
Test Score: 0.670792281627655
Test Accuracy: 5.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.62      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.70      0.50      0.44      4650
weighted avg       0.74      0.78      0.68      4650

[[3599    3]
 [1043    5]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.2464440413269907, &#39;ERDE_50&#39;: 0.2417159879058174, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.03519875299623789}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 18ms/step - loss: 0.7520 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0145
Test Score: 0.7519775629043579
Test Accuracy: 15.0
146/146 [==============================] - 2s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701351728348284, &#39;ERDE_50&#39;: 0.23284095926317186, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.10109040188248324}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 26ms/step - loss: 0.5439 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5439128279685974
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 15ms/step - loss: 0.5439 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5439128279685974
Test Accuracy: 0.0
146/146 [==============================] - 2s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 62.23788772398257
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5113636363636364, &#39;ERDE_5&#39;: 0.2613866779455418, &#39;ERDE_50&#39;: 0.15517328102208233, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4914305595907713}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 62.23788772398257} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.83      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.82      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3557   45]
 [ 822  226]]
Evaluating after getting time 213636.005617823
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.83      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.82      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3557   45]
 [ 822  226]]
Evaluated with elapsed time 96.75709906901466
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7796610169491526, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5644171779141105, &#39;ERDE_5&#39;: 0.2532585676025228, &#39;ERDE_50&#39;: 0.14467190896948043, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5424160614106183}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516272770513196, &#39;ERDE_50&#39;: 0.16420479631585844, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.4057971014492754, &#39;ERDE_5&#39;: 0.24933851711694585, &#39;ERDE_50&#39;: 0.18315644752946836, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3860302243908098}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.82      0.97      0.88      3602
           1       0.68      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3477  125]
 [ 787  261]]
Evaluating after getting time 213740.590768765
              precision    recall  f1-score   support

           0       0.82      0.97      0.88      3602
           1       0.68      0.25      0.36      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.61      0.62      4650
weighted avg       0.78      0.80      0.77      4650

[[3477  125]
 [ 787  261]]
Evaluated with elapsed time 4.730700574000366
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5113636363636364, &#39;ERDE_5&#39;: 0.2613866779455418, &#39;ERDE_50&#39;: 0.15517328102208233, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4914305595907713}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 1.0158 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0157561302185059
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.7615 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7614580988883972
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 3s 12ms/step - loss: 0.4701 - tp: 270.0000 - fp: 145.0000 - tn: 3457.0000 - fn: 778.0000 - accuracy: 0.8015 - precision: 0.6506 - recall: 0.2576 - f1_metric: 0.1963
Test Score: 0.47006726264953613
Test Accuracy: 270.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.65      0.26      0.37      1048

    accuracy                           0.80      4650
   macro avg       0.73      0.61      0.63      4650
weighted avg       0.78      0.80      0.77      4650

[[3457  145]
 [ 778  270]]
Finished training and evaluation
{&#39;precision&#39;: 0.6086956521739131, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2665697818600151, &#39;ERDE_50&#39;: 0.13439967808460837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5491541491300049}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0127419233322144
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.9733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9733266234397888
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 0.9733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9733266234397888
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.48915849300101
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7916666666666666, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5, &#39;ERDE_5&#39;: 0.25155482168545124, &#39;ERDE_50&#39;: 0.1618407301220041, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.47856314925157917}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989483510626725, &#39;ERDE_50&#39;: 0.17900955127452955, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4072877865970886}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.2487595592761683, &#39;ERDE_50&#39;: 0.19675960855982216, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3195168378545524}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.625, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5113636363636364, &#39;ERDE_5&#39;: 0.2613866779455418, &#39;ERDE_50&#39;: 0.15517328102208233, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4914305595907713}
Writing results to CSV file
{&#39;precision&#39;: 0.6615384615384615, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5088757396449703, &#39;ERDE_5&#39;: 0.2585955106977907, &#39;ERDE_50&#39;: 0.15699523274595287, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4870583530844474}
Writing results to CSV file
{&#39;precision&#39;: 0.7021276595744681, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.43708609271523174, &#39;ERDE_5&#39;: 0.25398628767752435, &#39;ERDE_50&#39;: 0.17598600562234762, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.414944795891682}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.48915849300101} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluating after getting time 216519.405170558
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluated with elapsed time 55.06292191101238
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.2521198039434659, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 55.06292191101238}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluating after getting time 216678.79165598
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluated with elapsed time 52.56637382801273
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.2521198039434659, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 52.56637382801273}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluating after getting time 216895.617393996
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluated with elapsed time 49.81233688798966
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.2521198039434659, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 49.81233688798966}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 5000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-5000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluating after getting time 217030.840957351
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.81      0.80      0.75      4650

[[3562   40]
 [ 872  176]]
Evaluated with elapsed time 48.49128003101214
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.2521198039434659, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 5000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 48.49128003101214}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 841  207]]
Evaluating after getting time 217290.210966566
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 841  207]]
Evaluated with elapsed time 123.17616527801147
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532663209828765, &#39;ERDE_50&#39;: 0.1399437765817735, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5568734827654739}
Writing results to CSV file
{&#39;precision&#39;: 0.9210526315789473, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.49295774647887325, &#39;ERDE_5&#39;: 0.247568722070843, &#39;ERDE_50&#39;: 0.16486427577419344, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46798618145274}
Writing results to CSV file
{&#39;precision&#39;: 0.9583333333333334, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.359375, &#39;ERDE_5&#39;: 0.24643514867769387, &#39;ERDE_50&#39;: 0.19207059783489866, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.33977260042621}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3569   33]
 [ 930  118]]
Evaluating after getting time 217419.703331709
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3569   33]
 [ 930  118]]
Evaluated with elapsed time 3.7557355600001756
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.48, &#39;ERDE_5&#39;: 0.2515785957734392, &#39;ERDE_50&#39;: 0.16656886250971528, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.459420623281516}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00023: early stopping
Evaluating
146/146 [==============================] - 7s 28ms/step - loss: 0.7576 - tp: 2.0000 - fp: 1.0000 - tn: 3601.0000 - fn: 1046.0000 - accuracy: 0.7748 - precision: 0.6667 - recall: 0.0019 - f1_metric: 0.0020
Test Score: 0.7576147317886353
Test Accuracy: 2.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.67      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.72      0.50      0.44      4650
weighted avg       0.75      0.77      0.68      4650

[[3601    1]
 [1046    2]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827458266893, &#39;ERDE_50&#39;: 0.241715987905818, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05841121951671113, &#39;speed&#39;: 0.9415887804832889, &#39;latency_weighted_f1&#39;: 0.03519958057881453}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 27ms/step - loss: 0.5245 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5245046615600586
Test Accuracy: 0.0
146/146 [==============================] - 4s 25ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 19ms/step - loss: 0.5559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5558797717094421
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.7413 - tp: 6.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1042.0000 - accuracy: 0.7755 - precision: 0.7500 - recall: 0.0057 - f1_metric: 0.0048
Test Score: 0.7413125038146973
Test Accuracy: 6.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.75      0.01      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.76      0.50      0.44      4650
weighted avg       0.77      0.78      0.68      4650

[[3600    2]
 [1042    6]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464379824125908, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.05274129981451514}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470939874649048
Test Accuracy: 0.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 13ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470939874649048
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.68287783002597
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.2464379824125908, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.05274129981451514}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.009615384615384616, &#39;F1&#39;: 0.01886792452830189, &#39;ERDE_5&#39;: 0.24644401296995758, &#39;ERDE_50&#39;: 0.24408005409967082, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.01783875834887403}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456076074145, &#39;ERDE_50&#39;: 0.17962990907007859, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456076074145, &#39;ERDE_50&#39;: 0.17962990907007859, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456076074145, &#39;ERDE_50&#39;: 0.17962990907007859, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.24643827412553637, &#39;ERDE_50&#39;: 0.24171598790581764, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.056472456613507305, &#39;speed&#39;: 0.9435275433864927, &#39;latency_weighted_f1&#39;: 0.03527205769669131}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456076074145, &#39;ERDE_50&#39;: 0.17962990907007859, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456076074145, &#39;ERDE_50&#39;: 0.17962990907007859, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.48, &#39;ERDE_5&#39;: 0.2515785957734392, &#39;ERDE_50&#39;: 0.16656886250971528, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.459420623281516}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.68287783002597} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 841  207]]
Evaluating after getting time 220844.366930903
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 841  207]]
Evaluated with elapsed time 92.2554594569956
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7868852459016393, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5818181818181818, &#39;ERDE_5&#39;: 0.2532663209828765, &#39;ERDE_50&#39;: 0.1399437765817735, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5568734827654739}
Writing results to CSV file
{&#39;precision&#39;: 0.9210526315789473, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.49295774647887325, &#39;ERDE_5&#39;: 0.247568722070843, &#39;ERDE_50&#39;: 0.16486427577419344, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46798618145274}
Writing results to CSV file
{&#39;precision&#39;: 0.9583333333333334, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.359375, &#39;ERDE_5&#39;: 0.24643514867769387, &#39;ERDE_50&#39;: 0.19207059783489866, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.33977260042621}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3569   33]
 [ 930  118]]
Evaluating after getting time 220941.236703505
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.79      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3569   33]
 [ 930  118]]
Evaluated with elapsed time 3.27768494898919
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.48, &#39;ERDE_5&#39;: 0.2515785957734392, &#39;ERDE_50&#39;: 0.16656886250971528, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.459420623281516}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9585 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9585027098655701
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.7868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7867793440818787
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 13ms/step - loss: 1.0354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0354331731796265
Test Accuracy: 0.0
146/146 [==============================] - 2s 10ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.9631 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9630653858184814
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 17ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0042067766189575
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 7s 26ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0042067766189575
Test Accuracy: 0.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.51488883499405
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.24811456138604368, &#39;ERDE_50&#39;: 0.17962990907008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.782608695652174, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.48, &#39;ERDE_5&#39;: 0.2515785957734392, &#39;ERDE_50&#39;: 0.16656886250971528, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.459420623281516}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.51488883499405} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3577   25]
 [ 858  190]]
Evaluating after getting time 223398.267989476
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3577   25]
 [ 858  190]]
Evaluated with elapsed time 108.64388806998613
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526869733310236, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.2481495688515637, &#39;ERDE_50&#39;: 0.17962990907008042, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.95, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.3064516129032258, &#39;ERDE_5&#39;: 0.24643498050792578, &#39;ERDE_50&#39;: 0.20152686261031102, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29212013901434697}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.21      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.80      0.73      4650

[[3574   28]
 [ 925  123]]
Evaluating after getting time 223512.421299383
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.21      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.80      0.73      4650

[[3574   28]
 [ 925  123]]
Evaluated with elapsed time 5.11637894102023
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156636525929177, &#39;ERDE_50&#39;: 0.1783891934789783, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3125, &#39;ERDE_5&#39;: 0.24816904220353975, &#39;ERDE_50&#39;: 0.20090650481475963, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.29606212330493686}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23140495867768596, &#39;ERDE_5&#39;: 0.2476016482859899, &#39;ERDE_50&#39;: 0.21450966584511266, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.21833298918971586}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5939057469367981
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 28ms/step - loss: 0.5348 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.534772515296936
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 23ms/step - loss: 0.6532 - tp: 9.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1039.0000 - accuracy: 0.7761 - precision: 0.8182 - recall: 0.0086 - f1_metric: 0.0071
Test Score: 0.6532244682312012
Test Accuracy: 9.0
146/146 [==============================] - 4s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.82      0.01      0.02      1048

    accuracy                           0.78      4650
   macro avg       0.80      0.50      0.45      4650
weighted avg       0.79      0.78      0.68      4650

[[3600    2]
 [1039    9]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07339449541284404, &#39;ERDE_5&#39;: 0.246437372769449, &#39;ERDE_50&#39;: 0.23698785551811063, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.050655834836693225, &#39;speed&#39;: 0.9493441651633068, &#39;latency_weighted_f1&#39;: 0.06967663597528857}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 7s 29ms/step - loss: 0.7660 - tp: 4.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1044.0000 - accuracy: 0.7748 - precision: 0.5714 - recall: 0.0038 - f1_metric: 0.0039
Test Score: 0.7659893035888672
Test Accuracy: 4.0
146/146 [==============================] - 5s 33ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.57      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.67      0.50      0.44      4650
weighted avg       0.73      0.77      0.68      4650

[[3599    3]
 [1044    4]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470193640767729, &#39;ERDE_50&#39;: 0.2375690916508799, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.068618939459625}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 18ms/step - loss: 0.5453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5453248620033264
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 11s 27ms/step - loss: 0.5453 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5453248620033264
Test Accuracy: 0.0
146/146 [==============================] - 4s 23ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 75.3109890880005
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156636525929177, &#39;ERDE_50&#39;: 0.1783891934789783, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3125, &#39;ERDE_5&#39;: 0.24816904220353975, &#39;ERDE_50&#39;: 0.20090650481475963, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.29606212330493686}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23140495867768596, &#39;ERDE_5&#39;: 0.2476016482859899, &#39;ERDE_50&#39;: 0.21450966584511266, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.21833298918971586}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 75.3109890880005} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3577   25]
 [ 858  190]]
Evaluating after getting time 227136.103085942
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.18      0.30      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3577   25]
 [ 858  190]]
Evaluated with elapsed time 170.50680505597848
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8032786885245902, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.593939393939394, &#39;ERDE_5&#39;: 0.2526869733310236, &#39;ERDE_50&#39;: 0.13699847425515316, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5684750136564214}
Writing results to CSV file
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.2481495688515637, &#39;ERDE_50&#39;: 0.17962990907008042, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4052067541108262}
Writing results to CSV file
{&#39;precision&#39;: 0.95, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.3064516129032258, &#39;ERDE_5&#39;: 0.24643498050792578, &#39;ERDE_50&#39;: 0.20152686261031102, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29212013901434697}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.21      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.80      0.73      4650

[[3574   28]
 [ 925  123]]
Evaluating after getting time 227314.988624652
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.21      1048

    accuracy                           0.80      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.80      0.73      4650

[[3574   28]
 [ 925  123]]
Evaluated with elapsed time 2.8871357209864073
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156636525929177, &#39;ERDE_50&#39;: 0.1783891934789783, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3125, &#39;ERDE_5&#39;: 0.24816904220353975, &#39;ERDE_50&#39;: 0.20090650481475963, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.29606212330493686}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23140495867768596, &#39;ERDE_5&#39;: 0.2476016482859899, &#39;ERDE_50&#39;: 0.21450966584511266, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.21833298918971586}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.9674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9673503637313843
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 28ms/step - loss: 0.8130 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8130253553390503
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 13ms/step - loss: 0.9554 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9554456472396851
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.9788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9788213968276978
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 9s 24ms/step - loss: 1.1184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1184122562408447
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 14ms/step - loss: 1.1184 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1184122562408447
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.47907115000999
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8666666666666667, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.2184873949579832, &#39;ERDE_5&#39;: 0.24701332490765984, &#39;ERDE_50&#39;: 0.21629249590619815, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.20741956565708475}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17543859649122806, &#39;ERDE_5&#39;: 0.2458593022882919, &#39;ERDE_50&#39;: 0.2222222222222231, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.16621031483785928}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156636525929177, &#39;ERDE_50&#39;: 0.1783891934789783, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.8333333333333334, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3125, &#39;ERDE_5&#39;: 0.24816904220353975, &#39;ERDE_50&#39;: 0.20090650481475963, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.29606212330493686}
Writing results to CSV file
{&#39;precision&#39;: 0.8235294117647058, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23140495867768596, &#39;ERDE_5&#39;: 0.2476016482859899, &#39;ERDE_50&#39;: 0.21450966584511266, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.21833298918971586}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.47907115000999} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 229835.828128364
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 107.97977325099055
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 107.97977325099055}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 230123.387319146
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 110.7050758790283
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 110.7050758790283}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 230521.621606647
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 118.67554276098963
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 118.67554276098963}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluating after getting time 230875.508191709
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.48      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.68      4650

[[3578   24]
 [1026   22]]
Evaluated with elapsed time 157.31571589800296
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24933276462291873, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.0510275979280093}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.42857142857142855, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05405405405405405, &#39;ERDE_5&#39;: 0.24818545032210787, &#39;ERDE_50&#39;: 0.24109563011026722, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.051526169612772434}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 157.31571589800296}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluating after getting time 231360.424531111
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluated with elapsed time 133.68058070298866
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7288135593220338, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5276073619631901, &#39;ERDE_5&#39;: 0.2549924456636869, &#39;ERDE_50&#39;: 0.15350781594934398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5070411008838387}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluating after getting time 231502.403846236
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluated with elapsed time 4.38302122199093
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.5842 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0044
Test Score: 0.5842463374137878
Test Accuracy: 3.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643826878198014, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.051877609680282245}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5264641046524048
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.5304 - tp: 13.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1035.0000 - accuracy: 0.7748 - precision: 0.5200 - recall: 0.0124 - f1_metric: 0.0081
Test Score: 0.5303769707679749
Test Accuracy: 13.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.52      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.45      4650
weighted avg       0.72      0.77      0.68      4650

[[3590   12]
 [1035   13]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.6067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6066854596138
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 20ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 14ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 73.5583518499916
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 73.5583518499916} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluating after getting time 234392.55991449
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluated with elapsed time 189.2219922420045
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7288135593220338, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5276073619631901, &#39;ERDE_5&#39;: 0.2549924456636869, &#39;ERDE_50&#39;: 0.15350781594934398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5070411008838387}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluating after getting time 234588.597767926
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluated with elapsed time 4.475996818015119
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.4593 - tp: 221.0000 - fp: 97.0000 - tn: 3505.0000 - fn: 827.0000 - accuracy: 0.8013 - precision: 0.6950 - recall: 0.2109 - f1_metric: 0.1626
Test Score: 0.45927152037620544
Test Accuracy: 221.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3505   97]
 [ 827  221]]
Finished training and evaluation
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2590667709073719, &#39;ERDE_50&#39;: 0.15284833649101234, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502859177255673}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 19ms/step - loss: 0.8116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8116161227226257
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 5s 17ms/step - loss: 0.4668 - tp: 219.0000 - fp: 100.0000 - tn: 3502.0000 - fn: 829.0000 - accuracy: 0.8002 - precision: 0.6865 - recall: 0.2090 - f1_metric: 0.1638
Test Score: 0.4667632579803467
Test Accuracy: 219.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3502  100]
 [ 829  219]]
Finished training and evaluation
{&#39;precision&#39;: 0.5974025974025974, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5082872928176796, &#39;ERDE_5&#39;: 0.263711534955882, &#39;ERDE_50&#39;: 0.15513415935929992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48847413265155126}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 17ms/step - loss: 0.9446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9445651769638062
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Finished training and evaluation
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Evaluating for elapsed time
146/146 [==============================] - 4s 15ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Evaluated with elapsed time 78.36844806201407
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6851851851851852, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.46835443037974683, &#39;ERDE_5&#39;: 0.2556890811233068, &#39;ERDE_50&#39;: 0.16827344924523452, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44827434233692226}
Writing results to CSV file
{&#39;precision&#39;: 0.6153846153846154, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3356643356643356, &#39;ERDE_5&#39;: 0.25456871544294346, &#39;ERDE_50&#39;: 0.19784383749979395, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31996670360938406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8163265306122449, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5228758169934641, &#39;ERDE_5&#39;: 0.25094994601613113, &#39;ERDE_50&#39;: 0.1565313616015323, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5024939926679782}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2498860563176932, &#39;ERDE_50&#39;: 0.1766454850806766, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875661955726727, &#39;ERDE_50&#39;: 0.19675960855982053, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7407407407407407, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5063291139240507, &#39;ERDE_5&#39;: 0.25384887410578755, &#39;ERDE_50&#39;: 0.1594375422653688, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4865922840392448}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.25104365598384754, &#39;ERDE_50&#39;: 0.1683516925707989, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.45269487091365596}
Writing results to CSV file
{&#39;precision&#39;: 0.7419354838709677, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34074074074074073, &#39;ERDE_5&#39;: 0.2504999070196217, &#39;ERDE_50&#39;: 0.1961392507642719, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3248057062256988}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7818181818181819, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5408805031446541, &#39;ERDE_5&#39;: 0.2526767401628713, &#39;ERDE_50&#39;: 0.15118287141827438, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.51979685184947}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.25046803168899784, &#39;ERDE_50&#39;: 0.17486265501959128, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4253894660014037}
Writing results to CSV file
{&#39;precision&#39;: 0.7037037037037037, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.2900763358778626, &#39;ERDE_5&#39;: 0.2505021909891343, &#39;ERDE_50&#39;: 0.20559551553968347, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.27651066593724444}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 78.36844806201407} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluating after getting time 238362.685811386
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluated with elapsed time 109.45915940098348
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.2544231936533879, &#39;ERDE_50&#39;: 0.14819844742886934, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5273888932193644}
Writing results to CSV file
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25220919865042724, &#39;ERDE_50&#39;: 0.16478603244862622, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.2481760447535395, &#39;ERDE_50&#39;: 0.1796299090700811, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4019118029660862}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3486  116]
 [ 799  249]]
Evaluating after getting time 238479.477797007
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3486  116]
 [ 799  249]]
Evaluated with elapsed time 4.580904998991173
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6338028169014085, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5142857142857142, &#39;ERDE_5&#39;: 0.26081099554464326, &#39;ERDE_50&#39;: 0.15459204488931458, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49423873421700426}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5930 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5930377840995789
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 24ms/step - loss: 0.5290 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5289624333381653
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.5513 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.551337480545044
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 6s 24ms/step - loss: 0.7310 - tp: 14.0000 - fp: 7.0000 - tn: 3595.0000 - fn: 1034.0000 - accuracy: 0.7761 - precision: 0.6667 - recall: 0.0134 - f1_metric: 0.0073
Test Score: 0.7310192584991455
Test Accuracy: 14.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.67      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.72      0.51      0.45      4650
weighted avg       0.75      0.78      0.68      4650

[[3595    7]
 [1034   14]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.24701950881195792, &#39;ERDE_50&#39;: 0.23756909165087897, &#39;median_latency_tps&#39;: 20.0, &#39;median_penalty_tps&#39;: 0.07396467420452302, &#39;speed&#39;: 0.926035325795477, &#39;latency_weighted_f1&#39;: 0.06734802369421651}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.6108 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0028
Test Score: 0.6107832193374634
Test Accuracy: 3.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643242743810748, &#39;ERDE_50&#39;: 0.23935192171196407, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.053389986720972685}
Evaluating for elapsed time
146/146 [==============================] - 7s 20ms/step - loss: 0.6108 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0028
Test Score: 0.6107832193374634
Test Accuracy: 3.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Evaluated with elapsed time 69.662804786989
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8108108108108109, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.42553191489361697, &#39;ERDE_5&#39;: 0.24989944353411853, &#39;ERDE_50&#39;: 0.1790095512745312, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4048037307441622}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24817926618297548, &#39;ERDE_50&#39;: 0.19854243862090779, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30908854775018174}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6338028169014085, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5142857142857142, &#39;ERDE_5&#39;: 0.26081099554464326, &#39;ERDE_50&#39;: 0.15459204488931458, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49423873421700426}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.662804786989} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluating after getting time 241827.841995105
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3559   43]
 [ 822  226]]
Evaluated with elapsed time 137.63585778899142
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5487804878048781, &#39;ERDE_5&#39;: 0.2544231936533879, &#39;ERDE_50&#39;: 0.14819844742886934, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5273888932193644}
Writing results to CSV file
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.25220919865042724, &#39;ERDE_50&#39;: 0.16478603244862622, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.8787878787878788, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4233576642335767, &#39;ERDE_5&#39;: 0.2481760447535395, &#39;ERDE_50&#39;: 0.1796299090700811, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.4019118029660862}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3486  116]
 [ 799  249]]
Evaluating after getting time 241974.706560668
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3486  116]
 [ 799  249]]
Evaluated with elapsed time 3.5839314539916813
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6338028169014085, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5142857142857142, &#39;ERDE_5&#39;: 0.26081099554464326, &#39;ERDE_50&#39;: 0.15459204488931458, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49423873421700426}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 18ms/step - loss: 0.4518 - tp: 282.0000 - fp: 141.0000 - tn: 3461.0000 - fn: 766.0000 - accuracy: 0.8049 - precision: 0.6667 - recall: 0.2691 - f1_metric: 0.2141
Test Score: 0.4518105685710907
Test Accuracy: 282.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.67      0.27      0.38      1048

    accuracy                           0.80      4650
   macro avg       0.74      0.61      0.63      4650
weighted avg       0.78      0.80      0.77      4650

[[3461  141]
 [ 766  282]]
Finished training and evaluation
{&#39;precision&#39;: 0.6111111111111112, &#39;recall&#39;: 0.5288461538461539, &#39;F1&#39;: 0.5670103092783506, &#39;ERDE_5&#39;: 0.2659822572483078, &#39;ERDE_50&#39;: 0.1361825081456909, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5449081118944636}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 16ms/step - loss: 0.7674 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7674042582511902
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.4526 - tp: 284.0000 - fp: 129.0000 - tn: 3473.0000 - fn: 764.0000 - accuracy: 0.8080 - precision: 0.6877 - recall: 0.2710 - f1_metric: 0.2073
Test Score: 0.45255932211875916
Test Accuracy: 284.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.89      3602
           1       0.69      0.27      0.39      1048

    accuracy                           0.81      4650
   macro avg       0.75      0.62      0.64      4650
weighted avg       0.79      0.81      0.77      4650

[[3473  129]
 [ 764  284]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6073298429319371, &#39;ERDE_5&#39;: 0.2624860432742776, &#39;ERDE_50&#39;: 0.12560289276752482, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.583655980488958}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9993 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9993101954460144
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 20ms/step - loss: 0.9868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9867957234382629
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 19ms/step - loss: 0.9868 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9867957234382629
Test Accuracy: 0.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 70.76257313901442
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.5576923076923077, &#39;F1&#39;: 0.6073298429319371, &#39;ERDE_5&#39;: 0.2624860432742776, &#39;ERDE_50&#39;: 0.12560289276752482, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.583655980488958}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.6857142857142857, &#39;recall&#39;: 0.46153846153846156, &#39;F1&#39;: 0.5517241379310346, &#39;ERDE_5&#39;: 0.2585776141381924, &#39;ERDE_50&#39;: 0.14517490177668715, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5280696819327771}
Writing results to CSV file
{&#39;precision&#39;: 0.6792452830188679, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4585987261146497, &#39;ERDE_5&#39;: 0.25572381629884605, &#39;ERDE_50&#39;: 0.17063751543908998, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.43715196130071904}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2549828586632345, &#39;ERDE_50&#39;: 0.13932341878622365, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5572777312177267}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522027883448718, &#39;ERDE_50&#39;: 0.15532976767321446, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510807003994329, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.25154069638027526, &#39;ERDE_50&#39;: 0.15002039915273763, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5242857431291186}
Writing results to CSV file
{&#39;precision&#39;: 0.8372093023255814, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4897959183673469, &#39;ERDE_5&#39;: 0.24989071232618393, &#39;ERDE_50&#39;: 0.16482515411140958, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.46784337216476285}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.36363636363636365, &#39;ERDE_5&#39;: 0.2481784700788063, &#39;ERDE_50&#39;: 0.1914502400393464, &#39;median_latency_tps&#39;: 14.5, &#39;median_penalty_tps&#39;: 0.05260120542420199, &#39;speed&#39;: 0.947398794575798, &#39;latency_weighted_f1&#39;: 0.3445086525730175}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7288135593220338, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5276073619631901, &#39;ERDE_5&#39;: 0.25500282479284203, &#39;ERDE_50&#39;: 0.15350781594934335, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5070411008838387}
Writing results to CSV file
{&#39;precision&#39;: 0.7659574468085106, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4768211920529802, &#39;ERDE_5&#39;: 0.25221150287069166, &#39;ERDE_50&#39;: 0.1671500986424817, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4563781025975325}
Writing results to CSV file
{&#39;precision&#39;: 0.7567567567567568, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.3971631205673759, &#39;ERDE_5&#39;: 0.2510814965036021, &#39;ERDE_50&#39;: 0.184900155927776, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3785894448144131}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2549828586632345, &#39;ERDE_50&#39;: 0.13932341878622365, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5572777312177267}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522027883448718, &#39;ERDE_50&#39;: 0.15532976767321446, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510807003994329, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538343476103083, &#39;ERDE_50&#39;: 0.14525314510224868, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.7708333333333334, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4868421052631579, &#39;ERDE_5&#39;: 0.2522054484902803, &#39;ERDE_50&#39;: 0.16478603244862813, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4659693821660113}
Writing results to CSV file
{&#39;precision&#39;: 0.7714285714285715, &#39;recall&#39;: 0.25961538461538464, &#39;F1&#39;: 0.38848920863309355, &#39;ERDE_5&#39;: 0.2505005061094562, &#39;ERDE_50&#39;: 0.18668298598886, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3703211758500696}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2549828586632345, &#39;ERDE_50&#39;: 0.13932341878622365, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5572777312177267}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522027883448718, &#39;ERDE_50&#39;: 0.15532976767321446, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510807003994329, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7538461538461538, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5798816568047337, &#39;ERDE_5&#39;: 0.2549828586632345, &#39;ERDE_50&#39;: 0.13932341878622365, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5572777312177267}
Writing results to CSV file
{&#39;precision&#39;: 0.7884615384615384, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5256410256410257, &#39;ERDE_5&#39;: 0.2522027883448718, &#39;ERDE_50&#39;: 0.15532976767321446, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5031048492131986}
Writing results to CSV file
{&#39;precision&#39;: 0.775, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4305555555555556, &#39;ERDE_5&#39;: 0.2510807003994329, &#39;ERDE_50&#39;: 0.1778079573462146, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.4104202537906249}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6338028169014085, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5142857142857142, &#39;ERDE_5&#39;: 0.26081099554464326, &#39;ERDE_50&#39;: 0.15459204488931458, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.49423873421700426}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 70.76257313901442} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 244977.554052378
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 82.10230660199886
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 82.10230660199886}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 245186.978646308
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 72.45274679298745
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 72.45274679298745}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 245432.918181192
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 83.45795244397596
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 83.45795244397596}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': False, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-False,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluating after getting time 245634.560925086
              precision    recall  f1-score   support

           0       0.78      0.99      0.87      3602
           1       0.49      0.02      0.04      1048

    accuracy                           0.77      4650
   macro avg       0.63      0.51      0.46      4650
weighted avg       0.71      0.77      0.69      4650

[[3577   25]
 [1024   24]]
Evaluated with elapsed time 66.77324555499945
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.4, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07017543859649124, &#39;ERDE_5&#39;: 0.24932691917810404, &#39;ERDE_50&#39;: 0.2398940361819493, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.06743998322649183}
Writing results to CSV file
{&#39;precision&#39;: 0.3333333333333333, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05309734513274337, &#39;ERDE_5&#39;: 0.24934383960137432, &#39;ERDE_50&#39;: 0.2422581023758027, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.050820865407247354}
Writing results to CSV file
{&#39;precision&#39;: 0.375, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05357142857142857, &#39;ERDE_5&#39;: 0.2487666864548756, &#39;ERDE_50&#39;: 0.24167686624303492, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.05106611452694411}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: False, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 66.77324555499945}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 840  208]]
Evaluating after getting time 245984.104453477
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 840  208]]
Evaluated with elapsed time 146.96086566502345
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2532641671975469, &#39;ERDE_50&#39;: 0.13757971038792008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5650504653813826}
Writing results to CSV file
{&#39;precision&#39;: 0.9210526315789473, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.49295774647887325, &#39;ERDE_5&#39;: 0.247568722070843, &#39;ERDE_50&#39;: 0.16486427577419344, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46798618145274}
Writing results to CSV file
{&#39;precision&#39;: 0.9583333333333334, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.359375, &#39;ERDE_5&#39;: 0.24643514867769387, &#39;ERDE_50&#39;: 0.19207059783489866, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.33977260042621}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.78      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3568   34]
 [ 930  118]]
Evaluating after getting time 246137.17265411
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.78      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3568   34]
 [ 930  118]]
Evaluated with elapsed time 4.493454393988941
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7659574468085106, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4768211920529802, &#39;ERDE_5&#39;: 0.25215983190620694, &#39;ERDE_50&#39;: 0.16715009864248306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4563781025975325}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5956 - tp: 0.0000e+00 - fp: 1.0000 - tn: 3601.0000 - fn: 1048.0000 - accuracy: 0.7744 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.595599889755249
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3601    1]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5245 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.524502694606781
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5559 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5558697581291199
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7403 - tp: 7.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1041.0000 - accuracy: 0.7757 - precision: 0.7778 - recall: 0.0067 - f1_metric: 0.0055
Test Score: 0.7402687072753906
Test Accuracy: 7.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.78      0.01      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.78      0.50      0.44      4650
weighted avg       0.78      0.78      0.68      4650

[[3600    2]
 [1041    7]]
Finished training and evaluation
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07339449541284404, &#39;ERDE_5&#39;: 0.24643798231471994, &#39;ERDE_50&#39;: 0.23698785551811238, &#39;median_latency_tps&#39;: 17.0, &#39;median_penalty_tps&#39;: 0.06231063877162524, &#39;speed&#39;: 0.9376893612283748, &#39;latency_weighted_f1&#39;: 0.06882123752134861}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470923781394958
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 3s 13ms/step - loss: 0.5471 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5470923781394958
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 66.37541596099618
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.24644412029352425, &#39;ERDE_50&#39;: 0.24644412029352425, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7659574468085106, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4768211920529802, &#39;ERDE_5&#39;: 0.25215983190620694, &#39;ERDE_50&#39;: 0.16715009864248306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4563781025975325}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 66.37541596099618} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 840  208]]
Evaluating after getting time 249134.459582757
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.89      0.20      0.32      1048

    accuracy                           0.81      4650
   macro avg       0.85      0.60      0.61      4650
weighted avg       0.83      0.81      0.76      4650

[[3577   25]
 [ 840  208]]
Evaluated with elapsed time 113.436416335986
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7903225806451613, &#39;recall&#39;: 0.47115384615384615, &#39;F1&#39;: 0.5903614457831325, &#39;ERDE_5&#39;: 0.2532641671975469, &#39;ERDE_50&#39;: 0.13757971038792008, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5650504653813826}
Writing results to CSV file
{&#39;precision&#39;: 0.9210526315789473, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.49295774647887325, &#39;ERDE_5&#39;: 0.247568722070843, &#39;ERDE_50&#39;: 0.16486427577419344, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.46798618145274}
Writing results to CSV file
{&#39;precision&#39;: 0.9583333333333334, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.359375, &#39;ERDE_5&#39;: 0.24643514867769387, &#39;ERDE_50&#39;: 0.19207059783489866, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.33977260042621}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.78      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3568   34]
 [ 930  118]]
Evaluating after getting time 249254.99014064
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.78      0.11      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.78      0.55      0.54      4650
weighted avg       0.79      0.79      0.73      4650

[[3568   34]
 [ 930  118]]
Evaluated with elapsed time 5.269218539004214
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7659574468085106, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4768211920529802, &#39;ERDE_5&#39;: 0.25215983190620694, &#39;ERDE_50&#39;: 0.16715009864248306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4563781025975325}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9584 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9584147334098816
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.7878 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7877808213233948
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0354 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0354036092758179
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.9631 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.96307772397995
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0041662454605103
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 5s 13ms/step - loss: 1.0042 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0041662454605103
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 65.30980093599646
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24869364373348185, &#39;ERDE_50&#39;: 0.17784707900899432, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.875, &#39;recall&#39;: 0.1346153846153846, &#39;F1&#39;: 0.23333333333333334, &#39;ERDE_5&#39;: 0.24701533599031944, &#39;ERDE_50&#39;: 0.2139284297123442, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.22060597824774214}
Writing results to CSV file
{&#39;precision&#39;: 0.9090909090909091, &#39;recall&#39;: 0.09615384615384616, &#39;F1&#39;: 0.17391304347826086, &#39;ERDE_5&#39;: 0.24644133826227996, &#39;ERDE_50&#39;: 0.22280345835499013, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.1637507204607589}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7659574468085106, &#39;recall&#39;: 0.34615384615384615, &#39;F1&#39;: 0.4768211920529802, &#39;ERDE_5&#39;: 0.25215983190620694, &#39;ERDE_50&#39;: 0.16715009864248306, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4563781025975325}
Writing results to CSV file
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.16346153846153846, &#39;F1&#39;: 0.272, &#39;ERDE_5&#39;: 0.2481707200921471, &#39;ERDE_50&#39;: 0.20799870339631935, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.2592796854914709}
Writing results to CSV file
{&#39;precision&#39;: 0.8461538461538461, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.18803418803418803, &#39;ERDE_5&#39;: 0.24702155095572467, &#39;ERDE_50&#39;: 0.22102062829390443, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.1785090147568205}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 65.30980093599646} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3575   27]
 [ 854  194]]
Evaluating after getting time 251553.167928976
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3575   27]
 [ 854  194]]
Evaluated with elapsed time 145.30733728100313
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2526861798179439, &#39;ERDE_50&#39;: 0.13227034186744652, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5845921104630069}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873069766076478, &#39;ERDE_50&#39;: 0.1778470790089947, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9523809523809523, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.32, &#39;ERDE_5&#39;: 0.24643569433129878, &#39;ERDE_50&#39;: 0.1991627964164576, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.30441240551961}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.79      0.73      4650

[[3573   29]
 [ 925  123]]
Evaluating after getting time 251702.849369389
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.79      0.73      4650

[[3573   29]
 [ 925  123]]
Evaluated with elapsed time 2.9906566179997753
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156643309959165, &#39;ERDE_50&#39;: 0.17838919347897833, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24816905263633565, &#39;ERDE_50&#39;: 0.19854243862090626, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.3078222952294076}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.21666666666666667, &#39;ERDE_5&#39;: 0.24760166281122536, &#39;ERDE_50&#39;: 0.2168737320389661, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.20484840837290344}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 29ms/step - loss: 0.5939 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5938882827758789
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.5347 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5347276926040649
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 22ms/step - loss: 0.5435 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5435420870780945
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 0.7629 - tp: 5.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1043.0000 - accuracy: 0.7751 - precision: 0.6250 - recall: 0.0048 - f1_metric: 0.0051
Test Score: 0.7629133462905884
Test Accuracy: 5.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.62      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.70      0.50      0.44      4650
weighted avg       0.74      0.78      0.68      4650

[[3599    3]
 [1043    5]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.038461538461538464, &#39;F1&#39;: 0.07272727272727274, &#39;ERDE_5&#39;: 0.2470193640767729, &#39;ERDE_50&#39;: 0.2375690916508799, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.068618939459625}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 0.5452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5452309250831604
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 7s 20ms/step - loss: 0.5452 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5452309250831604
Test Accuracy: 0.0
146/146 [==============================] - 2s 15ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 67.98751556902425
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156643309959165, &#39;ERDE_50&#39;: 0.17838919347897833, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24816905263633565, &#39;ERDE_50&#39;: 0.19854243862090626, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.3078222952294076}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.21666666666666667, &#39;ERDE_5&#39;: 0.24760166281122536, &#39;ERDE_50&#39;: 0.2168737320389661, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.20484840837290344}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 67.98751556902425} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3575   27]
 [ 854  194]]
Evaluating after getting time 254947.337098204
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.88      0.19      0.31      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.59      0.60      4650
weighted avg       0.82      0.81      0.76      4650

[[3575   27]
 [ 854  194]]
Evaluated with elapsed time 243.2490995929984
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8095238095238095, &#39;recall&#39;: 0.49038461538461536, &#39;F1&#39;: 0.6107784431137724, &#39;ERDE_5&#39;: 0.2526861798179439, &#39;ERDE_50&#39;: 0.13227034186744652, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.5845921104630069}
Writing results to CSV file
{&#39;precision&#39;: 0.8571428571428571, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.43165467625899273, &#39;ERDE_5&#39;: 0.24873069766076478, &#39;ERDE_50&#39;: 0.1778470790089947, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.41314804251934883}
Writing results to CSV file
{&#39;precision&#39;: 0.9523809523809523, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.32, &#39;ERDE_5&#39;: 0.24643569433129878, &#39;ERDE_50&#39;: 0.1991627964164576, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.30441240551961}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.79      0.73      4650

[[3573   29]
 [ 925  123]]
Evaluating after getting time 255199.939217915
              precision    recall  f1-score   support

           0       0.79      0.99      0.88      3602
           1       0.81      0.12      0.20      1048

    accuracy                           0.79      4650
   macro avg       0.80      0.55      0.54      4650
weighted avg       0.80      0.79      0.73      4650

[[3573   29]
 [ 925  123]]
Evaluated with elapsed time 2.2021704709914047
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156643309959165, &#39;ERDE_50&#39;: 0.17838919347897833, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24816905263633565, &#39;ERDE_50&#39;: 0.19854243862090626, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.3078222952294076}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.21666666666666667, &#39;ERDE_5&#39;: 0.24760166281122536, &#39;ERDE_50&#39;: 0.2168737320389661, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.20484840837290344}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 23ms/step - loss: 0.9665 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9664586186408997
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 7s 29ms/step - loss: 0.8136 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.813572108745575
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 25ms/step - loss: 0.9550 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9550172090530396
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.9789 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9789014458656311
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 6s 22ms/step - loss: 1.1166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1166073083877563
Test Accuracy: 0.0
146/146 [==============================] - 3s 21ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 9s 29ms/step - loss: 1.1166 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.1166073083877563
Test Accuracy: 0.0
146/146 [==============================] - 4s 27ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 77.49126563500613
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8387096774193549, &#39;recall&#39;: 0.25, &#39;F1&#39;: 0.38518518518518513, &#39;ERDE_5&#39;: 0.24869556280908472, &#39;ERDE_50&#39;: 0.18730334378440675, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.36867087053454983}
Writing results to CSV file
{&#39;precision&#39;: 0.8823529411764706, &#39;recall&#39;: 0.14423076923076922, &#39;F1&#39;: 0.24793388429752067, &#39;ERDE_5&#39;: 0.24701320305885768, &#39;ERDE_50&#39;: 0.2115643635184913, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.2344101303695017}
Writing results to CSV file
{&#39;precision&#39;: 1.0, &#39;recall&#39;: 0.10576923076923077, &#39;F1&#39;: 0.19130434782608693, &#39;ERDE_5&#39;: 0.24586001611166486, &#39;ERDE_50&#39;: 0.21985815602836967, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.18012579250683475}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7560975609756098, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4275862068965517, &#39;ERDE_5&#39;: 0.25156643309959165, &#39;ERDE_50&#39;: 0.17838919347897833, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4109187943490036}
Writing results to CSV file
{&#39;precision&#39;: 0.84, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3255813953488372, &#39;ERDE_5&#39;: 0.24816905263633565, &#39;ERDE_50&#39;: 0.19854243862090626, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.3078222952294076}
Writing results to CSV file
{&#39;precision&#39;: 0.8125, &#39;recall&#39;: 0.125, &#39;F1&#39;: 0.21666666666666667, &#39;ERDE_5&#39;: 0.24760166281122536, &#39;ERDE_50&#39;: 0.2168737320389661, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.20484840837290344}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 77.49126563500613} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluating after getting time 257744.908859178
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluated with elapsed time 81.79289994301507
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 81.79289994301507}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluating after getting time 257964.440555875
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluated with elapsed time 77.79259484802606
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 77.79259484802606}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=True, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Normalizing features
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluating after getting time 258242.743016017
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluated with elapsed time 98.65122769301524
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 98.65122769301524}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': True, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-True,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluating after getting time 258533.911124111
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.86      0.21      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.84      0.60      0.61      4650
weighted avg       0.82      0.81      0.77      4650

[[3567   35]
 [ 829  219]]
Evaluated with elapsed time 115.40667181598837
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.8113207547169812, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5477707006369427, &#39;ERDE_5&#39;: 0.2515151699596063, &#39;ERDE_50&#39;: 0.1500203991527378, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.526418467796597}
Writing results to CSV file
{&#39;precision&#39;: 0.8043478260869565, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4933333333333333, &#39;ERDE_5&#39;: 0.251042516828514, &#39;ERDE_50&#39;: 0.16362356018309254, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4721823072615581}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875487747533578, &#39;ERDE_50&#39;: 0.18257521139670116, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: True, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 115.40667181598837}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluating after getting time 259002.227180548
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluated with elapsed time 189.04825098798028
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7288135593220338, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5276073619631901, &#39;ERDE_5&#39;: 0.2549924456636869, &#39;ERDE_50&#39;: 0.15350781594934398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5070411008838387}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluating after getting time 259199.379696101
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluated with elapsed time 3.8607948489952832
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00021: early stopping
Evaluating
146/146 [==============================] - 5s 15ms/step - loss: 0.5842 - tp: 3.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1045.0000 - accuracy: 0.7748 - precision: 0.6000 - recall: 0.0029 - f1_metric: 0.0044
Test Score: 0.5842463374137878
Test Accuracy: 3.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.60      0.00      0.01      1048

    accuracy                           0.77      4650
   macro avg       0.69      0.50      0.44      4650
weighted avg       0.74      0.77      0.68      4650

[[3600    2]
 [1045    3]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05555555555555555, &#39;ERDE_5&#39;: 0.24643826878198014, &#39;ERDE_50&#39;: 0.2393519217119642, &#39;median_latency_tps&#39;: 18.0, &#39;median_penalty_tps&#39;: 0.06620302575491954, &#39;speed&#39;: 0.9337969742450805, &#39;latency_weighted_f1&#39;: 0.051877609680282245}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 8s 30ms/step - loss: 0.5265 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5264641046524048
Test Accuracy: 0.0
146/146 [==============================] - 3s 18ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00014: early stopping
Evaluating
146/146 [==============================] - 9s 22ms/step - loss: 0.5304 - tp: 13.0000 - fp: 12.0000 - tn: 3590.0000 - fn: 1035.0000 - accuracy: 0.7748 - precision: 0.5200 - recall: 0.0124 - f1_metric: 0.0081
Test Score: 0.5303769707679749
Test Accuracy: 13.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.52      0.01      0.02      1048

    accuracy                           0.77      4650
   macro avg       0.65      0.50      0.45      4650
weighted avg       0.72      0.77      0.68      4650

[[3590   12]
 [1035   13]]
Finished training and evaluation
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 9s 32ms/step - loss: 0.6067 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.6066854596138
Test Accuracy: 0.0
146/146 [==============================] - 4s 26ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 8s 19ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 3s 17ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 6s 20ms/step - loss: 0.5413 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5413414835929871
Test Accuracy: 0.0
146/146 [==============================] - 3s 20ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 72.00371540198103
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6, &#39;recall&#39;: 0.028846153846153848, &#39;F1&#39;: 0.05504587155963303, &#39;ERDE_5&#39;: 0.24701939831435432, &#39;ERDE_50&#39;: 0.23993315784473174, &#39;median_latency_tps&#39;: 15.0, &#39;median_penalty_tps&#39;: 0.054545807509676525, &#39;speed&#39;: 0.9454541924903235, &#39;latency_weighted_f1&#39;: 0.05204335004533891}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702531497723793, &#39;ERDE_50&#39;: 0.24229722403858522, &#39;median_latency_tps&#39;: 17.5, &#39;median_penalty_tps&#39;: 0.06425913403756756, &#39;speed&#39;: 0.9357408659624324, &#39;latency_weighted_f1&#39;: 0.03465706910971972}
Writing results to CSV file
{&#39;precision&#39;: 0.5, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037037037037037035, &#39;ERDE_5&#39;: 0.24702534117788344, &#39;ERDE_50&#39;: 0.24229722403858533, &#39;median_latency_tps&#39;: 18.5, &#39;median_penalty_tps&#39;: 0.06814190497030137, &#39;speed&#39;: 0.9318580950296986, &#39;latency_weighted_f1&#39;: 0.03451326277887772}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7857142857142857, &#39;recall&#39;: 0.3173076923076923, &#39;F1&#39;: 0.45205479452054786, &#39;ERDE_5&#39;: 0.25097557366851775, &#39;ERDE_50&#39;: 0.17307982495850496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4344335905788736}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40287769784172667, &#39;ERDE_5&#39;: 0.24989346044721628, &#39;ERDE_50&#39;: 0.18373768366223742, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3856048396847257}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.31007751937984496, &#39;ERDE_5&#39;: 0.2487583048808437, &#39;ERDE_50&#39;: 0.2014877409475295, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29557647684846206}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 72.00371540198103} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluating after getting time 262071.735751423
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.85      0.23      0.36      1048

    accuracy                           0.82      4650
   macro avg       0.83      0.61      0.62      4650
weighted avg       0.82      0.82      0.77      4650

[[3559   43]
 [ 812  236]]
Evaluated with elapsed time 114.3198226679815
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7288135593220338, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5276073619631901, &#39;ERDE_5&#39;: 0.2549924456636869, &#39;ERDE_50&#39;: 0.15350781594934398, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5070411008838387}
Writing results to CSV file
{&#39;precision&#39;: 0.7777777777777778, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.4697986577181208, &#39;ERDE_5&#39;: 0.2516200705954998, &#39;ERDE_50&#39;: 0.16893292870356427, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4496566503034972}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.24875355106646005, &#39;ERDE_50&#39;: 0.18257521139670038, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.38964315123235216}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluating after getting time 262192.171347437
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.68      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.78      0.80      0.76      4650

[[3487  115]
 [ 799  249]]
Evaluated with elapsed time 4.2930618730024435
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 5s 21ms/step - loss: 0.4593 - tp: 221.0000 - fp: 97.0000 - tn: 3505.0000 - fn: 827.0000 - accuracy: 0.8013 - precision: 0.6950 - recall: 0.2109 - f1_metric: 0.1626
Test Score: 0.45927152037620544
Test Accuracy: 221.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3505   97]
 [ 827  221]]
Finished training and evaluation
{&#39;precision&#39;: 0.6617647058823529, &#39;recall&#39;: 0.4326923076923077, &#39;F1&#39;: 0.5232558139534883, &#39;ERDE_5&#39;: 0.2590667709073719, &#39;ERDE_50&#39;: 0.15284833649101234, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.502859177255673}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 20ms/step - loss: 0.8116 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.8116161227226257
Test Accuracy: 0.0
146/146 [==============================] - 3s 22ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00022: early stopping
Evaluating
146/146 [==============================] - 5s 20ms/step - loss: 0.4668 - tp: 219.0000 - fp: 100.0000 - tn: 3502.0000 - fn: 829.0000 - accuracy: 0.8002 - precision: 0.6865 - recall: 0.2090 - f1_metric: 0.1638
Test Score: 0.4667632579803467
Test Accuracy: 219.0
146/146 [==============================] - 3s 19ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.21      0.32      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3502  100]
 [ 829  219]]
Finished training and evaluation
{&#39;precision&#39;: 0.5974025974025974, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5082872928176796, &#39;ERDE_5&#39;: 0.263711534955882, &#39;ERDE_50&#39;: 0.15513415935929992, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48847413265155126}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 13ms/step - loss: 0.9446 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9445651769638062
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 16ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Finished training and evaluation
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Evaluating for elapsed time
146/146 [==============================] - 5s 14ms/step - loss: 0.4839 - tp: 212.0000 - fp: 91.0000 - tn: 3511.0000 - fn: 836.0000 - accuracy: 0.8006 - precision: 0.6997 - recall: 0.2023 - f1_metric: 0.1600
Test Score: 0.48385748267173767
Test Accuracy: 212.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.70      0.20      0.31      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.59      0.60      4650
weighted avg       0.78      0.80      0.76      4650

[[3511   91]
 [ 836  212]]
Evaluated with elapsed time 68.51598773698788
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0.6527777777777778, &#39;recall&#39;: 0.4519230769230769, &#39;F1&#39;: 0.5340909090909091, &#39;ERDE_5&#39;: 0.2602022577475455, &#39;ERDE_50&#39;: 0.14928267636884116, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5132719177948056}
Writing results to CSV file
{&#39;precision&#39;: 0.6851851851851852, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.46835443037974683, &#39;ERDE_5&#39;: 0.2556890811233068, &#39;ERDE_50&#39;: 0.16827344924523452, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.44827434233692226}
Writing results to CSV file
{&#39;precision&#39;: 0.6153846153846154, &#39;recall&#39;: 0.23076923076923078, &#39;F1&#39;: 0.3356643356643356, &#39;ERDE_5&#39;: 0.25456871544294346, &#39;ERDE_50&#39;: 0.19784383749979395, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.31996670360938406}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.8163265306122449, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5228758169934641, &#39;ERDE_5&#39;: 0.25094994601613113, &#39;ERDE_50&#39;: 0.1565313616015323, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5024939926679782}
Writing results to CSV file
{&#39;precision&#39;: 0.8157894736842105, &#39;recall&#39;: 0.2980769230769231, &#39;F1&#39;: 0.4366197183098592, &#39;ERDE_5&#39;: 0.2498860563176932, &#39;ERDE_50&#39;: 0.1766454850806766, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4179002148394072}
Writing results to CSV file
{&#39;precision&#39;: 0.8148148148148148, &#39;recall&#39;: 0.21153846153846154, &#39;F1&#39;: 0.3358778625954198, &#39;ERDE_5&#39;: 0.24875661955726727, &#39;ERDE_50&#39;: 0.19675960855982053, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3201702447694409}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7407407407407407, &#39;recall&#39;: 0.38461538461538464, &#39;F1&#39;: 0.5063291139240507, &#39;ERDE_5&#39;: 0.25384887410578755, &#39;ERDE_50&#39;: 0.1594375422653688, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4865922840392448}
Writing results to CSV file
{&#39;precision&#39;: 0.7954545454545454, &#39;recall&#39;: 0.33653846153846156, &#39;F1&#39;: 0.47297297297297297, &#39;ERDE_5&#39;: 0.25104365598384754, &#39;ERDE_50&#39;: 0.1683516925707989, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.45269487091365596}
Writing results to CSV file
{&#39;precision&#39;: 0.7419354838709677, &#39;recall&#39;: 0.22115384615384615, &#39;F1&#39;: 0.34074074074074073, &#39;ERDE_5&#39;: 0.2504999070196217, &#39;ERDE_50&#39;: 0.1961392507642719, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3248057062256988}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7818181818181819, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5408805031446541, &#39;ERDE_5&#39;: 0.2526767401628713, &#39;ERDE_50&#39;: 0.15118287141827438, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.51979685184947}
Writing results to CSV file
{&#39;precision&#39;: 0.8, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.4444444444444444, &#39;ERDE_5&#39;: 0.25046803168899784, &#39;ERDE_50&#39;: 0.17486265501959128, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4253894660014037}
Writing results to CSV file
{&#39;precision&#39;: 0.7037037037037037, &#39;recall&#39;: 0.18269230769230768, &#39;F1&#39;: 0.2900763358778626, &#39;ERDE_5&#39;: 0.2505021909891343, &#39;ERDE_50&#39;: 0.20559551553968347, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.27651066593724444}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7666666666666667, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5609756097560975, &#39;ERDE_5&#39;: 0.2538232859366677, &#39;ERDE_50&#39;: 0.1452531451022496, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5391086464020168}
Writing results to CSV file
{&#39;precision&#39;: 0.8085106382978723, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.5033112582781457, &#39;ERDE_5&#39;: 0.2510362518543245, &#39;ERDE_50&#39;: 0.16125949398923806, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.4817324416307287}
Writing results to CSV file
{&#39;precision&#39;: 0.7575757575757576, &#39;recall&#39;: 0.2403846153846154, &#39;F1&#39;: 0.36496350364963503, &#39;ERDE_5&#39;: 0.250498226773561, &#39;ERDE_50&#39;: 0.1914111183765635, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.34789567074317157}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6417910447761194, &#39;recall&#39;: 0.41346153846153844, &#39;F1&#39;: 0.5029239766081871, &#39;ERDE_5&#39;: 0.25964430341003514, &#39;ERDE_50&#39;: 0.15815770501148593, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.483319879789858}
Writing results to CSV file
{&#39;precision&#39;: 0.7068965517241379, &#39;recall&#39;: 0.3942307692307692, &#39;F1&#39;: 0.5061728395061729, &#39;ERDE_5&#39;: 0.2556907365412597, &#39;ERDE_50&#39;: 0.15881718446982082, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.48447133627937644}
Writing results to CSV file
{&#39;precision&#39;: 0.7142857142857143, &#39;recall&#39;: 0.28846153846153844, &#39;F1&#39;: 0.410958904109589, &#39;ERDE_5&#39;: 0.25282223427192163, &#39;ERDE_50&#39;: 0.18191573193837016, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3917400566450507}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 68.51598773698788} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=True, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Discretizing
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:188: UserWarning: Feature 5 is constant and will be replaced with 0.
  &#34;replaced with 0.&#34; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 6 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/preprocessing/_discretization.py:222: UserWarning: Bins whose width are too small (i.e., &lt;= 1e-8) in feature 7 are removed. Consider decreasing the number of bins.
  &#39;decreasing the number of bins.&#39; % jj)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3560   42]
 [ 822  226]]
Evaluating after getting time 265842.186037527
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3560   42]
 [ 822  226]]
Evaluated with elapsed time 116.46199257601984
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7796610169491526, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5644171779141105, &#39;ERDE_5&#39;: 0.2532585676025228, &#39;ERDE_50&#39;: 0.14467190896948043, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5424160614106183}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516272770513196, &#39;ERDE_50&#39;: 0.16420479631585844, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2487572809841781, &#39;ERDE_50&#39;: 0.18257521139670063, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3888479632549763}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.79      0.80      0.76      4650

[[3489  113]
 [ 799  249]]
Evaluating after getting time 265966.737010539
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.79      0.80      0.76      4650

[[3489  113]
 [ 799  249]]
Evaluated with elapsed time 3.958890911017079
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6376811594202898, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5086705202312138, &#39;ERDE_5&#39;: 0.26023055220178204, &#39;ERDE_50&#39;: 0.15637487495040026, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48884242176890597}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5917 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.591661810874939
Test Accuracy: 0.0
146/146 [==============================] - 2s 14ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.5209 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5208550095558167
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00018: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.6708 - tp: 5.0000 - fp: 3.0000 - tn: 3599.0000 - fn: 1043.0000 - accuracy: 0.7751 - precision: 0.6250 - recall: 0.0048 - f1_metric: 0.0041
Test Score: 0.670792281627655
Test Accuracy: 5.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.62      0.00      0.01      1048

    accuracy                           0.78      4650
   macro avg       0.70      0.50      0.44      4650
weighted avg       0.74      0.78      0.68      4650

[[3599    3]
 [1043    5]]
Finished training and evaluation
{&#39;precision&#39;: 0.6666666666666666, &#39;recall&#39;: 0.019230769230769232, &#39;F1&#39;: 0.037383177570093455, &#39;ERDE_5&#39;: 0.2464440413269907, &#39;ERDE_50&#39;: 0.2417159879058174, &#39;median_latency_tps&#39;: 16.0, &#39;median_penalty_tps&#39;: 0.05843335735063637, &#39;speed&#39;: 0.9415666426493636, &#39;latency_weighted_f1&#39;: 0.03519875299623789}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00031: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.7520 - tp: 15.0000 - fp: 2.0000 - tn: 3600.0000 - fn: 1033.0000 - accuracy: 0.7774 - precision: 0.8824 - recall: 0.0143 - f1_metric: 0.0145
Test Score: 0.7519775629043579
Test Accuracy: 15.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.78      1.00      0.87      3602
           1       0.88      0.01      0.03      1048

    accuracy                           0.78      4650
   macro avg       0.83      0.51      0.45      4650
weighted avg       0.80      0.78      0.68      4650

[[3600    2]
 [1033   15]]
Finished training and evaluation
{&#39;precision&#39;: 0.75, &#39;recall&#39;: 0.057692307692307696, &#39;F1&#39;: 0.10714285714285714, &#39;ERDE_5&#39;: 0.24701351728348284, &#39;ERDE_50&#39;: 0.23284095926317186, &#39;median_latency_tps&#39;: 15.5, &#39;median_penalty_tps&#39;: 0.05648958243015645, &#39;speed&#39;: 0.9435104175698436, &#39;latency_weighted_f1&#39;: 0.10109040188248324}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 14ms/step - loss: 0.5439 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5439128279685974
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 14ms/step - loss: 0.5439 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.5439128279685974
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 70.45164771203417
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6376811594202898, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5086705202312138, &#39;ERDE_5&#39;: 0.26023055220178204, &#39;ERDE_50&#39;: 0.15637487495040026, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48884242176890597}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 70.45164771203417} ************* 

************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': True, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-True,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3560   42]
 [ 822  226]]
Evaluating after getting time 269082.411772552
              precision    recall  f1-score   support

           0       0.81      0.99      0.89      3602
           1       0.84      0.22      0.34      1048

    accuracy                           0.81      4650
   macro avg       0.83      0.60      0.62      4650
weighted avg       0.82      0.81      0.77      4650

[[3560   42]
 [ 822  226]]
Evaluated with elapsed time 109.86907666397747
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7796610169491526, &#39;recall&#39;: 0.4423076923076923, &#39;F1&#39;: 0.5644171779141105, &#39;ERDE_5&#39;: 0.2532585676025228, &#39;ERDE_50&#39;: 0.14467190896948043, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5424160614106183}
Writing results to CSV file
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.2516272770513196, &#39;ERDE_50&#39;: 0.16420479631585844, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8484848484848485, &#39;recall&#39;: 0.2692307692307692, &#39;F1&#39;: 0.40875912408759124, &#39;ERDE_5&#39;: 0.2487572809841781, &#39;ERDE_50&#39;: 0.18257521139670063, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.3888479632549763}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.79      0.80      0.76      4650

[[3489  113]
 [ 799  249]]
Evaluating after getting time 269199.715664457
              precision    recall  f1-score   support

           0       0.81      0.97      0.88      3602
           1       0.69      0.24      0.35      1048

    accuracy                           0.80      4650
   macro avg       0.75      0.60      0.62      4650
weighted avg       0.79      0.80      0.76      4650

[[3489  113]
 [ 799  249]]
Evaluated with elapsed time 3.765068890992552
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL bayes
{&#39;precision&#39;: 0.6376811594202898, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5086705202312138, &#39;ERDE_5&#39;: 0.26023055220178204, &#39;ERDE_50&#39;: 0.15637487495040026, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48884242176890597}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
TRAINING AND EVALUATING DL MODEL cnn_model
STARTING ITERATION FOR DL MODEL cnn_model FOR 5 ITERATIONS
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 15ms/step - loss: 1.0158 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0157561302185059
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.7615 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.7614580988883972
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00029: early stopping
Evaluating
146/146 [==============================] - 5s 14ms/step - loss: 0.4701 - tp: 270.0000 - fp: 145.0000 - tn: 3457.0000 - fn: 778.0000 - accuracy: 0.8015 - precision: 0.6506 - recall: 0.2576 - f1_metric: 0.1963
Test Score: 0.47006726264953613
Test Accuracy: 270.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.82      0.96      0.88      3602
           1       0.65      0.26      0.37      1048

    accuracy                           0.80      4650
   macro avg       0.73      0.61      0.63      4650
weighted avg       0.78      0.80      0.77      4650

[[3457  145]
 [ 778  270]]
Finished training and evaluation
{&#39;precision&#39;: 0.6086956521739131, &#39;recall&#39;: 0.5384615384615384, &#39;F1&#39;: 0.5714285714285715, &#39;ERDE_5&#39;: 0.2665697818600151, &#39;ERDE_50&#39;: 0.13439967808460837, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.5491541491300049}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 3s 14ms/step - loss: 1.0127 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 1.0127419233322144
Test Accuracy: 0.0
146/146 [==============================] - 2s 11ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Starting training deep model cnn_model
Starting training with model_name=cnn_model and maxlen=1000 and batch size=32
Generating embeddings
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>Data size: 3926
Training with callback
Restoring model weights from the end of the best epoch.
Epoch 00011: early stopping
Evaluating
146/146 [==============================] - 4s 15ms/step - loss: 0.9733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9733266234397888
Test Accuracy: 0.0
146/146 [==============================] - 2s 12ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Finished training and evaluation
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Evaluating for elapsed time
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>146/146 [==============================] - 4s 15ms/step - loss: 0.9733 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 3602.0000 - fn: 1048.0000 - accuracy: 0.7746 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1_metric: 0.0000e+00
Test Score: 0.9733266234397888
Test Accuracy: 0.0
146/146 [==============================] - 2s 13ms/step
Entered here
              precision    recall  f1-score   support

           0       0.77      1.00      0.87      3602
           1       0.00      0.00      0.00      1048

    accuracy                           0.77      4650
   macro avg       0.39      0.50      0.44      4650
weighted avg       0.60      0.77      0.68      4650

[[3602    0]
 [1048    0]]
Evaluated with elapsed time 69.8003943329677
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL cnn_model
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr">
<pre>/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/ecampillo/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/usr/local/lib64/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/usr/local/lib64/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 1, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 1, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [2, 2, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [2, 2, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 1, 2]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 1, 2] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
{&#39;precision&#39;: 0, &#39;recall&#39;: 0, &#39;F1&#39;: 0, &#39;ERDE_5&#39;: 0.2458628841607565, &#39;ERDE_50&#39;: 0.2458628841607565, &#39;median_latency_tps&#39;: nan, &#39;median_penalty_tps&#39;: nan, &#39;speed&#39;: nan, &#39;latency_weighted_f1&#39;: nan}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [3, 3, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [3, 3, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [5, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [5, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.7872340425531915, &#39;recall&#39;: 0.3557692307692308, &#39;F1&#39;: 0.4900662251655629, &#39;ERDE_5&#39;: 0.251560667130266, &#39;ERDE_50&#39;: 0.16420479631585752, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.46905527211413056}
Writing results to CSV file
{&#39;precision&#39;: 0.8055555555555556, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.41428571428571426, &#39;ERDE_5&#39;: 0.2498995508576852, &#39;ERDE_50&#39;: 0.18137361746838462, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.3949112856750344}
Writing results to CSV file
{&#39;precision&#39;: 0.8076923076923077, &#39;recall&#39;: 0.20192307692307693, &#39;F1&#39;: 0.3230769230769231, &#39;ERDE_5&#39;: 0.24876050231574326, &#39;ERDE_50&#39;: 0.19912367475367557, &#39;median_latency_tps&#39;: 14.0, &#39;median_penalty_tps&#39;: 0.05065660333872746, &#39;speed&#39;: 0.9493433966612725, &#39;latency_weighted_f1&#39;: 0.30671094353671885}
Writing results to CSV file
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] with weights [1, 5, 1]
EVALUATING ENSEMBLE [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;] WITH WEIGHTS [1, 5, 1] FOR WINDOW SIZES 1, 2 AND 3
{&#39;precision&#39;: 0.6376811594202898, &#39;recall&#39;: 0.4230769230769231, &#39;F1&#39;: 0.5086705202312138, &#39;ERDE_5&#39;: 0.26023055220178204, &#39;ERDE_50&#39;: 0.15637487495040026, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.48884242176890597}
Writing results to CSV file
{&#39;precision&#39;: 0.6885245901639344, &#39;recall&#39;: 0.40384615384615385, &#39;F1&#39;: 0.5090909090909091, &#39;ERDE_5&#39;: 0.2568567558532196, &#39;ERDE_50&#39;: 0.1576155905415031, &#39;median_latency_tps&#39;: 12.5, &#39;median_penalty_tps&#39;: 0.044819781830275796, &#39;speed&#39;: 0.9551802181697242, &#39;latency_weighted_f1&#39;: 0.48627356561367785}
Writing results to CSV file
{&#39;precision&#39;: 0.7441860465116279, &#39;recall&#39;: 0.3076923076923077, &#39;F1&#39;: 0.43537414965986393, &#39;ERDE_5&#39;: 0.2522428460341353, &#39;ERDE_50&#39;: 0.1766063634178978, &#39;median_latency_tps&#39;: 13.5, &#39;median_penalty_tps&#39;: 0.04871123275121869, &#39;speed&#39;: 0.9512887672487813, &#39;latency_weighted_f1&#39;: 0.4141665381219184}
Writing results to CSV file
************ FINISHED EXPERIMENT {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: True, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: [1, 5, 1], &#39;model&#39;: [&#39;svm&#39;, &#39;bayes&#39;, &#39;cnn_model&#39;], &#39;eval_time&#39;: 69.8003943329677} ************* 

********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=50, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluating after getting time 272032.681546366
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluated with elapsed time 90.48136222996982
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25212059138981613, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 90.48136222996982}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 50, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-50,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluating after getting time 272337.48286638
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluated with elapsed time 123.7377168139792
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25212059138981613, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 50, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 123.7377168139792}: Negative values in data passed to MultinomialNB (input X)
*************************************
********** CALCULATING FEATURES FOR {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***********
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Calculating features for {'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Calculating-features-for-{'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>PREPARING DATA FOR PARAMS {&#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;}
Windowfying training users
[====================] 100%
Windowfying test users
[====================] 100%Data size: 3926

Finished windowfying
Featurizing calculate_feats=True, normalize=False, discretize=False, discretize_size=75, include_feats=[&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;]
Initialized numpy random and tensorflow random seed at 42
Data size: 3926, 3926
Data size: 4650, 4650
Calculating first prons
Calculating sentiment
Calculating NSSI words
Calculating first prons
Calculating sentiment
Calculating NSSI words
Scaling features
Training features shape: (3926, 8)
Test features shape: (4650, 8)
Is the combined the same from tfidf: False
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': True, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-True,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluating after getting time 272664.661957972
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluated with elapsed time 80.96493117202772
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25212059138981613, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: True, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 80.96493117202772}: Negative values in data passed to MultinomialNB (input X)
*************************************
************ STARTING EXPERIMENT {&#39;eval_window_size&#39;: 1, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;} ***************
</pre>
</div>
</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>



<div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-OutputArea-output " data-mime-type="text/markdown">
<h4 id="Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">Experiment {'eval_window_size': 1, 'maxlen': 1000, 'batch_size': 32, 'epochs': 100, 'patience': 10, 'iterations': 5, 'shuffle': False, 'include_feats': ['first_prons', 'sentiment', 'nssi'], 'feat_window_size': 10, 'max_size': 20, 'sample_weights_size': 20, 'oversample': False, 'include_new_data': False, 'tfidf_max_features': 50000, 'scale': True, 'normalize': False, 'discretize': False, 'discretize_size': 75, 'dis_strategy': 'quantile'}<a class="anchor-link" href="#Experiment-{'eval_window_size':-1,-'maxlen':-1000,-'batch_size':-32,-'epochs':-100,-'patience':-10,-'iterations':-5,-'shuffle':-False,-'include_feats':-['first_prons',-'sentiment',-'nssi'],-'feat_window_size':-10,-'max_size':-20,-'sample_weights_size':-20,-'oversample':-False,-'include_new_data':-False,-'tfidf_max_features':-50000,-'scale':-True,-'normalize':-False,-'discretize':-False,-'discretize_size':-75,-'dis_strategy':-'quantile'}">&#182;</a></h4>
</div>

</div>

<div class="jp-OutputArea-child">

    
    <div class="jp-OutputPrompt jp-OutputArea-prompt"></div>


<div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain">
<pre>TRAINING AND EVALUATING TRADITIONAL MODEL svm
Starting training traditional
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluating after getting time 272884.316134036
              precision    recall  f1-score   support

           0       0.80      0.99      0.89      3602
           1       0.81      0.17      0.28      1048

    accuracy                           0.80      4650
   macro avg       0.81      0.58      0.58      4650
weighted avg       0.80      0.80      0.75      4650

[[3561   41]
 [ 873  175]]
Evaluated with elapsed time 79.46023004403105
EVALUATING FOR WINDOW SIZES 1, 2 AND 3 MODEL svm
{&#39;precision&#39;: 0.7755102040816326, &#39;recall&#39;: 0.36538461538461536, &#39;F1&#39;: 0.4967320261437908, &#39;ERDE_5&#39;: 0.25212059138981613, &#39;ERDE_50&#39;: 0.16242196625477218, &#39;median_latency_tps&#39;: 11.0, &#39;median_penalty_tps&#39;: 0.03898023902249159, &#39;speed&#39;: 0.9610197609775084, &#39;latency_weighted_f1&#39;: 0.4773692930345793}
Writing results to CSV file
{&#39;precision&#39;: 0.7631578947368421, &#39;recall&#39;: 0.27884615384615385, &#39;F1&#39;: 0.4084507042253521, &#39;ERDE_5&#39;: 0.25105875301807423, &#39;ERDE_50&#39;: 0.18253608973391908, &#39;median_latency_tps&#39;: 12.0, &#39;median_penalty_tps&#39;: 0.042873701496841665, &#39;speed&#39;: 0.9571262985031583, &#39;latency_weighted_f1&#39;: 0.3909389106562196}
Writing results to CSV file
{&#39;precision&#39;: 0.7692307692307693, &#39;recall&#39;: 0.19230769230769232, &#39;F1&#39;: 0.3076923076923077, &#39;ERDE_5&#39;: 0.24933924769878996, &#39;ERDE_50&#39;: 0.20206897708029514, &#39;median_latency_tps&#39;: 13.0, &#39;median_penalty_tps&#39;: 0.046765862163709926, &#39;speed&#39;: 0.9532341378362901, &#39;latency_weighted_f1&#39;: 0.29330281164193545}
Writing results to CSV file
TRAINING AND EVALUATING TRADITIONAL MODEL bayes
Starting training traditional
*************************************
Error during experiment {&#39;eval_window_size&#39;: 3, &#39;maxlen&#39;: 1000, &#39;batch_size&#39;: 32, &#39;epochs&#39;: 100, &#39;patience&#39;: 10, &#39;iterations&#39;: 5, &#39;shuffle&#39;: False, &#39;include_feats&#39;: [&#39;first_prons&#39;, &#39;sentiment&#39;, &#39;nssi&#39;], &#39;feat_window_size&#39;: 10, &#39;max_size&#39;: 20, &#39;sample_weights_size&#39;: 20, &#39;oversample&#39;: False, &#39;include_new_data&#39;: False, &#39;tfidf_max_features&#39;: 50000, &#39;scale&#39;: True, &#39;normalize&#39;: False, &#39;discretize&#39;: False, &#39;discretize_size&#39;: 75, &#39;dis_strategy&#39;: &#39;quantile&#39;, &#39;weights&#39;: None, &#39;model&#39;: &#39;bayes&#39;, &#39;eval_time&#39;: 79.46023004403105}: Negative values in data passed to MultinomialNB (input X)
*************************************
</pre>
</div>
</div>

</div>

</div>

</div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs  ">
<div class="jp-Cell-inputWrapper">
<div class="jp-InputArea jp-Cell-inputArea">
<div class="jp-InputPrompt jp-InputArea-prompt">In&nbsp;[&nbsp;]:</div>
<div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline">
     <div class="CodeMirror cm-s-jupyter">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

     </div>
</div>
</div>
</div>

</div>
</body>







</html>
